<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Linux Sysadmin</title><link href="http://www.linuxsysadmin.tk/" rel="alternate"></link><link href="http://www.linuxsysadmin.tk/feeds/all.atom.xml" rel="self"></link><id>http://www.linuxsysadmin.tk/</id><updated>2016-01-04T10:00:00+01:00</updated><entry><title>Enjaulado de usuarios para uso de rsync</title><link href="http://www.linuxsysadmin.tk/2016/01/enjaulado-de-usuarios-para-uso-de-rsync.html" rel="alternate"></link><updated>2016-01-04T10:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2016-01-04:2016/01/enjaulado-de-usuarios-para-uso-de-rsync.html</id><summary type="html">&lt;p&gt;Todos nos hemos encontrado alguna vez con una web, sea en &lt;em&gt;HTML&lt;/em&gt; o en &lt;em&gt;PHP&lt;/em&gt;, que se compone de centenares o miles de ficheros, y que hay que ir actualizando cada vez que cambian unos pocos ficheros. En estos casos la capacidad incremental de la herramienta &lt;strong&gt;rsync&lt;/strong&gt; puede ayudarnos mucho.&lt;/p&gt;
&lt;p&gt;Sin embargo, la herramienta &lt;strong&gt;rsync&lt;/strong&gt; funciona por el puerto de &lt;em&gt;SSH&lt;/em&gt;, y dar acceso al mismo es un problema desde el punto de vista de la seguridad del sistema. Vamos a crear una jaula para los usuarios que lo necesiten, y vamos a limitar los comandos que puede utilizar, de forma que solo pueda hacer &lt;strong&gt;rsync&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Para poder continuar, necesitamos las 2 herramientas que se van a usar: &lt;strong&gt;rsync&lt;/strong&gt; y &lt;strong&gt;rssh&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# apt-get install rssh rsync
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
...
Se instalarán los siguientes paquetes NUEVOS:
  libpopt0 rssh rsync
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;3&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;505&lt;/span&gt; kB de archivos.
Se utilizarán &lt;span class="m"&gt;962&lt;/span&gt; kB de espacio de disco adicional después de esta operación.
...
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Preparación del sistema de enjaulado&lt;/h2&gt;
&lt;p&gt;Como decisión de diseño, he decidido que voy a enjaular todos los usuarios que pertenezcan a un grupo, al que llamaremos &lt;em&gt;restricted&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# groupadd restricted
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora vamos a configurar el demonio &lt;strong&gt;SSH&lt;/strong&gt; para que todos los usuarios del grupo &lt;em&gt;restricted&lt;/em&gt; queden enjaulados en &lt;em&gt;/srv/jails/&lt;/em&gt;, en una carpeta por usuario. La directiva &lt;em&gt;X11Forwarding&lt;/em&gt; y &lt;em&gt;AllowTcpForwarding&lt;/em&gt; son restricciones adicionales y no son necesarias.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# cat /etc/ssh/sshd_config 
...
Match group restricted
    ChrootDirectory /srv/jails/%u
    X11Forwarding no
    AllowTcpForwarding no
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y reiniciamos el demonio para que se apliquen las modificaciones en la configuración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# service ssh restart
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Creando una jaula para el primer usuario&lt;/h2&gt;
&lt;p&gt;Para tener un usuario enjaulado, necesitamos un usuario, en este caso, el usuario &lt;em&gt;web&lt;/em&gt;. Le vamos a poner &lt;em&gt;rssh&lt;/em&gt; como shell, su carpeta personal como &lt;em&gt;/&lt;/em&gt; y le asignamos el grupo &lt;em&gt;restricted&lt;/em&gt; para que quede enjaulado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# useradd -d / -s /usr/bin/rssh -G restricted web
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para que el usuario &lt;em&gt;web&lt;/em&gt; pueda entrar en esta máquina, necesita una contraseña. Alternativamente, podríamos haber montado una autenticación por claves &lt;em&gt;SSH&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# passwd web
Introduzca la nueva contraseña de UNIX: 
Vuelva a escribir la nueva contraseña de UNIX: 
passwd: contraseña actualizada correctamente
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y ahora vamos a crearle una estructura de carpetas muy básica en donde deberá estar su jaula. Puesto que se trata del usuario &lt;em&gt;web&lt;/em&gt;, la carpeta de la jaula (la que el usuario verá como &lt;em&gt;/&lt;/em&gt;) va a ser &lt;em&gt;/srv/jails/web/&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;IMPORTANTE&lt;/strong&gt;: Esta carpeta y todas las de la ruta deben perteneces al usuario &lt;em&gt;root&lt;/em&gt; y tener permisos de escritura solo por el &lt;em&gt;owner&lt;/em&gt;; de otra manera, el &lt;em&gt;SSH&lt;/em&gt; falla al enjaular.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# mkdir -p /srv/jails/web/&lt;span class="o"&gt;{&lt;/span&gt;usr/bin,etc,lib&lt;span class="o"&gt;}&lt;/span&gt;
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para limitar que el usuario solo pueda hacer &lt;em&gt;rsync&lt;/em&gt; vamos a necesitar la ayuda de &lt;em&gt;rssh&lt;/em&gt;; así pues, vamos a poner ambos binarios en la jaula.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# cp /usr/bin/rssh /srv/jails/web/usr/bin/
root@webserver:~# cp /usr/bin/rsync /srv/jails/web/usr/bin/
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Estos dos comandos son binarios &lt;em&gt;linkados&lt;/em&gt; dinámicamente que necesitan librerías. Vamos a buscarlos con el comando &lt;strong&gt;ldd&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# ldd /usr/bin/rssh 
    linux-gate.so.1 &lt;span class="o"&gt;(&lt;/span&gt;0xb7789000&lt;span class="o"&gt;)&lt;/span&gt;
    libc.so.6 &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; /lib/i386-linux-gnu/libc.so.6 &lt;span class="o"&gt;(&lt;/span&gt;0xb760a000&lt;span class="o"&gt;)&lt;/span&gt;
    /lib/ld-linux.so.2 &lt;span class="o"&gt;(&lt;/span&gt;0xb778c000&lt;span class="o"&gt;)&lt;/span&gt;
root@webserver:~# ldd /usr/bin/rsync 
    linux-gate.so.1 &lt;span class="o"&gt;(&lt;/span&gt;0xb7741000&lt;span class="o"&gt;)&lt;/span&gt;
    libattr.so.1 &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; /lib/i386-linux-gnu/libattr.so.1 &lt;span class="o"&gt;(&lt;/span&gt;0xb76a3000&lt;span class="o"&gt;)&lt;/span&gt;
    libacl.so.1 &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; /lib/i386-linux-gnu/libacl.so.1 &lt;span class="o"&gt;(&lt;/span&gt;0xb7699000&lt;span class="o"&gt;)&lt;/span&gt;
    libpopt.so.0 &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; /lib/i386-linux-gnu/libpopt.so.0 &lt;span class="o"&gt;(&lt;/span&gt;0xb768a000&lt;span class="o"&gt;)&lt;/span&gt;
    libc.so.6 &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; /lib/i386-linux-gnu/libc.so.6 &lt;span class="o"&gt;(&lt;/span&gt;0xb7519000&lt;span class="o"&gt;)&lt;/span&gt;
    /lib/ld-linux.so.2 &lt;span class="o"&gt;(&lt;/span&gt;0xb7744000&lt;span class="o"&gt;)&lt;/span&gt;
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y las copiamos en la carpeta &lt;em&gt;lib&lt;/em&gt; de la jaula.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# cp /lib/ld-linux.so.2 /srv/jails/web/lib/
root@webserver:~# cp /lib/i386-linux-gnu/libc.so.6 /srv/jails/web/lib/
root@webserver:~# cp /lib/i386-linux-gnu/libattr.so.1 /srv/jails/web/lib/
root@webserver:~# cp /lib/i386-linux-gnu/libacl.so.1 /srv/jails/web/lib/
root@webserver:~# cp /lib/i386-linux-gnu/libpopt.so.0 /srv/jails/web/lib/
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Voy a quitar los permisos de ejecución de la librería &lt;em&gt;libc&lt;/em&gt; porque no lo necesita.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# chmod &lt;span class="m"&gt;644&lt;/span&gt; /srv/jails/web/lib/libc.so.6 
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora que tenemos las librerías en la jaula, volvemos a mirar que otras librerías puedan necesitar con &lt;strong&gt;ldd&lt;/strong&gt;, para evitar dejarnos ninguna.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# ldd /srv/jails/web/lib/*
/srv/jails/web/lib/ld-linux.so.2:
    statically linked
/srv/jails/web/lib/libacl.so.1:
    linux-gate.so.1 &lt;span class="o"&gt;(&lt;/span&gt;0xb77b3000&lt;span class="o"&gt;)&lt;/span&gt;
    libattr.so.1 &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; /lib/i386-linux-gnu/libattr.so.1 &lt;span class="o"&gt;(&lt;/span&gt;0xb779e000&lt;span class="o"&gt;)&lt;/span&gt;
    libc.so.6 &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; /lib/i386-linux-gnu/libc.so.6 &lt;span class="o"&gt;(&lt;/span&gt;0xb762d000&lt;span class="o"&gt;)&lt;/span&gt;
    /lib/ld-linux.so.2 &lt;span class="o"&gt;(&lt;/span&gt;0xb77b6000&lt;span class="o"&gt;)&lt;/span&gt;
/srv/jails/web/lib/libattr.so.1:
    linux-gate.so.1 &lt;span class="o"&gt;(&lt;/span&gt;0xb7756000&lt;span class="o"&gt;)&lt;/span&gt;
    libc.so.6 &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; /lib/i386-linux-gnu/libc.so.6 &lt;span class="o"&gt;(&lt;/span&gt;0xb75da000&lt;span class="o"&gt;)&lt;/span&gt;
    /lib/ld-linux.so.2 &lt;span class="o"&gt;(&lt;/span&gt;0xb7759000&lt;span class="o"&gt;)&lt;/span&gt;
/srv/jails/web/lib/libc.so.6:
    /lib/ld-linux.so.2 &lt;span class="o"&gt;(&lt;/span&gt;0xb779f000&lt;span class="o"&gt;)&lt;/span&gt;
    linux-gate.so.1 &lt;span class="o"&gt;(&lt;/span&gt;0xb779c000&lt;span class="o"&gt;)&lt;/span&gt;
/srv/jails/web/lib/libpopt.so.0:
    linux-gate.so.1 &lt;span class="o"&gt;(&lt;/span&gt;0xb7782000&lt;span class="o"&gt;)&lt;/span&gt;
    libc.so.6 &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; /lib/i386-linux-gnu/libc.so.6 &lt;span class="o"&gt;(&lt;/span&gt;0xb75fe000&lt;span class="o"&gt;)&lt;/span&gt;
    /lib/ld-linux.so.2 &lt;span class="o"&gt;(&lt;/span&gt;0xb7785000&lt;span class="o"&gt;)&lt;/span&gt;
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y como no han entrado de nuevas, hemos acabado con esto. Ahora vamos a copiar la configuración de &lt;strong&gt;rssh&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# cp /etc/rssh.conf /srv/jails/web/etc/
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a añadir la directiva &lt;em&gt;allowrsync&lt;/em&gt; ya que, por defecto, no se permite nada:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ANTES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# grep allowrsync /srv/jails/web/etc/rssh.conf 
&lt;span class="c"&gt;#allowrsync&lt;/span&gt;
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;DESPUES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# grep allowrsync /srv/jails/web/etc/rssh.conf 
allowrsync
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como estamos esperando que el usuario &lt;em&gt;web&lt;/em&gt; deje sus cosas en una carpeta &lt;em&gt;www&lt;/em&gt;, vamos a crearla, ya que va a ser la única en la que pueda copiar sus cosas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# mkdir /srv/jails/web/www
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y le damos permisos necesarios para que escriba en ella; por ejemplo, le damos la propiedad de la carpeta.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# chown web:web /srv/jails/web/www/
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto queda completa la jaula. Como demostración, muestro la salida del comando &lt;strong&gt;tree&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# tree /srv/jails/web/
/srv/jails/web/
├── etc
│   └── rssh.conf
├── lib
│   ├── ld-linux.so.2
│   ├── libacl.so.1
│   ├── libattr.so.1
│   ├── libc.so.6
│   └── libpopt.so.0
├── usr
│   └── bin
│       ├── rssh
│       └── rsync
└── www

&lt;span class="m"&gt;5&lt;/span&gt; directories, &lt;span class="m"&gt;8&lt;/span&gt; files
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Uso de la jaula&lt;/h2&gt;
&lt;p&gt;Supongamos que tenemos un proyecto web en una máquina &lt;em&gt;developer&lt;/em&gt;, por ejemplo:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@developer:~&lt;span class="nv"&gt;$ &lt;/span&gt;tree web/
web/
└── index.html

&lt;span class="m"&gt;0&lt;/span&gt; directories, &lt;span class="m"&gt;1&lt;/span&gt; file
gerard@developer:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Intentamos entrar por &lt;em&gt;SSH&lt;/em&gt; y vemos que falla:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@developer:~&lt;span class="nv"&gt;$ &lt;/span&gt;ssh web@10.0.0.2
web@10.0.0.2&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 

The programs included with the Debian GNU/Linux system are free software&lt;span class="p"&gt;;&lt;/span&gt;
the exact distribution terms &lt;span class="k"&gt;for&lt;/span&gt; each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
Last login: Wed Dec &lt;span class="m"&gt;30&lt;/span&gt; 21:12:44 &lt;span class="m"&gt;2015&lt;/span&gt; from 10.0.0.3

This account is restricted by rssh.
Allowed commands: rsync 

If you believe this is in error, please contact your system administrator.

Connection to 10.0.0.2 closed.
gerard@developer:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a usar &lt;em&gt;rsync&lt;/em&gt; para sincronizar este proyecto con el servidor que acabamos de montar. Para eso, la máquina cliente necesita tener instalado el paquete &lt;strong&gt;rsync&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@developer:~&lt;span class="nv"&gt;$ &lt;/span&gt;rsync -rvzc --delete web/ web@10.0.0.2:/www
web@10.0.0.2&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
sending incremental file list
index.html

sent &lt;span class="m"&gt;139&lt;/span&gt; bytes  received &lt;span class="m"&gt;35&lt;/span&gt; bytes  49.71 bytes/sec
total size is &lt;span class="m"&gt;12&lt;/span&gt;  speedup is 0.07
gerard@developer:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Si repetimos el comando, vemos que la lista de ficheros no incluye el &lt;em&gt;index.html&lt;/em&gt;, porque no ha cambiado respecto a lo que tenemos en el servidor, así que no lo manda.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@developer:~&lt;span class="nv"&gt;$ &lt;/span&gt;rsync -rvzc --delete web/ web@10.0.0.2:/www
web@10.0.0.2&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
sending incremental file list

sent &lt;span class="m"&gt;83&lt;/span&gt; bytes  received &lt;span class="m"&gt;12&lt;/span&gt; bytes  7.60 bytes/sec
total size is &lt;span class="m"&gt;12&lt;/span&gt;  speedup is 0.13
gerard@developer:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;los &lt;em&gt;flags&lt;/em&gt; elegidos son &lt;strong&gt;-r&lt;/strong&gt; (recursivo), &lt;strong&gt;-v&lt;/strong&gt; (verbose), &lt;strong&gt;-z&lt;/strong&gt; (comprimido), &lt;strong&gt;-c&lt;/strong&gt; (diferenciar por &lt;em&gt;checksum&lt;/em&gt;) y &lt;strong&gt;--delete&lt;/strong&gt; (para borrar fichero que estén en el servidor y no deban).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;IMPORTANTE&lt;/strong&gt;: la carpeta origen acaba con &lt;em&gt;/&lt;/em&gt;. Esa es la diferencia entre copiar el contenido de la carpeta y copiar la carpeta misma.&lt;/p&gt;
&lt;p&gt;Analizamos el resultado y vemos que lo hemos copiado en &lt;em&gt;/www/&lt;/em&gt;, siempre desde el punto de vista de la jaula.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@webserver:~# ls /www
ls: no se puede acceder a /www: No existe el fichero o el directorio
root@webserver:~# tree /srv/jails/web/
/srv/jails/web/
├── etc
│   └── rssh.conf
├── lib
│   ├── ld-linux.so.2
│   ├── libacl.so.1
│   ├── libattr.so.1
│   ├── libc.so.6
│   └── libpopt.so.0
├── usr
│   └── bin
│       ├── rssh
│       └── rsync
└── www
    └── index.html

&lt;span class="m"&gt;5&lt;/span&gt; directories, &lt;span class="m"&gt;9&lt;/span&gt; files
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto está todo hecho. Solo falta instalar el servidor web, pero eso lo dejo pendiente.&lt;/p&gt;</summary><category term="linux"></category><category term="rsync"></category><category term="rssh"></category><category term="ssh"></category><category term="ldd"></category><category term="jaula"></category></entry><entry><title>Empaquetando ficheros .deb</title><link href="http://www.linuxsysadmin.tk/2015/12/empaquetando-ficheros-punto-deb.html" rel="alternate"></link><updated>2015-12-28T10:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-12-28:2015/12/empaquetando-ficheros-punto-deb.html</id><summary type="html">&lt;p&gt;Una de las grandes ventajas de &lt;em&gt;linux&lt;/em&gt; es su sistema de paquetes. Con ellos es posible instalar de forma fácil un paquete de forma fácil y confiable. Hoy vamos a hacer un paquete &lt;em&gt;.deb&lt;/em&gt; como ejemplo que instale un &lt;em&gt;script&lt;/em&gt; cualquiera en la carpeta &lt;em&gt;/usr/bin/&lt;/em&gt; para su uso cotidiano.&lt;/p&gt;
&lt;p&gt;Por limpieza, vamos a crear una carpeta temporal para hacer el empaquetado, desde donde vamos a ejecutar todo el resto del procedimiento.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@packager:~# mkdir workspace
root@packager:~# &lt;span class="nb"&gt;cd &lt;/span&gt;workspace/
root@packager:~/workspace# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Preparación de la estructura del paquete&lt;/h2&gt;
&lt;p&gt;Vamos a poner el &lt;em&gt;script&lt;/em&gt; que queramos empaquetar, respetando al estructura que tendrá una vez se instale el paquete. También le damos los permisos que va a tener una vez instalado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@packager:~/workspace# mkdir -p usr/bin
root@packager:~/workspace# cat usr/bin/welcome
&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Hello world!&amp;#39;&lt;/span&gt;
root@packager:~/workspace# chmod &lt;span class="m"&gt;755&lt;/span&gt; usr/bin/welcome
root@packager:~/workspace# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Empaquetado de la carpeta de trabajo&lt;/h2&gt;
&lt;p&gt;Antes de empaquetar de acuerdo a las políticas de los paquetes &lt;em&gt;.deb&lt;/em&gt;, sea en &lt;em&gt;Debian&lt;/em&gt; o en &lt;em&gt;Ubuntu&lt;/em&gt;, se requiere de una carpeta &lt;strong&gt;DEBIAN&lt;/strong&gt; con un fichero &lt;strong&gt;control&lt;/strong&gt;, que va a contener los metadatos del paquete.&lt;/p&gt;
&lt;p&gt;Para este fichero nos podemos guiar por la &lt;a href="https://www.debian.org/doc/debian-policy/ch-controlfields.html"&gt;documentación oficial&lt;/a&gt;. Como vamos a hacer un paquete mínimo, vamos a poner solamente los campos obligatorios y uno de los opcionales, que indicarán las necesidades de nuestro script:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Obligatorios&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;Package&lt;/li&gt;
&lt;li&gt;Version&lt;/li&gt;
&lt;li&gt;Architecture compilado los binarios&lt;/li&gt;
&lt;li&gt;Maintainer&lt;/li&gt;
&lt;li&gt;Description&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Opcionales&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;Depends&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Para que el &lt;em&gt;script&lt;/em&gt; pueda funcionar, hay que localizar todo aquello que pueda necesitar, y añadirlo al paquete o declarar los paquetes de los que dependa, para que se puedan instalar automáticamente si no estuvieran en el sistema destino.&lt;/p&gt;
&lt;p&gt;Concretamente, este &lt;em&gt;script&lt;/em&gt; necesita dos comandos para funcionar: &lt;strong&gt;bash&lt;/strong&gt; y &lt;strong&gt;echo&lt;/strong&gt;. Vamos a localizarlos a ver de que paquete provienen. La idea es que nuestro paquete va a necesitar todos los paquetes que contengan los comandos necesarios, sin necesidad de incorporarlos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@packager:~/workspace# which bash
/bin/bash
root@packager:~/workspace# dpkg -S /bin/bash
bash: /bin/bash
root@packager:~/workspace# which &lt;span class="nb"&gt;echo&lt;/span&gt;
/bin/echo
root@packager:~/workspace# dpkg -S /bin/echo 
coreutils: /bin/echo
root@packager:~/workspace# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;De ahí deducimos que necesitamos los paquetes &lt;strong&gt;bash&lt;/strong&gt; y &lt;strong&gt;coreutils&lt;/strong&gt;, que aunque suelen venir de serie, vale la pena declararlos por si no fuera el caso. Esto es lo que va en el campo &lt;strong&gt;Depends&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Reuniendo estos datos, podemos crear el fichero &lt;strong&gt;control&lt;/strong&gt;, por ejemplo, como este:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@packager:~/workspace# mkdir -p DEBIAN
root@packager:~/workspace# cat DEBIAN/control 
Package: welcome
Version: 1.0-1
Architecture: all
Maintainer: Linux Sysadmin
Description: A fancy shell script
 To demonstrate how to package a .deb file
Depends: bash, coreutils
root@packager:~/workspace# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Adicionalmente, la carpeta &lt;strong&gt;DEBIAN&lt;/strong&gt; puede contener otros &lt;em&gt;scripts&lt;/em&gt;, como por ejemplo, &lt;strong&gt;preinst&lt;/strong&gt;, &lt;strong&gt;postinst&lt;/strong&gt;, &lt;strong&gt;prerm&lt;/strong&gt; y &lt;strong&gt;postrm&lt;/strong&gt;, que podrían, por ejemplo, crear los usuarios necesarios.&lt;/p&gt;
&lt;p&gt;Como último paso, vamos a invocar el comando &lt;strong&gt;dpkg-deb&lt;/strong&gt; para empaquetar la carpeta de trabajo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@packager:~/workspace# &lt;span class="nb"&gt;cd&lt;/span&gt; ..
root@packager:~# dpkg-deb --build workspace/ welcome_1.0-1_all.deb
dpkg-deb: construyendo el paquete &lt;span class="sb"&gt;`&lt;/span&gt;welcome&lt;span class="s1"&gt;&amp;#39; en `welcome_1.0-1_all.deb&amp;#39;&lt;/span&gt;.
root@packager:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comprobación de que el paquete funciona&lt;/h2&gt;
&lt;p&gt;Vamos a comprobar que el paquete no está instalado, por ejemplo buscando el &lt;em&gt;script&lt;/em&gt; que hemos empaquetado:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@packager:~# which welcome
root@packager:~# welcome 
bash: /usr/bin/welcome: No existe el fichero o el directorio
root@packager:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Efectivamente, no lo está; ahora se trata de invocar &lt;strong&gt;dpkg&lt;/strong&gt; para instalar nuestro paquete.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@packager:~# dpkg -i welcome_1.0-1_all.deb 
Seleccionando el paquete welcome previamente no seleccionado.
&lt;span class="o"&gt;(&lt;/span&gt;Leyendo la base de datos ... &lt;span class="m"&gt;9984&lt;/span&gt; ficheros o directorios instalados actualmente.&lt;span class="o"&gt;)&lt;/span&gt;
Preparando para desempaquetar welcome_1.0-1_all.deb ...
Desempaquetando welcome &lt;span class="o"&gt;(&lt;/span&gt;1.0-1&lt;span class="o"&gt;)&lt;/span&gt; ...
Configurando welcome &lt;span class="o"&gt;(&lt;/span&gt;1.0-1&lt;span class="o"&gt;)&lt;/span&gt; ...
root@packager:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y finalmente, verificamos que tenemos nuestro &lt;em&gt;script&lt;/em&gt; en &lt;em&gt;/usr/bin/&lt;/em&gt; como esperábamos:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@packager:~# which welcome
/usr/bin/welcome
root@packager:~# welcome
Hello world!
root@packager:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto tenemos nuestro paquete que podemos poner a buen recaudo.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="ubuntu"></category><category term="paquete"></category><category term=".deb"></category></entry><entry><title>Utilizando apt-cacher-ng para agilizar la instalación de paquetes</title><link href="http://www.linuxsysadmin.tk/2015/12/utilizando-apt-cacher-ng-para-agilizar-la-instalacion-de-paquetes.html" rel="alternate"></link><updated>2015-12-21T10:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-12-21:2015/12/utilizando-apt-cacher-ng-para-agilizar-la-instalacion-de-paquetes.html</id><summary type="html">&lt;p&gt;Hace tiempo veo que tras usar muchas maquinas virtuales &lt;em&gt;Debian&lt;/em&gt; para el uso diario y para las demostraciones de este blog, el ancho de banda usado para bajar los paquetes se dispara. La mayoría de veces se trata de los mismos paquetes, para instalar las mismas aplicaciones, servicios o actualizaciones.&lt;/p&gt;
&lt;p&gt;En el artículo de hoy, voy a enseñar como usar un &lt;em&gt;proxy&lt;/em&gt; con una &lt;em&gt;caché&lt;/em&gt; para &lt;em&gt;apt-get&lt;/em&gt;, llamado &lt;strong&gt;apt-cacher-ng&lt;/strong&gt;, de forma que los paquetes son descargados por la primera máquina que los pida, guardados en un servidor local y aprovechados por el resto de máquinas.&lt;/p&gt;
&lt;h2&gt;Preparación de las máquinas&lt;/h2&gt;
&lt;p&gt;Partimos de la máquina habitual, llamada &lt;strong&gt;aptcacher&lt;/strong&gt;, siendo esta un contenedor LXC con una &lt;em&gt;Debian Jessie&lt;/em&gt; básica, aunque esto se podría haber puesto en una &lt;em&gt;Ubuntu&lt;/em&gt; o cualquier otra distribución que funcione con paquetes &lt;em&gt;.deb&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Otras máquinas que vamos a usar son unas máquinas cliente en donde vamos a instalar paquetes cualesquiera para demostrar el funcionamiento, llamadas &lt;strong&gt;client1&lt;/strong&gt; y &lt;strong&gt;client2&lt;/strong&gt;; estos clientes están en la misma red que la máquina &lt;strong&gt;aptcacher&lt;/strong&gt; y tienen conectividad con ella por el puerto &lt;em&gt;TCP&lt;/em&gt; 3142.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-ls -f
NAME       STATE    IPV4      IPV6  AUTOSTART  
---------------------------------------------
aptcacher  RUNNING  10.0.0.2  -     YES        
client1    RUNNING  10.0.0.3  -     YES        
client2    RUNNING  10.0.0.4  -     YES        
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Empezamos instalando el servicio &lt;strong&gt;apt-cacher-ng&lt;/strong&gt; en la máquina servidor &lt;strong&gt;aptcacher&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@aptcacher:~# apt-get install apt-cacher-ng
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
...  
Se instalarán los siguientes paquetes NUEVOS:
  apt-cacher-ng ed
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;2&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;500&lt;/span&gt; kB de archivos.
Se utilizarán 1.168 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@aptcacher:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Las configuraciones que vienen por defecto son bastante adecuadas y no tuve que efectuar ningún cambio.&lt;/p&gt;
&lt;p&gt;Por otra parte, hay que configurar las máquinas que se quieran beneficiar de este servidor, añadiendo una línea de configuración en su &lt;strong&gt;apt-get&lt;/strong&gt;, por ejemplo, poniendo un fichero adicional en &lt;em&gt;/etc/apt/apt.conf.d/&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@aptcacher:~# cat /etc/apt/apt.conf.d/02proxy 
Acquire::http &lt;span class="o"&gt;{&lt;/span&gt; Proxy &lt;span class="s2"&gt;&amp;quot;http://10.0.0.2:3142&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
root@aptcacher:~# 

root@client1:~# cat /etc/apt/apt.conf.d/02proxy 
Acquire::http &lt;span class="o"&gt;{&lt;/span&gt; Proxy &lt;span class="s2"&gt;&amp;quot;http://10.0.0.2:3142&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
root@client1:~# 

root@client2:~# cat /etc/apt/apt.conf.d/02proxy 
Acquire::http &lt;span class="o"&gt;{&lt;/span&gt; Proxy &lt;span class="s2"&gt;&amp;quot;http://10.0.0.2:3142&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
root@client2:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto queda montado todo el sistema.&lt;/p&gt;
&lt;h2&gt;Funcionamiento de la caché&lt;/h2&gt;
&lt;p&gt;El funcionamiento es muy simple: basta con instalar en un cliente un paquete, por ejemplo, &lt;em&gt;python&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client1:~# apt-get install python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
...  
Se instalarán los siguientes paquetes NUEVOS:
  file libexpat1 libffi6 libmagic1 libpython-stdlib libpython2.7-minimal
  libpython2.7-stdlib libsqlite3-0 mime-support python python-minimal
  python2.7 python2.7-minimal
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;13&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar 5.010 kB de archivos.
Se utilizarán 21,3 MB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
Descargados 5.010 kB en 15s &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;327&lt;/span&gt; kB/s&lt;span class="o"&gt;)&lt;/span&gt;                                        
...
root@client1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como estos paquetes no están en la &lt;em&gt;caché&lt;/em&gt; del servidor, se han descargado de internet en 15 segundos, de acuerdo a la velocidad de mi conexión de internet y de la velocidad de respuesta de los repositorios elegidos.&lt;/p&gt;
&lt;p&gt;Si revisamos la página de estadísticas de &lt;strong&gt;apt-cacher-ng&lt;/strong&gt;, disponible en &lt;em&gt;http://aptcacher:3142/acng-report.html&lt;/em&gt; podemos ver que se han descargado 4,78mb en 13 paquetes; todos son &lt;strong&gt;miss&lt;/strong&gt; de la cache, es decir, se han ido a buscar al repositorio oficial.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Estadísticas web de apt-cacher" src="http://www.linuxsysadmin.tk/images/apt-cacher-ng-1.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Ahora vamos a instalar &lt;em&gt;python&lt;/em&gt; en otro de los clientes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client2:~# apt-get install python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
...
Se instalarán los siguientes paquetes NUEVOS:
  file libexpat1 libffi6 libmagic1 libpython-stdlib libpython2.7-minimal
  libpython2.7-stdlib libsqlite3-0 mime-support python python-minimal
  python2.7 python2.7-minimal
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;13&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar 5.010 kB de archivos.
Se utilizarán 21,3 MB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
Descargados 5.010 kB en 1s &lt;span class="o"&gt;(&lt;/span&gt;3.902 kB/s&lt;span class="o"&gt;)&lt;/span&gt;
root@client2:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hemos elegido el paquete &lt;em&gt;python&lt;/em&gt; para asegurar que ambas máquinas instalan lo mismo; como se puede ver, se ha descargado la misma cantidad de datos, pero en vez de los 15 segundos anteriores, ahora se ha tardado 1 segundo. Eso es porque los paquetes solicitados estaban en el &lt;em&gt;proxy&lt;/em&gt;, es decir, en el servidor &lt;strong&gt;aptcacher&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Podemos ver en la misma página de administración el resultado: ahora hay 13 &lt;strong&gt;hits&lt;/strong&gt; adicionales, ya que los paquetes solicitados estaban en local.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Estadísticas web de apt-cacher" src="http://www.linuxsysadmin.tk/images/apt-cacher-ng-2.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;De esta forma, si tenemos un elevado número de máquinas del mismo tipo, solo consumiremos el ancho de banda necesario para traerlos de internet &lt;strong&gt;una sola vez&lt;/strong&gt;.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="apt-cacher-ng"></category><category term="cache"></category></entry><entry><title>Construyendo un RAID 10 en linux</title><link href="http://www.linuxsysadmin.tk/2015/12/construyendo-un-raid-10-en-linux.html" rel="alternate"></link><updated>2015-12-17T23:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-12-17:2015/12/construyendo-un-raid-10-en-linux.html</id><summary type="html">&lt;p&gt;El otro día estaba habilitando un servidor de &lt;em&gt;mongodb&lt;/em&gt; para un entorno de producción. Como me interesaba mejorar el rendimiento de los accesos a disco y no disponía de discos SSD con una durabilidad aceptable, me propuse montar un &lt;em&gt;array de discos&lt;/em&gt; en configuración de &lt;strong&gt;RAID 10&lt;/strong&gt;, como se recomienda.&lt;/p&gt;
&lt;p&gt;Para este tutorial vamos a tener una máquina virtual (es una &lt;em&gt;Debian&lt;/em&gt;, pero vale cualquier otra distribución) con 5 discos, 1 de sistema y otros 4 para usar en la configuración &lt;strong&gt;RAID 10&lt;/strong&gt;, cada uno con 8gb, a efecto de demostración.&lt;/p&gt;
&lt;p&gt;En este caso, el sistema operativo estaba en &lt;em&gt;/dev/sda&lt;/em&gt; y sus particiones, mientras que los discos para los datos de &lt;em&gt;mongodb&lt;/em&gt; fueron &lt;em&gt;/dev/sdb&lt;/em&gt;, &lt;em&gt;/dev/sdc&lt;/em&gt;, &lt;em&gt;/dev/sdd&lt;/em&gt;, &lt;em&gt;/dev/sde&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# ls /dev/sd* -1
/dev/sda
/dev/sda1
/dev/sdb
/dev/sdc
/dev/sdd
/dev/sde
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Creación del dispositivo RAID 10&lt;/h2&gt;
&lt;p&gt;Empezamos instalando el controlador de &lt;strong&gt;RAID&lt;/strong&gt; por software:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# apt-get install mdadm
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
..
Se instalarán los siguientes paquetes NUEVOS:
  bsd-mailx exim4-base exim4-config exim4-daemon-light liblockfile-bin
  liblockfile1 mdadm psmisc
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;8&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
...
update-initramfs: Generating /boot/initrd.img-3.16.0-4-586
W: mdadm: /etc/mdadm/mdadm.conf defines no arrays.
W: mdadm: no arrays defined in configuration file.
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Con las herramientas instaladas, procedemos a crear un &lt;em&gt;/dev/md0&lt;/em&gt; que será nuestro &lt;strong&gt;disco RAID&lt;/strong&gt;, indicando el nivel &lt;strong&gt;RAID 10&lt;/strong&gt; y los 4 discos reales que van a formarlo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mdadm -v --create /dev/md0 --level&lt;span class="o"&gt;=&lt;/span&gt;raid10 --raid-devices&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt; /dev/sdb /dev/sdc /dev/sdd /dev/sde
mdadm: layout defaults to n2
mdadm: layout defaults to n2
mdadm: chunk size defaults to 512K
mdadm: size &lt;span class="nb"&gt;set &lt;/span&gt;to 8380416K
mdadm: Defaulting to version 1.2 metadata
mdadm: array /dev/md0 started.
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para que ese array de discos sea reconocido en cada inicio del sistema, hay que añadir en &lt;em&gt;/etc/mdadm/mdadm.conf&lt;/em&gt; la información relacionada al array, de la misma forma que la tengamos en este momento.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mdadm --detail --scan --verbose &amp;gt;&amp;gt; /etc/mdadm/mdadm.conf
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y ya tenemos nuestro dispositivo &lt;strong&gt;RAID 10&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Preparación del dispositivo&lt;/h2&gt;
&lt;p&gt;Ahora disponemos de un &lt;strong&gt;RAID 10&lt;/strong&gt; de 4 discos de 8gb, que corresponden a una capacidad total de 16gb utilizables, como el dispositivo &lt;em&gt;/dev/md0&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Este dispositivo es transparente para nosotros y no es diferente de cualquier otro dispositivo de bloques, con lo que se puede particionar, formatear e incluso actuar como un &lt;em&gt;physical volume&lt;/em&gt; en caso de usar &lt;strong&gt;LVM&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Para esta demostración, se creará una única partición que ocupe todo el disco y que será montada en &lt;em&gt;/data&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Así pues, sin mas preámbulo la particionamos; en mi caso lo hice con &lt;em&gt;cfdisk&lt;/em&gt;. Este es el resultado:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# fdisk -l /dev/md0

Disco /dev/md0: &lt;span class="m"&gt;16&lt;/span&gt; GiB, &lt;span class="m"&gt;17163091968&lt;/span&gt; bytes, &lt;span class="m"&gt;33521664&lt;/span&gt; sectores
Unidades: sectores de &lt;span class="m"&gt;1&lt;/span&gt; * &lt;span class="nv"&gt;512&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;512&lt;/span&gt; bytes
Tamaño de sector &lt;span class="o"&gt;(&lt;/span&gt;lógico/físico&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;512&lt;/span&gt; bytes / &lt;span class="m"&gt;512&lt;/span&gt; bytes
Tamaño de E/S &lt;span class="o"&gt;(&lt;/span&gt;mínimo/óptimo&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;524288&lt;/span&gt; bytes / &lt;span class="m"&gt;1048576&lt;/span&gt; bytes
Tipo de etiqueta de disco: gpt
Identificador del disco: E3FE7B0A-0F5D-4151-84E8-49670C33B65E

Device     Start      End  Sectors Size Type
/dev/md0p1  &lt;span class="m"&gt;2048&lt;/span&gt; &lt;span class="m"&gt;33521630&lt;/span&gt; &lt;span class="m"&gt;33519583&lt;/span&gt;  16G Linux filesystem

root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La primera (y única partición) se llama &lt;em&gt;/dev/md0p1&lt;/em&gt; y es el dispositivo que vamos a formatear, para posteriormente montarlo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mkfs.ext4 /dev/md0p1 
mke2fs 1.42.12 &lt;span class="o"&gt;(&lt;/span&gt;29-Aug-2014&lt;span class="o"&gt;)&lt;/span&gt;
Se está creando El sistema de ficheros con &lt;span class="m"&gt;4189947&lt;/span&gt; 4k bloques y &lt;span class="m"&gt;1048576&lt;/span&gt; nodos-i

UUID del sistema de ficheros: 11e454ce-72c4-41f8-a7bc-4d4a78b873c0
Respaldo del superbloque guardado en los bloques: 
    32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 
    4096000

Reservando las tablas de grupo: hecho                           
Escribiendo las tablas de nodos-i: hecho                           
Creando el fichero de transacciones &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;32768&lt;/span&gt; bloques&lt;span class="o"&gt;)&lt;/span&gt;: hecho
Escribiendo superbloques y la información contable del sistema de ficheros:   hecho  

root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos la carpeta que va a servir de &lt;em&gt;mountpoint&lt;/em&gt; para esta nueva partición:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mkdir /data
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Añadimos la partición en el fichero &lt;em&gt;/etc/fstab&lt;/em&gt;, para que se monte automáticamente tras cada reinicio:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# grep md0p1 /etc/fstab 
/dev/md0p1 /data ext4 defaults &lt;span class="m"&gt;0&lt;/span&gt; 0
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente la montamos. Como esta información ya está en el fichero &lt;em&gt;/etc/fstab&lt;/em&gt; no es necesario especificar los detalles.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mount /data
root@server:~# df -h
S.ficheros     Tamaño Usados  Disp Uso% Montado en
/dev/sda1        2,0G   651M  1,2G  35% /
udev              10M      &lt;span class="m"&gt;0&lt;/span&gt;   10M   0% /dev
tmpfs             50M   4,4M   46M   9% /run
tmpfs            124M      &lt;span class="m"&gt;0&lt;/span&gt;  124M   0% /dev/shm
tmpfs            5,0M      &lt;span class="m"&gt;0&lt;/span&gt;  5,0M   0% /run/lock
tmpfs            124M      &lt;span class="m"&gt;0&lt;/span&gt;  124M   0% /sys/fs/cgroup
/dev/md0p1        16G    44M   15G   1% /data
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como detalle, al no tratarse de una partición raíz de sistema operativo, no hace falta reservar bloques de emergencia; se trata de un 5% de la capacidad que podemos liberar (5% de 16gb son 800mb que podemos usar).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# tune2fs -m &lt;span class="m"&gt;0&lt;/span&gt; /dev/md0p1 
tune2fs 1.42.12 &lt;span class="o"&gt;(&lt;/span&gt;29-Aug-2014&lt;span class="o"&gt;)&lt;/span&gt;
Se pone el porcentaje de bloques reservados a 0% &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; bloques&lt;span class="o"&gt;)&lt;/span&gt;
root@server:~# df -h
S.ficheros     Tamaño Usados  Disp Uso% Montado en
/dev/sda1        2,0G   651M  1,2G  35% /
udev              10M      &lt;span class="m"&gt;0&lt;/span&gt;   10M   0% /dev
tmpfs             50M   4,4M   46M   9% /run
tmpfs            124M      &lt;span class="m"&gt;0&lt;/span&gt;  124M   0% /dev/shm
tmpfs            5,0M      &lt;span class="m"&gt;0&lt;/span&gt;  5,0M   0% /run/lock
tmpfs            124M      &lt;span class="m"&gt;0&lt;/span&gt;  124M   0% /sys/fs/cgroup
/dev/md0p1        16G    44M   16G   1% /data
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Verificación&lt;/h2&gt;
&lt;p&gt;Podemos ver la información de estado del array de discos con el mismo comando &lt;em&gt;mdadm&lt;/em&gt;, como sigue:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mdadm --detail /dev/md0
/dev/md0:
        Version : 1.2
  Creation Time : Sat Dec &lt;span class="m"&gt;12&lt;/span&gt; 21:19:42 2015
     Raid Level : raid10
     Array Size : &lt;span class="m"&gt;16760832&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;15.98 GiB 17.16 GB&lt;span class="o"&gt;)&lt;/span&gt;
  Used Dev Size : &lt;span class="m"&gt;8380416&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;7.99 GiB 8.58 GB&lt;span class="o"&gt;)&lt;/span&gt;
   Raid Devices : 4
  Total Devices : 4
    Persistence : Superblock is persistent

    Update Time : Sat Dec &lt;span class="m"&gt;12&lt;/span&gt; 21:30:11 2015
          State : clean 
 Active Devices : 4
Working Devices : 4
 Failed Devices : 0
  Spare Devices : 0

         Layout : &lt;span class="nv"&gt;near&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;2
     Chunk Size : 512K

           Name : server:0  &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;local &lt;/span&gt;to host server&lt;span class="o"&gt;)&lt;/span&gt;
           UUID : 217558a7:bc1cb1d4:9530ecda:ea477a6b
         Events : 19

    Number   Major   Minor   RaidDevice State
       &lt;span class="m"&gt;0&lt;/span&gt;       &lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;16&lt;/span&gt;        &lt;span class="m"&gt;0&lt;/span&gt;      active sync &lt;span class="nb"&gt;set&lt;/span&gt;-A   /dev/sdb
       &lt;span class="m"&gt;1&lt;/span&gt;       &lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;32&lt;/span&gt;        &lt;span class="m"&gt;1&lt;/span&gt;      active sync &lt;span class="nb"&gt;set&lt;/span&gt;-B   /dev/sdc
       &lt;span class="m"&gt;2&lt;/span&gt;       &lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;48&lt;/span&gt;        &lt;span class="m"&gt;2&lt;/span&gt;      active sync &lt;span class="nb"&gt;set&lt;/span&gt;-A   /dev/sdd
       &lt;span class="m"&gt;3&lt;/span&gt;       &lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;64&lt;/span&gt;        &lt;span class="m"&gt;3&lt;/span&gt;      active sync &lt;span class="nb"&gt;set&lt;/span&gt;-B   /dev/sde
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;RESUMEN&lt;/strong&gt;: Ahora tengo un disco doble de rápido, doble de capacidad y con doble copia de datos. Afortunadamente, los discos duros son baratos...&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="raid"></category></entry><entry><title>Construyendo una replica set en mongodb</title><link href="http://www.linuxsysadmin.tk/2015/12/construyendo-una-replica-set-en-mongodb.html" rel="alternate"></link><updated>2015-12-08T12:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-12-08:2015/12/construyendo-una-replica-set-en-mongodb.html</id><summary type="html">&lt;p&gt;Muchas veces nos interesa obtener alta disponibilidad en los servicios que gestionamos. No hay nada mas desagradable que una llamada a las tantas de la noche porque se ha caído un nodo de una base de datos y no damos servicio. Para eso &lt;em&gt;mongodb&lt;/em&gt; nos ofrece el mecanismo de replicación.&lt;/p&gt;
&lt;p&gt;En este artículo vamos a montar una &lt;em&gt;replica set&lt;/em&gt;, de forma que si se cayera un nodo de la base de datos, otro asumiría su rol, de forma que se seguiría dando servicio.&lt;/p&gt;
&lt;p&gt;Nuestra &lt;em&gt;replica set&lt;/em&gt; va a tener 3 nodos, que vamos a alojar en 3 máquinas distintas, de forma que la caída de una máquina afecte solamente a 1 proceso de &lt;em&gt;mongodb&lt;/em&gt;. La caonfiguración de 3 nodos nos da una tolerancia a fallos de 1 máquina; mientras queden 2, el clúster va a seguir operativo.&lt;/p&gt;
&lt;h2&gt;Descripción del entorno&lt;/h2&gt;
&lt;p&gt;Disponemos de 3 máquinas que vamos a llamar &lt;strong&gt;mongo1&lt;/strong&gt;, &lt;strong&gt;mongo2&lt;/strong&gt; y &lt;strong&gt;mongo3&lt;/strong&gt;. Cada una funciona con un sistema operativo &lt;em&gt;Debian jessie&lt;/em&gt; con &lt;em&gt;systemd&lt;/em&gt; y cuenta 1 gb de disco y con 256 mb de memoria; para esta demostración no se necesita mas.&lt;/p&gt;
&lt;p&gt;Como pequeño detalle, las máquinas se van referir entre ellas por nombre, pero como no me interesa poner una solución completa de &lt;em&gt;DNS&lt;/em&gt;, he puesto en el fichero &lt;em&gt;/etc/hosts&lt;/em&gt; de todas las máquinas las equivalencias.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# grep mongo /etc/hosts
10.0.0.2    mongo1
10.0.0.3    mongo2
10.0.0.4    mongo3
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Consideraciones de seguridad&lt;/h2&gt;
&lt;p&gt;Estas máquinas se comunican entre sí por el puerto TCP en el que corran sus procesos; para seguir con el puerto "titular" vamos a ponerlos en el puerto 27017. Es importante que las 3 máquinas puedan acceder al puerto de las otras 2. Adicionalmente, la máquina que vaya a usar este clúster también debe pode acceder al puerto 27017 de las 3 máquinas.&lt;/p&gt;
&lt;h2&gt;Preparación de las máquinas individuales&lt;/h2&gt;
&lt;p&gt;Queremos una versión de &lt;em&gt;mongodb&lt;/em&gt; un poco reciente, así que no vamos a usar los paquetes oficiales de la distribución, y la empresa de &lt;em&gt;mongodb&lt;/em&gt; no ofrece paquete para &lt;em&gt;Debian jessie&lt;/em&gt;. Por ello vamos a montar un esqueleto de ficheros como se describe en &lt;a href="http://www.linuxsysadmin.tk/2015/11/escribiendo-units-en-systemd.html"&gt;un artículo anterior&lt;/a&gt;. Vamos a describir el proceso en la máquina &lt;strong&gt;mongo1&lt;/strong&gt;, para replicarlo a posteriori en las otras 2.&lt;/p&gt;
&lt;p&gt;Creamos la estructura de carpetas que van a contener todo lo relativo a &lt;strong&gt;mongodb&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# mkdir -p /opt/mongodb/&lt;span class="o"&gt;{&lt;/span&gt;bin,conf,data/replica,logs&lt;span class="o"&gt;}&lt;/span&gt;
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Copiamos el binario &lt;strong&gt;mongod&lt;/strong&gt; que encontraremos en el fichero &lt;em&gt;.tar.gz&lt;/em&gt; de la página de descargas de la página web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cp mongod /opt/mongodb/bin/
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos un fichero de configuración con el que vamos a levantar el proceso en esta máquina.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cat /opt/mongodb/conf/replica.conf
systemLog:
    path: /opt/mongodb/logs/replica.log
    logAppend: &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nb"&gt;    &lt;/span&gt;destination: file

net:
    port: 27017
    bindIp: 0.0.0.0

storage:
    dbPath: /opt/mongodb/data/replica
    smallFiles: &lt;span class="nb"&gt;true&lt;/span&gt;

replication:
    replSetName: replica
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Por razones de seguridad vamos a lanzar el servicio con un usuario propio de sistema.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# useradd -s /usr/sbin/nologin -r -M mongo -d /opt/mongodb/
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para ahorrarnos problemas de permisos, lo hacemos propietario de todo lo referente al servicio:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# chown -R mongo:mongo /opt/mongodb/
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a crearle una &lt;strong&gt;unit&lt;/strong&gt; para que el sistema se encargue de levantar automáticamente el servicio en caso de reinicio de la máquina:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cat /etc/systemd/system/mongo.service
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;MongoDB

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;User&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mongo
&lt;span class="nv"&gt;LimitFSIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitCPU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitNOFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;LimitNPROC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/rm -f /opt/mongodb/data/replica/mongod.lock
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/opt/mongodb/bin/mongod -f /opt/mongodb/conf/replica.conf

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente activamos la &lt;strong&gt;unit&lt;/strong&gt; e iniciamos el servicio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mongo
Created symlink from /etc/systemd/system/multi-user.target.wants/mongo.service to /etc/systemd/system/mongo.service.
root@mongo1:~# systemctl start mongo
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora toca repetir el proceso en las otras 2 máquinas, exactamente igual.&lt;/p&gt;
&lt;h2&gt;Configuración del clúster&lt;/h2&gt;
&lt;p&gt;Accedemos a una de las máquinas del futuro clúster desde cualquier máquina que pueda hacerlo y que disponga del binario &lt;strong&gt;mongo&lt;/strong&gt; (el mongo shell), que también viene en el archivo &lt;em&gt;.tar.gz&lt;/em&gt; descargado de la página oficial; este shell no es necesario para la aplicación que use el clúster ya que el &lt;strong&gt;driver&lt;/strong&gt; de cada lenguaje suple sus funciones, pero es muy útil tenerlo a mano para tareas de administración y consultas varias.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client:~# ./mongo --host 10.0.0.2
MongoDB shell version: 3.0.7
connecting to: 10.0.0.2:27017/test
Welcome to the MongoDB shell.
For interactive &lt;span class="nb"&gt;help&lt;/span&gt;, &lt;span class="nb"&gt;type&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;help&amp;quot;&lt;/span&gt;.
&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hay dos formas de crear la configuración del clúster: pasando el documento de configuración en el método &lt;em&gt;initiate&lt;/em&gt; o añadir los nodos a posteriori con el método &lt;em&gt;add&lt;/em&gt;. Voy a usar este método por ser mas fácil.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;gt; rs.initiate&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;info2&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;no configuration explicitly specified -- making one&amp;quot;&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;me&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : 1
&lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; rs.add&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mongo2:27017&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; rs.add&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mongo3:27017&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a lanzar el método &lt;em&gt;status&lt;/em&gt; hasta que todos los nodos sean primarios o secundarios, momento en el que la &lt;em&gt;replica&lt;/em&gt; va a quedar correctamente montada.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;replica:PRIMARY&amp;gt; rs.status&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;set&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;replica&amp;quot;&lt;/span&gt;,
...
    &lt;span class="s2"&gt;&amp;quot;members&amp;quot;&lt;/span&gt; : &lt;span class="o"&gt;[&lt;/span&gt;
        &lt;span class="o"&gt;{&lt;/span&gt;
...
            &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;PRIMARY&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;self&amp;quot;&lt;/span&gt; : &lt;span class="nb"&gt;true&lt;/span&gt;
...
        &lt;span class="o"&gt;}&lt;/span&gt;,
        &lt;span class="o"&gt;{&lt;/span&gt;
...
            &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo2:27017&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;SECONDARY&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;syncingTo&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
...
        &lt;span class="o"&gt;}&lt;/span&gt;,
        &lt;span class="o"&gt;{&lt;/span&gt;
...
            &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo3:27017&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;SECONDARY&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;syncingTo&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
...
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;]&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : 1
&lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esta salida del método &lt;em&gt;status&lt;/em&gt; ya lo tenemos todo funcionando correctamente.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="mongodb"></category><category term="replica set"></category><category term="systemd"></category></entry><entry><title>Creación de un livecd con Debian</title><link href="http://www.linuxsysadmin.tk/2015/12/creacion-de-un-livecd-con-debian.html" rel="alternate"></link><updated>2015-12-02T12:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-12-02:2015/12/creacion-de-un-livecd-con-debian.html</id><summary type="html">&lt;p&gt;Tras ver como las actualizaciones de mis máquinas virtuales &lt;em&gt;VirtualBox&lt;/em&gt; expandían mis discos &lt;em&gt;.vdi&lt;/em&gt; sin control, quise pasar la herramienta &lt;em&gt;zerofree&lt;/em&gt; y un compactado con la herramienta oficial &lt;em&gt;VBoxManage&lt;/em&gt;. No quería instalar &lt;em&gt;zerofree&lt;/em&gt; de forma permanente y no pude encontrar un &lt;em&gt;livecd&lt;/em&gt; que lo tuviera, así que decidí crear uno.&lt;/p&gt;
&lt;p&gt;Para conseguirlo, se va a usar un sistema de ficheros creado con &lt;em&gt;debootstrap&lt;/em&gt; y compactado mediante &lt;em&gt;SquashFS&lt;/em&gt;; este sistema de ficheros se va a empaquetar en un &lt;em&gt;.iso&lt;/em&gt; junto con un &lt;em&gt;kernel&lt;/em&gt;, un &lt;em&gt;initrd&lt;/em&gt; y el bootloader &lt;em&gt;isolinux&lt;/em&gt;. La herramienta que hace eso es &lt;em&gt;genisoimage&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Este tutorial se ejecutó en una distribución &lt;em&gt;Debian&lt;/em&gt;, pero no hay ningún problema en hacerlo en una &lt;em&gt;Ubuntu&lt;/em&gt; u otra distribución, siempre que sepamos como crear la imagen base para empaquetar.&lt;/p&gt;
&lt;h2&gt;Preparación del entorno&lt;/h2&gt;
&lt;p&gt;Todo el proceso va a ser ejecutado con el usuario &lt;em&gt;root&lt;/em&gt; por comodidad.&lt;/p&gt;
&lt;p&gt;Empezaremos por instalar todas las tecnologías que hemos mencionado:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~# apt-get install debootstrap isolinux squashfs-tools genisoimage
...
root@desktop:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos una carpeta de trabajo para contener todos los ficheros temporales y el producto final, por limpieza:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~# mkdir live_boot
root@desktop:~# &lt;span class="nb"&gt;cd &lt;/span&gt;live_boot
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Todos los comandos que se detallan a continuación se hacen desde dentro de esta carpeta.&lt;/p&gt;
&lt;h2&gt;Preparación del sistema de ficheros, el kernel y el initrd&lt;/h2&gt;
&lt;p&gt;El sistema de ficheros se hace a partir de una jaula estándar de una distribución normal. En este paso, las distribuciones que usan &lt;em&gt;debootstrap&lt;/em&gt; nos facilitan mucho las cosas (aunque esta es la operación mas larga de este tutorial):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# debootstrap --variant&lt;span class="o"&gt;=&lt;/span&gt;minbase jessie chroot
I: Retrieving Release 
I: Retrieving Release.gpg 
I: Checking Release signature
I: Valid Release signature &lt;span class="o"&gt;(&lt;/span&gt;key id 75DDC3C4A499F1A18CB5F3C8CBF8D6FD518E17E1&lt;span class="o"&gt;)&lt;/span&gt;
I: Retrieving Packages 
I: Validating Packages 
I: Resolving dependencies of required packages...
I: Resolving dependencies of base packages...
...
I: Base system installed successfully.
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora se trata de preparar esta jaula con los paquetes que necesitemos y las configuraciones adecuadas. Vamos a montar los pseudo sistemas de ficheros &lt;em&gt;/proc&lt;/em&gt;, &lt;em&gt;/sys&lt;/em&gt;, &lt;em&gt;/dev&lt;/em&gt; y &lt;em&gt;/dev/pts&lt;/em&gt;, que posiblemente nos van a hacer falta cuando estemos dentro de la jaula.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# mount -o &lt;span class="nb"&gt;bind&lt;/span&gt; /proc/ chroot/proc/
root@desktop:~/live_boot# mount -o &lt;span class="nb"&gt;bind&lt;/span&gt; /sys/ chroot/sys/
root@desktop:~/live_boot# mount -o &lt;span class="nb"&gt;bind&lt;/span&gt; /dev/ chroot/dev/
root@desktop:~/live_boot# mount -o &lt;span class="nb"&gt;bind&lt;/span&gt; /dev/pts/ chroot/dev/pts/
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Entramos en la jaula:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# chroot chroot
root@desktop:/# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;CUIDADO&lt;/strong&gt;: A partir de ahora, y hasta nuevo aviso, todos los comandos se hacen &lt;strong&gt;dentro&lt;/strong&gt; de la jaula.&lt;/p&gt;
&lt;p&gt;Antes de nada, vamos a asignar una password al usuario &lt;em&gt;root&lt;/em&gt;, porque sino, no vamos a poder entrar en el &lt;em&gt;livecd&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:/# passwd    
Enter new UNIX password: 
Retype new UNIX password: 
passwd: password updated successfully
root@desktop:/# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Asignamos el nombre de máquina que mostrará el &lt;em&gt;livecd&lt;/em&gt; una vez haya hecho el &lt;em&gt;boot&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:/# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;zerofree&amp;quot;&lt;/span&gt; &amp;gt; /etc/hostname
root@desktop:/# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para que el &lt;em&gt;livecd&lt;/em&gt; pueda hacer &lt;em&gt;boot&lt;/em&gt;, vamos a necesitar el paquete &lt;strong&gt;live-boot&lt;/strong&gt; y un &lt;em&gt;kernel&lt;/em&gt; adecuado a la máquina que va a usar el &lt;em&gt;livecd&lt;/em&gt;. El paquete del &lt;em&gt;kernel&lt;/em&gt; ya nos va a dotar de un &lt;em&gt;initrd&lt;/em&gt; que también vamos a necesitar para el &lt;em&gt;livecd&lt;/em&gt;. Este paso también tarda un poco.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:/# apt-get install linux-image-486 live-boot
Reading package lists... Done
Building dependency tree... Done
...
Setting up linux-image-3.16.0-4-586 &lt;span class="o"&gt;(&lt;/span&gt;3.16.7-ckt11-1+deb8u3&lt;span class="o"&gt;)&lt;/span&gt; ...
...  
/etc/kernel/postinst.d/initramfs-tools:
update-initramfs: Generating /boot/initrd.img-3.16.0-4-586
...
root@desktop:/# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora vamos a instalar los paquetes que queramos en el &lt;em&gt;livecd&lt;/em&gt;; yo voy a poner &lt;em&gt;zerofree&lt;/em&gt; que es la herramienta que motivó este &lt;em&gt;livecd&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:/# apt-get install zerofree
...
Unpacking zerofree &lt;span class="o"&gt;(&lt;/span&gt;1.0.3-1&lt;span class="o"&gt;)&lt;/span&gt; ...
Setting up zerofree &lt;span class="o"&gt;(&lt;/span&gt;1.0.3-1&lt;span class="o"&gt;)&lt;/span&gt; ...
root@desktop:/# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;OPCIONAL&lt;/strong&gt;: Para reducir el tamaño final, voy a limpiar todos los archivos temporales que usa &lt;em&gt;apt&lt;/em&gt;, tanto los archivos &lt;em&gt;.deb&lt;/em&gt; en &lt;em&gt;/var/cache/apt&lt;/em&gt;, como las listas de paquetes disponibles en &lt;em&gt;/var/lib/apt&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:/# cat /dev/null &amp;gt; /etc/apt/sources.list
root@desktop:/# apt-get update
Reading package lists... Done
root@desktop:/# apt-get clean 
root@desktop:/# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y finalmente salimos de la jaula:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:/# &lt;span class="nb"&gt;exit&lt;/span&gt;
&lt;span class="nb"&gt;exit&lt;/span&gt;
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;CUIDADO&lt;/strong&gt;: A partir de ahora, todos los comandos se hacen &lt;strong&gt;fuera&lt;/strong&gt; de la jaula.&lt;/p&gt;
&lt;p&gt;Vamos a desmontar los pseudo sistemas de ficheros que ya no son necesarios, y que van a molestar cuando compactemos la jaula. Como apunte, la jaula había levantado un proceso &lt;em&gt;/usr/sbin/uuidd&lt;/em&gt; que evitaba desmontar &lt;em&gt;chroot/dev&lt;/em&gt;, por lo que tuve que finalizar el proceso con un &lt;em&gt;kill&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# umount chroot/dev/pts/
root@desktop:~/live_boot# umount chroot/dev/
root@desktop:~/live_boot# umount chroot/sys/
root@desktop:~/live_boot# umount chroot/proc/
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;OPCIONAL&lt;/strong&gt;: Sabiendo que mis máquinas virtuales son clones y el comando que va a correr siempre el comando &lt;em&gt;zerofree&lt;/em&gt; contra el disco &lt;em&gt;/dev/sda1&lt;/em&gt;, se puede poner los comandos en el &lt;em&gt;.bash_history&lt;/em&gt; de &lt;em&gt;root&lt;/em&gt; para poderlos recuperar mediante el uso de flechas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# cat chroot/root/.bash_history 
zerofree /dev/sda1
poweroff
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Empaquetando la imagen&lt;/h2&gt;
&lt;p&gt;Vamos a crear una carpeta contenedora, que va a servir como raíz del &lt;em&gt;livecd&lt;/em&gt;. Dentro le vamos a poner una carpeta &lt;em&gt;live&lt;/em&gt; (para el sistema de ficheros, el &lt;em&gt;kernel&lt;/em&gt; y el &lt;em&gt;initrd&lt;/em&gt;) y una carpeta &lt;em&gt;isolinux&lt;/em&gt; (para todo lo referente al &lt;em&gt;bootloader&lt;/em&gt;).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# mkdir -p image/&lt;span class="o"&gt;{&lt;/span&gt;live,isolinux&lt;span class="o"&gt;}&lt;/span&gt;
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a poner el sistema de ficheros en formato &lt;em&gt;SquashFS&lt;/em&gt;. Como apunte, el &lt;em&gt;kernel&lt;/em&gt; y el &lt;em&gt;initrd&lt;/em&gt; (ambos en la carpeta &lt;em&gt;/boot&lt;/em&gt;) se excluyen porque el &lt;em&gt;bootloader&lt;/em&gt; es incapaz de leerlos de allí; así que los copiamos a la misma carpeta.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# mksquashfs chroot image/live/filesystem.squashfs -e boot
Parallel mksquashfs: Using &lt;span class="m"&gt;1&lt;/span&gt; processor
Creating 4.0 filesystem on image/live/filesystem.squashfs, block size 131072.
...  
root@desktop:~/live_boot# cp chroot/boot/vmlinuz-3.16.0-4-586 image/live/vmlinuz
root@desktop:~/live_boot# cp chroot/boot/initrd.img-3.16.0-4-586 image/live/initrd
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora vamos con el &lt;em&gt;bootloader&lt;/em&gt;. Lo primero es poner una configuración para saber qué menú nos va a mostrar:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# cat image/isolinux/isolinux.cfg 
UI menu.c32

prompt 0
menu title Debian Zerofree

timeout 50

label Debian Live 3.16.0-4-586
menu label ^Debian Live 3.16.0-4-586
menu default
kernel /live/vmlinuz
append &lt;span class="nv"&gt;initrd&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/live/initrd &lt;span class="nv"&gt;boot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;live
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Copiamos la imagen del &lt;em&gt;bootloader&lt;/em&gt; &lt;strong&gt;isolinux&lt;/strong&gt; y los módulos que se necesitan, tanto porque nuestra configuración los usa o porque se usan desde otros módulos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# cp /usr/lib/ISOLINUX/isolinux.bin image/isolinux/
root@desktop:~/live_boot# cp /usr/lib/syslinux/modules/bios/ldlinux.c32 image/isolinux/
root@desktop:~/live_boot# cp /usr/lib/syslinux/modules/bios/menu.c32 image/isolinux/
root@desktop:~/live_boot# cp /usr/lib/syslinux/modules/bios/libutil.c32 image/isolinux/
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente empaquetamos la imagen &lt;em&gt;.iso&lt;/em&gt;. Para ello usaremos la herramienta &lt;em&gt;genisoimage&lt;/em&gt; en la carpeta raíz de lo que sería el &lt;em&gt;livecd&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# &lt;span class="nb"&gt;cd &lt;/span&gt;image/
root@desktop:~/live_boot/image# genisoimage -rational-rock -volid &lt;span class="s2"&gt;&amp;quot;Debian Zerofree&amp;quot;&lt;/span&gt; -cache-inodes -joliet -full-iso9660-filenames -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size &lt;span class="m"&gt;4&lt;/span&gt; -boot-info-table -output ../debian-zerofree.iso .
I: -input-charset not specified, using utf-8 &lt;span class="o"&gt;(&lt;/span&gt;detected in locale settings&lt;span class="o"&gt;)&lt;/span&gt;
Size of boot image is &lt;span class="m"&gt;4&lt;/span&gt; sectors -&amp;gt; No emulation
  9.24% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:43 2015
 18.48% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:38 2015
 27.69% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:36 2015
 36.94% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:38 2015
 46.15% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:37 2015
 55.40% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:36 2015
 64.61% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:37 2015
 73.85% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:37 2015
 83.07% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:37 2015
 92.30% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:38 2015
Total translation table size: 2048
Total rockridge attributes bytes: 1335
Total directory bytes: 4570
Path table size&lt;span class="o"&gt;(&lt;/span&gt;bytes&lt;span class="o"&gt;)&lt;/span&gt;: 38
Max brk space used 1a000
&lt;span class="m"&gt;54178&lt;/span&gt; extents written &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;105&lt;/span&gt; MB&lt;span class="o"&gt;)&lt;/span&gt;
root@desktop:~/live_boot/image# &lt;span class="nb"&gt;cd&lt;/span&gt; ..
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y nuestra imagen &lt;em&gt;.iso&lt;/em&gt; queda en la carpeta de trabajo, junto a la jaula y a la estructura del &lt;em&gt;livecd&lt;/em&gt;. Solo necesitamos la imagen &lt;em&gt;.iso&lt;/em&gt;, pero podemos dejar los ficheros intermedios hasta que estemos satisfechos con la imagen; es mas fácil modificar la jaula, el empaquetado &lt;em&gt;filesystem.squashfs&lt;/em&gt; y la imagen &lt;em&gt;.iso&lt;/em&gt; que volver a hacer un &lt;em&gt;debootstrap&lt;/em&gt; entero...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# ls -lh
total 106M
drwxr-xr-x &lt;span class="m"&gt;20&lt;/span&gt; root root 4,0K dic  &lt;span class="m"&gt;2&lt;/span&gt; 11:30 chroot
-rw-r--r--  &lt;span class="m"&gt;1&lt;/span&gt; root root 106M dic  &lt;span class="m"&gt;2&lt;/span&gt; 12:06 debian-zerofree.iso
drwxr-xr-x  &lt;span class="m"&gt;4&lt;/span&gt; root root 4,0K dic  &lt;span class="m"&gt;2&lt;/span&gt; 11:53 image
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Conclusión&lt;/h2&gt;
&lt;p&gt;Copiando esta imagen &lt;em&gt;.iso&lt;/em&gt; a mi máquina con &lt;em&gt;VirtualBox&lt;/em&gt; y montándola antes de hacer el &lt;em&gt;boot&lt;/em&gt; de cada máquina, puedo usar la herramienta &lt;em&gt;zerofree&lt;/em&gt; libremente, sin instalarla en las máquinas virtuales. Tras ello, el compactado de los ficheros &lt;em&gt;.vdi&lt;/em&gt; libera los megabytes a cientos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@virtualbox:~/VirtualBox VMs&lt;span class="nv"&gt;$ &lt;/span&gt;VBoxManage modifyvdi Debian/Debian.vdi --compact
...
gerard@virtualbox:~/VirtualBox VMs&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este caso concreto, la máquina &lt;strong&gt;Debian&lt;/strong&gt; (&lt;em&gt;netinstall&lt;/em&gt;) volvió a ocupar 700 mb, que es mucho mas interesante teniendo en cuenta que es la imagen que suelo clonar para hacer otras máquinas virtuales.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="zerofree"></category><category term="debootstrap"></category><category term="squashfs"></category><category term="genisoimage"></category><category term="isolinux"></category><category term="iso"></category><category term="livecd"></category></entry><entry><title>Virtualizando contenedores LXC tras bridge interno</title><link href="http://www.linuxsysadmin.tk/2015/11/virtualizando-contenedores-lxc-tras-bridge-interno.html" rel="alternate"></link><updated>2015-11-23T23:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-11-23:2015/11/virtualizando-contenedores-lxc-tras-bridge-interno.html</id><summary type="html">&lt;p&gt;En un artículo anterior propusimos virtualizar contenedores en la red de la máquina &lt;em&gt;host&lt;/em&gt;. Sin embargo, puede ser mas interesante esconder los contenedores detrás de una máquina que haga las funciones de &lt;em&gt;host&lt;/em&gt; y de &lt;em&gt;firewall&lt;/em&gt;. Expondremos una serie de puertos tras la misma dirección &lt;em&gt;IP&lt;/em&gt; mediante el protocolo &lt;em&gt;NAT&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Para conseguir este objetivo, se van a usar las siguientes tecnologías:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Debian jessie&lt;/strong&gt;: Es necesario usar alguna distribución de linux para hacer funcionar LXC&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LXC&lt;/strong&gt;: Tecnología que permite aislar los contenedores entre sí y darles entidad propia&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bridges&lt;/strong&gt;: Un bridge es en software el equivalente a un switch hardware&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Firehol&lt;/strong&gt;: Una serie de scripts para construir firewalls basados en iptables de forma fácil&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En cuanto a las capacidades hardware, vamos a hacer el tutorial con un equipo de capacidades modestas, virtualizado en una máquina virtual VirtualBox.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPUs&lt;/strong&gt;: 1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memoria&lt;/strong&gt;: 256 Mb&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disco&lt;/strong&gt;: 2 Gb&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Red&lt;/strong&gt;: 1 interfaz (&lt;em&gt;eth0&lt;/em&gt;) &lt;em&gt;host-only&lt;/em&gt; o &lt;em&gt;bridged&lt;/em&gt; con IP fija&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Partimos de una distribución &lt;em&gt;Debian jessie&lt;/em&gt; instalada con un CD &lt;em&gt;netinstall&lt;/em&gt; y con el único paquete instalado &lt;em&gt;openssh-server&lt;/em&gt;, para mi comodidad.&lt;/p&gt;
&lt;h2&gt;Preparar el servidor&lt;/h2&gt;
&lt;p&gt;El primer paso consiste en instalar las tecnologías usadas:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# apt-get install bridge-utils firehol lxc
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
...
Configurando lxc &lt;span class="o"&gt;(&lt;/span&gt;1:1.0.6-6+deb8u2&lt;span class="o"&gt;)&lt;/span&gt; ...
Configurando dh-python &lt;span class="o"&gt;(&lt;/span&gt;1.20141111-2&lt;span class="o"&gt;)&lt;/span&gt; ...
Procesando disparadores para libc-bin &lt;span class="o"&gt;(&lt;/span&gt;2.19-18+deb8u1&lt;span class="o"&gt;)&lt;/span&gt; ...
Procesando disparadores para systemd &lt;span class="o"&gt;(&lt;/span&gt;215-17+deb8u2&lt;span class="o"&gt;)&lt;/span&gt; ...
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora vamos a modificar la configuración de red, para habilitar el &lt;em&gt;bridge&lt;/em&gt; en el que vamos a conectar el resto de contenedores virtualizados. Como dato importante, se define una interfaz falsa en la directiva &lt;em&gt;bridge_ports&lt;/em&gt; para que la &lt;em&gt;unit&lt;/em&gt; de red lo levante automáticamente.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ANTES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/network/interfaces
&lt;span class="nb"&gt;source&lt;/span&gt; /etc/network/interfaces.d/*

auto lo
iface lo inet loopback

auto eth0
iface eth0 inet static
    address 192.168.56.4
    netmask 255.255.255.0
    gateway 192.168.56.1
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;DESPUES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/network/interfaces
&lt;span class="nb"&gt;source&lt;/span&gt; /etc/network/interfaces.d/*

auto lo
iface lo inet loopback

auto eth0
iface eth0 inet static
    address 192.168.56.4
    netmask 255.255.255.0
    gateway 192.168.56.1

auto lxc0
iface lxc0 inet static
    bridge_ports dummy
    address 10.0.0.1
    netmask 255.255.255.0
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora toca reiniciar el servicio de red, para que el nuevo &lt;em&gt;bridge&lt;/em&gt; quede configurado como debe estarlo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# service networking restart
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El siguiente paso consiste en poner las reglas de &lt;em&gt;firewall&lt;/em&gt; necesarias para proteger al equipo anfitrión y para permitirle actuar como &lt;em&gt;gateway&lt;/em&gt; para los contenedores tras el &lt;em&gt;bridge&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf 
interface eth0 world
    policy drop
    protection strong
    server ssh accept
    client all accept

interface lxc0 lan
    policy drop
    client all accept

router lan2world inface lxc0 outface eth0
    masquerade
    route all accept
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hay que modificar otro fichero para permitir el inicio del &lt;em&gt;firewall&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ANTES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# grep START /etc/default/firehol 
&lt;span class="c"&gt;#To enable firehol at startup set START_FIREHOL=YES&lt;/span&gt;
&lt;span class="nv"&gt;START_FIREHOL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;NO
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;DESPUES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# grep START /etc/default/firehol 
&lt;span class="c"&gt;#To enable firehol at startup set START_FIREHOL=YES&lt;/span&gt;
&lt;span class="nv"&gt;START_FIREHOL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;YES
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para acabar, reiniciamos el servicio &lt;em&gt;firehol&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# service firehol restart
...
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Creación de contenedores&lt;/h2&gt;
&lt;p&gt;La creación de contenedores pasa por usar las herramientas estándar de la distribución, a lo solo tendremos que modificar algunas configuraciones propias de nuestra red.&lt;/p&gt;
&lt;p&gt;Creamos un contenedor &lt;em&gt;webserver&lt;/em&gt; como demostración. La primera que se crea es un poco lenta porque hace un &lt;em&gt;debootstrap&lt;/em&gt; de una distribución &lt;em&gt;Debian estable&lt;/em&gt; para crear una cache en &lt;em&gt;/var/cache/lxc&lt;/em&gt;; las siguientes se benefician de esta caché y solo la actualizan, acelerando el proceso.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-create -n webserver -t debian
debootstrap is /usr/sbin/debootstrap
Checking cache download in /var/cache/lxc/debian/rootfs-jessie-i386 ... 
Downloading debian minimal ...
...

I: Base system installed successfully.
Download complete.
Copying rootfs to /var/lib/lxc/webserver/rootfs...
...
Current default &lt;span class="nb"&gt;time &lt;/span&gt;zone: &lt;span class="s1"&gt;&amp;#39;Europe/Madrid&amp;#39;&lt;/span&gt;
Local &lt;span class="nb"&gt;time &lt;/span&gt;is now:      Mon Nov &lt;span class="m"&gt;23&lt;/span&gt; 16:29:36 CET 2015.
Universal Time is now:  Mon Nov &lt;span class="m"&gt;23&lt;/span&gt; 15:29:36 UTC 2015.

Root password is &lt;span class="s1"&gt;&amp;#39;E3+K9SpU&amp;#39;&lt;/span&gt;, please change !
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Acabada la generación del contenedor, vamos a configurarle algunos parámetros; que tenga una interfaz &lt;em&gt;eth0&lt;/em&gt; activa y enchufada al bridge &lt;em&gt;lxc0&lt;/em&gt;, y que el contenedor se inicie automáticamente en cada reinicio del anfitrión.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /var/lib/lxc/webserver/config 
...
lxc.start.auto &lt;span class="o"&gt;=&lt;/span&gt; 1
lxc.network.type &lt;span class="o"&gt;=&lt;/span&gt; veth
lxc.network.flags &lt;span class="o"&gt;=&lt;/span&gt; up
lxc.network.link &lt;span class="o"&gt;=&lt;/span&gt; lxc0
lxc.network.name &lt;span class="o"&gt;=&lt;/span&gt; eth0
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para que su interfaz de red sea funcional, vamos a configurarle una dirección IP. Todo esto se hace en los ficheros habituales, teniendo en cuenta que un contenedor es una jaula, y que esta se encuentra en &lt;em&gt;/var/lib/lxc/webserver/rootfs/&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /var/lib/lxc/webserver/rootfs/etc/network/interfaces
auto lo
iface lo inet loopback

auto eth0
iface eth0 inet static
    address 10.0.0.2
    netmask 255.255.255.0
    gateway 10.0.0.1
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El contenedor ya está funcional, y se puede levantar:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-start -n webserver -d
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Supongamos que este nuevo contenedor tiene un servidor web y queremos hacerlo disponible en puerto 80 del &lt;em&gt;host&lt;/em&gt;, mediante el protocolo &lt;em&gt;NAT&lt;/em&gt;. También se necesita definir una regla de &lt;em&gt;forward&lt;/em&gt; para permitir ese tráfico. Se reinicia el servicio &lt;em&gt;firehol&lt;/em&gt; para aplicar las nuevas reglas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf 
dnat 10.0.0.2:80 proto tcp dst 192.168.56.4 dport 80

interface eth0 world
    policy drop
    protection strong
    server ssh accept
    client all accept

interface lxc0 lan
    policy drop
    client all accept

router lan2world inface lxc0 outface eth0
    masquerade
    route all accept

router world2lan inface eth0 outface lxc0
    route http accept dst 10.0.0.2
root@lxc:~# service firehol restart
...
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora podemos acceder al servidor web instalado en el contenedor &lt;em&gt;webserver&lt;/em&gt; mediante el puerto 80 del &lt;em&gt;host&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Supongamos que tenemos otro contenedor con un servidor de aplicaciones escuchando en el puerto 8080 con dirección 10.0.0.3 y pretendemos que el contenedor original haga de &lt;em&gt;proxy HTTP&lt;/em&gt;. Esta funcionalidad requiere que el contenedor &lt;em&gt;webserver&lt;/em&gt; pueda conectarse al puerto 8080 del nuevo contenedor &lt;em&gt;appserver&lt;/em&gt;. Esta regla de &lt;em&gt;forward&lt;/em&gt; aplica a todas las conexiones que inician y finalizan en el &lt;em&gt;bridge&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf 
dnat 10.0.0.2:80 proto tcp dst 192.168.56.4 dport 80

interface eth0 world
    policy drop
    protection strong
    server ssh accept
    client all accept

interface lxc0 lan
    policy drop
    client all accept

router lan2world inface lxc0 outface eth0
    masquerade
    route all accept

router world2lan inface eth0 outface lxc0
    route http accept dst 10.0.0.2

router internal inface lxc0 outface lxc0
    route webcache accept src 10.0.0.2 dst 10.0.0.3
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con eso tenemos nuestro &lt;em&gt;proxy HTTP&lt;/em&gt; funcionando.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="lxc"></category><category term="bridge"></category><category term="firehol"></category></entry><entry><title>Creando sistemas de ficheros temporales con tmpfs</title><link href="http://www.linuxsysadmin.tk/2015/11/creando-sistemas-de-ficheros-temporales-con-tmpfs.html" rel="alternate"></link><updated>2015-11-16T23:15:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-11-16:2015/11/creando-sistemas-de-ficheros-temporales-con-tmpfs.html</id><summary type="html">&lt;p&gt;A veces nos podemos encontrar con un sistema de ficheros lleno que no nos permite completar alguna acción por falta de espacio en disco. En un caso así, existe la posibilidad de sacar un sistema de ficheros completo de memoria, de una forma temporal, usando el sistema de ficheros &lt;em&gt;tmpfs&lt;/em&gt;. Otra opción es la de tener un sistema de ficheros temporal, en donde podamos dejar ficheros cuya persistencia no sea necesaria entre reinicios.&lt;/p&gt;
&lt;p&gt;El primer paso es tener un &lt;em&gt;punto de montaje&lt;/em&gt;, que sea la carpeta en la que se va a montar el nuevo sistema de fichero. Por ejemplo podemos usar el punto de montaje &lt;em&gt;/mnt/auxiliar&lt;/em&gt;; empezaremos creándolo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mkdir /mnt/auxiliar
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Observemos como la carpeta creada se construye sobre el mismo dispositivo que la partición raíz:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# df -h /mnt/auxiliar/
S.ficheros     Tamaño Usados  Disp Uso% Montado en
/dev/sda1        2,0G   640M  1,2G  35% /
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Creando el sistema de ficheros de forma temporal&lt;/h2&gt;
&lt;p&gt;Como prueba de concepto, podemos crear este sistema de ficheros de forma temporal. En caso de no salir bien, los efectos no serían permanentes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mount -o &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;100M -t tmpfs auxiliar /mnt/auxiliar/
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Podemos ver como la carpeta pertenece ahora a un sistema de ficheros nuevo:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# df -h /mnt/auxiliar/
S.ficheros     Tamaño Usados  Disp Uso% Montado en
auxiliar            100M      &lt;span class="m"&gt;0&lt;/span&gt;  100M   0% /mnt/auxiliar
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Cuando nos cansemos del nuevo sistema de ficheros, haya cumplido con su utilidad y ya no necesitemos su contenido, la podemos desmontar; vamos a perder todos los ficheros dentro del sistema de ficheros temporal.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# umount /mnt/auxiliar/
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Haciendo el cambio permanente&lt;/h2&gt;
&lt;p&gt;Si nos interesa que este sistema de fichero se &lt;em&gt;monte&lt;/em&gt; y se &lt;em&gt;desmonte&lt;/em&gt; cada vez que la máquina se inicie y se apague, basta con usar el mecanismo estándar de todo sistema de ficheros &lt;em&gt;Linux&lt;/em&gt;: el fichero &lt;em&gt;/etc/fstab&lt;/em&gt;. Basta con añadir una línea nueva con las especificaciones de este punto de montaje, por ejemplo en el final del mismo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# tail -1 /etc/fstab 
auxiliar /mnt/auxiliar tmpfs &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;100M &lt;span class="m"&gt;0&lt;/span&gt; 0
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Con este cambio es suficiente para las sesiones venideras. En caso de querer disponer inmediatamente del sistema de ficheros podemos solicitar el montaje con un comando &lt;em&gt;mount&lt;/em&gt; normal, comando que va a usar las especificaciones del fichero &lt;em&gt;/etc/fstab&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mount /mnt/auxiliar
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto queda completado nuestro objetivo.&lt;/p&gt;</summary><category term="linux"></category><category term="tmpfs"></category></entry><entry><title>Escribiendo units en systemd</title><link href="http://www.linuxsysadmin.tk/2015/11/escribiendo-units-en-systemd.html" rel="alternate"></link><updated>2015-11-09T22:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-11-09:2015/11/escribiendo-units-en-systemd.html</id><summary type="html">&lt;p&gt;Cuando se anunció &lt;em&gt;systemd&lt;/em&gt; me llamó la atención que además de las funciones estándares de otros sistemas de &lt;em&gt;init&lt;/em&gt; (por ejemplo &lt;em&gt;sysvinit&lt;/em&gt;), también se ofrecían otras funcionalidades normalmente delegadas a otros procesos, como por ejemplo, la posibilidad de reiniciar procesos automáticamente o de lanzar procesos temporales al estilo de &lt;em&gt;cron&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;En este artículo se explica como escribir estos ficheros que rigen las tareas propias del sistema &lt;em&gt;init&lt;/em&gt; para iniciar procesos que no disponen de tales facilidades. Adicionalmente, vamos a ver como beneficiarnos del sistema de plantillas de estos mismos ficheros para evitarnos tener que repetirnos, de acuerdo con el principio &lt;a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself"&gt;DRY (don't repeat yourself)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Como ejemplo, vamos a utilizar un sistema básico de &lt;em&gt;Linux&lt;/em&gt; con &lt;em&gt;systemd&lt;/em&gt;; que podría ser &lt;em&gt;RedHat 7&lt;/em&gt;, &lt;em&gt;ArchLinux&lt;/em&gt; o &lt;em&gt;Debian 8&lt;/em&gt;. En este caso, se va a utilizar un sistema &lt;em&gt;Debian Jessie&lt;/em&gt; con una instalación básica &lt;em&gt;netinstall&lt;/em&gt; con &lt;em&gt;SSH&lt;/em&gt; y nada mas.&lt;/p&gt;
&lt;p&gt;Vamos a suponer que queremos montar un servidor con 2 instancias de &lt;em&gt;MongoDB&lt;/em&gt;, escuchando en los puertos 27001 y 27002. Empecemos con montar una estructura en &lt;em&gt;/opt/&lt;/em&gt; para contener todo lo relacionado con este despliegue. La idea es que vamos a levantar el binario &lt;em&gt;mongod&lt;/em&gt; con dos configuraciones distintas. Por eso, de momento basta con poner el binario &lt;em&gt;mongod&lt;/em&gt;, las dos configuraciones y las dos carpetas de datos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# tree /opt/
/opt/
└── mongodb
    ├── bin
    │   └── mongod
    ├── conf
    │   ├── mongo1.conf
    │   └── mongo2.conf
    ├── data
    │   ├── mongo1
    │   └── mongo2
    └── logs

&lt;span class="m"&gt;7&lt;/span&gt; directories, &lt;span class="m"&gt;3&lt;/span&gt; files
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La configuración de ambos procesos va a ser la mínima necesaria para que los procesos no entren en conflicto entre ellos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /opt/mongodb/conf/mongo1.conf 
systemLog:
    path: /opt/mongodb/logs/mongo1.log
    logAppend: &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nb"&gt;    &lt;/span&gt;destination: file

net:
    port: 27001

storage:
    dbPath: /opt/mongodb/data/mongo1
    smallFiles: &lt;span class="nb"&gt;true&lt;/span&gt;
root@server:~# cat /opt/mongodb/conf/mongo2.conf 
systemLog:
    path: /opt/mongodb/logs/mongo2.log
    logAppend: &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nb"&gt;    &lt;/span&gt;destination: file

net:
    port: 27002

storage:
    dbPath: /opt/mongodb/data/mongo2
    smallFiles: &lt;span class="nb"&gt;true&lt;/span&gt;
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como apunte importante, no se ha definido un archivo para guardar el &lt;em&gt;PID&lt;/em&gt; del proceso; &lt;em&gt;systemd&lt;/em&gt; no lo necesita y conoce el &lt;em&gt;PID&lt;/em&gt; de los procesos que levanta.&lt;/p&gt;
&lt;p&gt;Siguiendo las directivas de seguridad mínimas, los dos procesos &lt;em&gt;mongod&lt;/em&gt; van a levantarse con un usuario estándar que no sea &lt;em&gt;root&lt;/em&gt;. En este caso, toda la carpeta &lt;em&gt;/opt/mongodb/&lt;/em&gt; pertenece al usuario &lt;em&gt;mongo&lt;/em&gt;, aunque bastaría con la carpeta de datos y la de logs.&lt;/p&gt;
&lt;p&gt;Ponemos la definición de nuestras &lt;strong&gt;units&lt;/strong&gt; en la carpeta designada según el estándar, que es &lt;em&gt;/etc/systemd/system/&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /etc/systemd/system/mongo1.service 
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;MongoDB

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;User&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mongo
&lt;span class="nv"&gt;LimitFSIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitCPU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitNOFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;LimitNPROC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/rm -f /opt/mongodb/data/mongo1/mongod.lock
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/opt/mongodb/bin/mongod -f /opt/mongodb/conf/mongo1.conf

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
root@server:~# cat /etc/systemd/system/mongo2.service 
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;MongoDB

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;User&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mongo
&lt;span class="nv"&gt;LimitFSIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitCPU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitNOFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;LimitNPROC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/rm -f /opt/mongodb/data/mongo2/mongod.lock
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/opt/mongodb/bin/mongod -f /opt/mongodb/conf/mongo2.conf

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Es especialmente interesante ver que el lenguaje de la &lt;strong&gt;units&lt;/strong&gt; de &lt;em&gt;systemd&lt;/em&gt; es declarativo, y que no son &lt;em&gt;init scripts&lt;/em&gt;; &lt;em&gt;systemd&lt;/em&gt; se encarga de todo por nosotros. Basta con declarar el comando con el que levantar el servicio y el usuario con el que hacerlo.&lt;/p&gt;
&lt;p&gt;La directiva &lt;strong&gt;WantedBy&lt;/strong&gt; indica que se tiene que levantar con el &lt;strong&gt;target&lt;/strong&gt; &lt;em&gt;multi-user&lt;/em&gt;, que es el que usa &lt;em&gt;Debian&lt;/em&gt; por defecto. Un &lt;strong&gt;target&lt;/strong&gt; viene a ser el equivalente a un &lt;em&gt;runlevel&lt;/em&gt; de &lt;em&gt;sysvinit&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Hay una directiva &lt;strong&gt;ExecStartPre&lt;/strong&gt; que se encarga de eliminar el &lt;em&gt;lock file&lt;/em&gt; de &lt;em&gt;MongoDB&lt;/em&gt; por si el proceso hubiera acabado de forma inesperada. El binario &lt;em&gt;mongod&lt;/em&gt; no levanta si este fichero existe, ya que cree que ya hay una instancia de &lt;em&gt;mongod&lt;/em&gt; usando la carpeta de datos.&lt;/p&gt;
&lt;p&gt;El resto de directivas se limitan a modificar los límites de los procesos a levantar, de acuerdo a la documentación de &lt;em&gt;MongoDB&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;A partir de ahora, son &lt;strong&gt;units&lt;/strong&gt; normales del sistema y se pueden activar e iniciar. Si ya estuvieran cargados, habría que recargar la configuración de &lt;em&gt;systemd&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mongo1
root@server:~# systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mongo2
root@server:~# systemctl start mongo1
root@server:~# systemctl start mongo2
root@server:~# systemctl daemon-reload
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Uso de plantillas para evitar repetirnos&lt;/h2&gt;
&lt;p&gt;Toda &lt;strong&gt;unit&lt;/strong&gt; cuyo nombre acabe en &lt;strong&gt;arroba&lt;/strong&gt; seguido por &lt;em&gt;.service&lt;/em&gt; o cualquier otro tipo de &lt;strong&gt;unit&lt;/strong&gt;, es por convención, una &lt;strong&gt;plantilla&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;La idea es que vamos a crear un &lt;em&gt;link&lt;/em&gt; a la &lt;strong&gt;plantilla&lt;/strong&gt;, que ponga un texto detrás de la &lt;strong&gt;arroba&lt;/strong&gt;. Este texto va a estar disponible en la plantilla como &lt;strong&gt;%i&lt;/strong&gt;. De esta forma podemos "pasar un parámetro" a la plantilla, usando ese parámetro como diferenciador de los dos procesos.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Veamos un ejemplo:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Creamos dos &lt;em&gt;links&lt;/em&gt; a la &lt;strong&gt;plantilla&lt;/strong&gt; &lt;em&gt;mongodb@.service&lt;/em&gt;, con los nombres &lt;em&gt;mongodb@mongo1.service&lt;/em&gt; y &lt;em&gt;mongodb@mongo2.service&lt;/em&gt;, que son nuestras instancias. Estas instancias se rigen con las directivas de la &lt;strong&gt;plantilla&lt;/strong&gt;, con la variable &lt;strong&gt;%i&lt;/strong&gt; conteniendo los valores &lt;em&gt;mongo1&lt;/em&gt; y &lt;em&gt;mongo2&lt;/em&gt; respectivamente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# ls -l /etc/systemd/system/mongodb&lt;span class="se"&gt;\@&lt;/span&gt;*
lrwxrwxrwx &lt;span class="m"&gt;1&lt;/span&gt; root root  &lt;span class="m"&gt;16&lt;/span&gt; nov  &lt;span class="m"&gt;3&lt;/span&gt; 12:46 /etc/systemd/system/mongodb@mongo1.service -&amp;gt; mongodb@.service
lrwxrwxrwx &lt;span class="m"&gt;1&lt;/span&gt; root root  &lt;span class="m"&gt;16&lt;/span&gt; nov  &lt;span class="m"&gt;3&lt;/span&gt; 12:46 /etc/systemd/system/mongodb@mongo2.service -&amp;gt; mongodb@.service
-rw-r--r-- &lt;span class="m"&gt;1&lt;/span&gt; root root &lt;span class="m"&gt;207&lt;/span&gt; nov  &lt;span class="m"&gt;3&lt;/span&gt; 12:45 /etc/systemd/system/mongodb@.service
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora redactamos la plantilla, teniendo en cuenta los valores que se van a cambiarse por la variable &lt;strong&gt;%i&lt;/strong&gt;, que vamos a usar para identificar el fichero de configuración de cada instancia. También es posible poner otras variables en la &lt;strong&gt;plantilla&lt;/strong&gt;, como por ejemplo, el nombre de la máquina o la versión del &lt;em&gt;kernel&lt;/em&gt; de la máquina.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /etc/systemd/system/mongodb&lt;span class="se"&gt;\@&lt;/span&gt;.service 
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;MongoDB

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;User&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mongo
&lt;span class="nv"&gt;LimitFSIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitCPU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitNOFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;LimitNPROC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/rm -f /opt/mongodb/data/%i/mongod.lock
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/opt/mongodb/bin/mongod -f /opt/mongodb/conf/%i.conf

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora solo falta activar las instancias e iniciarlas, con los comandos habituales del demonio &lt;em&gt;systemd&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mongodb@mongo1
Created symlink from /etc/systemd/system/multi-user.target.wants/mongodb@mongo1.service to /etc/systemd/system/mongodb@.service.
root@server:~# systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mongodb@mongo2
Created symlink from /etc/systemd/system/multi-user.target.wants/mongodb@mongo2.service to /etc/systemd/system/mongodb@.service.
root@server:~# systemctl start mongodb@mongo1
root@server:~# systemctl start mongodb@mongo2
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto lo hemos conseguido.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="systemd"></category><category term="mongodb"></category></entry><entry><title>Restart automático de servicios con systemd</title><link href="http://www.linuxsysadmin.tk/2015/11/restart-automatico-de-servicios-con-systemd.html" rel="alternate"></link><updated>2015-11-05T22:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-11-05:2015/11/restart-automatico-de-servicios-con-systemd.html</id><summary type="html">&lt;p&gt;Cuando estamos gestionando un servidor, es posible que se caiga alguno de sus servicios. Esto es especialmente molesto cuando nos interesa tener un &lt;em&gt;uptime&lt;/em&gt; elevado. Para conseguirlo, se han utilizado diferentes maneras, desde poner personas a monitorizar en modo 24x7 hasta herramientas auxiliares como gestores tipo &lt;em&gt;runit&lt;/em&gt;, &lt;em&gt;supervisor&lt;/em&gt; o &lt;em&gt;monit&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Con la entrada en escena de &lt;em&gt;systemd&lt;/em&gt; en la mayoría de distribuciones grandes de &lt;em&gt;linux&lt;/em&gt; este problema se ha acabado; el mismo proceso que hace de &lt;strong&gt;init&lt;/strong&gt; puede encargarse de mantener los procesos levantados, y reiniciarlos en caso de caída.&lt;/p&gt;
&lt;p&gt;En este tutorial pretendo hacer que un servicio estándar se vea beneficiado de un &lt;strong&gt;override&lt;/strong&gt;, que permita el inicio automático de un servicio cuando se cae, sin tener que reescribir la &lt;strong&gt;unit&lt;/strong&gt; que se encarga del servicio o proceso.&lt;/p&gt;
&lt;p&gt;Partimos de un servidor básico &lt;em&gt;Linux&lt;/em&gt; con &lt;em&gt;systemd&lt;/em&gt;. En este caso vamos a utilizar la última versión estable de &lt;em&gt;Debian&lt;/em&gt;, a la que le vamos a instalar un servicio estándar como &lt;em&gt;nginx&lt;/em&gt; que nos va a servir como conejillo de indias.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# apt-get install nginx-light
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Procedimiento&lt;/h2&gt;
&lt;p&gt;Como comprobación previa, observemos como este &lt;strong&gt;restart&lt;/strong&gt; automático no funciona; tenemos el servicio en ejecución, lo matamos y observamos que no se levanta de nuevo, por mucho que esperemos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;685&lt;/span&gt;  0.0  0.8   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2240&lt;/span&gt; pts/0    S+   11:41   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;662&lt;/span&gt;  0.0  0.7   &lt;span class="m"&gt;6356&lt;/span&gt;  &lt;span class="m"&gt;1856&lt;/span&gt; ?        Ss   11:41   0:00 nginx: master process /usr/sbin/nginx -g daemon on&lt;span class="p"&gt;;&lt;/span&gt; master_process on&lt;span class="p"&gt;;&lt;/span&gt;
www-data   &lt;span class="m"&gt;663&lt;/span&gt;  0.1  0.9   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2456&lt;/span&gt; ?        S    11:41   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;664&lt;/span&gt;  0.0  0.9   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2456&lt;/span&gt; ?        S    11:41   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;665&lt;/span&gt;  0.0  0.9   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2456&lt;/span&gt; ?        S    11:41   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;666&lt;/span&gt;  0.1  0.9   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2456&lt;/span&gt; ?        S    11:41   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
root@server:~# &lt;span class="nb"&gt;kill &lt;/span&gt;662
root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;691&lt;/span&gt;  0.0  0.8   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2220&lt;/span&gt; pts/0    S+   11:41   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora necesitamos localizar el nombre de la &lt;strong&gt;unit&lt;/strong&gt; que se encarga de ese servicio, puesto que la carpeta de &lt;strong&gt;overrides&lt;/strong&gt; debe llamarse igual.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# systemctl list-units -a &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
  nginx.service    loaded    inactive dead    A high performance web server and a reverse proxy server
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como curiosidad, este fichero se encuentra en &lt;em&gt;/lib/systemd/system/&lt;/em&gt;, siguiendo las convenciones del empaquetado de &lt;em&gt;Debian&lt;/em&gt;. Alternativamente, podemos localizar los ficheros instalados por un paquete con el comando &lt;em&gt;dpkg -L nginx-light&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# ls -lh /lib/systemd/system/nginx.service 
-rw-r--r-- &lt;span class="m"&gt;1&lt;/span&gt; root root &lt;span class="m"&gt;986&lt;/span&gt; dic  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;2014&lt;/span&gt; /lib/systemd/system/nginx.service
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En caso de ser una &lt;strong&gt;unit&lt;/strong&gt; escrita por nosotros, se encontraría en &lt;em&gt;/etc/systemd/system/&lt;/em&gt;. Esta es la convención:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;/lib/systemd/system/&lt;/em&gt; &amp;rarr; &lt;strong&gt;units&lt;/strong&gt; de sistema, puestas por los paquetes instalados&lt;/li&gt;
&lt;li&gt;&lt;em&gt;/lib/systemd/system/&lt;/em&gt; &amp;rarr; &lt;strong&gt;units&lt;/strong&gt; o &lt;strong&gt;overrides&lt;/strong&gt; puestos por el usuario (nosotros)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Para añadir nuevas directivas (&lt;strong&gt;overrides&lt;/strong&gt;) a una &lt;strong&gt;unit&lt;/strong&gt; sin reescribirla entera, basta con crear una carpeta con su mismo nombre, concatenando &lt;strong&gt;.d&lt;/strong&gt;. Dentro podemos poner tantos ficheros &lt;em&gt;.conf&lt;/em&gt; como creamos necesarios, añadiendo las directivas que queramos añadir o modificar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mkdir /etc/systemd/system/nginx.service.d
root@server:~# cat /etc/systemd/system/nginx.service.d/autorestart.conf
&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Restart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;always
&lt;span class="nv"&gt;RestartSec&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este caso, se ha indicado que queremos un &lt;strong&gt;restart&lt;/strong&gt; siempre, sean cuales sean las circunstancias en las que se cayó el proceso, y que espere 1 segundo antes de intentarlo. Por como está hecho &lt;em&gt;systemd&lt;/em&gt;, &lt;strong&gt;no&lt;/strong&gt; va a levantar un servicio que hemos parado invocando el comando &lt;em&gt;systemctl&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Para que los cambios en el fichero de configuración se apliquen es necesario recargar las configuraciones, indicando a &lt;em&gt;systemd&lt;/em&gt; que tienen que recargarlas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# systemctl daemon-reload
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comprobación&lt;/h2&gt;
&lt;p&gt;Básicamente vamos a repetir el paso de la comprobación; se localiza el proceso &lt;strong&gt;master&lt;/strong&gt; y se finaliza (por ejemplo, con un &lt;strong&gt;SIGTERM&lt;/strong&gt; normal).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;782&lt;/span&gt;  0.0  0.8   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2252&lt;/span&gt; pts/0    S+   11:56   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;776&lt;/span&gt;  0.0  0.7   &lt;span class="m"&gt;6356&lt;/span&gt;  &lt;span class="m"&gt;1936&lt;/span&gt; ?        Ss   11:56   0:00 nginx: master process /usr/sbin/nginx -g daemon on&lt;span class="p"&gt;;&lt;/span&gt; master_process on&lt;span class="p"&gt;;&lt;/span&gt;
www-data   &lt;span class="m"&gt;777&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2536&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;778&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2536&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;779&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2536&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;780&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2536&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
root@server:~# &lt;span class="nb"&gt;kill &lt;/span&gt;776
root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;787&lt;/span&gt;  0.0  0.9   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2280&lt;/span&gt; pts/0    S+   11:56   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora solo hay que esperar el paso de los segundos configurados, y volver a ver si el servicio está corriendo; aunque en este esperé algo menos de lo configurado; la paciencia no es una de mis virtudes...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;789&lt;/span&gt;  0.0  0.8   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2192&lt;/span&gt; pts/0    S+   11:56   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;791&lt;/span&gt;  0.0  0.9   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2280&lt;/span&gt; pts/0    S+   11:56   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;802&lt;/span&gt;  0.0  0.8   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2236&lt;/span&gt; pts/0    S+   11:56   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;796&lt;/span&gt;  0.0  0.7   &lt;span class="m"&gt;6356&lt;/span&gt;  &lt;span class="m"&gt;1932&lt;/span&gt; ?        Ss   11:56   0:00 nginx: master process /usr/sbin/nginx -g daemon on&lt;span class="p"&gt;;&lt;/span&gt; master_process on&lt;span class="p"&gt;;&lt;/span&gt;
www-data   &lt;span class="m"&gt;797&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2592&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;798&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2592&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;799&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2592&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;800&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2532&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto tenemos nuestro &lt;strong&gt;autorestart&lt;/strong&gt; para este servicio.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="systemd"></category><category term="nginx"></category></entry><entry><title>Liberando memoria caché</title><link href="http://www.linuxsysadmin.tk/2015/11/liberando-memoria-cache.html" rel="alternate"></link><updated>2015-11-02T14:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-11-02:2015/11/liberando-memoria-cache.html</id><summary type="html">&lt;p&gt;A veces nos encontramos que nuestro sistema linux parece tener la memoria &lt;em&gt;virtual&lt;/em&gt; ocupada, cuando no tenemos nada de memoria &lt;em&gt;RSS&lt;/em&gt;; esto no es un problema, ya que por la forma de funcionar del &lt;em&gt;memory manager&lt;/em&gt; de linux, se conserva "por si acaso" y se libera cuando realmente se necesita.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;free -m
             total       used       free     shared    buffers     cached
Mem:          &lt;span class="m"&gt;3858&lt;/span&gt;       &lt;span class="m"&gt;3226&lt;/span&gt;        &lt;span class="m"&gt;632&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;        &lt;span class="m"&gt;114&lt;/span&gt;       2545
-/+ buffers/cache:        &lt;span class="m"&gt;566&lt;/span&gt;       3291
Swap:         &lt;span class="m"&gt;2381&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;       2381
gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Sin embargo este detalle nos puede resultar molesto y puede que queramos &lt;strong&gt;liberar&lt;/strong&gt; esa memoria de verdad, por ejemplo, para comparar memoria real ocupada por el sistema o sencillamente porque así lo queremos.&lt;/p&gt;
&lt;p&gt;En este caso no tenemos mas remedio que solicitar el &lt;em&gt;memory manager&lt;/em&gt; que la libere, escribiendo en el fichero de control habilitado para ello, de acuerdo a la &lt;a href="https://www.kernel.org/doc/Documentation/sysctl/vm.txt"&gt;documentación del &lt;em&gt;kernel&lt;/em&gt; de linux&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;drop_caches

Writing to this will cause the kernel to drop clean caches, as well as
reclaimable slab objects like dentries and inodes.  Once dropped, their
memory becomes free.

To free pagecache:
    &lt;span class="nb"&gt;echo &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &amp;gt; /proc/sys/vm/drop_caches
To free reclaimable slab objects &lt;span class="o"&gt;(&lt;/span&gt;includes dentries and inodes&lt;span class="o"&gt;)&lt;/span&gt;:
    &lt;span class="nb"&gt;echo &lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt; &amp;gt; /proc/sys/vm/drop_caches
To free slab objects and pagecache:
    &lt;span class="nb"&gt;echo &lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt; &amp;gt; /proc/sys/vm/drop_caches

This is a non-destructive operation and will not free any dirty objects.
To increase the number of objects freed by this operation, the user may run
&lt;span class="sb"&gt;`&lt;/span&gt;sync&lt;span class="err"&gt;&amp;#39;&lt;/span&gt; prior to writing to /proc/sys/vm/drop_caches.  This will minimize the
number of dirty objects on the system and create more candidates to be
dropped.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Este fichero viene por defecto con permisos de escritura solamente para el usuario &lt;strong&gt;root&lt;/strong&gt; y no se puede escribir sin el mismo. Como no queremos trabajar con el usuario &lt;strong&gt;root&lt;/strong&gt;, vamos a usar el comando &lt;em&gt;sudo&lt;/em&gt; con un usuario normal:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;sudo bash -c &lt;span class="s2"&gt;&amp;quot;echo 3 &amp;gt; /proc/sys/vm/drop_caches&amp;quot;&lt;/span&gt;
gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Alternativamente, podemos utilizar el comando &lt;em&gt;tee&lt;/em&gt; para realizar la misma operación, sin el envoltorio de &lt;em&gt;bash&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;echo &lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sudo tee /proc/sys/vm/drop_caches
3
gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y finalmente nuestra memoria queda vacía de todo aquello que no era indispensable para la ejecución del sistema.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;free -m
             total       used       free     shared    buffers     cached
Mem:          &lt;span class="m"&gt;3858&lt;/span&gt;        &lt;span class="m"&gt;752&lt;/span&gt;       &lt;span class="m"&gt;3105&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;          &lt;span class="m"&gt;2&lt;/span&gt;        207
-/+ buffers/cache:        &lt;span class="m"&gt;542&lt;/span&gt;       3315
Swap:         &lt;span class="m"&gt;2381&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;       2381
gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;¡Acabamos de liberar 2 gigabytes de memoria!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CUIDADO&lt;/strong&gt;: Esta operación puede afectar el rendimiento puntual del sistema, ya que en caso de volver a necesitar la información &lt;em&gt;cacheada&lt;/em&gt;, deberá volver a recargar la memoria, probablemente desde disco.&lt;/p&gt;</summary><category term="linux"></category><category term="kernel"></category><category term="memory manager"></category><category term="drop caches"></category></entry><entry><title>Ocultando puertos con port knocking</title><link href="http://www.linuxsysadmin.tk/2015/10/ocultando-puertos-con-port-knocking.html" rel="alternate"></link><updated>2015-10-29T11:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-10-29:2015/10/ocultando-puertos-con-port-knocking.html</id><summary type="html">&lt;p&gt;En este artículo vamos a enseñar como ocultar un puerto tras el firewall, de forma que solamente se abra tras utilizar el protocolo &lt;em&gt;port knocking&lt;/em&gt;. Las tecnologías usadas van a ser &lt;em&gt;firehol&lt;/em&gt; como firewall y el demonio &lt;em&gt;knockd&lt;/em&gt; ocultando el &lt;em&gt;SSH&lt;/em&gt;, aunque vamos a permitir acceder al puerto de HTTP.&lt;/p&gt;
&lt;p&gt;El protocolo de &lt;em&gt;port knocking&lt;/em&gt; es un sistema en el que para abrir la conectividad en un puerto se debe primero abrir una secuencia concreta a otros puertos, sean &lt;em&gt;TCP&lt;/em&gt; o &lt;em&gt;UDP&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Para conseguir este objetivo, se van a usar las siguientes tecnologías:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Debian jessie&lt;/strong&gt;: Como distribución base; podría ser cualquier otra&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Firehol&lt;/strong&gt;: Scripts para levantar un firewall basado en &lt;em&gt;iptables&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El hardware va a ser uno con capacidades limitadas, virtualizado en VirtualBox.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPUs&lt;/strong&gt;: 1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memoria&lt;/strong&gt;: 256 Mb&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disco&lt;/strong&gt;: 2 Gb&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Red&lt;/strong&gt;: 1 interfaz (&lt;em&gt;eth0&lt;/em&gt;) &lt;em&gt;host-only&lt;/em&gt; o &lt;em&gt;bridged&lt;/em&gt; con IP fija&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La instalación base es una &lt;em&gt;Debian&lt;/em&gt; mínima instalada con el CD netinstall, con todo desmarcado y con el servidor de &lt;em&gt;SSH&lt;/em&gt; previamente instalado.&lt;/p&gt;
&lt;h2&gt;Instalación del servidor&lt;/h2&gt;
&lt;p&gt;Para empezar, vamos a instalar los dos servicios implicados:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# apt-get install firehol knockd
...
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Configuramos las reglas del firewall, de acuerdo a la documentación relacionada con &lt;em&gt;port knocking&lt;/em&gt;. Se define un nivel de protección máximo, ya que se trata de la interfaz que deberá estar accesible desde internet; esto nos evita la mayoría de ataques conocidos en la capa 3 y 4.&lt;/p&gt;
&lt;p&gt;En cuanto a las conectividad, vamos a permitir que este servidor acceda a servicios &lt;em&gt;DNS&lt;/em&gt; y &lt;em&gt;HTTP&lt;/em&gt;, que es lo justo para actualizarse. Como servidor vamos a permitir el acceso a &lt;em&gt;HTTP&lt;/em&gt; (ya que en el ejemplo, esta máquina va a servir como servidor &lt;em&gt;HTTP&lt;/em&gt;) y a &lt;em&gt;SSH&lt;/em&gt; siempre y cuando se cumpla con el protocolo de seguridad.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /etc/firehol/firehol.conf 
version 5

interface any world
    protection strong
    client &lt;span class="s2"&gt;&amp;quot;dns http&amp;quot;&lt;/span&gt; accept
    server http accept
    server ssh accept with knock hidden
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Acto seguido vamos a definir las reglas para que se abra el &lt;em&gt;knock hidden&lt;/em&gt; (que corresponde con el puerto &lt;em&gt;SSH&lt;/em&gt;) si se completa la secuencia de &lt;em&gt;knock&lt;/em&gt;. En este caso concreto, se indica una secuencia de los puertos &lt;em&gt;TCP&lt;/em&gt; 123, 456 y 789; aunque es posible definir puertos &lt;em&gt;UDP&lt;/em&gt;, dejamos sin indicarlo, que nos los va a definir como &lt;em&gt;TCP&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Como medida de seguridad vamos a indicar un tiempo máximo de 10 segundos para completar la secuencia de &lt;em&gt;knock&lt;/em&gt; y un autocierre del puerto a los 5 segundos (aunque firehol va a permitir las conexiones que se hayan establecido en esos 5 segundos).&lt;/p&gt;
&lt;p&gt;Es especialmente interesante ver que la regla incluye la dirección origen, con lo que la apertura de puerto solo será visible desde la máquina que completó la secuencia de &lt;em&gt;knock&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /etc/knockd.conf 
&lt;span class="o"&gt;[&lt;/span&gt;options&lt;span class="o"&gt;]&lt;/span&gt;
    UseSyslog

&lt;span class="o"&gt;[&lt;/span&gt;SSH&lt;span class="o"&gt;]&lt;/span&gt;
    &lt;span class="nv"&gt;sequence&lt;/span&gt;      &lt;span class="o"&gt;=&lt;/span&gt; 123,456,789
    &lt;span class="nv"&gt;seq_timeout&lt;/span&gt;   &lt;span class="o"&gt;=&lt;/span&gt; 10
    &lt;span class="nv"&gt;start_command&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; iptables -A knock_hidden -s %IP% -j ACCEPT
    &lt;span class="nv"&gt;cmd_timeout&lt;/span&gt;   &lt;span class="o"&gt;=&lt;/span&gt; 5
    &lt;span class="nv"&gt;stop_command&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; iptables -D knock_hidden -s %IP% -j ACCEPT
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como medida de seguridad, &lt;em&gt;Debian&lt;/em&gt; tiene una protección para levantar ambos servicios, así que tenemos que indicarle que queremos que se puedan levantar, editando otros ficheros de configuración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /etc/default/knockd 
...
&lt;span class="nv"&gt;START_KNOCKD&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1
...
root@server:~# cat /etc/default/firehol 
...
&lt;span class="nv"&gt;START_FIREHOL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;YES
...
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente podemos levantar los servicios de &lt;em&gt;port knocking&lt;/em&gt; y de &lt;em&gt;firewall&lt;/em&gt;, usando las herramientas estándares que nos ofrece la distribución.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# service knockd restart
root@server:~# service firehol restart
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comprobación de funcionamiento&lt;/h2&gt;
&lt;p&gt;Para comprobar el funcionamiento basta con comprobar que el puerto está normalmente cerrado. Personalmente he usado &lt;em&gt;nmap&lt;/em&gt;, aunque se podría usar &lt;em&gt;netcat&lt;/em&gt; o &lt;em&gt;telnet&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;nmap -PN 192.168.56.3 -p 22

Starting Nmap 5.21 &lt;span class="o"&gt;(&lt;/span&gt; http://nmap.org &lt;span class="o"&gt;)&lt;/span&gt; at 2015-10-28 17:33 CET
Nmap scan report &lt;span class="k"&gt;for&lt;/span&gt; server &lt;span class="o"&gt;(&lt;/span&gt;192.168.56.3&lt;span class="o"&gt;)&lt;/span&gt;
Host is up.
PORT   STATE    SERVICE
22/tcp filtered ssh

Nmap &lt;span class="k"&gt;done&lt;/span&gt;: &lt;span class="m"&gt;1&lt;/span&gt; IP address &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; host up&lt;span class="o"&gt;)&lt;/span&gt; scanned in 2.13 seconds
gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vemos que sale &lt;strong&gt;filtered&lt;/strong&gt;, que significa que el firewall lo está bloqueando. Ahora vamos a lanzar la secuencia de &lt;em&gt;knock&lt;/em&gt; usando el helper &lt;strong&gt;knock&lt;/strong&gt;, que en &lt;em&gt;Debian&lt;/em&gt; se encuentra en el mismo paquete &lt;em&gt;knockd&lt;/em&gt;. Acto seguido, el puerto de &lt;em&gt;SSH&lt;/em&gt; queda abierto (en otras palabras: escuchando). Ahora sería posible iniciar sesión por &lt;em&gt;SSH&lt;/em&gt; en la máquina.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;knock 192.168.56.3 &lt;span class="m"&gt;123&lt;/span&gt; &lt;span class="m"&gt;456&lt;/span&gt; 789
gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;nmap -PN 192.168.56.3 -p 22

Starting Nmap 5.21 &lt;span class="o"&gt;(&lt;/span&gt; http://nmap.org &lt;span class="o"&gt;)&lt;/span&gt; at 2015-10-28 17:34 CET
Nmap scan report &lt;span class="k"&gt;for&lt;/span&gt; server &lt;span class="o"&gt;(&lt;/span&gt;192.168.56.3&lt;span class="o"&gt;)&lt;/span&gt;
Host is up &lt;span class="o"&gt;(&lt;/span&gt;0.0011s latency&lt;span class="o"&gt;)&lt;/span&gt;.
PORT   STATE SERVICE
22/tcp open  ssh

Nmap &lt;span class="k"&gt;done&lt;/span&gt;: &lt;span class="m"&gt;1&lt;/span&gt; IP address &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; host up&lt;span class="o"&gt;)&lt;/span&gt; scanned in 0.07 seconds
gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente comprobamos que, transcurridos los 5 segundos configurados, el puerto vuelve a verse como &lt;strong&gt;filtrado&lt;/strong&gt;, con lo que no se puede establecer nuevas conexiones en este puerto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;nmap -PN 192.168.56.3 -p 22

Starting Nmap 5.21 &lt;span class="o"&gt;(&lt;/span&gt; http://nmap.org &lt;span class="o"&gt;)&lt;/span&gt; at 2015-10-28 17:34 CET
Nmap scan report &lt;span class="k"&gt;for&lt;/span&gt; server &lt;span class="o"&gt;(&lt;/span&gt;192.168.56.3&lt;span class="o"&gt;)&lt;/span&gt;
Host is up.
PORT   STATE    SERVICE
22/tcp filtered ssh

Nmap &lt;span class="k"&gt;done&lt;/span&gt;: &lt;span class="m"&gt;1&lt;/span&gt; IP address &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; host up&lt;span class="o"&gt;)&lt;/span&gt; scanned in 2.08 seconds
gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto queda protegido el acceso por &lt;em&gt;SSH&lt;/em&gt; a la máquina.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="firehol"></category><category term="port knocking"></category><category term="ssh"></category><category term="nmap"></category></entry><entry><title>Virtualizando contenedores LXC con acceso a la red local</title><link href="http://www.linuxsysadmin.tk/2015/10/virtualizando-contenedores-lxc-con-acceso-red-local.html" rel="alternate"></link><updated>2015-10-15T12:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-10-15:2015/10/virtualizando-contenedores-lxc-con-acceso-red-local.html</id><summary type="html">&lt;p&gt;En este tutorial se propone montar un servidor de contenedores LXC, de forma que todos los contenedores queden expuestos a la misma red que el servidor que los aloja. Para protegerlos de posibles ataques de esta red, pondremos un firewall basado en &lt;em&gt;iptables&lt;/em&gt; mediante una capa de abstracción llamada &lt;em&gt;firehol&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Para conseguir este objetivo, se van a usar las siguientes tecnologías:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Debian jessie&lt;/strong&gt;: Es necesario usar alguna distribución de linux para hacer funcionar LXC&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LXC&lt;/strong&gt;: Tecnología que permite aislar los contenedores entre sí y darles entidad propia&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bridges&lt;/strong&gt;: Un bridge es en software el equivalente a un switch hardware&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Firehol&lt;/strong&gt;: Una serie de scripts para construir firewalls basados en iptables de forma fácil&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En cuanto a las capacidades hardware, vamos a hacer el tutorial con un equipo de capacidades modestas, virtualizado en una máquina virtual VirtualBox.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPUs&lt;/strong&gt;: 1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memoria&lt;/strong&gt;: 256 Mb&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disco&lt;/strong&gt;: 2 Gb&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Red&lt;/strong&gt;: 1 interfaz (&lt;em&gt;eth0&lt;/em&gt;) &lt;em&gt;host-only&lt;/em&gt; o &lt;em&gt;bridged&lt;/em&gt; con IP fija&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Partimos de una distribución &lt;em&gt;Debian jessie&lt;/em&gt; instalada con un CD &lt;em&gt;netinstall&lt;/em&gt; y con el único paquete instalado &lt;em&gt;openssh-server&lt;/em&gt;, para mi comodidad.&lt;/p&gt;
&lt;h2&gt;Preparar el servidor&lt;/h2&gt;
&lt;p&gt;El primer paso consiste en instalar las tecnologías usadas:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# apt-get install bridge-utils firehol lxc
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
...
Configurando lxc &lt;span class="o"&gt;(&lt;/span&gt;1:1.0.6-6+deb8u1&lt;span class="o"&gt;)&lt;/span&gt; ...
Configurando dh-python &lt;span class="o"&gt;(&lt;/span&gt;1.20141111-2&lt;span class="o"&gt;)&lt;/span&gt; ...
Procesando disparadores para libc-bin &lt;span class="o"&gt;(&lt;/span&gt;2.19-18+deb8u1&lt;span class="o"&gt;)&lt;/span&gt; ...
Procesando disparadores para systemd &lt;span class="o"&gt;(&lt;/span&gt;215-17+deb8u2&lt;span class="o"&gt;)&lt;/span&gt; ...
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Acto seguido debemos modificar la configuración de red, para que la interfaz de red de la máquina represente la salida de todas las IPs que maneja el bridge y para que el host obtenga una dirección de red en el bridge.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ANTES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/network/interfaces
&lt;span class="nb"&gt;source&lt;/span&gt; /etc/network/interfaces.d/*

auto lo
iface lo inet loopback

auto eth0
iface eth0 inet static
    address 192.168.56.4
    netmask 255.255.255.0
    gateway 192.168.56.1
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;DESPUES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/network/interfaces
&lt;span class="nb"&gt;source&lt;/span&gt; /etc/network/interfaces.d/*

auto lo
iface lo inet loopback

auto lxc0
iface lxc0 inet static
    bridge_ports eth0
    address 192.168.56.4
    netmask 255.255.255.0
    gateway 192.168.56.1
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este punto es necesario reconfigurar la red, siendo especialmente importante que &lt;em&gt;eth0&lt;/em&gt; quede sin dirección IP asignada (en mi caso tuve que reiniciar la máquina).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# ip addr
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu &lt;span class="m"&gt;65536&lt;/span&gt; qdisc noqueue state UNKNOWN group default 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu &lt;span class="m"&gt;1500&lt;/span&gt; qdisc pfifo_fast master lxc0 state UP group default qlen 1000
    link/ether 08:00:27:e4:0a:60 brd ff:ff:ff:ff:ff:ff
3: lxc0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu &lt;span class="m"&gt;1500&lt;/span&gt; qdisc noqueue state UP group default 
    link/ether 08:00:27:e4:0a:60 brd ff:ff:ff:ff:ff:ff
    inet 192.168.56.4/24 brd 192.168.56.255 scope global lxc0
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:fee4:a60/64 scope link 
       valid_lft forever preferred_lft forever
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El último paso consiste en activar el firewall con unas reglas básicas, para proteger el equipo anfitrión de posibles ataques o intrusiones, dejando solamente el acceso a SSH. Con firehol es posible combinar el demonio &lt;em&gt;knockd&lt;/em&gt; para ocultar el puerto tras una secuencia de port knocking; en principio sería suficiente con forzar la entrada SSH por claves RSA.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf 
interface lxc0 world
    policy drop
    protection strong
    server ssh accept
    client all accept
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hay que modificar otro fichero para permitir el inicio del firewall:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ANTES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# grep START /etc/default/firehol 
&lt;span class="c"&gt;#To enable firehol at startup set START_FIREHOL=YES&lt;/span&gt;
&lt;span class="nv"&gt;START_FIREHOL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;NO
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;DESPUES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# grep START /etc/default/firehol 
&lt;span class="c"&gt;#To enable firehol at startup set START_FIREHOL=YES&lt;/span&gt;
&lt;span class="nv"&gt;START_FIREHOL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;YES
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para acabar, (re)iniciamos el servicio firehol.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# service firehol restart

Broadcast message from systemd-journald@lxc &lt;span class="o"&gt;(&lt;/span&gt;Wed 2015-10-14 16:59:30 CEST&lt;span class="o"&gt;)&lt;/span&gt;:

FireHOL&lt;span class="o"&gt;[&lt;/span&gt;620&lt;span class="o"&gt;]&lt;/span&gt;: Firewall has been stopped. Policy is ACCEPT EVERYTHING!


Message from syslogd@lxc at Oct &lt;span class="m"&gt;14&lt;/span&gt; 16:59:30 ...
 FireHOL&lt;span class="o"&gt;[&lt;/span&gt;493&lt;span class="o"&gt;]&lt;/span&gt;: Firewall has been stopped. Policy is ACCEPT EVERYTHING!
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Creación de contenedores&lt;/h2&gt;
&lt;p&gt;La creación de contenedores pasa por usar las herramientas estándar de la distribución, a lo solo tendremos que modificar algunas configuraciones propias de nuestra red.&lt;/p&gt;
&lt;p&gt;Creamos un contenedor &lt;em&gt;webserver&lt;/em&gt; como demostración. La primera que se crea es un poco lenta porque hace un &lt;em&gt;debootstrap&lt;/em&gt; de una distribución debian estable para crear una cache en &lt;em&gt;/var/cache/lxc&lt;/em&gt;; las siguientes se benefician de esta caché y solo la actualizan, acelerando el proceso.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-create -n webserver -t debian
debootstrap is /usr/sbin/debootstrap
Checking cache download in /var/cache/lxc/debian/rootfs-jessie-i386 ... 
Downloading debian minimal ...
...
I: Base system installed successfully.
Download complete.
Copying rootfs to /var/lib/lxc/webserver/rootfs...
...
Current default &lt;span class="nb"&gt;time &lt;/span&gt;zone: &lt;span class="s1"&gt;&amp;#39;Europe/Madrid&amp;#39;&lt;/span&gt;
Local &lt;span class="nb"&gt;time &lt;/span&gt;is now:      Wed Oct &lt;span class="m"&gt;14&lt;/span&gt; 17:26:37 CEST 2015.
Universal Time is now:  Wed Oct &lt;span class="m"&gt;14&lt;/span&gt; 15:26:37 UTC 2015.

Root password is &lt;span class="s1"&gt;&amp;#39;sFj7Jm9N&amp;#39;&lt;/span&gt;, please change !
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Acabada la generación del contenedor, vamos a configurarle algunos parámetros; que tenga una interfaz &lt;em&gt;eth0&lt;/em&gt; activa y enchufada al bridge &lt;em&gt;lxc0&lt;/em&gt;, y que el contenedor se autoinicie en cada reinicio del anfitrión.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /var/lib/lxc/webserver/config 
...
lxc.start.auto &lt;span class="o"&gt;=&lt;/span&gt; 1
lxc.network.type &lt;span class="o"&gt;=&lt;/span&gt; veth
lxc.network.flags &lt;span class="o"&gt;=&lt;/span&gt; up
lxc.network.link &lt;span class="o"&gt;=&lt;/span&gt; lxc0
lxc.network.name &lt;span class="o"&gt;=&lt;/span&gt; eth0
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para que su interfaz de red sea funcional, vamos a configurarle una dirección IP. Todo esto se hace en los ficheros habituales, teniendo en cuenta que un contenedor es una jaula, y que esta se encuentra en &lt;em&gt;/var/lib/lxc/webserver/rootfs/&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /var/lib/lxc/webserver/rootfs/etc/network/interfaces
auto lo
iface lo inet loopback

auto eth0
iface eth0 inet static
    address 192.168.56.10
    netmask 255.255.255.0
    gateway 192.168.56.1
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El contenedor ya está funcional, y se puede levantar:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-start -n webserver -d
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Sin embargo, el firewall impide que se llegue al mismo; tendremos que poner reglas para permitir el flujo de red hacia la nueva dirección IP configurada para el contenedor. Esto se consigue con reglas de &lt;em&gt;forward&lt;/em&gt; que entren por el bridge y salgan por el mismo hacia nuestro contenedor.&lt;/p&gt;
&lt;p&gt;Ya de paso habilitamos reglas para que todo lo que pase por el bridge hacia internet se permita. Como particularidad de nuestra red, el servidor anfitrión tiene un servidor DNS &lt;em&gt;dnsmasq&lt;/em&gt;; así que añadimos también esa ruta.&lt;/p&gt;
&lt;p&gt;Por ejemplo, suponiendo que queremos habilitar el servicio &lt;em&gt;SSH&lt;/em&gt; (tcp 22) y el puerto del servicio &lt;em&gt;HTTP&lt;/em&gt; (tcp 80), pondremos lo siguiente en la configuración del firewall (tras lo cual lo reiniciaremos):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf 
interface lxc0 world
    policy drop
    protection strong
    server ssh accept
    client all accept

router internal inface lxc0 outface lxc0
    policy drop
    client all accept
    group with dst not &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;UNROUTABLE_IPS&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
        route all accept
    group end
    group with dst 192.168.56.1
        route dns accept
    group end
    group with dst 192.168.56.10
        route ssh accept
        route http accept
    group end
root@lxc:~# service firehol restart

Broadcast message from systemd-journald@lxc &lt;span class="o"&gt;(&lt;/span&gt;Wed 2015-10-14 17:43:38 CEST&lt;span class="o"&gt;)&lt;/span&gt;:

FireHOL&lt;span class="o"&gt;[&lt;/span&gt;8690&lt;span class="o"&gt;]&lt;/span&gt;: Firewall has been stopped. Policy is ACCEPT EVERYTHING!


Message from syslogd@lxc at Oct &lt;span class="m"&gt;14&lt;/span&gt; 17:43:38 ...
 FireHOL&lt;span class="o"&gt;[&lt;/span&gt;8565&lt;span class="o"&gt;]&lt;/span&gt;: Firewall has been stopped. Policy is ACCEPT EVERYTHING!
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y solamente queda entrar al contenedor, por ejemplo por &lt;em&gt;SSH&lt;/em&gt; para instalar lo que se necesite; en este caso con un &lt;em&gt;nginx&lt;/em&gt; sería suficiente como demostración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;ssh root@192.168.56.10
root@192.168.56.10&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 

The programs included with the Debian GNU/Linux system are free software&lt;span class="p"&gt;;&lt;/span&gt;
the exact distribution terms &lt;span class="k"&gt;for&lt;/span&gt; each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
root@webserver:~# apt-get install nginx-light
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
Se instalarán los siguientes paquetes extras:
  nginx-common
Paquetes sugeridos:
  fcgiwrap nginx-doc ssl-cert
Se instalarán los siguientes paquetes NUEVOS:
  nginx-common nginx-light
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;2&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;439&lt;/span&gt; kB de archivos.
Se utilizarán 1.040 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
Configurando nginx-common &lt;span class="o"&gt;(&lt;/span&gt;1.6.2-5&lt;span class="o"&gt;)&lt;/span&gt; ...
Configurando nginx-light &lt;span class="o"&gt;(&lt;/span&gt;1.6.2-5&lt;span class="o"&gt;)&lt;/span&gt; ...
Procesando disparadores para systemd &lt;span class="o"&gt;(&lt;/span&gt;215-17+deb8u2&lt;span class="o"&gt;)&lt;/span&gt; ...
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto ya tenemos nuestro contenedor en marcha y ofreciendo servicios en nuestra red local de forma segura.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="lxc"></category><category term="bridge"></category><category term="firehol"></category></entry></feed>