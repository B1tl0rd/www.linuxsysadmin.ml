<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Linux Sysadmin</title><link href="http://www.linuxsysadmin.tk/" rel="alternate"></link><link href="http://www.linuxsysadmin.tk/feeds/all.atom.xml" rel="self"></link><id>http://www.linuxsysadmin.tk/</id><updated>2015-12-08T12:30:00+01:00</updated><entry><title>Construyendo una replica set en mongodb</title><link href="http://www.linuxsysadmin.tk/2015/12/construyendo-una-replica-set-en-mongodb.html" rel="alternate"></link><updated>2015-12-08T12:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-12-08:2015/12/construyendo-una-replica-set-en-mongodb.html</id><summary type="html">&lt;p&gt;Muchas veces nos interesa obtener alta disponibilidad en los servicios que gestionamos. No hay nada mas desagradable que una llamada a las tantas de la noche porque se ha caído un nodo de una base de datos y no damos servicio. Para eso &lt;em&gt;mongodb&lt;/em&gt; nos ofrece el mecanismo de replicación.&lt;/p&gt;
&lt;p&gt;En este artículo vamos a montar una &lt;em&gt;replica set&lt;/em&gt;, de forma que si se cayera un nodo de la base de datos, otro asumiría su rol, de forma que se seguiría dando servicio.&lt;/p&gt;
&lt;p&gt;Nuestra &lt;em&gt;replica set&lt;/em&gt; va a tener 3 nodos, que vamos a alojar en 3 máquinas distintas, de forma que la caída de una máquina afecte solamente a 1 proceso de &lt;em&gt;mongodb&lt;/em&gt;. La caonfiguración de 3 nodos nos da una tolerancia a fallos de 1 máquina; mientras queden 2, el clúster va a seguir operativo.&lt;/p&gt;
&lt;h2&gt;Descripción del entorno&lt;/h2&gt;
&lt;p&gt;Disponemos de 3 máquinas que vamos a llamar &lt;strong&gt;mongo1&lt;/strong&gt;, &lt;strong&gt;mongo2&lt;/strong&gt; y &lt;strong&gt;mongo3&lt;/strong&gt;. Cada una funciona con un sistema operativo &lt;em&gt;Debian jessie&lt;/em&gt; con &lt;em&gt;systemd&lt;/em&gt; y cuenta 1 gb de disco y con 256 mb de memoria; para esta demostración no se necesita mas.&lt;/p&gt;
&lt;p&gt;Como pequeño detalle, las máquinas se van referir entre ellas por nombre, pero como no me interesa poner una solución completa de &lt;em&gt;DNS&lt;/em&gt;, he puesto en el fichero &lt;em&gt;/etc/hosts&lt;/em&gt; de todas las máquinas las equivalencias.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# grep mongo /etc/hosts
10.0.0.2    mongo1
10.0.0.3    mongo2
10.0.0.4    mongo3
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Consideraciones de seguridad&lt;/h2&gt;
&lt;p&gt;Estas máquinas se comunican entre sí por el puerto TCP en el que corran sus procesos; para seguir con el puerto "titular" vamos a ponerlos en el puerto 27017. Es importante que las 3 máquinas puedan acceder al puerto de las otras 2. Adicionalmente, la máquina que vaya a usar este clúster también debe pode acceder al puerto 27017 de las 3 máquinas.&lt;/p&gt;
&lt;h2&gt;Preparación de las máquinas individuales&lt;/h2&gt;
&lt;p&gt;Queremos una versión de &lt;em&gt;mongodb&lt;/em&gt; un poco reciente, así que no vamos a usar los paquetes oficiales de la distribución, y la empresa de &lt;em&gt;mongodb&lt;/em&gt; no ofrece paquete para &lt;em&gt;Debian jessie&lt;/em&gt;. Por ello vamos a montar un esqueleto de ficheros como se describe en &lt;a href="http://www.linuxsysadmin.tk/2015/11/escribiendo-units-en-systemd.html"&gt;un artículo anterior&lt;/a&gt;. Vamos a describir el proceso en la máquina &lt;strong&gt;mongo1&lt;/strong&gt;, para replicarlo a posteriori en las otras 2.&lt;/p&gt;
&lt;p&gt;Creamos la estructura de carpetas que van a contener todo lo relativo a &lt;strong&gt;mongodb&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# mkdir -p /opt/mongodb/&lt;span class="o"&gt;{&lt;/span&gt;bin,conf,data/replica,logs&lt;span class="o"&gt;}&lt;/span&gt;
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Copiamos el binario &lt;strong&gt;mongod&lt;/strong&gt; que encontraremos en el fichero &lt;em&gt;.tar.gz&lt;/em&gt; de la página de descargas de la página web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cp mongod /opt/mongodb/bin/
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos un fichero de configuración con el que vamos a levantar el proceso en esta máquina.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cat /opt/mongodb/conf/replica.conf
systemLog:
    path: /opt/mongodb/logs/replica.log
    logAppend: &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nb"&gt;    &lt;/span&gt;destination: file

net:
    port: 27017
    bindIp: 0.0.0.0

storage:
    dbPath: /opt/mongodb/data/replica
    smallFiles: &lt;span class="nb"&gt;true&lt;/span&gt;

replication:
    replSetName: replica
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Por razones de seguridad vamos a lanzar el servicio con un usuario propio de sistema.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# useradd -s /usr/sbin/nologin -r -M mongo -d /opt/mongodb/
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para ahorrarnos problemas de permisos, lo hacemos propietario de todo lo referente al servicio:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# chown -R mongo:mongo /opt/mongodb/
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a crearle una &lt;strong&gt;unit&lt;/strong&gt; para que el sistema se encargue de levantar automáticamente el servicio en caso de reinicio de la máquina:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cat /etc/systemd/system/mongo.service
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;MongoDB

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;User&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mongo
&lt;span class="nv"&gt;LimitFSIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitCPU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitNOFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;LimitNPROC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/rm -f /opt/mongodb/data/replica/mongod.lock
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/opt/mongodb/bin/mongod -f /opt/mongodb/conf/replica.conf

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente activamos la &lt;strong&gt;unit&lt;/strong&gt; e iniciamos el servicio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mongo
Created symlink from /etc/systemd/system/multi-user.target.wants/mongo.service to /etc/systemd/system/mongo.service.
root@mongo1:~# systemctl start mongo
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora toca repetir el proceso en las otras 2 máquinas, exactamente igual.&lt;/p&gt;
&lt;h2&gt;Configuración del clúster&lt;/h2&gt;
&lt;p&gt;Accedemos a una de las máquinas del futuro clúster desde cualquier máquina que pueda hacerlo y que disponga del binario &lt;strong&gt;mongo&lt;/strong&gt; (el mongo shell), que también viene en el archivo &lt;em&gt;.tar.gz&lt;/em&gt; descargado de la página oficial; este shell no es necesario para la aplicación que use el clúster ya que el &lt;strong&gt;driver&lt;/strong&gt; de cada lenguaje suple sus funciones, pero es muy útil tenerlo a mano para tareas de administración y consultas varias.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client:~# ./mongo --host 10.0.0.2
MongoDB shell version: 3.0.7
connecting to: 10.0.0.2:27017/test
Welcome to the MongoDB shell.
For interactive &lt;span class="nb"&gt;help&lt;/span&gt;, &lt;span class="nb"&gt;type&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;help&amp;quot;&lt;/span&gt;.
&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hay dos formas de crear la configuración del clúster: pasando el documento de configuración en el método &lt;em&gt;initiate&lt;/em&gt; o añadir los nodos a posteriori con el método &lt;em&gt;add&lt;/em&gt;. Voy a usar este método por ser mas fácil.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;gt; rs.initiate&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;info2&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;no configuration explicitly specified -- making one&amp;quot;&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;me&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : 1
&lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; rs.add&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mongo2:27017&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; rs.add&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mongo3:27017&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a lanzar el método &lt;em&gt;status&lt;/em&gt; hasta que todos los nodos sean primarios o secundarios, momento en el que la &lt;em&gt;replica&lt;/em&gt; va a quedar correctamente montada.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;replica:PRIMARY&amp;gt; rs.status&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;set&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;replica&amp;quot;&lt;/span&gt;,
...
    &lt;span class="s2"&gt;&amp;quot;members&amp;quot;&lt;/span&gt; : &lt;span class="o"&gt;[&lt;/span&gt;
        &lt;span class="o"&gt;{&lt;/span&gt;
...
            &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;PRIMARY&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;self&amp;quot;&lt;/span&gt; : &lt;span class="nb"&gt;true&lt;/span&gt;
...
        &lt;span class="o"&gt;}&lt;/span&gt;,
        &lt;span class="o"&gt;{&lt;/span&gt;
...
            &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo2:27017&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;SECONDARY&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;syncingTo&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
...
        &lt;span class="o"&gt;}&lt;/span&gt;,
        &lt;span class="o"&gt;{&lt;/span&gt;
...
            &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo3:27017&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;SECONDARY&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;syncingTo&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
...
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;]&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : 1
&lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esta salida del método &lt;em&gt;status&lt;/em&gt; ya lo tenemos todo funcionando correctamente.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="mongodb"></category><category term="replica set"></category><category term="systemd"></category></entry><entry><title>Creación de un livecd con Debian</title><link href="http://www.linuxsysadmin.tk/2015/12/creacion-de-un-livecd-con-debian.html" rel="alternate"></link><updated>2015-12-02T12:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-12-02:2015/12/creacion-de-un-livecd-con-debian.html</id><summary type="html">&lt;p&gt;Tras ver como las actualizaciones de mis máquinas virtuales &lt;em&gt;VirtualBox&lt;/em&gt; expandían mis discos &lt;em&gt;.vdi&lt;/em&gt; sin control, quise pasar la herramienta &lt;em&gt;zerofree&lt;/em&gt; y un compactado con la herramienta oficial &lt;em&gt;VBoxManage&lt;/em&gt;. No quería instalar &lt;em&gt;zerofree&lt;/em&gt; de forma permanente y no pude encontrar un &lt;em&gt;livecd&lt;/em&gt; que lo tuviera, así que decidí crear uno.&lt;/p&gt;
&lt;p&gt;Para conseguirlo, se va a usar un sistema de ficheros creado con &lt;em&gt;debootstrap&lt;/em&gt; y compactado mediante &lt;em&gt;SquashFS&lt;/em&gt;; este sistema de ficheros se va a empaquetar en un &lt;em&gt;.iso&lt;/em&gt; junto con un &lt;em&gt;kernel&lt;/em&gt;, un &lt;em&gt;initrd&lt;/em&gt; y el bootloader &lt;em&gt;isolinux&lt;/em&gt;. La herramienta que hace eso es &lt;em&gt;genisoimage&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Este tutorial se ejecutó en una distribución &lt;em&gt;Debian&lt;/em&gt;, pero no hay ningún problema en hacerlo en una &lt;em&gt;Ubuntu&lt;/em&gt; u otra distribución, siempre que sepamos como crear la imagen base para empaquetar.&lt;/p&gt;
&lt;h2&gt;Preparación del entorno&lt;/h2&gt;
&lt;p&gt;Todo el proceso va a ser ejecutado con el usuario &lt;em&gt;root&lt;/em&gt; por comodidad.&lt;/p&gt;
&lt;p&gt;Empezaremos por instalar todas las tecnologías que hemos mencionado:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~# apt-get install debootstrap isolinux squashfs-tools genisoimage
...
root@desktop:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos una carpeta de trabajo para contener todos los ficheros temporales y el producto final, por limpieza:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~# mkdir live_boot
root@desktop:~# &lt;span class="nb"&gt;cd &lt;/span&gt;live_boot
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Todos los comandos que se detallan a continuación se hacen desde dentro de esta carpeta.&lt;/p&gt;
&lt;h2&gt;Preparación del sistema de ficheros, el kernel y el initrd&lt;/h2&gt;
&lt;p&gt;El sistema de ficheros se hace a partir de una jaula estándar de una distribución normal. En este paso, las distribuciones que usan &lt;em&gt;debootstrap&lt;/em&gt; nos facilitan mucho las cosas (aunque esta es la operación mas larga de este tutorial):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# debootstrap --variant&lt;span class="o"&gt;=&lt;/span&gt;minbase jessie chroot
I: Retrieving Release 
I: Retrieving Release.gpg 
I: Checking Release signature
I: Valid Release signature &lt;span class="o"&gt;(&lt;/span&gt;key id 75DDC3C4A499F1A18CB5F3C8CBF8D6FD518E17E1&lt;span class="o"&gt;)&lt;/span&gt;
I: Retrieving Packages 
I: Validating Packages 
I: Resolving dependencies of required packages...
I: Resolving dependencies of base packages...
...
I: Base system installed successfully.
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora se trata de preparar esta jaula con los paquetes que necesitemos y las configuraciones adecuadas. Vamos a montar los pseudo sistemas de ficheros &lt;em&gt;/proc&lt;/em&gt;, &lt;em&gt;/sys&lt;/em&gt;, &lt;em&gt;/dev&lt;/em&gt; y &lt;em&gt;/dev/pts&lt;/em&gt;, que posiblemente nos van a hacer falta cuando estemos dentro de la jaula.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# mount -o &lt;span class="nb"&gt;bind&lt;/span&gt; /proc/ chroot/proc/
root@desktop:~/live_boot# mount -o &lt;span class="nb"&gt;bind&lt;/span&gt; /sys/ chroot/sys/
root@desktop:~/live_boot# mount -o &lt;span class="nb"&gt;bind&lt;/span&gt; /dev/ chroot/dev/
root@desktop:~/live_boot# mount -o &lt;span class="nb"&gt;bind&lt;/span&gt; /dev/pts/ chroot/dev/pts/
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Entramos en la jaula:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# chroot chroot
root@desktop:/# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;CUIDADO&lt;/strong&gt;: A partir de ahora, y hasta nuevo aviso, todos los comandos se hacen &lt;strong&gt;dentro&lt;/strong&gt; de la jaula.&lt;/p&gt;
&lt;p&gt;Antes de nada, vamos a asignar una password al usuario &lt;em&gt;root&lt;/em&gt;, porque sino, no vamos a poder entrar en el &lt;em&gt;livecd&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:/# passwd    
Enter new UNIX password: 
Retype new UNIX password: 
passwd: password updated successfully
root@desktop:/# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Asignamos el nombre de máquina que mostrará el &lt;em&gt;livecd&lt;/em&gt; una vez haya hecho el &lt;em&gt;boot&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:/# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;zerofree&amp;quot;&lt;/span&gt; &amp;gt; /etc/hostname
root@desktop:/# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para que el &lt;em&gt;livecd&lt;/em&gt; pueda hacer &lt;em&gt;boot&lt;/em&gt;, vamos a necesitar el paquete &lt;strong&gt;live-boot&lt;/strong&gt; y un &lt;em&gt;kernel&lt;/em&gt; adecuado a la máquina que va a usar el &lt;em&gt;livecd&lt;/em&gt;. El paquete del &lt;em&gt;kernel&lt;/em&gt; ya nos va a dotar de un &lt;em&gt;initrd&lt;/em&gt; que también vamos a necesitar para el &lt;em&gt;livecd&lt;/em&gt;. Este paso también tarda un poco.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:/# apt-get install linux-image-486 live-boot
Reading package lists... Done
Building dependency tree... Done
...
Setting up linux-image-3.16.0-4-586 &lt;span class="o"&gt;(&lt;/span&gt;3.16.7-ckt11-1+deb8u3&lt;span class="o"&gt;)&lt;/span&gt; ...
...  
/etc/kernel/postinst.d/initramfs-tools:
update-initramfs: Generating /boot/initrd.img-3.16.0-4-586
...
root@desktop:/# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora vamos a instalar los paquetes que queramos en el &lt;em&gt;livecd&lt;/em&gt;; yo voy a poner &lt;em&gt;zerofree&lt;/em&gt; que es la herramienta que motivó este &lt;em&gt;livecd&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:/# apt-get install zerofree
...
Unpacking zerofree &lt;span class="o"&gt;(&lt;/span&gt;1.0.3-1&lt;span class="o"&gt;)&lt;/span&gt; ...
Setting up zerofree &lt;span class="o"&gt;(&lt;/span&gt;1.0.3-1&lt;span class="o"&gt;)&lt;/span&gt; ...
root@desktop:/# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;OPCIONAL&lt;/strong&gt;: Para reducir el tamaño final, voy a limpiar todos los archivos temporales que usa &lt;em&gt;apt&lt;/em&gt;, tanto los archivos &lt;em&gt;.deb&lt;/em&gt; en &lt;em&gt;/var/cache/apt&lt;/em&gt;, como las listas de paquetes disponibles en &lt;em&gt;/var/lib/apt&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:/# cat /dev/null &amp;gt; /etc/apt/sources.list
root@desktop:/# apt-get update
Reading package lists... Done
root@desktop:/# apt-get clean 
root@desktop:/# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y finalmente salimos de la jaula:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:/# &lt;span class="nb"&gt;exit&lt;/span&gt;
&lt;span class="nb"&gt;exit&lt;/span&gt;
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;CUIDADO&lt;/strong&gt;: A partir de ahora, todos los comandos se hacen &lt;strong&gt;fuera&lt;/strong&gt; de la jaula.&lt;/p&gt;
&lt;p&gt;Vamos a desmontar los pseudo sistemas de ficheros que ya no son necesarios, y que van a molestar cuando compactemos la jaula. Como apunte, la jaula había levantado un proceso &lt;em&gt;/usr/sbin/uuidd&lt;/em&gt; que evitaba desmontar &lt;em&gt;chroot/dev&lt;/em&gt;, por lo que tuve que finalizar el proceso con un &lt;em&gt;kill&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# umount chroot/dev/pts/
root@desktop:~/live_boot# umount chroot/dev/
root@desktop:~/live_boot# umount chroot/sys/
root@desktop:~/live_boot# umount chroot/proc/
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;OPCIONAL&lt;/strong&gt;: Sabiendo que mis máquinas virtuales son clones y el comando que va a correr siempre el comando &lt;em&gt;zerofree&lt;/em&gt; contra el disco &lt;em&gt;/dev/sda1&lt;/em&gt;, se puede poner los comandos en el &lt;em&gt;.bash_history&lt;/em&gt; de &lt;em&gt;root&lt;/em&gt; para poderlos recuperar mediante el uso de flechas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# cat chroot/root/.bash_history 
zerofree /dev/sda1
poweroff
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Empaquetando la imagen&lt;/h2&gt;
&lt;p&gt;Vamos a crear una carpeta contenedora, que va a servir como raíz del &lt;em&gt;livecd&lt;/em&gt;. Dentro le vamos a poner una carpeta &lt;em&gt;live&lt;/em&gt; (para el sistema de ficheros, el &lt;em&gt;kernel&lt;/em&gt; y el &lt;em&gt;initrd&lt;/em&gt;) y una carpeta &lt;em&gt;isolinux&lt;/em&gt; (para todo lo referente al &lt;em&gt;bootloader&lt;/em&gt;).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# mkdir -p image/&lt;span class="o"&gt;{&lt;/span&gt;live,isolinux&lt;span class="o"&gt;}&lt;/span&gt;
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a poner el sistema de ficheros en formato &lt;em&gt;SquashFS&lt;/em&gt;. Como apunte, el &lt;em&gt;kernel&lt;/em&gt; y el &lt;em&gt;initrd&lt;/em&gt; (ambos en la carpeta &lt;em&gt;/boot&lt;/em&gt;) se excluyen porque el &lt;em&gt;bootloader&lt;/em&gt; es incapaz de leerlos de allí; así que los copiamos a la misma carpeta.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# mksquashfs chroot image/live/filesystem.squashfs -e boot
Parallel mksquashfs: Using &lt;span class="m"&gt;1&lt;/span&gt; processor
Creating 4.0 filesystem on image/live/filesystem.squashfs, block size 131072.
...  
root@desktop:~/live_boot# cp chroot/boot/vmlinuz-3.16.0-4-586 image/live/vmlinuz
root@desktop:~/live_boot# cp chroot/boot/initrd.img-3.16.0-4-586 image/live/initrd
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora vamos con el &lt;em&gt;bootloader&lt;/em&gt;. Lo primero es poner una configuración para saber qué menú nos va a mostrar:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# cat image/isolinux/isolinux.cfg 
UI menu.c32

prompt 0
menu title Debian Zerofree

timeout 50

label Debian Live 3.16.0-4-586
menu label ^Debian Live 3.16.0-4-586
menu default
kernel /live/vmlinuz
append &lt;span class="nv"&gt;initrd&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/live/initrd &lt;span class="nv"&gt;boot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;live
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Copiamos la imagen del &lt;em&gt;bootloader&lt;/em&gt; &lt;strong&gt;isolinux&lt;/strong&gt; y los módulos que se necesitan, tanto porque nuestra configuración los usa o porque se usan desde otros módulos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# cp /usr/lib/ISOLINUX/isolinux.bin image/isolinux/
root@desktop:~/live_boot# cp /usr/lib/syslinux/modules/bios/ldlinux.c32 image/isolinux/
root@desktop:~/live_boot# cp /usr/lib/syslinux/modules/bios/menu.c32 image/isolinux/
root@desktop:~/live_boot# cp /usr/lib/syslinux/modules/bios/libutil.c32 image/isolinux/
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente empaquetamos la imagen &lt;em&gt;.iso&lt;/em&gt;. Para ello usaremos la herramienta &lt;em&gt;genisoimage&lt;/em&gt; en la carpeta raíz de lo que sería el &lt;em&gt;livecd&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# &lt;span class="nb"&gt;cd &lt;/span&gt;image/
root@desktop:~/live_boot/image# genisoimage -rational-rock -volid &lt;span class="s2"&gt;&amp;quot;Debian Zerofree&amp;quot;&lt;/span&gt; -cache-inodes -joliet -full-iso9660-filenames -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size &lt;span class="m"&gt;4&lt;/span&gt; -boot-info-table -output ../debian-zerofree.iso .
I: -input-charset not specified, using utf-8 &lt;span class="o"&gt;(&lt;/span&gt;detected in locale settings&lt;span class="o"&gt;)&lt;/span&gt;
Size of boot image is &lt;span class="m"&gt;4&lt;/span&gt; sectors -&amp;gt; No emulation
  9.24% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:43 2015
 18.48% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:38 2015
 27.69% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:36 2015
 36.94% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:38 2015
 46.15% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:37 2015
 55.40% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:36 2015
 64.61% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:37 2015
 73.85% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:37 2015
 83.07% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:37 2015
 92.30% &lt;span class="k"&gt;done&lt;/span&gt;, estimate finish Wed Dec  &lt;span class="m"&gt;2&lt;/span&gt; 12:06:38 2015
Total translation table size: 2048
Total rockridge attributes bytes: 1335
Total directory bytes: 4570
Path table size&lt;span class="o"&gt;(&lt;/span&gt;bytes&lt;span class="o"&gt;)&lt;/span&gt;: 38
Max brk space used 1a000
&lt;span class="m"&gt;54178&lt;/span&gt; extents written &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;105&lt;/span&gt; MB&lt;span class="o"&gt;)&lt;/span&gt;
root@desktop:~/live_boot/image# &lt;span class="nb"&gt;cd&lt;/span&gt; ..
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y nuestra imagen &lt;em&gt;.iso&lt;/em&gt; queda en la carpeta de trabajo, junto a la jaula y a la estructura del &lt;em&gt;livecd&lt;/em&gt;. Solo necesitamos la imagen &lt;em&gt;.iso&lt;/em&gt;, pero podemos dejar los ficheros intermedios hasta que estemos satisfechos con la imagen; es mas fácil modificar la jaula, el empaquetado &lt;em&gt;filesystem.squashfs&lt;/em&gt; y la imagen &lt;em&gt;.iso&lt;/em&gt; que volver a hacer un &lt;em&gt;debootstrap&lt;/em&gt; entero...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@desktop:~/live_boot# ls -lh
total 106M
drwxr-xr-x &lt;span class="m"&gt;20&lt;/span&gt; root root 4,0K dic  &lt;span class="m"&gt;2&lt;/span&gt; 11:30 chroot
-rw-r--r--  &lt;span class="m"&gt;1&lt;/span&gt; root root 106M dic  &lt;span class="m"&gt;2&lt;/span&gt; 12:06 debian-zerofree.iso
drwxr-xr-x  &lt;span class="m"&gt;4&lt;/span&gt; root root 4,0K dic  &lt;span class="m"&gt;2&lt;/span&gt; 11:53 image
root@desktop:~/live_boot# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Conclusión&lt;/h2&gt;
&lt;p&gt;Copiando esta imagen &lt;em&gt;.iso&lt;/em&gt; a mi máquina con &lt;em&gt;VirtualBox&lt;/em&gt; y montándola antes de hacer el &lt;em&gt;boot&lt;/em&gt; de cada máquina, puedo usar la herramienta &lt;em&gt;zerofree&lt;/em&gt; libremente, sin instalarla en las máquinas virtuales. Tras ello, el compactado de los ficheros &lt;em&gt;.vdi&lt;/em&gt; libera los megabytes a cientos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@virtualbox:~/VirtualBox VMs&lt;span class="nv"&gt;$ &lt;/span&gt;VBoxManage modifyvdi Debian/Debian.vdi --compact
...
gerard@virtualbox:~/VirtualBox VMs&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este caso concreto, la máquina &lt;strong&gt;Debian&lt;/strong&gt; (&lt;em&gt;netinstall&lt;/em&gt;) volvió a ocupar 700 mb, que es mucho mas interesante teniendo en cuenta que es la imagen que suelo clonar para hacer otras máquinas virtuales.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="zerofree"></category><category term="debootstrap"></category><category term="squashfs"></category><category term="genisoimage"></category><category term="isolinux"></category><category term="iso"></category><category term="livecd"></category></entry><entry><title>Virtualizando contenedores LXC tras bridge interno</title><link href="http://www.linuxsysadmin.tk/2015/11/virtualizando-contenedores-lxc-tras-bridge-interno.html" rel="alternate"></link><updated>2015-11-23T23:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-11-23:2015/11/virtualizando-contenedores-lxc-tras-bridge-interno.html</id><summary type="html">&lt;p&gt;En un artículo anterior propusimos virtualizar contenedores en la red de la máquina &lt;em&gt;host&lt;/em&gt;. Sin embargo, puede ser mas interesante esconder los contenedores detrás de una máquina que haga las funciones de &lt;em&gt;host&lt;/em&gt; y de &lt;em&gt;firewall&lt;/em&gt;. Expondremos una serie de puertos tras la misma dirección &lt;em&gt;IP&lt;/em&gt; mediante el protocolo &lt;em&gt;NAT&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Para conseguir este objetivo, se van a usar las siguientes tecnologías:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Debian jessie&lt;/strong&gt;: Es necesario usar alguna distribución de linux para hacer funcionar LXC&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LXC&lt;/strong&gt;: Tecnología que permite aislar los contenedores entre sí y darles entidad propia&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bridges&lt;/strong&gt;: Un bridge es en software el equivalente a un switch hardware&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Firehol&lt;/strong&gt;: Una serie de scripts para construir firewalls basados en iptables de forma fácil&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En cuanto a las capacidades hardware, vamos a hacer el tutorial con un equipo de capacidades modestas, virtualizado en una máquina virtual VirtualBox.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPUs&lt;/strong&gt;: 1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memoria&lt;/strong&gt;: 256 Mb&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disco&lt;/strong&gt;: 2 Gb&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Red&lt;/strong&gt;: 1 interfaz (&lt;em&gt;eth0&lt;/em&gt;) &lt;em&gt;host-only&lt;/em&gt; o &lt;em&gt;bridged&lt;/em&gt; con IP fija&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Partimos de una distribución &lt;em&gt;Debian jessie&lt;/em&gt; instalada con un CD &lt;em&gt;netinstall&lt;/em&gt; y con el único paquete instalado &lt;em&gt;openssh-server&lt;/em&gt;, para mi comodidad.&lt;/p&gt;
&lt;h2&gt;Preparar el servidor&lt;/h2&gt;
&lt;p&gt;El primer paso consiste en instalar las tecnologías usadas:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# apt-get install bridge-utils firehol lxc
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
...
Configurando lxc &lt;span class="o"&gt;(&lt;/span&gt;1:1.0.6-6+deb8u2&lt;span class="o"&gt;)&lt;/span&gt; ...
Configurando dh-python &lt;span class="o"&gt;(&lt;/span&gt;1.20141111-2&lt;span class="o"&gt;)&lt;/span&gt; ...
Procesando disparadores para libc-bin &lt;span class="o"&gt;(&lt;/span&gt;2.19-18+deb8u1&lt;span class="o"&gt;)&lt;/span&gt; ...
Procesando disparadores para systemd &lt;span class="o"&gt;(&lt;/span&gt;215-17+deb8u2&lt;span class="o"&gt;)&lt;/span&gt; ...
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora vamos a modificar la configuración de red, para habilitar el &lt;em&gt;bridge&lt;/em&gt; en el que vamos a conectar el resto de contenedores virtualizados. Como dato importante, se define una interfaz falsa en la directiva &lt;em&gt;bridge_ports&lt;/em&gt; para que la &lt;em&gt;unit&lt;/em&gt; de red lo levante automáticamente.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ANTES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/network/interfaces
&lt;span class="nb"&gt;source&lt;/span&gt; /etc/network/interfaces.d/*

auto lo
iface lo inet loopback

auto eth0
iface eth0 inet static
    address 192.168.56.4
    netmask 255.255.255.0
    gateway 192.168.56.1
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;DESPUES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/network/interfaces
&lt;span class="nb"&gt;source&lt;/span&gt; /etc/network/interfaces.d/*

auto lo
iface lo inet loopback

auto eth0
iface eth0 inet static
    address 192.168.56.4
    netmask 255.255.255.0
    gateway 192.168.56.1

auto lxc0
iface lxc0 inet static
    bridge_ports dummy
    address 10.0.0.1
    netmask 255.255.255.0
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora toca reiniciar el servicio de red, para que el nuevo &lt;em&gt;bridge&lt;/em&gt; quede configurado como debe estarlo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# service networking restart
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El siguiente paso consiste en poner las reglas de &lt;em&gt;firewall&lt;/em&gt; necesarias para proteger al equipo anfitrión y para permitirle actuar como &lt;em&gt;gateway&lt;/em&gt; para los contenedores tras el &lt;em&gt;bridge&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf 
interface eth0 world
    policy drop
    protection strong
    server ssh accept
    client all accept

interface lxc0 lan
    policy drop
    client all accept

router lan2world inface lxc0 outface eth0
    masquerade
    route all accept
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hay que modificar otro fichero para permitir el inicio del &lt;em&gt;firewall&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ANTES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# grep START /etc/default/firehol 
&lt;span class="c"&gt;#To enable firehol at startup set START_FIREHOL=YES&lt;/span&gt;
&lt;span class="nv"&gt;START_FIREHOL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;NO
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;DESPUES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# grep START /etc/default/firehol 
&lt;span class="c"&gt;#To enable firehol at startup set START_FIREHOL=YES&lt;/span&gt;
&lt;span class="nv"&gt;START_FIREHOL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;YES
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para acabar, reiniciamos el servicio &lt;em&gt;firehol&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# service firehol restart
...
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Creación de contenedores&lt;/h2&gt;
&lt;p&gt;La creación de contenedores pasa por usar las herramientas estándar de la distribución, a lo solo tendremos que modificar algunas configuraciones propias de nuestra red.&lt;/p&gt;
&lt;p&gt;Creamos un contenedor &lt;em&gt;webserver&lt;/em&gt; como demostración. La primera que se crea es un poco lenta porque hace un &lt;em&gt;debootstrap&lt;/em&gt; de una distribución &lt;em&gt;Debian estable&lt;/em&gt; para crear una cache en &lt;em&gt;/var/cache/lxc&lt;/em&gt;; las siguientes se benefician de esta caché y solo la actualizan, acelerando el proceso.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-create -n webserver -t debian
debootstrap is /usr/sbin/debootstrap
Checking cache download in /var/cache/lxc/debian/rootfs-jessie-i386 ... 
Downloading debian minimal ...
...

I: Base system installed successfully.
Download complete.
Copying rootfs to /var/lib/lxc/webserver/rootfs...
...
Current default &lt;span class="nb"&gt;time &lt;/span&gt;zone: &lt;span class="s1"&gt;&amp;#39;Europe/Madrid&amp;#39;&lt;/span&gt;
Local &lt;span class="nb"&gt;time &lt;/span&gt;is now:      Mon Nov &lt;span class="m"&gt;23&lt;/span&gt; 16:29:36 CET 2015.
Universal Time is now:  Mon Nov &lt;span class="m"&gt;23&lt;/span&gt; 15:29:36 UTC 2015.

Root password is &lt;span class="s1"&gt;&amp;#39;E3+K9SpU&amp;#39;&lt;/span&gt;, please change !
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Acabada la generación del contenedor, vamos a configurarle algunos parámetros; que tenga una interfaz &lt;em&gt;eth0&lt;/em&gt; activa y enchufada al bridge &lt;em&gt;lxc0&lt;/em&gt;, y que el contenedor se inicie automáticamente en cada reinicio del anfitrión.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /var/lib/lxc/webserver/config 
...
lxc.start.auto &lt;span class="o"&gt;=&lt;/span&gt; 1
lxc.network.type &lt;span class="o"&gt;=&lt;/span&gt; veth
lxc.network.flags &lt;span class="o"&gt;=&lt;/span&gt; up
lxc.network.link &lt;span class="o"&gt;=&lt;/span&gt; lxc0
lxc.network.name &lt;span class="o"&gt;=&lt;/span&gt; eth0
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para que su interfaz de red sea funcional, vamos a configurarle una dirección IP. Todo esto se hace en los ficheros habituales, teniendo en cuenta que un contenedor es una jaula, y que esta se encuentra en &lt;em&gt;/var/lib/lxc/webserver/rootfs/&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /var/lib/lxc/webserver/rootfs/etc/network/interfaces
auto lo
iface lo inet loopback

auto eth0
iface eth0 inet static
    address 10.0.0.2
    netmask 255.255.255.0
    gateway 10.0.0.1
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El contenedor ya está funcional, y se puede levantar:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-start -n webserver -d
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Supongamos que este nuevo contenedor tiene un servidor web y queremos hacerlo disponible en puerto 80 del &lt;em&gt;host&lt;/em&gt;, mediante el protocolo &lt;em&gt;NAT&lt;/em&gt;. También se necesita definir una regla de &lt;em&gt;forward&lt;/em&gt; para permitir ese tráfico. Se reinicia el servicio &lt;em&gt;firehol&lt;/em&gt; para aplicar las nuevas reglas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf 
dnat 10.0.0.2:80 proto tcp dst 192.168.56.4 dport 80

interface eth0 world
    policy drop
    protection strong
    server ssh accept
    client all accept

interface lxc0 lan
    policy drop
    client all accept

router lan2world inface lxc0 outface eth0
    masquerade
    route all accept

router world2lan inface eth0 outface lxc0
    route http accept dst 10.0.0.2
root@lxc:~# service firehol restart
...
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora podemos acceder al servidor web instalado en el contenedor &lt;em&gt;webserver&lt;/em&gt; mediante el puerto 80 del &lt;em&gt;host&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Supongamos que tenemos otro contenedor con un servidor de aplicaciones escuchando en el puerto 8080 con dirección 10.0.0.3 y pretendemos que el contenedor original haga de &lt;em&gt;proxy HTTP&lt;/em&gt;. Esta funcionalidad requiere que el contenedor &lt;em&gt;webserver&lt;/em&gt; pueda conectarse al puerto 8080 del nuevo contenedor &lt;em&gt;appserver&lt;/em&gt;. Esta regla de &lt;em&gt;forward&lt;/em&gt; aplica a todas las conexiones que inician y finalizan en el &lt;em&gt;bridge&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf 
dnat 10.0.0.2:80 proto tcp dst 192.168.56.4 dport 80

interface eth0 world
    policy drop
    protection strong
    server ssh accept
    client all accept

interface lxc0 lan
    policy drop
    client all accept

router lan2world inface lxc0 outface eth0
    masquerade
    route all accept

router world2lan inface eth0 outface lxc0
    route http accept dst 10.0.0.2

router internal inface lxc0 outface lxc0
    route webcache accept src 10.0.0.2 dst 10.0.0.3
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con eso tenemos nuestro &lt;em&gt;proxy HTTP&lt;/em&gt; funcionando.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="lxc"></category><category term="bridge"></category><category term="firehol"></category></entry><entry><title>Creando sistemas de ficheros temporales con tmpfs</title><link href="http://www.linuxsysadmin.tk/2015/11/creando-sistemas-de-ficheros-temporales-con-tmpfs.html" rel="alternate"></link><updated>2015-11-16T23:15:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-11-16:2015/11/creando-sistemas-de-ficheros-temporales-con-tmpfs.html</id><summary type="html">&lt;p&gt;A veces nos podemos encontrar con un sistema de ficheros lleno que no nos permite completar alguna acción por falta de espacio en disco. En un caso así, existe la posibilidad de sacar un sistema de ficheros completo de memoria, de una forma temporal, usando el sistema de ficheros &lt;em&gt;tmpfs&lt;/em&gt;. Otra opción es la de tener un sistema de ficheros temporal, en donde podamos dejar ficheros cuya persistencia no sea necesaria entre reinicios.&lt;/p&gt;
&lt;p&gt;El primer paso es tener un &lt;em&gt;punto de montaje&lt;/em&gt;, que sea la carpeta en la que se va a montar el nuevo sistema de fichero. Por ejemplo podemos usar el punto de montaje &lt;em&gt;/mnt/auxiliar&lt;/em&gt;; empezaremos creándolo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mkdir /mnt/auxiliar
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Observemos como la carpeta creada se construye sobre el mismo dispositivo que la partición raíz:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# df -h /mnt/auxiliar/
S.ficheros     Tamaño Usados  Disp Uso% Montado en
/dev/sda1        2,0G   640M  1,2G  35% /
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Creando el sistema de ficheros de forma temporal&lt;/h2&gt;
&lt;p&gt;Como prueba de concepto, podemos crear este sistema de ficheros de forma temporal. En caso de no salir bien, los efectos no serían permanentes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mount -o &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;100M -t tmpfs auxiliar /mnt/auxiliar/
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Podemos ver como la carpeta pertenece ahora a un sistema de ficheros nuevo:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# df -h /mnt/auxiliar/
S.ficheros     Tamaño Usados  Disp Uso% Montado en
auxiliar            100M      &lt;span class="m"&gt;0&lt;/span&gt;  100M   0% /mnt/auxiliar
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Cuando nos cansemos del nuevo sistema de ficheros, haya cumplido con su utilidad y ya no necesitemos su contenido, la podemos desmontar; vamos a perder todos los ficheros dentro del sistema de ficheros temporal.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# umount /mnt/auxiliar/
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Haciendo el cambio permanente&lt;/h2&gt;
&lt;p&gt;Si nos interesa que este sistema de fichero se &lt;em&gt;monte&lt;/em&gt; y se &lt;em&gt;desmonte&lt;/em&gt; cada vez que la máquina se inicie y se apague, basta con usar el mecanismo estándar de todo sistema de ficheros &lt;em&gt;Linux&lt;/em&gt;: el fichero &lt;em&gt;/etc/fstab&lt;/em&gt;. Basta con añadir una línea nueva con las especificaciones de este punto de montaje, por ejemplo en el final del mismo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# tail -1 /etc/fstab 
auxiliar /mnt/auxiliar tmpfs &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;100M &lt;span class="m"&gt;0&lt;/span&gt; 0
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Con este cambio es suficiente para las sesiones venideras. En caso de querer disponer inmediatamente del sistema de ficheros podemos solicitar el montaje con un comando &lt;em&gt;mount&lt;/em&gt; normal, comando que va a usar las especificaciones del fichero &lt;em&gt;/etc/fstab&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mount /mnt/auxiliar
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto queda completado nuestro objetivo.&lt;/p&gt;</summary><category term="linux"></category><category term="tmpfs"></category></entry><entry><title>Escribiendo units en systemd</title><link href="http://www.linuxsysadmin.tk/2015/11/escribiendo-units-en-systemd.html" rel="alternate"></link><updated>2015-11-09T22:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-11-09:2015/11/escribiendo-units-en-systemd.html</id><summary type="html">&lt;p&gt;Cuando se anunció &lt;em&gt;systemd&lt;/em&gt; me llamó la atención que además de las funciones estándares de otros sistemas de &lt;em&gt;init&lt;/em&gt; (por ejemplo &lt;em&gt;sysvinit&lt;/em&gt;), también se ofrecían otras funcionalidades normalmente delegadas a otros procesos, como por ejemplo, la posibilidad de reiniciar procesos automáticamente o de lanzar procesos temporales al estilo de &lt;em&gt;cron&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;En este artículo se explica como escribir estos ficheros que rigen las tareas propias del sistema &lt;em&gt;init&lt;/em&gt; para iniciar procesos que no disponen de tales facilidades. Adicionalmente, vamos a ver como beneficiarnos del sistema de plantillas de estos mismos ficheros para evitarnos tener que repetirnos, de acuerdo con el principio &lt;a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself"&gt;DRY (don't repeat yourself)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Como ejemplo, vamos a utilizar un sistema básico de &lt;em&gt;Linux&lt;/em&gt; con &lt;em&gt;systemd&lt;/em&gt;; que podría ser &lt;em&gt;RedHat 7&lt;/em&gt;, &lt;em&gt;ArchLinux&lt;/em&gt; o &lt;em&gt;Debian 8&lt;/em&gt;. En este caso, se va a utilizar un sistema &lt;em&gt;Debian Jessie&lt;/em&gt; con una instalación básica &lt;em&gt;netinstall&lt;/em&gt; con &lt;em&gt;SSH&lt;/em&gt; y nada mas.&lt;/p&gt;
&lt;p&gt;Vamos a suponer que queremos montar un servidor con 2 instancias de &lt;em&gt;MongoDB&lt;/em&gt;, escuchando en los puertos 27001 y 27002. Empecemos con montar una estructura en &lt;em&gt;/opt/&lt;/em&gt; para contener todo lo relacionado con este despliegue. La idea es que vamos a levantar el binario &lt;em&gt;mongod&lt;/em&gt; con dos configuraciones distintas. Por eso, de momento basta con poner el binario &lt;em&gt;mongod&lt;/em&gt;, las dos configuraciones y las dos carpetas de datos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# tree /opt/
/opt/
└── mongodb
    ├── bin
    │   └── mongod
    ├── conf
    │   ├── mongo1.conf
    │   └── mongo2.conf
    ├── data
    │   ├── mongo1
    │   └── mongo2
    └── logs

&lt;span class="m"&gt;7&lt;/span&gt; directories, &lt;span class="m"&gt;3&lt;/span&gt; files
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La configuración de ambos procesos va a ser la mínima necesaria para que los procesos no entren en conflicto entre ellos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /opt/mongodb/conf/mongo1.conf 
systemLog:
    path: /opt/mongodb/logs/mongo1.log
    logAppend: &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nb"&gt;    &lt;/span&gt;destination: file

net:
    port: 27001

storage:
    dbPath: /opt/mongodb/data/mongo1
    smallFiles: &lt;span class="nb"&gt;true&lt;/span&gt;
root@server:~# cat /opt/mongodb/conf/mongo2.conf 
systemLog:
    path: /opt/mongodb/logs/mongo2.log
    logAppend: &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nb"&gt;    &lt;/span&gt;destination: file

net:
    port: 27002

storage:
    dbPath: /opt/mongodb/data/mongo2
    smallFiles: &lt;span class="nb"&gt;true&lt;/span&gt;
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como apunte importante, no se ha definido un archivo para guardar el &lt;em&gt;PID&lt;/em&gt; del proceso; &lt;em&gt;systemd&lt;/em&gt; no lo necesita y conoce el &lt;em&gt;PID&lt;/em&gt; de los procesos que levanta.&lt;/p&gt;
&lt;p&gt;Siguiendo las directivas de seguridad mínimas, los dos procesos &lt;em&gt;mongod&lt;/em&gt; van a levantarse con un usuario estándar que no sea &lt;em&gt;root&lt;/em&gt;. En este caso, toda la carpeta &lt;em&gt;/opt/mongodb/&lt;/em&gt; pertenece al usuario &lt;em&gt;mongo&lt;/em&gt;, aunque bastaría con la carpeta de datos y la de logs.&lt;/p&gt;
&lt;p&gt;Ponemos la definición de nuestras &lt;strong&gt;units&lt;/strong&gt; en la carpeta designada según el estándar, que es &lt;em&gt;/etc/systemd/system/&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /etc/systemd/system/mongo1.service 
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;MongoDB

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;User&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mongo
&lt;span class="nv"&gt;LimitFSIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitCPU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitNOFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;LimitNPROC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/rm -f /opt/mongodb/data/mongo1/mongod.lock
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/opt/mongodb/bin/mongod -f /opt/mongodb/conf/mongo1.conf

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
root@server:~# cat /etc/systemd/system/mongo2.service 
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;MongoDB

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;User&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mongo
&lt;span class="nv"&gt;LimitFSIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitCPU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitNOFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;LimitNPROC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/rm -f /opt/mongodb/data/mongo2/mongod.lock
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/opt/mongodb/bin/mongod -f /opt/mongodb/conf/mongo2.conf

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Es especialmente interesante ver que el lenguaje de la &lt;strong&gt;units&lt;/strong&gt; de &lt;em&gt;systemd&lt;/em&gt; es declarativo, y que no son &lt;em&gt;init scripts&lt;/em&gt;; &lt;em&gt;systemd&lt;/em&gt; se encarga de todo por nosotros. Basta con declarar el comando con el que levantar el servicio y el usuario con el que hacerlo.&lt;/p&gt;
&lt;p&gt;La directiva &lt;strong&gt;WantedBy&lt;/strong&gt; indica que se tiene que levantar con el &lt;strong&gt;target&lt;/strong&gt; &lt;em&gt;multi-user&lt;/em&gt;, que es el que usa &lt;em&gt;Debian&lt;/em&gt; por defecto. Un &lt;strong&gt;target&lt;/strong&gt; viene a ser el equivalente a un &lt;em&gt;runlevel&lt;/em&gt; de &lt;em&gt;sysvinit&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Hay una directiva &lt;strong&gt;ExecStartPre&lt;/strong&gt; que se encarga de eliminar el &lt;em&gt;lock file&lt;/em&gt; de &lt;em&gt;MongoDB&lt;/em&gt; por si el proceso hubiera acabado de forma inesperada. El binario &lt;em&gt;mongod&lt;/em&gt; no levanta si este fichero existe, ya que cree que ya hay una instancia de &lt;em&gt;mongod&lt;/em&gt; usando la carpeta de datos.&lt;/p&gt;
&lt;p&gt;El resto de directivas se limitan a modificar los límites de los procesos a levantar, de acuerdo a la documentación de &lt;em&gt;MongoDB&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;A partir de ahora, son &lt;strong&gt;units&lt;/strong&gt; normales del sistema y se pueden activar e iniciar. Si ya estuvieran cargados, habría que recargar la configuración de &lt;em&gt;systemd&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mongo1
root@server:~# systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mongo2
root@server:~# systemctl start mongo1
root@server:~# systemctl start mongo2
root@server:~# systemctl daemon-reload
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Uso de plantillas para evitar repetirnos&lt;/h2&gt;
&lt;p&gt;Toda &lt;strong&gt;unit&lt;/strong&gt; cuyo nombre acabe en &lt;strong&gt;arroba&lt;/strong&gt; seguido por &lt;em&gt;.service&lt;/em&gt; o cualquier otro tipo de &lt;strong&gt;unit&lt;/strong&gt;, es por convención, una &lt;strong&gt;plantilla&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;La idea es que vamos a crear un &lt;em&gt;link&lt;/em&gt; a la &lt;strong&gt;plantilla&lt;/strong&gt;, que ponga un texto detrás de la &lt;strong&gt;arroba&lt;/strong&gt;. Este texto va a estar disponible en la plantilla como &lt;strong&gt;%i&lt;/strong&gt;. De esta forma podemos "pasar un parámetro" a la plantilla, usando ese parámetro como diferenciador de los dos procesos.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Veamos un ejemplo:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Creamos dos &lt;em&gt;links&lt;/em&gt; a la &lt;strong&gt;plantilla&lt;/strong&gt; &lt;em&gt;mongodb@.service&lt;/em&gt;, con los nombres &lt;em&gt;mongodb@mongo1.service&lt;/em&gt; y &lt;em&gt;mongodb@mongo2.service&lt;/em&gt;, que son nuestras instancias. Estas instancias se rigen con las directivas de la &lt;strong&gt;plantilla&lt;/strong&gt;, con la variable &lt;strong&gt;%i&lt;/strong&gt; conteniendo los valores &lt;em&gt;mongo1&lt;/em&gt; y &lt;em&gt;mongo2&lt;/em&gt; respectivamente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# ls -l /etc/systemd/system/mongodb&lt;span class="se"&gt;\@&lt;/span&gt;*
lrwxrwxrwx &lt;span class="m"&gt;1&lt;/span&gt; root root  &lt;span class="m"&gt;16&lt;/span&gt; nov  &lt;span class="m"&gt;3&lt;/span&gt; 12:46 /etc/systemd/system/mongodb@mongo1.service -&amp;gt; mongodb@.service
lrwxrwxrwx &lt;span class="m"&gt;1&lt;/span&gt; root root  &lt;span class="m"&gt;16&lt;/span&gt; nov  &lt;span class="m"&gt;3&lt;/span&gt; 12:46 /etc/systemd/system/mongodb@mongo2.service -&amp;gt; mongodb@.service
-rw-r--r-- &lt;span class="m"&gt;1&lt;/span&gt; root root &lt;span class="m"&gt;207&lt;/span&gt; nov  &lt;span class="m"&gt;3&lt;/span&gt; 12:45 /etc/systemd/system/mongodb@.service
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora redactamos la plantilla, teniendo en cuenta los valores que se van a cambiarse por la variable &lt;strong&gt;%i&lt;/strong&gt;, que vamos a usar para identificar el fichero de configuración de cada instancia. También es posible poner otras variables en la &lt;strong&gt;plantilla&lt;/strong&gt;, como por ejemplo, el nombre de la máquina o la versión del &lt;em&gt;kernel&lt;/em&gt; de la máquina.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /etc/systemd/system/mongodb&lt;span class="se"&gt;\@&lt;/span&gt;.service 
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;MongoDB

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;User&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mongo
&lt;span class="nv"&gt;LimitFSIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitCPU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitNOFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;LimitNPROC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/rm -f /opt/mongodb/data/%i/mongod.lock
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/opt/mongodb/bin/mongod -f /opt/mongodb/conf/%i.conf

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora solo falta activar las instancias e iniciarlas, con los comandos habituales del demonio &lt;em&gt;systemd&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mongodb@mongo1
Created symlink from /etc/systemd/system/multi-user.target.wants/mongodb@mongo1.service to /etc/systemd/system/mongodb@.service.
root@server:~# systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mongodb@mongo2
Created symlink from /etc/systemd/system/multi-user.target.wants/mongodb@mongo2.service to /etc/systemd/system/mongodb@.service.
root@server:~# systemctl start mongodb@mongo1
root@server:~# systemctl start mongodb@mongo2
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto lo hemos conseguido.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="systemd"></category><category term="mongodb"></category></entry><entry><title>Restart automático de servicios con systemd</title><link href="http://www.linuxsysadmin.tk/2015/11/restart-automatico-de-servicios-con-systemd.html" rel="alternate"></link><updated>2015-11-05T22:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-11-05:2015/11/restart-automatico-de-servicios-con-systemd.html</id><summary type="html">&lt;p&gt;Cuando estamos gestionando un servidor, es posible que se caiga alguno de sus servicios. Esto es especialmente molesto cuando nos interesa tener un &lt;em&gt;uptime&lt;/em&gt; elevado. Para conseguirlo, se han utilizado diferentes maneras, desde poner personas a monitorizar en modo 24x7 hasta herramientas auxiliares como gestores tipo &lt;em&gt;runit&lt;/em&gt;, &lt;em&gt;supervisor&lt;/em&gt; o &lt;em&gt;monit&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Con la entrada en escena de &lt;em&gt;systemd&lt;/em&gt; en la mayoría de distribuciones grandes de &lt;em&gt;linux&lt;/em&gt; este problema se ha acabado; el mismo proceso que hace de &lt;strong&gt;init&lt;/strong&gt; puede encargarse de mantener los procesos levantados, y reiniciarlos en caso de caída.&lt;/p&gt;
&lt;p&gt;En este tutorial pretendo hacer que un servicio estándar se vea beneficiado de un &lt;strong&gt;override&lt;/strong&gt;, que permita el inicio automático de un servicio cuando se cae, sin tener que reescribir la &lt;strong&gt;unit&lt;/strong&gt; que se encarga del servicio o proceso.&lt;/p&gt;
&lt;p&gt;Partimos de un servidor básico &lt;em&gt;Linux&lt;/em&gt; con &lt;em&gt;systemd&lt;/em&gt;. En este caso vamos a utilizar la última versión estable de &lt;em&gt;Debian&lt;/em&gt;, a la que le vamos a instalar un servicio estándar como &lt;em&gt;nginx&lt;/em&gt; que nos va a servir como conejillo de indias.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# apt-get install nginx-light
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Procedimiento&lt;/h2&gt;
&lt;p&gt;Como comprobación previa, observemos como este &lt;strong&gt;restart&lt;/strong&gt; automático no funciona; tenemos el servicio en ejecución, lo matamos y observamos que no se levanta de nuevo, por mucho que esperemos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;685&lt;/span&gt;  0.0  0.8   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2240&lt;/span&gt; pts/0    S+   11:41   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;662&lt;/span&gt;  0.0  0.7   &lt;span class="m"&gt;6356&lt;/span&gt;  &lt;span class="m"&gt;1856&lt;/span&gt; ?        Ss   11:41   0:00 nginx: master process /usr/sbin/nginx -g daemon on&lt;span class="p"&gt;;&lt;/span&gt; master_process on&lt;span class="p"&gt;;&lt;/span&gt;
www-data   &lt;span class="m"&gt;663&lt;/span&gt;  0.1  0.9   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2456&lt;/span&gt; ?        S    11:41   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;664&lt;/span&gt;  0.0  0.9   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2456&lt;/span&gt; ?        S    11:41   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;665&lt;/span&gt;  0.0  0.9   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2456&lt;/span&gt; ?        S    11:41   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;666&lt;/span&gt;  0.1  0.9   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2456&lt;/span&gt; ?        S    11:41   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
root@server:~# &lt;span class="nb"&gt;kill &lt;/span&gt;662
root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;691&lt;/span&gt;  0.0  0.8   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2220&lt;/span&gt; pts/0    S+   11:41   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora necesitamos localizar el nombre de la &lt;strong&gt;unit&lt;/strong&gt; que se encarga de ese servicio, puesto que la carpeta de &lt;strong&gt;overrides&lt;/strong&gt; debe llamarse igual.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# systemctl list-units -a &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
  nginx.service    loaded    inactive dead    A high performance web server and a reverse proxy server
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como curiosidad, este fichero se encuentra en &lt;em&gt;/lib/systemd/system/&lt;/em&gt;, siguiendo las convenciones del empaquetado de &lt;em&gt;Debian&lt;/em&gt;. Alternativamente, podemos localizar los ficheros instalados por un paquete con el comando &lt;em&gt;dpkg -L nginx-light&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# ls -lh /lib/systemd/system/nginx.service 
-rw-r--r-- &lt;span class="m"&gt;1&lt;/span&gt; root root &lt;span class="m"&gt;986&lt;/span&gt; dic  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;2014&lt;/span&gt; /lib/systemd/system/nginx.service
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En caso de ser una &lt;strong&gt;unit&lt;/strong&gt; escrita por nosotros, se encontraría en &lt;em&gt;/etc/systemd/system/&lt;/em&gt;. Esta es la convención:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;/lib/systemd/system/&lt;/em&gt; &amp;rarr; &lt;strong&gt;units&lt;/strong&gt; de sistema, puestas por los paquetes instalados&lt;/li&gt;
&lt;li&gt;&lt;em&gt;/lib/systemd/system/&lt;/em&gt; &amp;rarr; &lt;strong&gt;units&lt;/strong&gt; o &lt;strong&gt;overrides&lt;/strong&gt; puestos por el usuario (nosotros)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Para añadir nuevas directivas (&lt;strong&gt;overrides&lt;/strong&gt;) a una &lt;strong&gt;unit&lt;/strong&gt; sin reescribirla entera, basta con crear una carpeta con su mismo nombre, concatenando &lt;strong&gt;.d&lt;/strong&gt;. Dentro podemos poner tantos ficheros &lt;em&gt;.conf&lt;/em&gt; como creamos necesarios, añadiendo las directivas que queramos añadir o modificar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mkdir /etc/systemd/system/nginx.service.d
root@server:~# cat /etc/systemd/system/nginx.service.d/autorestart.conf
&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Restart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;always
&lt;span class="nv"&gt;RestartSec&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este caso, se ha indicado que queremos un &lt;strong&gt;restart&lt;/strong&gt; siempre, sean cuales sean las circunstancias en las que se cayó el proceso, y que espere 1 segundo antes de intentarlo. Por como está hecho &lt;em&gt;systemd&lt;/em&gt;, &lt;strong&gt;no&lt;/strong&gt; va a levantar un servicio que hemos parado invocando el comando &lt;em&gt;systemctl&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Para que los cambios en el fichero de configuración se apliquen es necesario recargar las configuraciones, indicando a &lt;em&gt;systemd&lt;/em&gt; que tienen que recargarlas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# systemctl daemon-reload
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comprobación&lt;/h2&gt;
&lt;p&gt;Básicamente vamos a repetir el paso de la comprobación; se localiza el proceso &lt;strong&gt;master&lt;/strong&gt; y se finaliza (por ejemplo, con un &lt;strong&gt;SIGTERM&lt;/strong&gt; normal).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;782&lt;/span&gt;  0.0  0.8   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2252&lt;/span&gt; pts/0    S+   11:56   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;776&lt;/span&gt;  0.0  0.7   &lt;span class="m"&gt;6356&lt;/span&gt;  &lt;span class="m"&gt;1936&lt;/span&gt; ?        Ss   11:56   0:00 nginx: master process /usr/sbin/nginx -g daemon on&lt;span class="p"&gt;;&lt;/span&gt; master_process on&lt;span class="p"&gt;;&lt;/span&gt;
www-data   &lt;span class="m"&gt;777&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2536&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;778&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2536&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;779&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2536&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;780&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2536&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
root@server:~# &lt;span class="nb"&gt;kill &lt;/span&gt;776
root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;787&lt;/span&gt;  0.0  0.9   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2280&lt;/span&gt; pts/0    S+   11:56   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora solo hay que esperar el paso de los segundos configurados, y volver a ver si el servicio está corriendo; aunque en este esperé algo menos de lo configurado; la paciencia no es una de mis virtudes...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;789&lt;/span&gt;  0.0  0.8   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2192&lt;/span&gt; pts/0    S+   11:56   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;791&lt;/span&gt;  0.0  0.9   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2280&lt;/span&gt; pts/0    S+   11:56   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root@server:~# ps faux &lt;span class="p"&gt;|&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;802&lt;/span&gt;  0.0  0.8   &lt;span class="m"&gt;4556&lt;/span&gt;  &lt;span class="m"&gt;2236&lt;/span&gt; pts/0    S+   11:56   0:00          &lt;span class="se"&gt;\_&lt;/span&gt; grep nginx
root       &lt;span class="m"&gt;796&lt;/span&gt;  0.0  0.7   &lt;span class="m"&gt;6356&lt;/span&gt;  &lt;span class="m"&gt;1932&lt;/span&gt; ?        Ss   11:56   0:00 nginx: master process /usr/sbin/nginx -g daemon on&lt;span class="p"&gt;;&lt;/span&gt; master_process on&lt;span class="p"&gt;;&lt;/span&gt;
www-data   &lt;span class="m"&gt;797&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2592&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;798&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2592&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;799&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2592&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
www-data   &lt;span class="m"&gt;800&lt;/span&gt;  0.0  1.0   &lt;span class="m"&gt;6504&lt;/span&gt;  &lt;span class="m"&gt;2532&lt;/span&gt; ?        S    11:56   0:00  &lt;span class="se"&gt;\_&lt;/span&gt; nginx: worker process                           
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto tenemos nuestro &lt;strong&gt;autorestart&lt;/strong&gt; para este servicio.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="systemd"></category><category term="nginx"></category></entry><entry><title>Liberando memoria caché</title><link href="http://www.linuxsysadmin.tk/2015/11/liberando-memoria-cache.html" rel="alternate"></link><updated>2015-11-02T14:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-11-02:2015/11/liberando-memoria-cache.html</id><summary type="html">&lt;p&gt;A veces nos encontramos que nuestro sistema linux parece tener la memoria &lt;em&gt;virtual&lt;/em&gt; ocupada, cuando no tenemos nada de memoria &lt;em&gt;RSS&lt;/em&gt;; esto no es un problema, ya que por la forma de funcionar del &lt;em&gt;memory manager&lt;/em&gt; de linux, se conserva "por si acaso" y se libera cuando realmente se necesita.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;free -m
             total       used       free     shared    buffers     cached
Mem:          &lt;span class="m"&gt;3858&lt;/span&gt;       &lt;span class="m"&gt;3226&lt;/span&gt;        &lt;span class="m"&gt;632&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;        &lt;span class="m"&gt;114&lt;/span&gt;       2545
-/+ buffers/cache:        &lt;span class="m"&gt;566&lt;/span&gt;       3291
Swap:         &lt;span class="m"&gt;2381&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;       2381
gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Sin embargo este detalle nos puede resultar molesto y puede que queramos &lt;strong&gt;liberar&lt;/strong&gt; esa memoria de verdad, por ejemplo, para comparar memoria real ocupada por el sistema o sencillamente porque así lo queremos.&lt;/p&gt;
&lt;p&gt;En este caso no tenemos mas remedio que solicitar el &lt;em&gt;memory manager&lt;/em&gt; que la libere, escribiendo en el fichero de control habilitado para ello, de acuerdo a la &lt;a href="https://www.kernel.org/doc/Documentation/sysctl/vm.txt"&gt;documentación del &lt;em&gt;kernel&lt;/em&gt; de linux&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;drop_caches

Writing to this will cause the kernel to drop clean caches, as well as
reclaimable slab objects like dentries and inodes.  Once dropped, their
memory becomes free.

To free pagecache:
    &lt;span class="nb"&gt;echo &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &amp;gt; /proc/sys/vm/drop_caches
To free reclaimable slab objects &lt;span class="o"&gt;(&lt;/span&gt;includes dentries and inodes&lt;span class="o"&gt;)&lt;/span&gt;:
    &lt;span class="nb"&gt;echo &lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt; &amp;gt; /proc/sys/vm/drop_caches
To free slab objects and pagecache:
    &lt;span class="nb"&gt;echo &lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt; &amp;gt; /proc/sys/vm/drop_caches

This is a non-destructive operation and will not free any dirty objects.
To increase the number of objects freed by this operation, the user may run
&lt;span class="sb"&gt;`&lt;/span&gt;sync&lt;span class="err"&gt;&amp;#39;&lt;/span&gt; prior to writing to /proc/sys/vm/drop_caches.  This will minimize the
number of dirty objects on the system and create more candidates to be
dropped.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Este fichero viene por defecto con permisos de escritura solamente para el usuario &lt;strong&gt;root&lt;/strong&gt; y no se puede escribir sin el mismo. Como no queremos trabajar con el usuario &lt;strong&gt;root&lt;/strong&gt;, vamos a usar el comando &lt;em&gt;sudo&lt;/em&gt; con un usuario normal:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;sudo bash -c &lt;span class="s2"&gt;&amp;quot;echo 3 &amp;gt; /proc/sys/vm/drop_caches&amp;quot;&lt;/span&gt;
gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Alternativamente, podemos utilizar el comando &lt;em&gt;tee&lt;/em&gt; para realizar la misma operación, sin el envoltorio de &lt;em&gt;bash&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;echo &lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sudo tee /proc/sys/vm/drop_caches
3
gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y finalmente nuestra memoria queda vacía de todo aquello que no era indispensable para la ejecución del sistema.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;free -m
             total       used       free     shared    buffers     cached
Mem:          &lt;span class="m"&gt;3858&lt;/span&gt;        &lt;span class="m"&gt;752&lt;/span&gt;       &lt;span class="m"&gt;3105&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;          &lt;span class="m"&gt;2&lt;/span&gt;        207
-/+ buffers/cache:        &lt;span class="m"&gt;542&lt;/span&gt;       3315
Swap:         &lt;span class="m"&gt;2381&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;       2381
gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;¡Acabamos de liberar 2 gigabytes de memoria!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CUIDADO&lt;/strong&gt;: Esta operación puede afectar el rendimiento puntual del sistema, ya que en caso de volver a necesitar la información &lt;em&gt;cacheada&lt;/em&gt;, deberá volver a recargar la memoria, probablemente desde disco.&lt;/p&gt;</summary><category term="linux"></category><category term="kernel"></category><category term="memory manager"></category><category term="drop caches"></category></entry><entry><title>Ocultando puertos con port knocking</title><link href="http://www.linuxsysadmin.tk/2015/10/ocultando-puertos-con-port-knocking.html" rel="alternate"></link><updated>2015-10-29T11:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-10-29:2015/10/ocultando-puertos-con-port-knocking.html</id><summary type="html">&lt;p&gt;En este artículo vamos a enseñar como ocultar un puerto tras el firewall, de forma que solamente se abra tras utilizar el protocolo &lt;em&gt;port knocking&lt;/em&gt;. Las tecnologías usadas van a ser &lt;em&gt;firehol&lt;/em&gt; como firewall y el demonio &lt;em&gt;knockd&lt;/em&gt; ocultando el &lt;em&gt;SSH&lt;/em&gt;, aunque vamos a permitir acceder al puerto de HTTP.&lt;/p&gt;
&lt;p&gt;El protocolo de &lt;em&gt;port knocking&lt;/em&gt; es un sistema en el que para abrir la conectividad en un puerto se debe primero abrir una secuencia concreta a otros puertos, sean &lt;em&gt;TCP&lt;/em&gt; o &lt;em&gt;UDP&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Para conseguir este objetivo, se van a usar las siguientes tecnologías:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Debian jessie&lt;/strong&gt;: Como distribución base; podría ser cualquier otra&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Firehol&lt;/strong&gt;: Scripts para levantar un firewall basado en &lt;em&gt;iptables&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El hardware va a ser uno con capacidades limitadas, virtualizado en VirtualBox.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPUs&lt;/strong&gt;: 1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memoria&lt;/strong&gt;: 256 Mb&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disco&lt;/strong&gt;: 2 Gb&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Red&lt;/strong&gt;: 1 interfaz (&lt;em&gt;eth0&lt;/em&gt;) &lt;em&gt;host-only&lt;/em&gt; o &lt;em&gt;bridged&lt;/em&gt; con IP fija&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La instalación base es una &lt;em&gt;Debian&lt;/em&gt; mínima instalada con el CD netinstall, con todo desmarcado y con el servidor de &lt;em&gt;SSH&lt;/em&gt; previamente instalado.&lt;/p&gt;
&lt;h2&gt;Instalación del servidor&lt;/h2&gt;
&lt;p&gt;Para empezar, vamos a instalar los dos servicios implicados:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# apt-get install firehol knockd
...
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Configuramos las reglas del firewall, de acuerdo a la documentación relacionada con &lt;em&gt;port knocking&lt;/em&gt;. Se define un nivel de protección máximo, ya que se trata de la interfaz que deberá estar accesible desde internet; esto nos evita la mayoría de ataques conocidos en la capa 3 y 4.&lt;/p&gt;
&lt;p&gt;En cuanto a las conectividad, vamos a permitir que este servidor acceda a servicios &lt;em&gt;DNS&lt;/em&gt; y &lt;em&gt;HTTP&lt;/em&gt;, que es lo justo para actualizarse. Como servidor vamos a permitir el acceso a &lt;em&gt;HTTP&lt;/em&gt; (ya que en el ejemplo, esta máquina va a servir como servidor &lt;em&gt;HTTP&lt;/em&gt;) y a &lt;em&gt;SSH&lt;/em&gt; siempre y cuando se cumpla con el protocolo de seguridad.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /etc/firehol/firehol.conf 
version 5

interface any world
    protection strong
    client &lt;span class="s2"&gt;&amp;quot;dns http&amp;quot;&lt;/span&gt; accept
    server http accept
    server ssh accept with knock hidden
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Acto seguido vamos a definir las reglas para que se abra el &lt;em&gt;knock hidden&lt;/em&gt; (que corresponde con el puerto &lt;em&gt;SSH&lt;/em&gt;) si se completa la secuencia de &lt;em&gt;knock&lt;/em&gt;. En este caso concreto, se indica una secuencia de los puertos &lt;em&gt;TCP&lt;/em&gt; 123, 456 y 789; aunque es posible definir puertos &lt;em&gt;UDP&lt;/em&gt;, dejamos sin indicarlo, que nos los va a definir como &lt;em&gt;TCP&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Como medida de seguridad vamos a indicar un tiempo máximo de 10 segundos para completar la secuencia de &lt;em&gt;knock&lt;/em&gt; y un autocierre del puerto a los 5 segundos (aunque firehol va a permitir las conexiones que se hayan establecido en esos 5 segundos).&lt;/p&gt;
&lt;p&gt;Es especialmente interesante ver que la regla incluye la dirección origen, con lo que la apertura de puerto solo será visible desde la máquina que completó la secuencia de &lt;em&gt;knock&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /etc/knockd.conf 
&lt;span class="o"&gt;[&lt;/span&gt;options&lt;span class="o"&gt;]&lt;/span&gt;
    UseSyslog

&lt;span class="o"&gt;[&lt;/span&gt;SSH&lt;span class="o"&gt;]&lt;/span&gt;
    &lt;span class="nv"&gt;sequence&lt;/span&gt;      &lt;span class="o"&gt;=&lt;/span&gt; 123,456,789
    &lt;span class="nv"&gt;seq_timeout&lt;/span&gt;   &lt;span class="o"&gt;=&lt;/span&gt; 10
    &lt;span class="nv"&gt;start_command&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; iptables -A knock_hidden -s %IP% -j ACCEPT
    &lt;span class="nv"&gt;cmd_timeout&lt;/span&gt;   &lt;span class="o"&gt;=&lt;/span&gt; 5
    &lt;span class="nv"&gt;stop_command&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; iptables -D knock_hidden -s %IP% -j ACCEPT
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como medida de seguridad, &lt;em&gt;Debian&lt;/em&gt; tiene una protección para levantar ambos servicios, así que tenemos que indicarle que queremos que se puedan levantar, editando otros ficheros de configuración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /etc/default/knockd 
...
&lt;span class="nv"&gt;START_KNOCKD&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1
...
root@server:~# cat /etc/default/firehol 
...
&lt;span class="nv"&gt;START_FIREHOL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;YES
...
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente podemos levantar los servicios de &lt;em&gt;port knocking&lt;/em&gt; y de &lt;em&gt;firewall&lt;/em&gt;, usando las herramientas estándares que nos ofrece la distribución.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# service knockd restart
root@server:~# service firehol restart
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comprobación de funcionamiento&lt;/h2&gt;
&lt;p&gt;Para comprobar el funcionamiento basta con comprobar que el puerto está normalmente cerrado. Personalmente he usado &lt;em&gt;nmap&lt;/em&gt;, aunque se podría usar &lt;em&gt;netcat&lt;/em&gt; o &lt;em&gt;telnet&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;nmap -PN 192.168.56.3 -p 22

Starting Nmap 5.21 &lt;span class="o"&gt;(&lt;/span&gt; http://nmap.org &lt;span class="o"&gt;)&lt;/span&gt; at 2015-10-28 17:33 CET
Nmap scan report &lt;span class="k"&gt;for&lt;/span&gt; server &lt;span class="o"&gt;(&lt;/span&gt;192.168.56.3&lt;span class="o"&gt;)&lt;/span&gt;
Host is up.
PORT   STATE    SERVICE
22/tcp filtered ssh

Nmap &lt;span class="k"&gt;done&lt;/span&gt;: &lt;span class="m"&gt;1&lt;/span&gt; IP address &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; host up&lt;span class="o"&gt;)&lt;/span&gt; scanned in 2.13 seconds
gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vemos que sale &lt;strong&gt;filtered&lt;/strong&gt;, que significa que el firewall lo está bloqueando. Ahora vamos a lanzar la secuencia de &lt;em&gt;knock&lt;/em&gt; usando el helper &lt;strong&gt;knock&lt;/strong&gt;, que en &lt;em&gt;Debian&lt;/em&gt; se encuentra en el mismo paquete &lt;em&gt;knockd&lt;/em&gt;. Acto seguido, el puerto de &lt;em&gt;SSH&lt;/em&gt; queda abierto (en otras palabras: escuchando). Ahora sería posible iniciar sesión por &lt;em&gt;SSH&lt;/em&gt; en la máquina.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;knock 192.168.56.3 &lt;span class="m"&gt;123&lt;/span&gt; &lt;span class="m"&gt;456&lt;/span&gt; 789
gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;nmap -PN 192.168.56.3 -p 22

Starting Nmap 5.21 &lt;span class="o"&gt;(&lt;/span&gt; http://nmap.org &lt;span class="o"&gt;)&lt;/span&gt; at 2015-10-28 17:34 CET
Nmap scan report &lt;span class="k"&gt;for&lt;/span&gt; server &lt;span class="o"&gt;(&lt;/span&gt;192.168.56.3&lt;span class="o"&gt;)&lt;/span&gt;
Host is up &lt;span class="o"&gt;(&lt;/span&gt;0.0011s latency&lt;span class="o"&gt;)&lt;/span&gt;.
PORT   STATE SERVICE
22/tcp open  ssh

Nmap &lt;span class="k"&gt;done&lt;/span&gt;: &lt;span class="m"&gt;1&lt;/span&gt; IP address &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; host up&lt;span class="o"&gt;)&lt;/span&gt; scanned in 0.07 seconds
gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente comprobamos que, transcurridos los 5 segundos configurados, el puerto vuelve a verse como &lt;strong&gt;filtrado&lt;/strong&gt;, con lo que no se puede establecer nuevas conexiones en este puerto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;nmap -PN 192.168.56.3 -p 22

Starting Nmap 5.21 &lt;span class="o"&gt;(&lt;/span&gt; http://nmap.org &lt;span class="o"&gt;)&lt;/span&gt; at 2015-10-28 17:34 CET
Nmap scan report &lt;span class="k"&gt;for&lt;/span&gt; server &lt;span class="o"&gt;(&lt;/span&gt;192.168.56.3&lt;span class="o"&gt;)&lt;/span&gt;
Host is up.
PORT   STATE    SERVICE
22/tcp filtered ssh

Nmap &lt;span class="k"&gt;done&lt;/span&gt;: &lt;span class="m"&gt;1&lt;/span&gt; IP address &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; host up&lt;span class="o"&gt;)&lt;/span&gt; scanned in 2.08 seconds
gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto queda protegido el acceso por &lt;em&gt;SSH&lt;/em&gt; a la máquina.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="firehol"></category><category term="port knocking"></category><category term="ssh"></category><category term="nmap"></category></entry><entry><title>Virtualizando contenedores LXC con acceso a la red local</title><link href="http://www.linuxsysadmin.tk/2015/10/virtualizando-contenedores-lxc-con-acceso-red-local.html" rel="alternate"></link><updated>2015-10-15T12:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-10-15:2015/10/virtualizando-contenedores-lxc-con-acceso-red-local.html</id><summary type="html">&lt;p&gt;En este tutorial se propone montar un servidor de contenedores LXC, de forma que todos los contenedores queden expuestos a la misma red que el servidor que los aloja. Para protegerlos de posibles ataques de esta red, pondremos un firewall basado en &lt;em&gt;iptables&lt;/em&gt; mediante una capa de abstracción llamada &lt;em&gt;firehol&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Para conseguir este objetivo, se van a usar las siguientes tecnologías:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Debian jessie&lt;/strong&gt;: Es necesario usar alguna distribución de linux para hacer funcionar LXC&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LXC&lt;/strong&gt;: Tecnología que permite aislar los contenedores entre sí y darles entidad propia&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bridges&lt;/strong&gt;: Un bridge es en software el equivalente a un switch hardware&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Firehol&lt;/strong&gt;: Una serie de scripts para construir firewalls basados en iptables de forma fácil&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En cuanto a las capacidades hardware, vamos a hacer el tutorial con un equipo de capacidades modestas, virtualizado en una máquina virtual VirtualBox.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPUs&lt;/strong&gt;: 1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memoria&lt;/strong&gt;: 256 Mb&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disco&lt;/strong&gt;: 2 Gb&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Red&lt;/strong&gt;: 1 interfaz (&lt;em&gt;eth0&lt;/em&gt;) &lt;em&gt;host-only&lt;/em&gt; o &lt;em&gt;bridged&lt;/em&gt; con IP fija&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Partimos de una distribución &lt;em&gt;Debian jessie&lt;/em&gt; instalada con un CD &lt;em&gt;netinstall&lt;/em&gt; y con el único paquete instalado &lt;em&gt;openssh-server&lt;/em&gt;, para mi comodidad.&lt;/p&gt;
&lt;h2&gt;Preparar el servidor&lt;/h2&gt;
&lt;p&gt;El primer paso consiste en instalar las tecnologías usadas:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# apt-get install bridge-utils firehol lxc
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
...
Configurando lxc &lt;span class="o"&gt;(&lt;/span&gt;1:1.0.6-6+deb8u1&lt;span class="o"&gt;)&lt;/span&gt; ...
Configurando dh-python &lt;span class="o"&gt;(&lt;/span&gt;1.20141111-2&lt;span class="o"&gt;)&lt;/span&gt; ...
Procesando disparadores para libc-bin &lt;span class="o"&gt;(&lt;/span&gt;2.19-18+deb8u1&lt;span class="o"&gt;)&lt;/span&gt; ...
Procesando disparadores para systemd &lt;span class="o"&gt;(&lt;/span&gt;215-17+deb8u2&lt;span class="o"&gt;)&lt;/span&gt; ...
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Acto seguido debemos modificar la configuración de red, para que la interfaz de red de la máquina represente la salida de todas las IPs que maneja el bridge y para que el host obtenga una dirección de red en el bridge.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ANTES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/network/interfaces
&lt;span class="nb"&gt;source&lt;/span&gt; /etc/network/interfaces.d/*

auto lo
iface lo inet loopback

auto eth0
iface eth0 inet static
    address 192.168.56.4
    netmask 255.255.255.0
    gateway 192.168.56.1
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;DESPUES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/network/interfaces
&lt;span class="nb"&gt;source&lt;/span&gt; /etc/network/interfaces.d/*

auto lo
iface lo inet loopback

auto lxc0
iface lxc0 inet static
    bridge_ports eth0
    address 192.168.56.4
    netmask 255.255.255.0
    gateway 192.168.56.1
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este punto es necesario reconfigurar la red, siendo especialmente importante que &lt;em&gt;eth0&lt;/em&gt; quede sin dirección IP asignada (en mi caso tuve que reiniciar la máquina).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# ip addr
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu &lt;span class="m"&gt;65536&lt;/span&gt; qdisc noqueue state UNKNOWN group default 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu &lt;span class="m"&gt;1500&lt;/span&gt; qdisc pfifo_fast master lxc0 state UP group default qlen 1000
    link/ether 08:00:27:e4:0a:60 brd ff:ff:ff:ff:ff:ff
3: lxc0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu &lt;span class="m"&gt;1500&lt;/span&gt; qdisc noqueue state UP group default 
    link/ether 08:00:27:e4:0a:60 brd ff:ff:ff:ff:ff:ff
    inet 192.168.56.4/24 brd 192.168.56.255 scope global lxc0
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:fee4:a60/64 scope link 
       valid_lft forever preferred_lft forever
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El último paso consiste en activar el firewall con unas reglas básicas, para proteger el equipo anfitrión de posibles ataques o intrusiones, dejando solamente el acceso a SSH. Con firehol es posible combinar el demonio &lt;em&gt;knockd&lt;/em&gt; para ocultar el puerto tras una secuencia de port knocking; en principio sería suficiente con forzar la entrada SSH por claves RSA.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf 
interface lxc0 world
    policy drop
    protection strong
    server ssh accept
    client all accept
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hay que modificar otro fichero para permitir el inicio del firewall:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ANTES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# grep START /etc/default/firehol 
&lt;span class="c"&gt;#To enable firehol at startup set START_FIREHOL=YES&lt;/span&gt;
&lt;span class="nv"&gt;START_FIREHOL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;NO
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;DESPUES&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# grep START /etc/default/firehol 
&lt;span class="c"&gt;#To enable firehol at startup set START_FIREHOL=YES&lt;/span&gt;
&lt;span class="nv"&gt;START_FIREHOL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;YES
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para acabar, (re)iniciamos el servicio firehol.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# service firehol restart

Broadcast message from systemd-journald@lxc &lt;span class="o"&gt;(&lt;/span&gt;Wed 2015-10-14 16:59:30 CEST&lt;span class="o"&gt;)&lt;/span&gt;:

FireHOL&lt;span class="o"&gt;[&lt;/span&gt;620&lt;span class="o"&gt;]&lt;/span&gt;: Firewall has been stopped. Policy is ACCEPT EVERYTHING!


Message from syslogd@lxc at Oct &lt;span class="m"&gt;14&lt;/span&gt; 16:59:30 ...
 FireHOL&lt;span class="o"&gt;[&lt;/span&gt;493&lt;span class="o"&gt;]&lt;/span&gt;: Firewall has been stopped. Policy is ACCEPT EVERYTHING!
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Creación de contenedores&lt;/h2&gt;
&lt;p&gt;La creación de contenedores pasa por usar las herramientas estándar de la distribución, a lo solo tendremos que modificar algunas configuraciones propias de nuestra red.&lt;/p&gt;
&lt;p&gt;Creamos un contenedor &lt;em&gt;webserver&lt;/em&gt; como demostración. La primera que se crea es un poco lenta porque hace un &lt;em&gt;debootstrap&lt;/em&gt; de una distribución debian estable para crear una cache en &lt;em&gt;/var/cache/lxc&lt;/em&gt;; las siguientes se benefician de esta caché y solo la actualizan, acelerando el proceso.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-create -n webserver -t debian
debootstrap is /usr/sbin/debootstrap
Checking cache download in /var/cache/lxc/debian/rootfs-jessie-i386 ... 
Downloading debian minimal ...
...
I: Base system installed successfully.
Download complete.
Copying rootfs to /var/lib/lxc/webserver/rootfs...
...
Current default &lt;span class="nb"&gt;time &lt;/span&gt;zone: &lt;span class="s1"&gt;&amp;#39;Europe/Madrid&amp;#39;&lt;/span&gt;
Local &lt;span class="nb"&gt;time &lt;/span&gt;is now:      Wed Oct &lt;span class="m"&gt;14&lt;/span&gt; 17:26:37 CEST 2015.
Universal Time is now:  Wed Oct &lt;span class="m"&gt;14&lt;/span&gt; 15:26:37 UTC 2015.

Root password is &lt;span class="s1"&gt;&amp;#39;sFj7Jm9N&amp;#39;&lt;/span&gt;, please change !
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Acabada la generación del contenedor, vamos a configurarle algunos parámetros; que tenga una interfaz &lt;em&gt;eth0&lt;/em&gt; activa y enchufada al bridge &lt;em&gt;lxc0&lt;/em&gt;, y que el contenedor se autoinicie en cada reinicio del anfitrión.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /var/lib/lxc/webserver/config 
...
lxc.start.auto &lt;span class="o"&gt;=&lt;/span&gt; 1
lxc.network.type &lt;span class="o"&gt;=&lt;/span&gt; veth
lxc.network.flags &lt;span class="o"&gt;=&lt;/span&gt; up
lxc.network.link &lt;span class="o"&gt;=&lt;/span&gt; lxc0
lxc.network.name &lt;span class="o"&gt;=&lt;/span&gt; eth0
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para que su interfaz de red sea funcional, vamos a configurarle una dirección IP. Todo esto se hace en los ficheros habituales, teniendo en cuenta que un contenedor es una jaula, y que esta se encuentra en &lt;em&gt;/var/lib/lxc/webserver/rootfs/&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /var/lib/lxc/webserver/rootfs/etc/network/interfaces
auto lo
iface lo inet loopback

auto eth0
iface eth0 inet static
    address 192.168.56.10
    netmask 255.255.255.0
    gateway 192.168.56.1
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El contenedor ya está funcional, y se puede levantar:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-start -n webserver -d
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Sin embargo, el firewall impide que se llegue al mismo; tendremos que poner reglas para permitir el flujo de red hacia la nueva dirección IP configurada para el contenedor. Esto se consigue con reglas de &lt;em&gt;forward&lt;/em&gt; que entren por el bridge y salgan por el mismo hacia nuestro contenedor.&lt;/p&gt;
&lt;p&gt;Ya de paso habilitamos reglas para que todo lo que pase por el bridge hacia internet se permita. Como particularidad de nuestra red, el servidor anfitrión tiene un servidor DNS &lt;em&gt;dnsmasq&lt;/em&gt;; así que añadimos también esa ruta.&lt;/p&gt;
&lt;p&gt;Por ejemplo, suponiendo que queremos habilitar el servicio &lt;em&gt;SSH&lt;/em&gt; (tcp 22) y el puerto del servicio &lt;em&gt;HTTP&lt;/em&gt; (tcp 80), pondremos lo siguiente en la configuración del firewall (tras lo cual lo reiniciaremos):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf 
interface lxc0 world
    policy drop
    protection strong
    server ssh accept
    client all accept

router internal inface lxc0 outface lxc0
    policy drop
    client all accept
    group with dst not &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;UNROUTABLE_IPS&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
        route all accept
    group end
    group with dst 192.168.56.1
        route dns accept
    group end
    group with dst 192.168.56.10
        route ssh accept
        route http accept
    group end
root@lxc:~# service firehol restart

Broadcast message from systemd-journald@lxc &lt;span class="o"&gt;(&lt;/span&gt;Wed 2015-10-14 17:43:38 CEST&lt;span class="o"&gt;)&lt;/span&gt;:

FireHOL&lt;span class="o"&gt;[&lt;/span&gt;8690&lt;span class="o"&gt;]&lt;/span&gt;: Firewall has been stopped. Policy is ACCEPT EVERYTHING!


Message from syslogd@lxc at Oct &lt;span class="m"&gt;14&lt;/span&gt; 17:43:38 ...
 FireHOL&lt;span class="o"&gt;[&lt;/span&gt;8565&lt;span class="o"&gt;]&lt;/span&gt;: Firewall has been stopped. Policy is ACCEPT EVERYTHING!
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y solamente queda entrar al contenedor, por ejemplo por &lt;em&gt;SSH&lt;/em&gt; para instalar lo que se necesite; en este caso con un &lt;em&gt;nginx&lt;/em&gt; sería suficiente como demostración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@workstation:~&lt;span class="nv"&gt;$ &lt;/span&gt;ssh root@192.168.56.10
root@192.168.56.10&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 

The programs included with the Debian GNU/Linux system are free software&lt;span class="p"&gt;;&lt;/span&gt;
the exact distribution terms &lt;span class="k"&gt;for&lt;/span&gt; each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
root@webserver:~# apt-get install nginx-light
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
Se instalarán los siguientes paquetes extras:
  nginx-common
Paquetes sugeridos:
  fcgiwrap nginx-doc ssl-cert
Se instalarán los siguientes paquetes NUEVOS:
  nginx-common nginx-light
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;2&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;439&lt;/span&gt; kB de archivos.
Se utilizarán 1.040 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
Configurando nginx-common &lt;span class="o"&gt;(&lt;/span&gt;1.6.2-5&lt;span class="o"&gt;)&lt;/span&gt; ...
Configurando nginx-light &lt;span class="o"&gt;(&lt;/span&gt;1.6.2-5&lt;span class="o"&gt;)&lt;/span&gt; ...
Procesando disparadores para systemd &lt;span class="o"&gt;(&lt;/span&gt;215-17+deb8u2&lt;span class="o"&gt;)&lt;/span&gt; ...
root@webserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto ya tenemos nuestro contenedor en marcha y ofreciendo servicios en nuestra red local de forma segura.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="lxc"></category><category term="bridge"></category><category term="firehol"></category></entry></feed>