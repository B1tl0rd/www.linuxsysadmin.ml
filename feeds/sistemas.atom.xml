<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Linux Sysadmin</title><link href="http://www.linuxsysadmin.tk/" rel="alternate"></link><link href="http://www.linuxsysadmin.tk/feeds/sistemas.atom.xml" rel="self"></link><id>http://www.linuxsysadmin.tk/</id><updated>2016-06-20T08:30:00+02:00</updated><entry><title>Preparando un servidor de repositorios GIT</title><link href="http://www.linuxsysadmin.tk/2016/06/preparando-un-servidor-de-repositorios-git.html" rel="alternate"></link><updated>2016-06-20T08:30:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2016-06-20:2016/06/preparando-un-servidor-de-repositorios-git.html</id><summary type="html">&lt;p&gt;Algunas veces tenemos necesidad de crear un proyecto con un equipo pequeño y necesitamos versionarlo en un sitio accesible para todos los participantes involucrados. El precio de soluciones en la nube suele ser prohibitivo, y montar una solución gráfica puede ser demasiado. Lo podemos hacer simplemente usando &lt;strong&gt;git&lt;/strong&gt; y &lt;strong&gt;ssh&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;La idea es muy simple; solo se necesita un servidor de &lt;strong&gt;ssh&lt;/strong&gt;, que es la forma de transportar los datos, y los binarios de &lt;strong&gt;git&lt;/strong&gt; para que los organice a placer. También vamos a necesitar un usuario &lt;strong&gt;git&lt;/strong&gt;, que es el que vamos a usar para entrar, ya sea para crear y borrar repositorios, como para las operaciones remotas recibidas por el repositorio.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: Podemos eliminar la petición de &lt;em&gt;password&lt;/em&gt; para todos los accesos que se hagan por &lt;strong&gt;SSH&lt;/strong&gt;, sean para entrar en las máquinas por &lt;strong&gt;SSH&lt;/strong&gt; mediante cualquier &lt;em&gt;shell&lt;/em&gt; de este artículo, o como resultado de una operación remota de &lt;strong&gt;git&lt;/strong&gt;. Esto se puede hacer usando autenticación &lt;strong&gt;SSH&lt;/strong&gt; por claves, como se explica en un &lt;a href="http://www.linuxsysadmin.tk/2016/05/autenticacion-ssh-por-claves.html"&gt;artículo anterior&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Montando el servidor&lt;/h2&gt;
&lt;p&gt;Para crear la máquina base, vamos a utilizar &lt;strong&gt;Docker&lt;/strong&gt; por comodidad. Aprovechando esta tecnología, podemos crear el contenedor partiendo de una imagen creada con un &lt;em&gt;Dockerfile&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;cat Dockerfile
FROM debian:jessie
RUN apt-get update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    apt-get install -y git openssh-server &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    mkdir /var/run/sshd
RUN useradd git -G sudo -s /bin/bash -m &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;git:git&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; chpasswd
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/usr/sbin/sshd&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;-D&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Construimos la imagen, basándonos en el anterior &lt;em&gt;Dockerfile&lt;/em&gt;, y le añadimos el &lt;em&gt;tag&lt;/em&gt; "gitserver".&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;docker build -t gitserver .
Sending build context to Docker daemon 5.632 kB
Step &lt;span class="m"&gt;1&lt;/span&gt; : FROM debian:jessie
 ---&amp;gt; bb5d89f9b6cb
Step &lt;span class="m"&gt;2&lt;/span&gt; : RUN apt-get update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     apt-get install -y git openssh-server &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     mkdir /var/run/sshd
 ---&amp;gt; Running in 6b612781b788
...
 ---&amp;gt; e88e644b0a53
Removing intermediate container 6b612781b788
Step &lt;span class="m"&gt;3&lt;/span&gt; : RUN useradd git -G sudo -s /bin/bash -m &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;git:git&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; chpasswd
 ---&amp;gt; Running in 0e865bda447e
 ---&amp;gt; 81d111c19c71
Removing intermediate container 0e865bda447e
Step &lt;span class="m"&gt;4&lt;/span&gt; : CMD /usr/sbin/sshd -D
 ---&amp;gt; Running in 67bbebe61c74
 ---&amp;gt; 81c2dd7b156a
Removing intermediate container 67bbebe61c74
Successfully built 81c2dd7b156a
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lanzamos una instancia del contenedor para que podamos utilizarla. La parte importante es el &lt;em&gt;flag&lt;/em&gt; &lt;strong&gt;-d&lt;/strong&gt; para ejecutar el contenedor en &lt;em&gt;background&lt;/em&gt;, y el &lt;em&gt;flag&lt;/em&gt; &lt;strong&gt;-p&lt;/strong&gt; que nos permite publicar el puerto 22 del contenedor en el puerto 22222 de la máquina &lt;em&gt;host&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;docker run -d --name gitserver1 -h gitserver1 -p 22222:22 gitserver
c26f30a94bb75b35c6d6cfe6a6bc5b1ef6929aafe1b5636acd207e019743540b
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a entrar en el servidor &lt;strong&gt;SSH&lt;/strong&gt; para crear el repositorio &lt;em&gt;myrepo.git&lt;/em&gt; que nos va a servir de ejemplo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;ssh git@localhost -p 22222
git@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 

The programs included with the Debian GNU/Linux system are free software&lt;span class="p"&gt;;&lt;/span&gt;
the exact distribution terms &lt;span class="k"&gt;for&lt;/span&gt; each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
git@gitserver1:~&lt;span class="nv"&gt;$ &lt;/span&gt;git init --bare myrepo.git
Initialized empty Git repository in /home/git/myrepo.git/
git@gitserver1:~&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;exit&lt;/span&gt;
&lt;span class="nb"&gt;logout&lt;/span&gt;
Connection to localhost closed.
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Desde la máquina &lt;em&gt;host&lt;/em&gt; (o desde cualquier otra), podemos clonar el repositorio. Como tenemos el puerto del contenedor publicado en el puerto 22222 de la máquina &lt;em&gt;host&lt;/em&gt; (la de trabajo, en este caso), la usamos tal cual para clonar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;git clone ssh://git@localhost:22222/home/git/myrepo.git
Cloning into &lt;span class="s1"&gt;&amp;#39;myrepo&amp;#39;&lt;/span&gt;...
git@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
warning: You appear to have cloned an empty repository.
Checking connectivity... &lt;span class="k"&gt;done&lt;/span&gt;.
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hacemos un poco de trabajo local, con sus respectivos &lt;em&gt;commits&lt;/em&gt;. Finalmente podemos hacer un &lt;em&gt;push&lt;/em&gt; a nuestro repositorio remoto, siguiendo el &lt;em&gt;workflow&lt;/em&gt; de trabajo que queramos seguir.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;cd &lt;/span&gt;myrepo/
gerard@sirius:~/build/myrepo&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;echo &lt;/span&gt;0.0.1 &amp;gt; VERSION
gerard@sirius:~/build/myrepo&lt;span class="nv"&gt;$ &lt;/span&gt;git add VERSION 
gerard@sirius:~/build/myrepo&lt;span class="nv"&gt;$ &lt;/span&gt;git commit -m &lt;span class="s2"&gt;&amp;quot;Initial commit&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;master &lt;span class="o"&gt;(&lt;/span&gt;root-commit&lt;span class="o"&gt;)&lt;/span&gt; f30b82a&lt;span class="o"&gt;]&lt;/span&gt; Initial commit
 &lt;span class="m"&gt;1&lt;/span&gt; file changed, &lt;span class="m"&gt;1&lt;/span&gt; insertion&lt;span class="o"&gt;(&lt;/span&gt;+&lt;span class="o"&gt;)&lt;/span&gt;
 create mode &lt;span class="m"&gt;100644&lt;/span&gt; VERSION
gerard@sirius:~/build/myrepo&lt;span class="nv"&gt;$ &lt;/span&gt;git push -u origin master
git@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
Counting objects: 3, &lt;span class="k"&gt;done&lt;/span&gt;.
Writing objects: 100% &lt;span class="o"&gt;(&lt;/span&gt;3/3&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;222&lt;/span&gt; bytes &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; bytes/s, &lt;span class="k"&gt;done&lt;/span&gt;.
Total &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;delta 0&lt;span class="o"&gt;)&lt;/span&gt;, reused &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;delta 0&lt;span class="o"&gt;)&lt;/span&gt;
To ssh://git@localhost:22222/home/git/myrepo.git
 * &lt;span class="o"&gt;[&lt;/span&gt;new branch&lt;span class="o"&gt;]&lt;/span&gt;      master -&amp;gt; master
Branch master &lt;span class="nb"&gt;set &lt;/span&gt;up to track remote branch master from origin.
gerard@sirius:~/build/myrepo&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; ..
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Añadiendo restricciones a la sesión SSH&lt;/h2&gt;
&lt;p&gt;Es un poco peligroso permitir que el usuario &lt;em&gt;git&lt;/em&gt; entre mediante una sesión &lt;strong&gt;SSH&lt;/strong&gt; para hacer lo que le parezca.&lt;/p&gt;
&lt;p&gt;Los mismos binarios de &lt;strong&gt;git&lt;/strong&gt; incluyen &lt;strong&gt;git-shell&lt;/strong&gt;, que es un &lt;em&gt;shell&lt;/em&gt; que limita lo que puede hacer el usuario, aunque solo permitiría hacer las operaciones &lt;em&gt;push&lt;/em&gt; y &lt;em&gt;pull&lt;/em&gt; propias del trabajo remoto con &lt;strong&gt;git&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;¿Y como podemos crear y destruir repositorios? En principio, no se puede. Sin embargo, si creamos una carpeta &lt;em&gt;/home/git/git-shell-commands/&lt;/em&gt;, el usuario va a poder ejecutar los &lt;em&gt;scripts&lt;/em&gt; que allí pongamos.&lt;/p&gt;
&lt;p&gt;Siguiendo esta idea, vamos a mejorar el &lt;em&gt;Dockerfile&lt;/em&gt; para asignar &lt;strong&gt;git-shell&lt;/strong&gt; al usuario &lt;em&gt;git&lt;/em&gt; y para ponerle un par de comandos.&lt;/p&gt;
&lt;p&gt;Vamos a crear dos &lt;em&gt;scripts&lt;/em&gt; que nos permitan crear y destruir repositorios, que son los siguientes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;cat create 
&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="si"&gt;${#}&lt;/span&gt; -ne &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[ERROR] Syntax: create &amp;lt;repository&amp;gt;&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; -1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; -e &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.git &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[ERROR] Repository &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; exists&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; -1
&lt;span class="k"&gt;fi&lt;/span&gt;

git init --bare &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.git
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[OK] Repository &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; created&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;exit &lt;/span&gt;0
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;cat destroy 
&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="si"&gt;${#}&lt;/span&gt; -ne &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[ERROR] Syntax: destroy &amp;lt;repository&amp;gt;&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; -1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; -e &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.git &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    rm -Rf &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.git
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[OK] Repository &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; deleted&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;0
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[ERROR] Repository &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; does not exist&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;exit&lt;/span&gt; -1
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;También vamos a reescribir el &lt;em&gt;Dockerfile&lt;/em&gt; con las nuevas modificaciones.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;cat Dockerfile.shell 
FROM debian:jessie
RUN apt-get update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    apt-get install -y git openssh-server &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    mkdir /var/run/sshd
RUN useradd git -G sudo -s /usr/bin/git-shell -m &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;git:git&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; chpasswd &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    mkdir /home/git/git-shell-commands
COPY create destroy /home/git/git-shell-commands/
RUN cp /usr/share/doc/git/contrib/git-shell-commands/help /home/git/git-shell-commands/ &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    cp /usr/share/doc/git/contrib/git-shell-commands/list /home/git/git-shell-commands/ &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    chmod &lt;span class="m"&gt;755&lt;/span&gt; /home/git/git-shell-commands/*
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/usr/sbin/sshd&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;-D&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos la imagen usando el &lt;em&gt;Dockerfile&lt;/em&gt; antes mencionado, siguiendo el mismo procedimiento de la versión básica. Le ponemos un &lt;em&gt;tag&lt;/em&gt; distinto para tener ambas imágenes funcionales.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;docker build -f Dockerfile.shell -t gitserver:shell .
Sending build context to Docker daemon 53.25 kB
Step &lt;span class="m"&gt;1&lt;/span&gt; : FROM debian:jessie
 ---&amp;gt; bb5d89f9b6cb
Step &lt;span class="m"&gt;2&lt;/span&gt; : RUN apt-get update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     apt-get install -y git openssh-server &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     mkdir /var/run/sshd
 ---&amp;gt; Using cache
 ---&amp;gt; e88e644b0a53
Step &lt;span class="m"&gt;3&lt;/span&gt; : RUN useradd git -G sudo -s /usr/bin/git-shell -m &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;git:git&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; chpasswd &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     mkdir /home/git/git-shell-commands
 ---&amp;gt; Running in 387d2791d63f
 ---&amp;gt; 0ab419cdfc2d
Removing intermediate container 387d2791d63f
Step &lt;span class="m"&gt;4&lt;/span&gt; : COPY create destroy /home/git/git-shell-commands/
 ---&amp;gt; e1aa5fa9cb44
Removing intermediate container 92fd282c6979
Step &lt;span class="m"&gt;5&lt;/span&gt; : RUN cp /usr/share/doc/git/contrib/git-shell-commands/help /home/git/git-shell-commands/ &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     cp /usr/share/doc/git/contrib/git-shell-commands/list /home/git/git-shell-commands/ &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     chmod &lt;span class="m"&gt;755&lt;/span&gt; /home/git/git-shell-commands/*
 ---&amp;gt; Running in 45ed8f24a547
 ---&amp;gt; 2237b87165bc
Removing intermediate container 45ed8f24a547
Step &lt;span class="m"&gt;6&lt;/span&gt; : CMD /usr/sbin/sshd -D
 ---&amp;gt; Running in b94b8c1ddf8a
 ---&amp;gt; e484e1465480
Removing intermediate container b94b8c1ddf8a
Successfully built e484e1465480
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lanzamos una instancia de la imagen creada. Es importante cambiar el puerto; puesto que el 22222 está ocupado por la instancia anterior, usaré el siguiente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;docker run -d --name gitserver2 -h gitserver2 -p 22223:22 gitserver:shell
e732027d11b90657ff109a455f032327f0e24eebe54a7e121d86eff6eab1bc4b
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Entramos por &lt;strong&gt;SSH&lt;/strong&gt;. Nos podemos dar cuenta de que el &lt;em&gt;prompt&lt;/em&gt; ha cambiado; estamos en el &lt;strong&gt;git-shell&lt;/strong&gt; y tenemos limitados los comandos a los que añadimos en el &lt;em&gt;Dockerfile&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;ssh git@localhost -p 22223
git@localhost&lt;span class="s1"&gt;&amp;#39;s password: &lt;/span&gt;

&lt;span class="s1"&gt;The programs included with the Debian GNU/Linux system are free software;&lt;/span&gt;
&lt;span class="s1"&gt;the exact distribution terms for each program are described in the&lt;/span&gt;
&lt;span class="s1"&gt;individual files in /usr/share/doc/*/copyright.&lt;/span&gt;

&lt;span class="s1"&gt;Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent&lt;/span&gt;
&lt;span class="s1"&gt;permitted by applicable law.&lt;/span&gt;
&lt;span class="s1"&gt;Run &amp;#39;&lt;/span&gt;&lt;span class="nb"&gt;help&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39; for help, or &amp;#39;&lt;/span&gt;&lt;span class="nb"&gt;exit&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt; to leave.  Available commands:
create
destroy
list
git&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Usamos el comando &lt;em&gt;create&lt;/em&gt; para crear el repositorio y verificamos que está usando el comando &lt;em&gt;list&lt;/em&gt;. Tendríamos disponible el comando &lt;em&gt;destroy&lt;/em&gt;, pero de momento no lo vamos a utilizar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;git&amp;gt; create myrepo2
Initialized empty Git repository in /home/git/myrepo2.git/
&lt;span class="o"&gt;[&lt;/span&gt;OK&lt;span class="o"&gt;]&lt;/span&gt; Repository myrepo2 created
git&amp;gt; list
myrepo2.git
git&amp;gt; &lt;span class="nb"&gt;exit&lt;/span&gt;
Connection to localhost closed.
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Verificamos que funciona, clonando el repositorio como hemos hecho antes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;git clone ssh://git@localhost:22223/home/git/myrepo2.git
Cloning into &lt;span class="s1"&gt;&amp;#39;myrepo2&amp;#39;&lt;/span&gt;...
git@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
warning: You appear to have cloned an empty repository.
Checking connectivity... &lt;span class="k"&gt;done&lt;/span&gt;.
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hacemos algunos &lt;em&gt;commits&lt;/em&gt; locales y finalmente los pasamos al repositorio remoto mediante un &lt;em&gt;push&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;cd &lt;/span&gt;myrepo2/
gerard@sirius:~/build/myrepo2&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;echo &lt;/span&gt;0.0.1 &amp;gt; VERSION
gerard@sirius:~/build/myrepo2&lt;span class="nv"&gt;$ &lt;/span&gt;git add VERSION
gerard@sirius:~/build/myrepo2&lt;span class="nv"&gt;$ &lt;/span&gt;git commit -m &lt;span class="s2"&gt;&amp;quot;Initial commit&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;master &lt;span class="o"&gt;(&lt;/span&gt;root-commit&lt;span class="o"&gt;)&lt;/span&gt; fd40f39&lt;span class="o"&gt;]&lt;/span&gt; Initial commit
 &lt;span class="m"&gt;1&lt;/span&gt; file changed, &lt;span class="m"&gt;1&lt;/span&gt; insertion&lt;span class="o"&gt;(&lt;/span&gt;+&lt;span class="o"&gt;)&lt;/span&gt;
 create mode &lt;span class="m"&gt;100644&lt;/span&gt; VERSION
gerard@sirius:~/build/myrepo2&lt;span class="nv"&gt;$ &lt;/span&gt;git push -u origin master
git@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
Counting objects: 3, &lt;span class="k"&gt;done&lt;/span&gt;.
Writing objects: 100% &lt;span class="o"&gt;(&lt;/span&gt;3/3&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;222&lt;/span&gt; bytes &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; bytes/s, &lt;span class="k"&gt;done&lt;/span&gt;.
Total &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;delta 0&lt;span class="o"&gt;)&lt;/span&gt;, reused &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;delta 0&lt;span class="o"&gt;)&lt;/span&gt;
To ssh://git@localhost:22223/home/git/myrepo2.git
 * &lt;span class="o"&gt;[&lt;/span&gt;new branch&lt;span class="o"&gt;]&lt;/span&gt;      master -&amp;gt; master
Branch master &lt;span class="nb"&gt;set &lt;/span&gt;up to track remote branch master from origin.
gerard@sirius:~/build/myrepo2&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; ..
gerard@sirius:~/build&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="linux"></category><category term="git"></category><category term="ssh"></category><category term="docker"></category></entry><entry><title>MongoDB sharding con ansible</title><link href="http://www.linuxsysadmin.tk/2016/05/mongodb-sharding-con-ansible.html" rel="alternate"></link><updated>2016-05-02T00:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2016-05-02:2016/05/mongodb-sharding-con-ansible.html</id><summary type="html">&lt;p&gt;Como ya vimos en un artículo anterior, los &lt;em&gt;replica sets&lt;/em&gt; nos ofrecen alta disponibilidad para nuestros despliegues de &lt;strong&gt;mongodb&lt;/strong&gt;. Sin embargo, algunas veces, necesitamos que nuestro &lt;em&gt;cluster&lt;/em&gt; ofrezca alto rendimiento, y esto se consigue mediante &lt;em&gt;sharding&lt;/em&gt;. Como no queremos renunciar a la alta disponibilidad, podemos aplicar ambas; hoy explicamos como.&lt;/p&gt;
&lt;p&gt;El mecanismo de &lt;em&gt;sharding&lt;/em&gt; es bastante simple: tenemos nuestros datos repartidos entre uno o mas &lt;em&gt;shards&lt;/em&gt;, que se van a repartir los datos del &lt;em&gt;cluster&lt;/em&gt;. Para mantener un control de donde están los datos, también vamos a necesitar unos procesos especiales llamados &lt;em&gt;config servers&lt;/em&gt;. Finalmente, habrá que poner algunos procesos &lt;em&gt;mongos&lt;/em&gt; que son unos &lt;em&gt;proxies&lt;/em&gt; al &lt;em&gt;cluster&lt;/em&gt; y sirven para ocultar la complejidad del mismo.&lt;/p&gt;
&lt;h2&gt;Visión del conjunto&lt;/h2&gt;
&lt;p&gt;Hay que decir que el mecanismo de &lt;em&gt;sharding&lt;/em&gt; permite poner y quitar &lt;em&gt;shards&lt;/em&gt; a &lt;em&gt;posteriori&lt;/em&gt;, igual que con los procesos &lt;em&gt;mongos&lt;/em&gt;, pero para empezar vamos a necesitar una arquitectura inicial que es lo que vamos a montar.&lt;/p&gt;
&lt;p&gt;Para empezar se ha decidido por un &lt;em&gt;cluster&lt;/em&gt; de 3 &lt;em&gt;shards&lt;/em&gt;, siendo cada uno de ellos un &lt;em&gt;replica set&lt;/em&gt; de dos nodos de datos y un árbitro cada uno. Usaremos la cantidad de &lt;em&gt;config servers&lt;/em&gt; que se recomienda en la documentación oficial.&lt;/p&gt;
&lt;p&gt;Así pues, y tras elegir nombres para los &lt;em&gt;shards&lt;/em&gt;, podemos pintar un esquema de nuestro &lt;em&gt;cluster&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Arquitectura lógica" src="http://www.linuxsysadmin.tk/images/sharding_arquitectura_logica.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Para repartir los procesos entre las máquinas, hay dos reglas que hay que respetar a rajatabla:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Los procesos de datos necesitan una máquina propia, para que no se disputen los recursos de disco y memoria.&lt;/li&gt;
&lt;li&gt;No hay que poner nunca dos o mas procesos de cada &lt;em&gt;shard&lt;/em&gt;, ya que la no disponibilidad de la máquina supondría la pérdida de la mayoría de las &lt;em&gt;replica sets&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El resto de procesos pueden compartir servidor con los de datos. Hay muchas formas de cumplir con las dos reglas, por ejemplo, la que vamos a montar:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Arquitectura física" src="http://www.linuxsysadmin.tk/images/sharding_arquitectura_fisica.jpg" /&gt;&lt;/p&gt;
&lt;h2&gt;Ansible al rescate&lt;/h2&gt;
&lt;p&gt;Debido a la gran cantidad de procesos que hay que levantar, se ha decidido por automatizar su despliegue mediante &lt;strong&gt;ansible&lt;/strong&gt;. El proceso es bastante similar a &lt;a href="http://www.linuxsysadmin.tk/2015/12/construyendo-una-replica-set-en-mongodb.html"&gt;otro de nuestros artículos&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Se ha utilizado el mecanismo de &lt;strong&gt;roles&lt;/strong&gt; de &lt;strong&gt;ansible&lt;/strong&gt;, para poder desplegar todos los procesos del mismo tipo; el detalle es que se han usado los parámetros en los &lt;strong&gt;roles&lt;/strong&gt; para los cambios menores. Si queréis intentarlo o entender como funcionan los despliegues, podéis encontrar los &lt;strong&gt;playbooks&lt;/strong&gt; &lt;a href="http://www.linuxsysadmin.tk/downloads/sharding_playbooks.tar.gz"&gt;aquí&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;El fichero comprimido no incluye los binarios de &lt;strong&gt;mongodb&lt;/strong&gt; para reducir tamaño, así que hay que añadirlos en las respectivas carpetas &lt;em&gt;files&lt;/em&gt;. Tras descomprimir el fichero &lt;em&gt;.tar.gz&lt;/em&gt; y poner los binarios ausentes, nos debería quedar algo como esto:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@ansible:~# tree
.
├── aquila_shard.yaml
├── clients.yaml
├── config_servers.yaml
├── cygnus_shard.yaml
├── hosts.yaml
├── lyra_shard.yaml
├── mongos_servers.yaml
└── roles
    ├── client
    │   ├── files
    │   │   └── mongo
    │   └── tasks
    │       └── main.yaml
    ├── config
    │   ├── meta
    │   │   └── main.yaml
    │   ├── tasks
    │   │   └── main.yaml
    │   └── templates
    │       ├── config.conf
    │       └── config.service
    ├── mongod
    │   ├── files
    │   │   └── mongod
    │   └── tasks
    │       └── main.yaml
    ├── mongos
    │   ├── files
    │   │   └── mongos
    │   ├── tasks
    │   │   └── main.yaml
    │   └── templates
    │       ├── mongos.conf
    │       └── mongos.service
    └── shard
        ├── meta
        │   └── main.yaml
        ├── tasks
        │   └── main.yaml
        └── templates
            ├── shard.conf
            └── shard.service

&lt;span class="m"&gt;19&lt;/span&gt; directories, &lt;span class="m"&gt;23&lt;/span&gt; files
root@ansible:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Preparación de las máquinas&lt;/h2&gt;
&lt;p&gt;De acuerdo con la arquitectura propuesta, vamos a necesitar 6 servidores para el &lt;em&gt;cluster&lt;/em&gt;, que vamos a montar como contenedores LXC y, aunque no es lo ideal, nos vale como demostración. En la séptima máquina es donde tenemos las herramientas de configuración, en este caso, &lt;strong&gt;ansible&lt;/strong&gt; y los &lt;strong&gt;playbooks&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-ls -f
NAME     STATE    IPV4        IPV6  AUTOSTART
---------------------------------------------
ansible  RUNNING  10.0.0.254  -     NO
mongo01  RUNNING  10.0.0.2    -     NO
mongo02  RUNNING  10.0.0.3    -     NO
mongo03  RUNNING  10.0.0.4    -     NO
mongo04  RUNNING  10.0.0.5    -     NO
mongo05  RUNNING  10.0.0.6    -     NO
mongo06  RUNNING  10.0.0.7    -     NO
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a declarar todas las máquina usadas en el fichero &lt;em&gt;hosts&lt;/em&gt; de &lt;strong&gt;ansible&lt;/strong&gt;. Ya de paso, los vamos a catalogar en grupos, para que los &lt;strong&gt;playbooks&lt;/strong&gt; se puedan lanzar a los grupos, indistintamente de los servidores que los formen.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@ansible:~# cat ansible/etc/hosts
&lt;span class="o"&gt;[&lt;/span&gt;mongo_servers&lt;span class="o"&gt;]&lt;/span&gt;
10.0.0.2
10.0.0.3
10.0.0.4
10.0.0.5
10.0.0.6
10.0.0.7

&lt;span class="o"&gt;[&lt;/span&gt;config_servers&lt;span class="o"&gt;]&lt;/span&gt;
10.0.0.2
10.0.0.3
10.0.0.4

&lt;span class="o"&gt;[&lt;/span&gt;aquila_shard_data&lt;span class="o"&gt;]&lt;/span&gt;
10.0.0.2
10.0.0.5

&lt;span class="o"&gt;[&lt;/span&gt;aquila_shard_arbiters&lt;span class="o"&gt;]&lt;/span&gt;
10.0.0.6

&lt;span class="o"&gt;[&lt;/span&gt;lyra_shard_data&lt;span class="o"&gt;]&lt;/span&gt;
10.0.0.3
10.0.0.6

&lt;span class="o"&gt;[&lt;/span&gt;lyra_shard_arbiters&lt;span class="o"&gt;]&lt;/span&gt;
10.0.0.7

&lt;span class="o"&gt;[&lt;/span&gt;cygnus_shard_data&lt;span class="o"&gt;]&lt;/span&gt;
10.0.0.4
10.0.0.7

&lt;span class="o"&gt;[&lt;/span&gt;cygnus_shard_arbiters&lt;span class="o"&gt;]&lt;/span&gt;
10.0.0.5

&lt;span class="o"&gt;[&lt;/span&gt;mongos_servers&lt;span class="o"&gt;]&lt;/span&gt;
10.0.0.2

&lt;span class="o"&gt;[&lt;/span&gt;clients&lt;span class="o"&gt;]&lt;/span&gt;
10.0.0.2
root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Por comodidad, vamos a referirnos a las máquinas por su nombre, y a falta de un servidor DNS adecuado, vamos a rellenar sus ficheros &lt;em&gt;/etc/hosts&lt;/em&gt;; para ello vamos a usar un &lt;strong&gt;playbook&lt;/strong&gt; que se asegure que esas líneas están en el fichero.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@ansible:~# ansible-playbook hosts.yaml

...

PLAY RECAP *********************************************************************
10.0.0.2                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.3                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.4                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.5                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.6                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.7                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Los config servers&lt;/h2&gt;
&lt;p&gt;Los &lt;em&gt;config servers&lt;/em&gt; son procesos &lt;strong&gt;mongod&lt;/strong&gt; con una configuración concreta. El &lt;strong&gt;playbook&lt;/strong&gt; se limita a crear una estructura en &lt;em&gt;/opt/mongodb/&lt;/em&gt; asegurándose que hay el binario &lt;strong&gt;mongod&lt;/strong&gt;, la configuración, la carpeta de datos y la &lt;em&gt;unit&lt;/em&gt; de &lt;strong&gt;systemd&lt;/strong&gt; activa.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@ansible:~# ansible-playbook config_servers.yaml

...

PLAY RECAP *********************************************************************
10.0.0.2                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.3                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.4                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Un acceso al cluster&lt;/h2&gt;
&lt;p&gt;Para poder configurar el &lt;em&gt;cluster&lt;/em&gt; y para un uso futuro, hemos decidido poner un proceso &lt;strong&gt;mongos&lt;/strong&gt; y el binario &lt;strong&gt;mongo&lt;/strong&gt; para poder acceder al &lt;em&gt;mongo shell&lt;/em&gt;. Se ha optado por separar los &lt;strong&gt;playbooks&lt;/strong&gt;; así se podrá utilizar para desplegarlos por separado en futuras máquinas que los puedan usar.&lt;/p&gt;
&lt;p&gt;De hecho, la recomendación oficial es poner un &lt;strong&gt;mongos&lt;/strong&gt; en cada &lt;em&gt;backend&lt;/em&gt;, aunque no necesitan el binario &lt;strong&gt;mongo&lt;/strong&gt; porque disponen de los &lt;em&gt;drivers&lt;/em&gt; oficiales del lenguaje que utilicen.&lt;/p&gt;
&lt;p&gt;Empezaremos desplegando los procesos &lt;strong&gt;mongos&lt;/strong&gt; en donde toque (de momento solo en el servidor &lt;em&gt;mongo01&lt;/em&gt;). Este &lt;strong&gt;playbook&lt;/strong&gt; se limita a poner el binario &lt;strong&gt;mongos&lt;/strong&gt; y su respectiva &lt;em&gt;unit&lt;/em&gt; para &lt;strong&gt;systemd&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@ansible:~# ansible-playbook mongos_servers.yaml

...

PLAY RECAP *********************************************************************
10.0.0.2                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para nuestra comodidad, también vamos a desplegar el &lt;em&gt;mongo shell&lt;/em&gt;. Este &lt;strong&gt;playbook&lt;/strong&gt; se limita a poner el binario &lt;strong&gt;mongo&lt;/strong&gt; en su sitio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@ansible:~# ansible-playbook clients.yaml

...

PLAY RECAP *********************************************************************
10.0.0.2                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Los procesos de los shards&lt;/h2&gt;
&lt;p&gt;Tenemos 9 procesos de este tipo, así que los &lt;strong&gt;roles&lt;/strong&gt; de &lt;strong&gt;ansible&lt;/strong&gt; tienen un protagonismo especial. Los cambios entre los procesos son mínimos, y se pasan por parámetro para que el rol cree los ficheros necesarios a partir de una plantilla. El rol se encarga solamente de poner el binario &lt;strong&gt;mongod&lt;/strong&gt; en &lt;em&gt;/opt/mongodb/bin&lt;/em&gt;, crear la carpeta de datos y configurar el servicio como una &lt;em&gt;unit&lt;/em&gt; de &lt;strong&gt;systemd&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Se ha decidido separar los &lt;em&gt;shards&lt;/em&gt; en diferentes &lt;strong&gt;playbooks&lt;/strong&gt; para simplificar la creación de futuros nuevos &lt;em&gt;shards&lt;/em&gt;; así pues, lanzamos el &lt;strong&gt;playbook&lt;/strong&gt; para el primer &lt;em&gt;shard&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@ansible:~# ansible-playbook aquila_shard.yaml

...

PLAY RECAP *********************************************************************
10.0.0.2                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.5                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.6                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Acto seguido, lanzamos el &lt;strong&gt;playbook&lt;/strong&gt; responsable de montar los procesos del segundo &lt;em&gt;shard&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@ansible:~# ansible-playbook lyra_shard.yaml

...

PLAY RECAP *********************************************************************
10.0.0.3                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.6                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.7                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y finalmente, lanzamos el tercer &lt;strong&gt;playbook&lt;/strong&gt; para desplegar los procesos del último &lt;em&gt;shard&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@ansible:~# ansible-playbook cygnus_shard.yaml

...

PLAY RECAP *********************************************************************
10.0.0.4                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.5                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
10.0.0.7                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Atando los replica sets&lt;/h2&gt;
&lt;p&gt;El paso anterior nos ha dejado todos los procesos en funcionamiento, pero no hemos iniciado los &lt;em&gt;replica sets&lt;/em&gt;. Para que funcionen como tal, tenemos que configurarlos uno por uno como ya sabemos hacer, usando &lt;em&gt;rs.status()&lt;/em&gt; para verificar que ha quedado todo como debe.&lt;/p&gt;
&lt;p&gt;Empezaremos con una máquina cualquiera del primer &lt;em&gt;shard&lt;/em&gt;; la configuración se propagará al resto sin nuestra intervención.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo01:~# /opt/mongodb/bin/mongo --host 10.0.0.5 --port 27018
MongoDB shell version: 3.2.5
connecting to: 10.0.0.5:27018/test
...
&amp;gt; &lt;span class="nv"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
...     _id : &lt;span class="s2"&gt;&amp;quot;aquila&amp;quot;&lt;/span&gt;,
...      members : &lt;span class="o"&gt;[&lt;/span&gt;
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : 0, host : &lt;span class="s2"&gt;&amp;quot;mongo01:27018&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : 1, host : &lt;span class="s2"&gt;&amp;quot;mongo04:27018&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : 2, host : &lt;span class="s2"&gt;&amp;quot;mongo05:27020&amp;quot;&lt;/span&gt;, arbiterOnly: &lt;span class="nb"&gt;true&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...      &lt;span class="o"&gt;]&lt;/span&gt;
... &lt;span class="o"&gt;}&lt;/span&gt;
...
&amp;gt; rs.initiate&lt;span class="o"&gt;(&lt;/span&gt;config&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
aquila:OTHER&amp;gt; rs.status&lt;span class="o"&gt;()&lt;/span&gt;
...
aquila:PRIMARY&amp;gt; &lt;span class="nb"&gt;exit&lt;/span&gt;
bye
root@mongo01:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Seguimos con el segundo &lt;em&gt;shard&lt;/em&gt;, entrando en una de sus máquinas y lanzando el comando de configuración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo01:~# /opt/mongodb/bin/mongo --host 10.0.0.6 --port 27018
MongoDB shell version: 3.2.5
connecting to: 10.0.0.6:27018/test
...
&amp;gt; &lt;span class="nv"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
...     _id : &lt;span class="s2"&gt;&amp;quot;lyra&amp;quot;&lt;/span&gt;,
...      members : &lt;span class="o"&gt;[&lt;/span&gt;
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : 0, host : &lt;span class="s2"&gt;&amp;quot;mongo02:27018&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : 1, host : &lt;span class="s2"&gt;&amp;quot;mongo05:27018&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : 2, host : &lt;span class="s2"&gt;&amp;quot;mongo06:27020&amp;quot;&lt;/span&gt;, arbiterOnly: &lt;span class="nb"&gt;true&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...      &lt;span class="o"&gt;]&lt;/span&gt;
... &lt;span class="o"&gt;}&lt;/span&gt;
...
&amp;gt; rs.initiate&lt;span class="o"&gt;(&lt;/span&gt;config&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
lyra:OTHER&amp;gt; rs.status&lt;span class="o"&gt;()&lt;/span&gt;
...
lyra:PRIMARY&amp;gt; &lt;span class="nb"&gt;exit&lt;/span&gt;
bye
root@mongo01:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y montamos el tercer &lt;em&gt;shard&lt;/em&gt; desde una cualquiera de sus &lt;em&gt;replicas&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo01:~# /opt/mongodb/bin/mongo --host 10.0.0.7 --port 27018
MongoDB shell version: 3.2.5
connecting to: 10.0.0.7:27018/test
...
&amp;gt; &lt;span class="nv"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
...     _id : &lt;span class="s2"&gt;&amp;quot;cygnus&amp;quot;&lt;/span&gt;,
...      members : &lt;span class="o"&gt;[&lt;/span&gt;
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : 0, host : &lt;span class="s2"&gt;&amp;quot;mongo03:27018&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : 1, host : &lt;span class="s2"&gt;&amp;quot;mongo06:27018&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : 2, host : &lt;span class="s2"&gt;&amp;quot;mongo04:27020&amp;quot;&lt;/span&gt;, arbiterOnly: &lt;span class="nb"&gt;true&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...      &lt;span class="o"&gt;]&lt;/span&gt;
... &lt;span class="o"&gt;}&lt;/span&gt;
...
&amp;gt; rs.initiate&lt;span class="o"&gt;(&lt;/span&gt;config&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
cygnus:OTHER&amp;gt; rs.status&lt;span class="o"&gt;()&lt;/span&gt;
...
cygnus:PRIMARY&amp;gt; &lt;span class="nb"&gt;exit&lt;/span&gt;
bye
root@mongo01:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Añadiendo los shards al cluster&lt;/h2&gt;
&lt;p&gt;Ahora tenemos un grupo de &lt;em&gt;config servers&lt;/em&gt;, que forman un &lt;em&gt;cluster&lt;/em&gt; de 0 &lt;em&gt;shards&lt;/em&gt; (válido pero inútil, ya que no tenemos donde guardar los datos). También disponemos de 3 &lt;em&gt;replica sets&lt;/em&gt; independientes, que se convertirán en los futuros &lt;em&gt;shards&lt;/em&gt;. Solo falta asociar los &lt;em&gt;shards&lt;/em&gt; al resto del &lt;em&gt;cluster&lt;/em&gt;, mediante el comando &lt;em&gt;sh.addShard()&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Para ello entramos en un &lt;strong&gt;mongos&lt;/strong&gt; desde donde lanzaremos los comandos. De hecho, solo tenemos uno, en &lt;em&gt;mongo01&lt;/em&gt;. Puesto que está en la misma máquina que el cliente &lt;strong&gt;mongo&lt;/strong&gt; y corre en el puerto estándar 27017, no hace falta especificar ni el &lt;em&gt;host&lt;/em&gt; ni el puerto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo01:~# /opt/mongodb/bin/mongo
MongoDB shell version: 3.2.5
connecting to: &lt;span class="nb"&gt;test&lt;/span&gt;
...
mongos&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Veamos como está el cluster antes de añadir los &lt;em&gt;shards&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mongos&amp;gt; printShardingStatus&lt;span class="o"&gt;()&lt;/span&gt;
--- Sharding Status ---
  sharding version: &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; : 1,
        &lt;span class="s2"&gt;&amp;quot;minCompatibleVersion&amp;quot;&lt;/span&gt; : 5,
        &lt;span class="s2"&gt;&amp;quot;currentVersion&amp;quot;&lt;/span&gt; : 6,
        &lt;span class="s2"&gt;&amp;quot;clusterId&amp;quot;&lt;/span&gt; : ObjectId&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;571dd47adbda7a5a80047a5d&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
  shards:
  active mongoses:
        &lt;span class="s2"&gt;&amp;quot;3.2.5&amp;quot;&lt;/span&gt; : 1
  balancer:
        Currently enabled:  yes
        Currently running:  no
        Failed balancer rounds in last &lt;span class="m"&gt;5&lt;/span&gt; attempts:  0
        Migration Results &lt;span class="k"&gt;for&lt;/span&gt; the last &lt;span class="m"&gt;24&lt;/span&gt; hours:
                No recent migrations
  databases:

mongos&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Procedemos a lanzar el comando para añadir cada &lt;em&gt;shard&lt;/em&gt;. Es interesante saber que el proceso &lt;strong&gt;mongos&lt;/strong&gt; puede reconocer la forma de cada &lt;em&gt;replica set&lt;/em&gt; a partir de cualquiera de sus procesos. Podemos dar la URL con una sola máquina, o con varias de ellas. Lo importante es que alguna de ellas esté levantada, para que el proceso &lt;strong&gt;mongos&lt;/strong&gt; pueda descubrir el resto a partir de su configuración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mongos&amp;gt; sh.addShard&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;aquila/mongo01:27018&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;shardAdded&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;aquila&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
mongos&amp;gt; sh.addShard&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lyra/mongo02:27018,mongo05:27018,mongo06:27020&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;shardAdded&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;lyra&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
mongos&amp;gt; sh.addShard&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;cygnus/mongo06:27018&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;shardAdded&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;cygnus&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
mongos&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Después de añadir los &lt;em&gt;shards&lt;/em&gt;, podemos ver como queda el &lt;em&gt;cluster&lt;/em&gt; con una sola consulta.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mongos&amp;gt; printShardingStatus&lt;span class="o"&gt;()&lt;/span&gt;
--- Sharding Status ---
  sharding version: &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; : 1,
        &lt;span class="s2"&gt;&amp;quot;minCompatibleVersion&amp;quot;&lt;/span&gt; : 5,
        &lt;span class="s2"&gt;&amp;quot;currentVersion&amp;quot;&lt;/span&gt; : 6,
        &lt;span class="s2"&gt;&amp;quot;clusterId&amp;quot;&lt;/span&gt; : ObjectId&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;571dd47adbda7a5a80047a5d&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
  shards:
        &lt;span class="o"&gt;{&lt;/span&gt;  &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;aquila&amp;quot;&lt;/span&gt;,  &lt;span class="s2"&gt;&amp;quot;host&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;aquila/mongo01:27018,mongo04:27018&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="o"&gt;{&lt;/span&gt;  &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;cygnus&amp;quot;&lt;/span&gt;,  &lt;span class="s2"&gt;&amp;quot;host&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;cygnus/mongo03:27018,mongo06:27018&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="o"&gt;{&lt;/span&gt;  &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;lyra&amp;quot;&lt;/span&gt;,  &lt;span class="s2"&gt;&amp;quot;host&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;lyra/mongo02:27018,mongo05:27018&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
  active mongoses:
        &lt;span class="s2"&gt;&amp;quot;3.2.5&amp;quot;&lt;/span&gt; : 1
  balancer:
        Currently enabled:  yes
        Currently running:  no
        Failed balancer rounds in last &lt;span class="m"&gt;5&lt;/span&gt; attempts:  0
        Migration Results &lt;span class="k"&gt;for&lt;/span&gt; the last &lt;span class="m"&gt;24&lt;/span&gt; hours:
                No recent migrations
  databases:

mongos&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y como todo funciona como debe, salimos del &lt;em&gt;mongo shell&lt;/em&gt; para evitar meter la pata.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mongos&amp;gt; &lt;span class="nb"&gt;exit&lt;/span&gt;
bye
root@mongo01:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto, tenemos nuestro &lt;em&gt;cluster&lt;/em&gt; listo y preparado para su uso.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="mongodb"></category><category term="replica set"></category><category term="sharding"></category><category term="ansible"></category><category term="playbook"></category><category term="systemd"></category></entry><entry><title>Creando un entorno escalable (IV)</title><link href="http://www.linuxsysadmin.tk/2016/03/creando-un-entorno-escalable-4.html" rel="alternate"></link><updated>2016-03-21T08:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2016-03-21:2016/03/creando-un-entorno-escalable-4.html</id><summary type="html">&lt;p&gt;Acabamos el artículo anterior de esta serie con las aplicaciones corriendo en sus respectivas máquinas. En este artículo vamos a poner una fachada a todo el sistema, mediante un &lt;em&gt;proxy HTTP&lt;/em&gt; que haga las funciones de terminación &lt;em&gt;SSL&lt;/em&gt; y de &lt;em&gt;balanceador&lt;/em&gt;, exponiendo todo el sistema en una sola dirección IP.&lt;/p&gt;
&lt;p&gt;Como &lt;em&gt;proxy HTTP&lt;/em&gt; tenemos varias opciones; solo se necesita un servidor web que soporte &lt;em&gt;virtual hosts&lt;/em&gt;, protocolo HTTP sobre SSL, capacidad de hacer de &lt;em&gt;proxy&lt;/em&gt; y capacidad para balancear las peticiones entre varias opciones.&lt;/p&gt;
&lt;p&gt;Si analizamos estos requisitos, podemos comprobar que las opciones son muchas; desde el todopoderoso &lt;strong&gt;apache&lt;/strong&gt; al &lt;strong&gt;nginx&lt;/strong&gt;, pasando por soluciones de balanceador puro como &lt;strong&gt;haproxy&lt;/strong&gt;, u opciones mas esotéricas como &lt;strong&gt;squid&lt;/strong&gt;. En este caso, se utiliza &lt;strong&gt;nginx&lt;/strong&gt; por su facilidad de uso y su bajo consumo de recursos. Cumple con el subconjunto básico de funcionalidades necesario, pero no dispone de tantos algoritmos de balanceo como otras opciones.&lt;/p&gt;
&lt;h2&gt;Instalación de paquetes&lt;/h2&gt;
&lt;p&gt;Empezamos instalando los requisitos para nuestra fachada; en principio solo se necesitaría el servidor web &lt;strong&gt;nginx&lt;/strong&gt; (en la versión mínima) y &lt;strong&gt;openssl&lt;/strong&gt; para generar los certificados. Adicionalmente instalaremos &lt;strong&gt;curl&lt;/strong&gt; para comprobar que el resultado es correcto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@frontend:~# apt-get install nginx-light curl
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  ca-certificates libcurl3 libffi6 libgmp10 libgnutls-deb0-28 libhogweed2 libidn11 libldap-2.4-2 libnettle4 libp11-kit0 librtmp1
  libsasl2-2 libsasl2-modules libsasl2-modules-db libssh2-1 libtasn1-6 nginx-common openssl
Paquetes sugeridos:
  gnutls-bin libsasl2-modules-otp libsasl2-modules-ldap libsasl2-modules-sql libsasl2-modules-gssapi-mit
  libsasl2-modules-gssapi-heimdal fcgiwrap nginx-doc ssl-cert
Se instalarán los siguientes paquetes NUEVOS:
  ca-certificates curl libcurl3 libffi6 libgmp10 libgnutls-deb0-28 libhogweed2 libidn11 libldap-2.4-2 libnettle4 libp11-kit0
  librtmp1 libsasl2-2 libsasl2-modules libsasl2-modules-db libssh2-1 libtasn1-6 nginx-common nginx-light openssl
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;20&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar 4.077 kB de archivos.
Se utilizarán 8.832 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El paquete &lt;strong&gt;nginx&lt;/strong&gt; de la distribución &lt;em&gt;Debian&lt;/em&gt; viene con una configuración por defecto en &lt;em&gt;/etc/nginx/sites-enabled/&lt;/em&gt;, que vamos a eliminar para evitar que se pise con nuestras configuraciones.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@frontend:~# ls -lh /etc/nginx/sites-enabled/
total 0
lrwxrwxrwx &lt;span class="m"&gt;1&lt;/span&gt; root root &lt;span class="m"&gt;34&lt;/span&gt; feb &lt;span class="m"&gt;26&lt;/span&gt; 11:28 default -&amp;gt; /etc/nginx/sites-available/default
root@frontend:~# unlink /etc/nginx/sites-enabled/default
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Consideraciones de seguridad&lt;/h2&gt;
&lt;p&gt;Cuando nuestro servidor web recibe una petición, va a iniciar una nueva conexión contra el servidor de &lt;em&gt;backend&lt;/em&gt; que toque o el de &lt;em&gt;backoffice&lt;/em&gt;. Para habilitar esto, se necesitan nuevas reglas en el &lt;em&gt;firewall&lt;/em&gt;, que en este caso es &lt;strong&gt;firehol&lt;/strong&gt;, instalado en la máquina anfitriona.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf
...  
&lt;span class="nv"&gt;app_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;10.0.0.3 10.0.0.4 10.0.0.5&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;frontend_server&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;10.0.0.2&amp;quot;&lt;/span&gt;
...
router internal inface lxc0 outface lxc0
...  
    route webcache accept src &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$frontend_server&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; dst &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$app_servers&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;No os olvidéis de reiniciar &lt;strong&gt;firehol&lt;/strong&gt;, para que se apliquen las nuevas reglas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# service firehol restart
...  
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Montando los virtualhosts de ambas aplicaciones&lt;/h2&gt;
&lt;p&gt;La parte privada va a estar escondida tras una terminación &lt;strong&gt;HTTPS&lt;/strong&gt;. Esa aplicación se podría esconder tras una &lt;a href="http://www.linuxsysadmin.tk/2016/02/restringiendo-accesos-mediante-certificados-de-cliente.html"&gt;autenticación de certificados cliente&lt;/a&gt; o mediante &lt;a href="http://www.linuxsysadmin.tk/2016/02/restringiendo-accesos-web-mediante-autenticacion-basica.html"&gt;autenticación básica&lt;/a&gt;. Por simplicidad vamos a usar esta última.&lt;/p&gt;
&lt;p&gt;Empezamos generando un certificado autofirmado para el servidor web, directamente firmado, y su clave. Fijaos que no generamos ningún certificado de CA, ya que no tenemos ninguna intención de generar autenticación cliente en el futuro.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@frontend:~# openssl req -new -newkey rsa:2048 -days &lt;span class="m"&gt;365&lt;/span&gt; -nodes -x509 -keyout server.key -out server.crt -subj &lt;span class="s2"&gt;&amp;quot;/C=ES/ST=Spain/L=Barcelona/O=LinuxSysadmin/CN=shop.linuxsysadmin.tk&amp;quot;&lt;/span&gt;
Generating a &lt;span class="m"&gt;2048&lt;/span&gt; bit RSA private key
.......................................+++
.................................................................................................................................................................+++
writing new private key to &lt;span class="s1"&gt;&amp;#39;server.key&amp;#39;&lt;/span&gt;
-----
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ponemos la clave y el certificado generado en sus respectivas localizaciones, de acuerdo a los estándares.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@frontend:~# cp server.key /etc/ssl/private/
root@frontend:~# cp server.crt /etc/ssl/certs/
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como verificación, así quedaría la carpeta &lt;em&gt;/etc/ssl/&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@frontend:~# tree /etc/ssl/
/etc/ssl/
├── certs
│   └── server.crt
├── openssl.cnf
└── private
    └── server.key

&lt;span class="m"&gt;2&lt;/span&gt; directories, &lt;span class="m"&gt;3&lt;/span&gt; files
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para poder autenticar mediante autenticación básica, generamos un usuario en un fichero tipo &lt;strong&gt;htpasswd&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@frontend:~# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;admin:&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;openssl passwd -crypt s3cr3t&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &amp;gt; /etc/nginx/shop.basic_auth
root@frontend:~# cat /etc/nginx/shop.basic_auth
admin:rOU9H0ABEB2H6
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con todas las piezas listas, montamos los virtualhosts, en un fichero de configuración o en varios, según nos apetezca.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@frontend:~# cat /etc/nginx/sites-enabled/shop
upstream backends &lt;span class="o"&gt;{&lt;/span&gt;
        server backend1:8080&lt;span class="p"&gt;;&lt;/span&gt;
        server backend2:8080&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

server &lt;span class="o"&gt;{&lt;/span&gt;
        listen &lt;span class="m"&gt;80&lt;/span&gt; default_server&lt;span class="p"&gt;;&lt;/span&gt;
        server_name _&lt;span class="p"&gt;;&lt;/span&gt;

        location / &lt;span class="o"&gt;{&lt;/span&gt;
                proxy_pass http://backends&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

server &lt;span class="o"&gt;{&lt;/span&gt;
        listen &lt;span class="m"&gt;443&lt;/span&gt; ssl&lt;span class="p"&gt;;&lt;/span&gt;
        server_name _&lt;span class="p"&gt;;&lt;/span&gt;

        ssl_certificate /etc/ssl/certs/server.crt&lt;span class="p"&gt;;&lt;/span&gt;
        ssl_certificate_key /etc/ssl/private/server.key&lt;span class="p"&gt;;&lt;/span&gt;

        auth_basic &lt;span class="s2"&gt;&amp;quot;Admin Area&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        auth_basic_user_file /etc/nginx/shop.basic_auth&lt;span class="p"&gt;;&lt;/span&gt;

        location / &lt;span class="o"&gt;{&lt;/span&gt;
                proxy_pass http://backoffice:8080&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La configuración es bastante estándar; se trata de un &lt;em&gt;server&lt;/em&gt; (equivalente en &lt;strong&gt;nginx&lt;/strong&gt; a un &lt;em&gt;virtualhost&lt;/em&gt; de &lt;strong&gt;apache&lt;/strong&gt;) para cada protocolo. La parte de administración es solamente la mediación &lt;strong&gt;SSL&lt;/strong&gt; y un &lt;em&gt;proxy_pass&lt;/em&gt; hacia el &lt;em&gt;backoffice&lt;/em&gt;. La parte de la API pública también se limita a hacer un &lt;em&gt;proxy_pass&lt;/em&gt;, solo que se hace contra &lt;em&gt;backends&lt;/em&gt; que es un objeto &lt;strong&gt;upstream&lt;/strong&gt;, que es el que define el balanceador.&lt;/p&gt;
&lt;p&gt;Ahora solo queda reiniciar el servidor web para aplicar los cambios. De acuerdo a la documentación, habría bastado un &lt;em&gt;reload&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@frontend:~# service nginx restart
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comprobando que las aplicaciones funcionan&lt;/h2&gt;
&lt;p&gt;Para comprobar que la parte de la API funciona y balancea adecuadamente, basta con hacer peticiones. Podemos comprobar el &lt;em&gt;backend&lt;/em&gt; que la ha servido porque la aplicación pone una cabecera que especifica el nombre del &lt;em&gt;host&lt;/em&gt; que la resolvió. Con dos peticiones veremos que va alternativamente a cada &lt;em&gt;backend&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@frontend:~# curl -i http://localhost/products/
HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Server: nginx/1.6.2
Date: Fri, &lt;span class="m"&gt;26&lt;/span&gt; Feb &lt;span class="m"&gt;2016&lt;/span&gt; 11:04:38 GMT
Content-Type: application/json
Content-Length: 3
Connection: keep-alive
Backend: backend1

&lt;span class="o"&gt;[]&lt;/span&gt;
root@frontend:~# curl -i http://localhost/products/
HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Server: nginx/1.6.2
Date: Fri, &lt;span class="m"&gt;26&lt;/span&gt; Feb &lt;span class="m"&gt;2016&lt;/span&gt; 11:04:40 GMT
Content-Type: application/json
Content-Length: 3
Connection: keep-alive
Backend: backend2

&lt;span class="o"&gt;[]&lt;/span&gt;
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para la parte privada, haremos la petición, de la misma manera; vamos a añadir el flag &lt;em&gt;-k&lt;/em&gt; para sobrepasar el certificado autofirmado. Como no hemos indicado el usuario y la contraseña, nos devuelve un error 401, que indica que no estamos autorizados a pasar mas allá.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@frontend:~# curl -i -k https://localhost/products
HTTP/1.1 &lt;span class="m"&gt;401&lt;/span&gt; Unauthorized
Server: nginx/1.6.2
Date: Fri, &lt;span class="m"&gt;26&lt;/span&gt; Feb &lt;span class="m"&gt;2016&lt;/span&gt; 11:05:35 GMT
Content-Type: text/html
Content-Length: 194
Connection: keep-alive
WWW-Authenticate: Basic &lt;span class="nv"&gt;realm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Admin Area&amp;quot;&lt;/span&gt;

&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;&amp;lt;title&amp;gt;401 Authorization Required&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;
&amp;lt;body &lt;span class="nv"&gt;bgcolor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;white&amp;quot;&lt;/span&gt;&amp;gt;
&amp;lt;center&amp;gt;&amp;lt;h1&amp;gt;401 Authorization Required&amp;lt;/h1&amp;gt;&amp;lt;/center&amp;gt;
&amp;lt;hr&amp;gt;&amp;lt;center&amp;gt;nginx/1.6.2&amp;lt;/center&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto parece que funciona, a falta de probar con un navegador adecuado.&lt;/p&gt;
&lt;h2&gt;Un pequeño detalle: abrimos los puertos&lt;/h2&gt;
&lt;p&gt;Puesto que este entorno está montado sobre virtualización &lt;strong&gt;LXC&lt;/strong&gt;, necesitamos que la dirección IP de la maquina anfitriona exponga los puertos de la máquina &lt;em&gt;frontend&lt;/em&gt;. Para ello hay que habilitar un mecanismo que se llama &lt;em&gt;port forwarding&lt;/em&gt;, coloquialmente conocido como "abrir el puerto".&lt;/p&gt;
&lt;p&gt;Mediante una directiva de &lt;strong&gt;firehol&lt;/strong&gt; indicamos que pasaremos todas las peticiones recibidas a los puertos 80 y 443 directamente a la máquina de &lt;em&gt;frontend&lt;/em&gt;. Hay que habilitar ese tráfico de &lt;strong&gt;FORWARD&lt;/strong&gt;, mediante otras reglas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf
...
&lt;span class="nv"&gt;frontend_server&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;10.0.0.2&amp;quot;&lt;/span&gt;
...
dnat to &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$frontend_server&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; proto tcp dport 80
dnat to &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$frontend_server&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; proto tcp dport 443
...
router world2lan inface eth0 outface lxc0
    route http accept dst &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$frontend_server&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
    route https accept dst &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$frontend_server&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
...
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y nuevamente reiniciamos el servicio para aplicar las nuevas reglas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# service firehol restart
...
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Accediendo a las aplicaciones en la IP pública&lt;/h2&gt;
&lt;p&gt;Vamos a acceder con un navegador a la parte de administración, para ver que funciona y para rellenar algunos datos, para que se vea una respuesta de la API con fundamento.&lt;/p&gt;
&lt;p&gt;El primer paso consiste en abrir el navegador con la URL adecuada, y nos tropezamos con la autenticación.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Auth basic" src="http://www.linuxsysadmin.tk/images/entorno-escalable-auth-basic.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Tras pasar la autenticación podemos acceder a los formularios para añadir productos.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Admin form" src="http://www.linuxsysadmin.tk/images/entorno-escalable-admin-form.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Tras añadir tres productos, vemos que ya se genera la lista, en formato web.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Admin list" src="http://www.linuxsysadmin.tk/images/entorno-escalable-admin-list.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Con los datos introducidos podemos consumir la API, para comprobar que los datos que hemos introducido en la base de datos (mediante la aplicación de administración) están disponibles.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;wget -qO- http://192.168.1.232/products/
&lt;span class="o"&gt;[&lt;/span&gt;
    &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;price&amp;quot;&lt;/span&gt;: 1.5, 
        &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;123&amp;quot;&lt;/span&gt;, 
        &lt;span class="s2"&gt;&amp;quot;description&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;Apples&amp;quot;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;, 
    &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;price&amp;quot;&lt;/span&gt;: 1.0, 
        &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;456&amp;quot;&lt;/span&gt;, 
        &lt;span class="s2"&gt;&amp;quot;description&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;Oranges&amp;quot;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;, 
    &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;price&amp;quot;&lt;/span&gt;: 2.0, 
        &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;789&amp;quot;&lt;/span&gt;, 
        &lt;span class="s2"&gt;&amp;quot;description&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;Pears&amp;quot;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;]&lt;/span&gt;
gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y consultando un producto concreto, también funciona como debe.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;wget -qO- http://192.168.1.232/products/456
&lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;price&amp;quot;&lt;/span&gt;: 1.0, 
    &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;456&amp;quot;&lt;/span&gt;, 
    &lt;span class="s2"&gt;&amp;quot;description&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;Oranges&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
gerard@desktop:~&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto comprobamos que todo queda en su sitio. Solo hará falta limpiar cualquier desecho que hayamos dejado en &lt;em&gt;/root/&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Y con este artículo cerramos la serie.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="proxy http"></category><category term="balanceador"></category><category term="ssl"></category><category term="nginx"></category><category term="virtual hosts"></category><category term="port forwarding"></category></entry><entry><title>Creando un entorno escalable (III)</title><link href="http://www.linuxsysadmin.tk/2016/03/creando-un-entorno-escalable-3.html" rel="alternate"></link><updated>2016-03-14T08:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2016-03-14:2016/03/creando-un-entorno-escalable-3.html</id><summary type="html">&lt;p&gt;En el artículo anterior de esta serie montamos el cluster de la base de datos que íbamos a necesitar para las aplicaciones que conformaban este entorno de ejemplo. Ahora que tenemos la base de datos, falta poner los servidores de aplicaciones que sirven nuestras aplicaciones y que usan el cluster.&lt;/p&gt;
&lt;p&gt;Las aplicaciones que pretendemos servir son aplicaciones hechas en &lt;strong&gt;python&lt;/strong&gt;, siguiendo el protocolo &lt;strong&gt;WSGI&lt;/strong&gt;. Para ir rápidos, ambas utilizan el &lt;em&gt;framework&lt;/em&gt; &lt;strong&gt;bottle&lt;/strong&gt;. En realidad, nos sirve cualquier &lt;em&gt;framework&lt;/em&gt; que construya aplicaciones &lt;strong&gt;WSGI&lt;/strong&gt; estándares, de acuerdo al protocolo. Estas aplicaciones se conectan a la base de datos antes creadas para resolver las peticiones, mediante el &lt;em&gt;driver&lt;/em&gt; de &lt;strong&gt;mongodb&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Desde el punto de vista de entrada al servidor, ambas aplicaciones se van a servir mediante el protocolo &lt;strong&gt;HTTP&lt;/strong&gt; en puerto TCP 8080. Hay muchos servidores que sirven aplicaciones &lt;strong&gt;WSGI&lt;/strong&gt;, por ejemplo, &lt;strong&gt;Apache mod_wsgi&lt;/strong&gt;, &lt;strong&gt;gunicorn&lt;/strong&gt; o &lt;strong&gt;uWSGI&lt;/strong&gt;. De hecho hay docenas de ellos, casi todos capaces de servir aplicaciones &lt;strong&gt;WSGI&lt;/strong&gt; en un puerto cualquiera TCP.&lt;/p&gt;
&lt;p&gt;En este caso, usaremos un servidor de aplicaciones &lt;strong&gt;uWSGI&lt;/strong&gt; que, aunque es un poco mas complicado que &lt;strong&gt;gunicorn&lt;/strong&gt; (y menos que &lt;strong&gt;mod_wsgi&lt;/strong&gt;), me tiene enamorado. Destaco especialmente el modo de funcionamiento &lt;em&gt;emperador&lt;/em&gt; y la capacidad de usar un &lt;em&gt;virtualenv&lt;/em&gt; distinto para cada aplicación servida. De hecho, puede servir diferentes lenguajes y/o versiones, una por cada aplicación.&lt;/p&gt;
&lt;h2&gt;Instalar el servidor de aplicaciones&lt;/h2&gt;
&lt;p&gt;Este paso se repite en las máquinas &lt;em&gt;backend1&lt;/em&gt;, &lt;em&gt;backend2&lt;/em&gt; y  &lt;em&gt;backoffice&lt;/em&gt;; aunque cada una va a servir una aplicación distinta, el servidor de aplicaciones es el mismo. En puntos posteriores pondremos y activaremos las aplicaciones.&lt;/p&gt;
&lt;p&gt;El servidor &lt;strong&gt;uWSGI&lt;/strong&gt; está disponible en los repositorios oficiales de &lt;em&gt;Debian Jessie&lt;/em&gt;. Vamos a instalarlo con un &lt;em&gt;init script&lt;/em&gt; que levante un emperador y le vamos a añadir el &lt;em&gt;plugin&lt;/em&gt; para servir &lt;strong&gt;python&lt;/strong&gt; (en la versión 2.7, según podemos ver).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:~# apt-get install uwsgi-emperor uwsgi-plugin-python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  file libexpat1 libffi6 libjansson4 libmagic1 libmatheval1 libpgm-5.1-0 libpython2.7 libpython2.7-minimal libpython2.7-stdlib
  libsodium13 libsqlite3-0 libxml2 libyaml-0-2 libzmq3 mime-support sgml-base uwsgi-core xml-core
Paquetes sugeridos:
  sgml-base-doc nginx-full cherokee libapache2-mod-proxy-uwsgi libapache2-mod-uwsgi libapache2-mod-ruwsgi uwsgi-plugins-all
  uwsgi-extra python-uwsgidecorators debhelper
Se instalarán los siguientes paquetes NUEVOS:
  file libexpat1 libffi6 libjansson4 libmagic1 libmatheval1 libpgm-5.1-0 libpython2.7 libpython2.7-minimal libpython2.7-stdlib
  libsodium13 libsqlite3-0 libxml2 libyaml-0-2 libzmq3 mime-support sgml-base uwsgi-core uwsgi-emperor uwsgi-plugin-python
  xml-core
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;21&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar 6.608 kB de archivos.
Se utilizarán 25,9 MB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto ya tenemos el servidor de aplicaciones en funcionamiento. Las instancias se declaran con un fichero de configuración en &lt;em&gt;/etc/uwsgi-emperor/vassals/&lt;/em&gt;, que haremos mas adelante.&lt;/p&gt;
&lt;h2&gt;Consideraciones de seguridad&lt;/h2&gt;
&lt;p&gt;Estas aplicaciones usarán el &lt;em&gt;driver&lt;/em&gt; &lt;strong&gt;pymongo&lt;/strong&gt; para conectar a las instancias de &lt;strong&gt;mongodb&lt;/strong&gt;. Para eso hay que habilitar el tráfico relativo (de los servidores de aplicaciones a los de mongodb, por el puerto TCP 27017).&lt;/p&gt;
&lt;p&gt;En nuestro caso, como estamos trabajando con &lt;strong&gt;LXC&lt;/strong&gt;, lo haremos desde el &lt;em&gt;host&lt;/em&gt;, mediante la modificación de las reglas de &lt;em&gt;firehol&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# cat /etc/firehol/firehol.conf
&lt;span class="nv"&gt;mongo_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;10.0.0.5 10.0.0.6 10.0.0.7&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;app_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;10.0.0.3 10.0.0.4 10.0.0.5&amp;quot;&lt;/span&gt;
...  
router internal inface lxc0 outface lxc0
...  
      route custom mongodb tcp/27017 default accept src &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$app_servers&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; dst &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$mongo_servers&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
...  
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;No os olvidéis de reiniciar el servicio &lt;em&gt;firehol&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Instalando las aplicaciones&lt;/h2&gt;
&lt;p&gt;Este punto se hace en los tres servidores que sirven aplicaciones (&lt;em&gt;backend1&lt;/em&gt;, &lt;em&gt;backend2&lt;/em&gt; y &lt;em&gt;backoffice&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Las aplicaciones de ejemplo que vamos a usar las podéis encontrar en &lt;a href="http://www.linuxsysadmin.tk/downloads/shop.tar.gz"&gt;este enlace&lt;/a&gt;. Debo admitir que no son bonitas, pero para esta demostración, nos valen.&lt;/p&gt;
&lt;p&gt;Descomprimimos el fichero comprimido con las dos aplicaciones.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:~# tar xzf shop.tar.gz
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Esta es la estructura que queda tras descomprimir:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:~# tree
.
├── shop
│   ├── requirements.txt
│   ├── shop_admin
│   │   ├── app.py
│   │   └── views
│   │       ├── index.tpl
│   │       ├── product_form.tpl
│   │       └── product_list.tpl
│   └── shop_api
│       └── app.py
└── shop.tar.gz

&lt;span class="m"&gt;4&lt;/span&gt; directories, &lt;span class="m"&gt;7&lt;/span&gt; files
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Esta estructura tiene las dos aplicaciones. Cada tipo de servidor usará solo una por simplicidad, así que borraremos la que no se utilice, de acuerdo al tipo de servidor.&lt;/p&gt;
&lt;p&gt;En resumen, vamos a poner la carpeta &lt;em&gt;shop&lt;/em&gt; en &lt;em&gt;/opt/&lt;/em&gt;, y vamos a poner dentro el &lt;em&gt;virtualenv&lt;/em&gt; con las librerías necesarias.&lt;/p&gt;
&lt;p&gt;Como buena &lt;em&gt;praxis&lt;/em&gt;, vamos a instalar las librerías en un &lt;em&gt;virtualenv&lt;/em&gt; dedicado por aplicación. Para ello necesitamos la herramienta, que puede salir del repositorio oficial o lo podemos descargar, para usarlo y desecharlo posteriormente. Podemos encontrar el paquete en &lt;a href="https://pypi.python.org/packages/source/v/virtualenv/virtualenv-14.0.6.tar.gz#md5=a035037925c82990a7659ecf8764bcdb"&gt;este enlace&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lo descomprimimos y lo dejamos ahí, para que los puntos específicos para cada servidor lo usen a su antojo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:~# tar xzf virtualenv-14.0.6.tar.gz
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El &lt;em&gt;script&lt;/em&gt; de creación del &lt;em&gt;virtualenv&lt;/em&gt; se ejecuta con &lt;strong&gt;python&lt;/strong&gt;; así que también lo necesitamos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:~# apt-get install python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  libpython-stdlib python-minimal python2.7 python2.7-minimal
Paquetes sugeridos:
  python-doc python-tk python2.7-doc binutils binfmt-support
Se instalarán los siguientes paquetes NUEVOS:
  libpython-stdlib python python-minimal python2.7 python2.7-minimal
0 actualizados, 5 nuevos se instalarán, 0 para eliminar y 0 no actualizados.
Se necesita descargar 1.854 kB de archivos.
Se utilizarán 5.131 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? [S/n] s
..
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Veamos ahora los puntos específicos por tipo de aplicación.&lt;/p&gt;
&lt;h3&gt;Aplicación de backend: la API pública&lt;/h3&gt;
&lt;p&gt;Este punto se ejecuta solamente en los &lt;em&gt;backends&lt;/em&gt; (&lt;em&gt;backend1&lt;/em&gt; y &lt;em&gt;backend2&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Eliminamos la aplicación de administración, que no se usa en los &lt;em&gt;backends&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:~# rm -R shop/shop_admin/
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Así nos queda la carpeta:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:~# tree shop
shop
├── requirements.txt
└── shop_api
    └── app.py

&lt;span class="m"&gt;1&lt;/span&gt; directory, &lt;span class="m"&gt;2&lt;/span&gt; files
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Copiamos la carpeta a &lt;em&gt;/opt/&lt;/em&gt; que va a ser su emplazamiento habitual.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:~# cp -R shop/ /opt/
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a trabajar ya desde la carpeta contenedora del proyecto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:~# &lt;span class="nb"&gt;cd&lt;/span&gt; /opt/shop/
root@backend1:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El siguiente paso es crear el conjunto de librerías necesarias, construyendo un &lt;em&gt;virtualenv&lt;/em&gt; con las librerías. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:/opt/shop# /root/virtualenv-14.0.6/virtualenv.py env
New python executable in /opt/shop/env/bin/python
Installing setuptools, pip, wheel...done.
root@backend1:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Activamos el entorno virtual para instalar las librerías declaradas en el fichero &lt;em&gt;requirements.txt&lt;/em&gt;. Luego salimos del entorno.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:/opt/shop# . env/bin/activate
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@backend1:/opt/shop# pip install -r requirements.txt
Collecting &lt;span class="nv"&gt;bottle&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;0.12.9 &lt;span class="o"&gt;(&lt;/span&gt;from -r requirements.txt &lt;span class="o"&gt;(&lt;/span&gt;line 1&lt;span class="o"&gt;))&lt;/span&gt;
...
Installing collected packages: bottle, pymongo
Successfully installed bottle-0.12.9 pymongo-3.2
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@backend1:/opt/shop# deactivate
root@backend1:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para evitarnos problemas de permisos, uniformizamos el propietario de la carpeta:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:~# chown -R www-data:www-data /opt/shop/
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Con todo lo necesario para levantar la aplicación, la declaramos como &lt;em&gt;vasallo&lt;/em&gt; del &lt;em&gt;emperador&lt;/em&gt;; el mismo &lt;strong&gt;emperador&lt;/strong&gt; va a levantar un proceso para servir esa configuración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:/opt/shop# cat /etc/uwsgi-emperor/vassals/shop_api.ini
&lt;span class="o"&gt;[&lt;/span&gt;uwsgi&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;plugin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; python
http-socket &lt;span class="o"&gt;=&lt;/span&gt; 0.0.0.0:8080
&lt;span class="nv"&gt;master&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nv"&gt;workers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; 2
&lt;span class="nv"&gt;virtualenv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/shop/env
&lt;span class="nv"&gt;chdir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/shop/shop_api
&lt;span class="nv"&gt;module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; app:app
root@backend1:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y podemos comprobar que todo funciona como debe haciendo una petición a la &lt;strong&gt;API&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backend1:~# curl -i http://localhost:8080/products/
HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Content-Length: 3
Content-Type: application/json
Backend: backend1

&lt;span class="o"&gt;[]&lt;/span&gt;
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Aplicación de backoffice: la interfaz de administración&lt;/h3&gt;
&lt;p&gt;Este punto aplica solamente a la máquina &lt;em&gt;backoffice&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;El proceso es análogo al de los &lt;em&gt;backends&lt;/em&gt;; quitamos la aplicación que no vamos a utilizar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backoffice:~# rm -R shop/shop_api/
root@backoffice:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Así nos queda la carpeta:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backoffice:~# tree shop
shop
├── requirements.txt
└── shop_admin
    ├── app.py
    └── views
        ├── index.tpl
        ├── product_form.tpl
        └── product_list.tpl

&lt;span class="m"&gt;2&lt;/span&gt; directories, &lt;span class="m"&gt;5&lt;/span&gt; files
root@backoffice:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La transferimos a la carpeta &lt;em&gt;/opt/&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backoffice:~# cp -R shop/ /opt/
root@backoffice:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Nos situamos en la carpeta contenedora:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backoffice:~# &lt;span class="nb"&gt;cd&lt;/span&gt; /opt/shop/
root@backoffice:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos el &lt;em&gt;virtualenv&lt;/em&gt; en la carpeta contenedora.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backoffice:/opt/shop# /root/virtualenv-14.0.6/virtualenv.py env
New python executable in /opt/shop/env/bin/python
Installing setuptools, pip, wheel...done.
root@backoffice:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y le instalamos las librerías necesarias, declaradas en el fichero &lt;em&gt;requirements.txt&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backoffice:/opt/shop# . env/bin/activate
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@backoffice:/opt/shop# pip install -r requirements.txt
Collecting &lt;span class="nv"&gt;bottle&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;0.12.9 &lt;span class="o"&gt;(&lt;/span&gt;from -r requirements.txt &lt;span class="o"&gt;(&lt;/span&gt;line 1&lt;span class="o"&gt;))&lt;/span&gt;
...
Installing collected packages: bottle, pymongo
Successfully installed bottle-0.12.9 pymongo-3.2
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@backoffice:/opt/shop# deactivate
root@backoffice:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Actualizamos el propietario de la aplicación &lt;strong&gt;WSGI&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backoffice:/opt/shop# chown -R www-data:www-data /opt/shop/
root@backoffice:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y creamos el fichero de configuración del &lt;em&gt;vasallo&lt;/em&gt;, para que lo levante el &lt;em&gt;emperador&lt;/em&gt;, quedando así:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backoffice:/opt/shop# cat /etc/uwsgi-emperor/vassals/shop_admin.ini
&lt;span class="o"&gt;[&lt;/span&gt;uwsgi&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;plugin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; python
http-socket &lt;span class="o"&gt;=&lt;/span&gt; 0.0.0.0:8080
&lt;span class="nv"&gt;master&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nv"&gt;workers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; 2
&lt;span class="nv"&gt;virtualenv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/shop/env
&lt;span class="nv"&gt;chdir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/shop/shop_admin
&lt;span class="nv"&gt;module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; app:app
root@backoffice:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y comprobamos que obtenemos la página web que se espera:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@backoffice:~# curl -i http://localhost:8080/
HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Content-Length: 33
Content-Type: text/html&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nv"&gt;charset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;UTF-8

&amp;lt;a &lt;span class="nv"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/products&amp;quot;&lt;/span&gt;&amp;gt;Products&amp;lt;/a&amp;gt;
root@backoffice:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto hemos acabado con las aplicaciones. Nuevamente, todo lo que queda en la carpeta &lt;em&gt;/root/&lt;/em&gt; es desechable.&lt;/p&gt;
&lt;p&gt;En el siguiente artículo vamos a montar el &lt;em&gt;proxy&lt;/em&gt;/balanceador que va a actuar como fachada de todo el sistema.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="WSGI"></category><category term="uWSGI"></category><category term="python"></category><category term="virtualenv"></category><category term="firehol"></category></entry><entry><title>Creando un entorno escalable (II)</title><link href="http://www.linuxsysadmin.tk/2016/03/creando-un-entorno-escalable-2.html" rel="alternate"></link><updated>2016-03-07T08:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2016-03-07:2016/03/creando-un-entorno-escalable-2.html</id><summary type="html">&lt;p&gt;Seguimos con la serie de montar un entorno escalable. Tras explicar en el primer artículo lo que vamos a montar, seguimos con ello. En este artículo vamos a montar un &lt;em&gt;cluster&lt;/em&gt; de bases de datos; será &lt;strong&gt;mongodb&lt;/strong&gt; porque la aplicación lo requiere y usará la topología de un &lt;strong&gt;replica set&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Este artículo se basa enormemente en &lt;a href="http://www.linuxsysadmin.tk/2015/12/construyendo-una-replica-set-en-mongodb.html"&gt;otro artículo&lt;/a&gt; que ya publicamos, al que vamos a añadir algunas mejoras reflejadas en otros.&lt;/p&gt;
&lt;p&gt;Como ya vimos en el artículo referido, solo necesitamos levantar un proceso &lt;em&gt;mongod&lt;/em&gt; en cada una de las máquinas, para posteriormente casarlos entre sí.&lt;/p&gt;
&lt;h2&gt;Levantando los procesos de mongodb&lt;/h2&gt;
&lt;p&gt;Este punto se repite en las máquinas que van a formar la &lt;strong&gt;replica set&lt;/strong&gt;, que son &lt;em&gt;mongo1&lt;/em&gt;, &lt;em&gt;mongo2&lt;/em&gt; y &lt;em&gt;backoffice&lt;/em&gt;. Vamos a seguir solamente una de ellas; el resto son análogas.&lt;/p&gt;
&lt;p&gt;Crearemos una estructura en &lt;em&gt;/opt/&lt;/em&gt; para alojar los binarios, las configuraciones, los datos y los logs.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# mkdir -p /opt/mongodb/&lt;span class="o"&gt;{&lt;/span&gt;bin,conf,data,logs&lt;span class="o"&gt;}&lt;/span&gt;
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En la carpeta de binarios vamos a poner el único que se necesita: el &lt;em&gt;mongod&lt;/em&gt;. Lo podemos sacar descomprimiendo el 
fichero comprimido &lt;em&gt;.tar.gz&lt;/em&gt; de la página de descargas de &lt;strong&gt;mongodb&lt;/strong&gt;. En nuestro caso concreto, lo he sacado de &lt;a href="https://fastdl.mongodb.org/linux/mongodb-linux-i686-3.2.3.tgz"&gt;https://fastdl.mongodb.org/linux/mongodb-linux-i686-3.2.3.tgz&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cp mongodb-linux-i686-3.2.3/bin/mongod /opt/mongodb/bin/
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ponemos un fichero de configuración para la instancia que queremos correr. Esta configuración puede variar mucho, pero un ejemplo básico para salir del paso con una máquina de 32 bits (que no soportan &lt;em&gt;WiredTiger&lt;/em&gt;) podría ser:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cat /opt/mongodb/conf/mongo.conf
systemLog:
    path: /opt/mongodb/logs/mongo.log
    logAppend: &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nb"&gt;    &lt;/span&gt;destination: file

net:
    port: 27017
    bindIp: 0.0.0.0

storage:
    dbPath: /opt/mongodb/data/
    engine: mmapv1
    mmapv1:
        smallFiles: &lt;span class="nb"&gt;true&lt;/span&gt;

replication:
    replSetName: rs
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Truco&lt;/strong&gt;: Es un buen momento para montar un sistema de ficheros alternativo para almacenar los datos, sea poner &lt;a href="http://www.linuxsysadmin.tk/2016/01/lvm-logical-volume-manager.html"&gt;LVM&lt;/a&gt; (para tener crecimiento dinámico o &lt;a href="http://www.linuxsysadmin.tk/2016/02/haciendo-snapshots-con-lvm.html"&gt;snapshots&lt;/a&gt;, sea un &lt;a href="http://www.linuxsysadmin.tk/2015/12/construyendo-un-raid-10-en-linux.html"&gt;RAID&lt;/a&gt; (por ejemplo para tener alto rendimiento y/o replicación de datos), o incluso ambos.&lt;/p&gt;
&lt;p&gt;Cumpliendo con una política de seguridad básica, vamos a crear un usuario de sistema para correr el proceso.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# useradd -s /usr/sbin/nologin -r -M mongo -d /opt/mongodb/
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Le damos la propiedad de toda la estructura de &lt;strong&gt;mongodb&lt;/strong&gt;, para ahorrarnos problemas de permisos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# chown -R mongo:mongo /opt/mongodb/
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y ya como resumen, ponemos una salida para ver como nos queda la estructura:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# tree /opt/mongodb/
/opt/mongodb/
├── bin
│   └── mongod
├── conf
│   └── mongo.conf
├── data
└── logs

&lt;span class="m"&gt;4&lt;/span&gt; directories, &lt;span class="m"&gt;2&lt;/span&gt; files
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El último paso consiste en crear una &lt;em&gt;unit&lt;/em&gt; en &lt;strong&gt;systemd&lt;/strong&gt; (o un &lt;em&gt;init script&lt;/em&gt;, dependiendo de la distribución usada; de hecho, cada máquina puede ir con una distribución distinta).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cat /etc/systemd/system/mongo.service
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;MongoDB

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;User&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mongo
&lt;span class="nv"&gt;LimitFSIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitCPU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitNOFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;LimitNPROC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/rm -f /opt/mongodb/data/mongod.lock
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/opt/mongodb/bin/mongod -f /opt/mongodb/conf/mongo.conf

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lo activamos para que se levante solo en los siguientes arranques, y lo levantamos para la sesión actual.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mongo
Created symlink from /etc/systemd/system/multi-user.target.wants/mongo.service to /etc/systemd/system/mongo.service.
root@mongo1:~# systemctl start mongo
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Repetid este paso en las otras máquinas de &lt;strong&gt;mongodb&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Consideraciones de seguridad&lt;/h2&gt;
&lt;p&gt;Para que una &lt;strong&gt;replica set&lt;/strong&gt; funcione como debe, todos los procesos deben comunicarse entre sí. Como los hemos puesto en el mismo puerto, podemos agruparlo todo en una sola regla.&lt;/p&gt;
&lt;p&gt;Como en nuestro caso estamos virtualizando con &lt;strong&gt;LXC&lt;/strong&gt;, vamos a controlar el tráfico con el &lt;strong&gt;firehol&lt;/strong&gt; de la máquina anfitriona.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;...
root@lxc:~# cat /etc/firehol/firehol.conf
&lt;span class="nv"&gt;mongo_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;10.0.0.5 10.0.0.6 10.0.0.7&amp;quot;&lt;/span&gt;
...  
router internal inface lxc0 outface lxc0
    route custom mongodb tcp/27017 default accept src &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$mongo_servers&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; dst &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$mongo_servers&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
...
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Acordaos de reiniciar &lt;strong&gt;firehol&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Atando la replica set&lt;/h2&gt;
&lt;p&gt;Este paso se ejecuta en una sola máquina, que va a reproducir los cambios a las demás, por efecto de la &lt;strong&gt;replica set&lt;/strong&gt;. Por ejemplo, lo hago en &lt;em&gt;mongo1&lt;/em&gt;, por hacer alguna.&lt;/p&gt;
&lt;p&gt;Entramos en el &lt;em&gt;mongo shell&lt;/em&gt;, desde donde lanzaremos el resto de comandos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# ./mongodb-linux-i686-3.2.3/bin/mongo
MongoDB shell version: 3.2.3
connecting to: &lt;span class="nb"&gt;test&lt;/span&gt;
Welcome to the MongoDB shell.
For interactive &lt;span class="nb"&gt;help&lt;/span&gt;, &lt;span class="nb"&gt;type&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;help&amp;quot;&lt;/span&gt;.
...
&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Siguiendo los pasos estándares, creamos una configuración vacía en la máquina elegida, y añadimos las otras dos. Tened en cuenta que la máquina &lt;em&gt;backoffice&lt;/em&gt; se declara como un árbitro, por decisión de diseño.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;gt; rs.initiate&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;info2&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;no configuration specified. Using a default configuration for the set&amp;quot;&lt;/span&gt;,
        &lt;span class="s2"&gt;&amp;quot;me&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
        &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : 1
&lt;span class="o"&gt;}&lt;/span&gt;
rs:SECONDARY&amp;gt; rs.add&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mongo2:27017&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
rs:PRIMARY&amp;gt; rs.addArb&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;backoffice:27017&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
rs:PRIMARY&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Podemos verificar que todo está bien mediante el comando &lt;em&gt;rs.status()&lt;/em&gt;, como sigue:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;rs:PRIMARY&amp;gt; rs.status&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;set&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;rs&amp;quot;&lt;/span&gt;,
...  
        &lt;span class="s2"&gt;&amp;quot;members&amp;quot;&lt;/span&gt; : &lt;span class="o"&gt;[&lt;/span&gt;
                &lt;span class="o"&gt;{&lt;/span&gt;
...  
                        &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
                        &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;PRIMARY&amp;quot;&lt;/span&gt;,
...  
                &lt;span class="o"&gt;}&lt;/span&gt;,
                &lt;span class="o"&gt;{&lt;/span&gt;
...  
                        &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo2:27017&amp;quot;&lt;/span&gt;,
                        &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;SECONDARY&amp;quot;&lt;/span&gt;,
...  
                &lt;span class="o"&gt;}&lt;/span&gt;,
                &lt;span class="o"&gt;{&lt;/span&gt;
...  
                        &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;backoffice:27017&amp;quot;&lt;/span&gt;,
                        &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;ARBITER&amp;quot;&lt;/span&gt;,
...  
                &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="o"&gt;]&lt;/span&gt;,
        &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : 1
&lt;span class="o"&gt;}&lt;/span&gt;
rs:PRIMARY&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y salimos del &lt;em&gt;mongo shell&lt;/em&gt;, que ya no necesitamos; las aplicaciones de &lt;em&gt;backend&lt;/em&gt; y de &lt;em&gt;backoffice&lt;/em&gt; ya incluyen una librería para conectarse por sí mismos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;rs:PRIMARY&amp;gt; &lt;span class="nb"&gt;exit&lt;/span&gt;
bye
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Todo lo que queda en &lt;em&gt;/root/&lt;/em&gt; es innecesario y se puede borrar. De todas formas podemos dejar el resto de binarios en &lt;em&gt;/opt/mongodb/&lt;/em&gt; en alguna de las máquinas por si acaso.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;El siguiente paso va a ser montar los servidores de aplicaciones en los backends y en el backoffice&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="mongodb"></category><category term="replica set"></category><category term="systemd"></category><category term="firehol"></category></entry><entry><title>Creando un entorno escalable (I)</title><link href="http://www.linuxsysadmin.tk/2016/02/creando-un-entorno-escalable.html" rel="alternate"></link><updated>2016-02-29T08:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2016-02-29:2016/02/creando-un-entorno-escalable.html</id><summary type="html">&lt;p&gt;Mucha gente tiene un servidor único para alojar páginas web dinámicas, por ejemplo con &lt;strong&gt;PHP&lt;/strong&gt; y con &lt;strong&gt;MySQL&lt;/strong&gt;. Sin embargo, a veces esto puede resultar insuficiente; nos puede interesar tener un entorno de bajas especificaciones y de bajo coste, pero preparado crecer al mismo ritmo que lo hacen los usuarios.&lt;/p&gt;
&lt;p&gt;En este caso, el truco consiste en hacer trabajar a varias máquinas como si fueran una sola, escondidas en una o varias subredes privadas y poniendo un representante único de todo el sistema (que es el que va a recibir &lt;strong&gt;todas&lt;/strong&gt; las peticiones).&lt;/p&gt;
&lt;p&gt;Este representante suele ser lo que llamamos un &lt;strong&gt;balanceador de carga&lt;/strong&gt;, cuya función es repartir el trabajo entre varios servidores de &lt;strong&gt;backend&lt;/strong&gt;. Al tratarse solo de un "policía de tráfico" su rendimiento es elevado con unas especificaciones modestas, mientras que los servidores de &lt;strong&gt;backend&lt;/strong&gt; consiguen resolver las mismas peticiones por unidad de tiempo; la mejora reside en que pueden haber varios servidores de &lt;strong&gt;backend&lt;/strong&gt; resolviendo peticiones en paralelo.&lt;/p&gt;
&lt;p&gt;Normalmente, estos servidores de &lt;strong&gt;backend&lt;/strong&gt; suelen conectarse a otros servicios (idealmente en otros servidores) para cumplir con sus funciones, por ejemplo con un grupo de servidores de &lt;strong&gt;bases de datos&lt;/strong&gt; dispuestos como un &lt;em&gt;cluster&lt;/em&gt;, que suelen tener una topología propia.&lt;/p&gt;
&lt;p&gt;En este tutorial se va a montar un entorno pequeño de estas características, sirviendo una &lt;em&gt;API&lt;/em&gt; pública en servidores de &lt;strong&gt;backend&lt;/strong&gt;, una aplicación web de administración de los datos de la &lt;em&gt;API&lt;/em&gt; en un servidor de &lt;strong&gt;backoffice&lt;/strong&gt;, y un &lt;em&gt;cluster&lt;/em&gt; de &lt;strong&gt;bases de datos&lt;/strong&gt; representado por una &lt;em&gt;replica set&lt;/em&gt; de MongoDB; todo ello oculto en una red privada y un balanceador usando &lt;em&gt;virtualhosts&lt;/em&gt; para ir a una aplicación u otra según el protocolo usado.&lt;/p&gt;
&lt;p&gt;Esto es lo que propongo montar:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Entorno propuesto" src="http://www.linuxsysadmin.tk/images/entorno_propuesto.png" /&gt;&lt;/p&gt;
&lt;p&gt;Para ello, vamos a crear las máquinas virtuales necesarias. En este caso, voy a usar mi servidor de &lt;strong&gt;virtualización con LXC&lt;/strong&gt;, tal como lo monté en &lt;a href="http://www.linuxsysadmin.tk/2015/11/virtualizando-contenedores-lxc-tras-bridge-interno.html"&gt;este artículo&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-ls -f
NAME        STATE    IPV4        IPV6  AUTOSTART
------------------------------------------------
backend1    RUNNING  10.0.0.3    -     YES
backend2    RUNNING  10.0.0.4    -     YES
backoffice  RUNNING  10.0.0.5    -     YES
frontend    RUNNING  10.0.0.2    -     YES
mongo1      RUNNING  10.0.0.6    -     YES
mongo2      RUNNING  10.0.0.7    -     YES
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para hacer mas fácil las referencias a las diferentes máquinas, vamos a utilizar sus nombres; como no me apetece montar un servidor DNS, vamos a ponerlas en el fichero &lt;em&gt;/etc/hosts&lt;/em&gt; en todas las máquinas virtuales.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cat /etc/hosts
...
10.0.0.2        frontend
10.0.0.3        backend1
10.0.0.4        backend2
10.0.0.5        backoffice
10.0.0.6        mongo1
10.0.0.7        mongo2
...
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a ir montando todas las máquinas una por una; es laborioso pero no es nada complicado. Las reglas del &lt;em&gt;firewall&lt;/em&gt; también las iremos explicando según el rol de cada máquina.&lt;/p&gt;
&lt;p&gt;El orden de montaje no es importante, pero como queremos ir comprobando en cada caso que va funcionando, se montarán de acuerdo al orden de requisitos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;El &lt;em&gt;cluster&lt;/em&gt; de &lt;strong&gt;bases de datos&lt;/strong&gt;, que no tiene dependencias.&lt;/li&gt;
&lt;li&gt;Los servidores de &lt;strong&gt;backend&lt;/strong&gt; y &lt;strong&gt;backoffice&lt;/strong&gt; que dependen del &lt;em&gt;cluster&lt;/em&gt; de &lt;strong&gt;bases de datos&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Finalmente, pondremos el servidor de &lt;strong&gt;frontend&lt;/strong&gt;, con los &lt;em&gt;virtualhosts&lt;/em&gt; y el balanceador, lanzando las peticiones contra los &lt;strong&gt;backends&lt;/strong&gt; y el &lt;strong&gt;backoffice&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Sabiendo lo que vamos a montar, solo queda decir: ¡Manos a la obra!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</summary><category term="linux"></category><category term="entorno"></category><category term="escalable"></category></entry><entry><title>Restringiendo accesos mediante certificados de cliente</title><link href="http://www.linuxsysadmin.tk/2016/02/restringiendo-accesos-mediante-certificados-de-cliente.html" rel="alternate"></link><updated>2016-02-22T08:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2016-02-22:2016/02/restringiendo-accesos-mediante-certificados-de-cliente.html</id><summary type="html">&lt;p&gt;De vez en cuando, tenemos algún contenido web o una API que necesita un control de acceso superior. El método mas eficaz del que disponemos hoy en día es la autenticación con certificados SSL cliente, en donde es el cliente el que debe ofrecer un certificado que el servidor validará.&lt;/p&gt;
&lt;p&gt;Como se trata de proteger contenido web, vamos a necesitar un servidor web, por ejemplo, &lt;strong&gt;nginx&lt;/strong&gt;. De paso, vamos a instalar el paquete &lt;strong&gt;openssl&lt;/strong&gt;, que nos permitirá generar los certificados usados.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# apt-get install nginx-light openssl
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  nginx-common
Paquetes sugeridos:
  fcgiwrap nginx-doc ssl-cert ca-certificates
Se instalarán los siguientes paquetes NUEVOS:
  nginx-common nginx-light openssl
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;3&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar 1.126 kB de archivos.
Se utilizarán 2.148 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Generar el certificado y la clave de la CA&lt;/h2&gt;
&lt;p&gt;Empezaremos por generar la clave de la CA, que va a servir para firmar el certificado que pondremos en el servidor.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl genrsa -des3 -out ca.key 4096
Generating RSA private key, &lt;span class="m"&gt;4096&lt;/span&gt; bit long modulus
...................................................................++
.++
e is &lt;span class="m"&gt;65537&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;0x10001&lt;span class="o"&gt;)&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
Verifying - Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora generamos el certificado de la CA. Lo generamos directamente firmado en un solo paso.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl req -new -x509 -days &lt;span class="m"&gt;365&lt;/span&gt; -key ca.key -out ca.crt -subj &lt;span class="s2"&gt;&amp;quot;/C=ES/ST=Spain/L=Barcelona/O=LinuxSysadmin&amp;quot;&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Generar el certificado para el servidor web&lt;/h2&gt;
&lt;p&gt;Generamos la clave para el certificado del servidor web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl genrsa -des3 -out server.key 4096
Generating RSA private key, &lt;span class="m"&gt;4096&lt;/span&gt; bit long modulus
.............................................++
.....................................++
e is &lt;span class="m"&gt;65537&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;0x10001&lt;span class="o"&gt;)&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key:
Verifying - Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora creamos un certificado para el servidor web. Es importante que el campo &lt;strong&gt;CN&lt;/strong&gt; sea el mismo que el nombre del &lt;em&gt;virtualhost&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl req -new -key server.key -out server.csr -subj &lt;span class="s2"&gt;&amp;quot;/C=ES/ST=Spain/L=Barcelona/O=LinuxSysadmin/CN=private.linuxsysadmin.tk&amp;quot;&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y lo firmamos con la clave y el certificado de la CA.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl x509 -req -days &lt;span class="m"&gt;365&lt;/span&gt; -in server.csr -CA ca.crt -CAkey ca.key -set_serial &lt;span class="m"&gt;01&lt;/span&gt; -out server.crt
Signature ok
&lt;span class="nv"&gt;subject&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/C&lt;span class="o"&gt;=&lt;/span&gt;ES/ST&lt;span class="o"&gt;=&lt;/span&gt;Spain/L&lt;span class="o"&gt;=&lt;/span&gt;Barcelona/O&lt;span class="o"&gt;=&lt;/span&gt;LinuxSysadmin/CN&lt;span class="o"&gt;=&lt;/span&gt;private.linuxsysadmin.tk
Getting CA Private Key
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: Si la clave está protegida por una passphrase, se va a necesitar introducirla cada vez que se quiera levantar el servidor web. Nos lo podemos ahorrar con unos simples comandos, que dejará la clave como insegura.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mv server.key server.key.secure
root@server:~# openssl rsa -in server.key.secure -out server.key
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key.secure:
writing RSA key
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Generar el certificado cliente&lt;/h2&gt;
&lt;p&gt;Generamos la clave para el certificado del cliente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl genrsa -des3 -out client.key 1024
Generating RSA private key, &lt;span class="m"&gt;1024&lt;/span&gt; bit long modulus
...............................++++++
.....................++++++
e is &lt;span class="m"&gt;65537&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;0x10001&lt;span class="o"&gt;)&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; client.key:
Verifying - Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; client.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El siguiente paso consiste en generar una petición de certificado, que posteriormente haremos firmar. El campo &lt;strong&gt;CN&lt;/strong&gt; puede ser recogido por el servidor web y trasladado mediante cabeceras a un hipotético &lt;em&gt;backend&lt;/em&gt;, en caso de hacer un &lt;em&gt;proxy_pass&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl req -new -key client.key -out client.csr -subj &lt;span class="s2"&gt;&amp;quot;/C=ES/ST=Spain/L=Barcelona/O=LinuxSysadmin/CN=Gerard Monells&amp;quot;&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; client.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Firmamos nuestra petición de certificado con la clave de la CA, obteniendo el certificado final.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl x509 -req -days &lt;span class="m"&gt;365&lt;/span&gt; -in client.csr -CA ca.crt -CAkey ca.key -set_serial &lt;span class="m"&gt;91&lt;/span&gt; -out client.crt
Signature ok
&lt;span class="nv"&gt;subject&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/C&lt;span class="o"&gt;=&lt;/span&gt;ES/ST&lt;span class="o"&gt;=&lt;/span&gt;Spain/L&lt;span class="o"&gt;=&lt;/span&gt;Barcelona/O&lt;span class="o"&gt;=&lt;/span&gt;LinuxSysadmin/CN&lt;span class="o"&gt;=&lt;/span&gt;Gerard Monells
Getting CA Private Key
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora queda empaquetar la clave y el certificado en un fichero &lt;em&gt;client.p12&lt;/em&gt; que pueda ser importado en un navegador web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl pkcs12 -export -in client.crt -inkey client.key -out client.p12 -name &lt;span class="s2"&gt;&amp;quot;LinuxSysadmin&amp;quot;&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; client.key:
Enter Export Password:
Verifying - Enter Export Password:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Montando el dominio web&lt;/h2&gt;
&lt;p&gt;Además de necesitar el certificado y la clave servidor, es necesario que el servidor web conozca el certificado de la CA para que pueda verificar el servidor cliente que nos ofrezca el navegador.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cp server.key /etc/ssl/private/
root@server:~# cp server.crt /etc/ssl/certs/
root@server:~# cp ca.crt /etc/ssl/certs/
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Así quedarían los certificados una vez en su sitio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# tree /etc/ssl/
/etc/ssl/
├── certs
│   ├── ca.crt
│   └── server.crt
├── openssl.cnf
└── private
    └── server.key

&lt;span class="m"&gt;2&lt;/span&gt; directories, &lt;span class="m"&gt;4&lt;/span&gt; files
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a poner un fichero de configuración en &lt;strong&gt;nginx&lt;/strong&gt;, que va a escuchar por el puerto 443 y con &lt;strong&gt;SSL&lt;/strong&gt; habilitado. Indicamos también donde están los ficheros que servirá el &lt;strong&gt;nginx&lt;/strong&gt;, la localización de los certificados y la necesidad de verificar al cliente mediante certificado contra el certificado de la CA.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /etc/nginx/sites-enabled/private.linuxsysadmin.tk
server &lt;span class="o"&gt;{&lt;/span&gt;
    listen                      &lt;span class="m"&gt;443&lt;/span&gt; ssl&lt;span class="p"&gt;;&lt;/span&gt;
    server_name                 private.linuxsysadmin.tk&lt;span class="p"&gt;;&lt;/span&gt;
    root                        /www&lt;span class="p"&gt;;&lt;/span&gt;

    ssl_certificate             /etc/ssl/certs/server.crt&lt;span class="p"&gt;;&lt;/span&gt;
    ssl_certificate_key         /etc/ssl/private/server.key&lt;span class="p"&gt;;&lt;/span&gt;
    ssl_client_certificate      /etc/ssl/certs/ca.crt&lt;span class="p"&gt;;&lt;/span&gt;
    ssl_verify_client           on&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Podemos verificar que la sintaxis de la configuración es correcta usando el binario de &lt;strong&gt;nginx&lt;/strong&gt; con el parámetro adecuado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# nginx -t
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf &lt;span class="nb"&gt;test &lt;/span&gt;is successful
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y sabiendo que es correcto, reiniciamos el servidor web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# service nginx restart
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comprobación de funcionamiento&lt;/h2&gt;
&lt;p&gt;Como hemos indicado en la configuración en el &lt;em&gt;document root&lt;/em&gt;, vamos a servir el contenido que se encuentra en &lt;em&gt;/www&lt;/em&gt;. Empezaremos poniendo algún contenido en él.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mkdir /www
root@server:~# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Private area&amp;quot;&lt;/span&gt; &amp;gt; /www/index.html
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora apuntemos el navegador a la &lt;strong&gt;URL&lt;/strong&gt; del servidor web. Debemos aceptar el certificado autofirmado, puesto que no viene firmado por ninguna autoridad certificadora conocida, por ejemplo, &lt;strong&gt;VeriSign&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Aún así, como no hemos presentado el certificado cliente, el servidor web nos impide el acceso, con una respuesta &lt;strong&gt;HTTP 400&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="2 way SSL access denied" src="http://www.linuxsysadmin.tk/images/2-way-ssl-access-denied.png" /&gt;&lt;/p&gt;
&lt;p&gt;Ahora debemos importar el certificado &lt;em&gt;client.p12&lt;/em&gt; en el navegador web. En el caso concreto de &lt;strong&gt;Google Chrome&lt;/strong&gt;, se hace desde el siguiente menú:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Menu &amp;rarr; Settings &amp;rarr; Show advanced settings &amp;rarr; HTTPS/SSL &amp;rarr; Manage certificates &amp;rarr; Your certificates &amp;rarr; Import &amp;rarr; client.p12&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Y ya podemos acceder a nuestro contenido protegido, previa selección del certificado a usar.&lt;/p&gt;
&lt;p&gt;&lt;img alt="2 way SSL certificate" src="http://www.linuxsysadmin.tk/images/2-way-ssl-certificate.png" /&gt;&lt;/p&gt;
&lt;p&gt;Y con esto ya tenemos montada la autenticación cliente mediante certificados.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="nginx"></category><category term="2 way ssl"></category><category term="ssl"></category><category term="https"></category><category term="certificado"></category></entry><entry><title>Restringiendo accesos web mediante autenticación básica</title><link href="http://www.linuxsysadmin.tk/2016/02/restringiendo-accesos-web-mediante-autenticacion-basica.html" rel="alternate"></link><updated>2016-02-08T08:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2016-02-08:2016/02/restringiendo-accesos-web-mediante-autenticacion-basica.html</id><summary type="html">&lt;p&gt;Algunas veces nos encontramos con la necesidad de restringir el acceso a algunos recursos web. Normalmente se suele implementar algún sistema de &lt;em&gt;login&lt;/em&gt;, &lt;em&gt;cookies&lt;/em&gt; o &lt;em&gt;sesiones&lt;/em&gt;; no obstante, esta opción no siempre nos es posible, y tenemos que proteger esos recursos usando los mecanismos que nos ofrezca el servidor web.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ATENCIÓN&lt;/strong&gt;: Este método es bastante simple, y se puede descodificar lo que manda el cliente; por eso se recomienda encarecidamente usar &lt;strong&gt;SSL&lt;/strong&gt;, mediante el uso de &lt;strong&gt;HTTPS&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Empezaremos instalando el servidor web y la herramienta de generación de certificados para usar con &lt;strong&gt;SSL&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# apt-get install nginx-light openssl
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  nginx-common
Paquetes sugeridos:
  fcgiwrap nginx-doc ssl-cert ca-certificates
Se instalarán los siguientes paquetes NUEVOS:
  nginx-common nginx-light openssl
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;3&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar 1.126 kB de archivos.
Se utilizarán 2.148 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Generar el certificado y la clave de la CA&lt;/h2&gt;
&lt;p&gt;Empezaremos por generar la clave de la CA, que va a servir para firmar el certificado que pondremos en el servidor.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl genrsa -des3 -out ca.key 4096
Generating RSA private key, &lt;span class="m"&gt;4096&lt;/span&gt; bit long modulus
..................................++
.....................................................................++
e is &lt;span class="m"&gt;65537&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;0x10001&lt;span class="o"&gt;)&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
Verifying - Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora generamos el certificado de la CA. Lo generamos directamente firmado en un solo paso.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl req -new -x509 -days &lt;span class="m"&gt;365&lt;/span&gt; -key ca.key -out ca.crt -subj &lt;span class="s2"&gt;&amp;quot;/C=ES/ST=Spain/L=Barcelona/O=LinuxSysadmin&amp;quot;&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Generar el certificado para el servidor web&lt;/h2&gt;
&lt;p&gt;Generamos la clave para el certificado del servidor web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl genrsa -des3 -out server.key 4096
Generating RSA private key, &lt;span class="m"&gt;4096&lt;/span&gt; bit long modulus
.....................................................................++
......................................................................................................................................................................++
e is &lt;span class="m"&gt;65537&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;0x10001&lt;span class="o"&gt;)&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key:
Verifying - Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora creamos un certificado para el servidor web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl req -new -key server.key -out server.csr -subj &lt;span class="s2"&gt;&amp;quot;/C=ES/ST=Spain/L=Barcelona/O=LinuxSysadmin/CN=private.linuxsysadmin.tk&amp;quot;&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y lo firmamos con la clave y el certificado de la CA.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# openssl x509 -req -days &lt;span class="m"&gt;365&lt;/span&gt; -in server.csr -CA ca.crt -CAkey ca.key -set_serial &lt;span class="m"&gt;01&lt;/span&gt; -out server.crt
Signature ok
&lt;span class="nv"&gt;subject&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/C&lt;span class="o"&gt;=&lt;/span&gt;ES/ST&lt;span class="o"&gt;=&lt;/span&gt;Spain/L&lt;span class="o"&gt;=&lt;/span&gt;Barcelona/O&lt;span class="o"&gt;=&lt;/span&gt;LinuxSysadmin/CN&lt;span class="o"&gt;=&lt;/span&gt;private.linuxsysadmin.tk
Getting CA Private Key
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: Si la clave está protegida por una &lt;em&gt;passphrase&lt;/em&gt;, se va a necesitar introducirla cada vez que se quiera levantar el servidor web. Nos lo podemos ahorrar con unos simples comandos, que dejará la clave como insegura.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mv server.key server.key.secure
root@server:~# openssl rsa -in server.key.secure -out server.key
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key.secure:
writing RSA key
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Montando el dominio web&lt;/h2&gt;
&lt;p&gt;Para habilitar &lt;strong&gt;SSL&lt;/strong&gt; en un dominio, necesitamos la clave y el certificado del servidor, así que vamos a ponerlos en una carpeta pensado para tal efecto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cp server.key /etc/ssl/private/
root@server:~# cp server.crt /etc/ssl/certs/
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Así quedarían los certificados una vez en su sitio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# tree /etc/ssl/
/etc/ssl/
├── certs
│   └── server.crt
├── openssl.cnf
└── private
    └── server.key

&lt;span class="m"&gt;2&lt;/span&gt; directories, &lt;span class="m"&gt;3&lt;/span&gt; files
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a poner un fichero de configuración en &lt;strong&gt;nginx&lt;/strong&gt;, que va a escuchar por el puerto 443 y con &lt;strong&gt;SSL&lt;/strong&gt; habilitado. Indicamos también donde están los ficheros que servirá el &lt;strong&gt;nginx&lt;/strong&gt;, la localización de los certificados y activamos la autenticación básica.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# cat /etc/nginx/sites-enabled/private.linuxsysadmin.tk
server &lt;span class="o"&gt;{&lt;/span&gt;
        listen &lt;span class="m"&gt;443&lt;/span&gt; ssl&lt;span class="p"&gt;;&lt;/span&gt;
        server_name private.linuxsysadmin.tk&lt;span class="p"&gt;;&lt;/span&gt;
        root /www&lt;span class="p"&gt;;&lt;/span&gt;

        ssl_certificate /etc/ssl/certs/server.crt&lt;span class="p"&gt;;&lt;/span&gt;
        ssl_certificate_key /etc/ssl/private/server.key&lt;span class="p"&gt;;&lt;/span&gt;

        auth_basic &lt;span class="s2"&gt;&amp;quot;Admin Area&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        auth_basic_user_file /etc/nginx/auth/private&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora tenemos que crear un fichero tipo &lt;em&gt;.htpasswd&lt;/em&gt; como los de &lt;strong&gt;apache&lt;/strong&gt;. Crearemos primero la carpeta en donde lo vamos a dejar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mkdir /etc/nginx/auth
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En la carpeta creada pondremos un fichero llamado &lt;em&gt;private&lt;/em&gt; con un formato idéntico a los &lt;em&gt;.htpasswd&lt;/em&gt; de &lt;strong&gt;apache&lt;/strong&gt;. Aquí podríamos usar las herramientas de &lt;strong&gt;apache-utils&lt;/strong&gt;, pero de momento nos conformaremos con crearlo con &lt;strong&gt;openssl&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;admin:&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;openssl passwd -crypt s3cr3t&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; /etc/nginx/auth/private
root@server:~# cat /etc/nginx/auth/private
admin:y6xasR0LI8mbg
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente reiniciamos el servidor web para que aplique los cambios en la configuración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# service nginx restart
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comprobación de funcionamiento&lt;/h2&gt;
&lt;p&gt;Es importante que nos acordemos de crear nuestro &lt;em&gt;document root&lt;/em&gt; con algún contenido.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mkdir /www
root@server:~# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Private area&amp;quot;&lt;/span&gt; &amp;gt; /www/index.html
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Si apuntamos un navegador al dominio configurado, y tras aceptar nuestro certificado autofirmado como excepción, deberíamos ver que se nos piden las credenciales en una ventana emergente.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Autenticación básica: credenciales" src="http://www.linuxsysadmin.tk/images/autenticacion-basica-credenciales.png" /&gt;&lt;/p&gt;
&lt;p&gt;Y con eso tenemos nuestro contenido protegido de los curiosos.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="nginx"></category><category term="autenticacion basica"></category><category term="htpasswd"></category><category term="ssl"></category><category term="https"></category><category term="certificado"></category></entry><entry><title>Un proxy DNS con dnsmasq</title><link href="http://www.linuxsysadmin.tk/2016/02/un-proxy-dns-con-dnsmasq.html" rel="alternate"></link><updated>2016-02-01T08:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2016-02-01:2016/02/un-proxy-dns-con-dnsmasq.html</id><summary type="html">&lt;p&gt;A veces nos puede interesar disponer de una servidor &lt;strong&gt;DNS&lt;/strong&gt; para nombrar las máquinas de nuestra red privada, sin la complejidad de &lt;strong&gt;BIND&lt;/strong&gt;. Otras, queremos acelerar el acceso a internet desde nuestra red; es interesante ver el tiempo que se pierde en la resolución &lt;strong&gt;DNS&lt;/strong&gt;. Para eso disponemos de &lt;strong&gt;dnsmasq&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;El servicio &lt;strong&gt;dnsmasq&lt;/strong&gt; proporciona servicios como caché &lt;strong&gt;DNS&lt;/strong&gt; y como servidor &lt;strong&gt;DHCP&lt;/strong&gt;. Se trata de un &lt;em&gt;proxy&lt;/em&gt; &lt;strong&gt;DNS&lt;/strong&gt; que va a dirigir las consultas &lt;strong&gt;DNS&lt;/strong&gt; contra el servidor configurado en el &lt;em&gt;proxy&lt;/em&gt;, guardando una copia en &lt;em&gt;caché&lt;/em&gt; para agilizar futuras consultas.&lt;/p&gt;
&lt;p&gt;Es muy fácil de configurar y es bastante ligero. Se considera ideal para redes pequeñas con menos de 50 ordenadores.&lt;/p&gt;
&lt;p&gt;En mi caso, resultó muy útil para solucionar el problema de &lt;strong&gt;DNS&lt;/strong&gt; que me planteaba una red &lt;strong&gt;Virtualbox&lt;/strong&gt; &lt;em&gt;solo anfitrión&lt;/em&gt;, en donde se escondían mis máquinas virtuales con dirección IP estática. Resulta que me muevo entre varias zonas de trabajo, y que no hay ningún servidor &lt;strong&gt;DNS&lt;/strong&gt; accesible desde todas; ir cambiando los &lt;strong&gt;DNS&lt;/strong&gt; de todas las máquinas era trabajoso.&lt;/p&gt;
&lt;p&gt;Con este problema, puse &lt;strong&gt;dnsmasq&lt;/strong&gt; en mi anfitrión (que usaba &lt;strong&gt;DHCP&lt;/strong&gt; y recibía el &lt;strong&gt;DNS&lt;/strong&gt; automáticamente), y configuré todas las máquinas para que usaran el anfitrión como servidor &lt;strong&gt;DNS&lt;/strong&gt;; nunca mas tuve que configurarlos.&lt;/p&gt;
&lt;h2&gt;Instalación&lt;/h2&gt;
&lt;p&gt;La instalación en una máquina derivada de &lt;em&gt;Debian&lt;/em&gt; es muy simple; está en los repositorios oficiales.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@proxy:~# apt-get install dnsmasq
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  dns-root-data dnsmasq-base libnetfilter-conntrack3
Paquetes sugeridos:
  resolvconf
Se instalarán los siguientes paquetes NUEVOS:
  dns-root-data dnsmasq dnsmasq-base libnetfilter-conntrack3
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;4&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;488&lt;/span&gt; kB de archivos.
Se utilizarán 1.170 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@proxy:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En caso de querer modificar la configuración, se debe editar el fichero &lt;em&gt;/etc/dnsmasq.conf&lt;/em&gt;, y luego reiniciar el servicio &lt;em&gt;dnsmasq&lt;/em&gt;. En este mismo fichero se puede configurar el servicio &lt;strong&gt;DHCP&lt;/strong&gt; (directiva &lt;em&gt;dhcp-range&lt;/em&gt;), el servidor de nombres a dar al resto (la misma máquina de &lt;em&gt;dnsmasq&lt;/em&gt;, por defecto), el servidor &lt;strong&gt;NTP&lt;/strong&gt; o el &lt;em&gt;gateway&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;En mi caso, no vi necesario activar estos servicios, así que el fichero de configuración no se vio modificada. Así pues, con esto basta.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: En caso de querer resolver localmente, &lt;em&gt;dnsmasq&lt;/em&gt; sirve los nombres alojados en &lt;em&gt;/etc/hosts&lt;/em&gt;, a menos que se indique lo contrario en la configuración. Basta con modificar ese fichero.&lt;/p&gt;
&lt;h2&gt;Comprobación y uso&lt;/h2&gt;
&lt;p&gt;Para comprobar que funciona, vamos a poner otra máquina, configurada para usar el nuevo servidor &lt;strong&gt;DNS&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client:~# cat /etc/resolv.conf 
nameserver 192.168.56.1
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En principio basta con comprobar que resuelve el nombre de una petición cualquiera, por ejemplo, con un &lt;strong&gt;ping&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Sin embargo, podemos apreciar la mejora de la &lt;em&gt;caché&lt;/em&gt; mediante una herramienta mas avanzada de resolución &lt;strong&gt;DNS&lt;/strong&gt;, por ejemplo, con &lt;strong&gt;dig&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client:~# dig www.linuxsysadmin.tk &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="s2"&gt;&amp;quot;Query time&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;;;&lt;/span&gt; Query &lt;span class="nb"&gt;time&lt;/span&gt;: &lt;span class="m"&gt;118&lt;/span&gt; msec
root@client:~# dig www.linuxsysadmin.tk &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="s2"&gt;&amp;quot;Query time&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;;;&lt;/span&gt; Query &lt;span class="nb"&gt;time&lt;/span&gt;: &lt;span class="m"&gt;5&lt;/span&gt; msec
root@client:~# dig www.linuxsysadmin.tk &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="s2"&gt;&amp;quot;Query time&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;;;&lt;/span&gt; Query &lt;span class="nb"&gt;time&lt;/span&gt;: &lt;span class="m"&gt;4&lt;/span&gt; msec
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto hemos cumplido; tenemos un &lt;em&gt;proxy caché&lt;/em&gt; &lt;strong&gt;DNS&lt;/strong&gt;, que nos agiliza las peticiones, nos resuelve localmente y nos evita ir cambiando el &lt;strong&gt;DNS&lt;/strong&gt; cada vez que nos movemos de zona de trabajo.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="dnsmasq"></category><category term="cache"></category><category term="dns"></category><category term="dhcp"></category></entry><entry><title>Un repositorio de Debian con reprepro</title><link href="http://www.linuxsysadmin.tk/2016/01/un-repositorio-de-debian-con-reprepro.html" rel="alternate"></link><updated>2016-01-11T08:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2016-01-11:2016/01/un-repositorio-de-debian-con-reprepro.html</id><summary type="html">&lt;p&gt;Una de las grandes facilidades que nos ofrece una distribución de Linux es su sistema de gestor de paquetes. Los paquetes oficiales nos simplifican la instalación y mantenimiento de paquetes; sin embargo, podemos sacar provecho del sistema de paquetes para uso personal, para automatizar instalaciones y actualizaciones que queramos hacer.&lt;/p&gt;
&lt;p&gt;En este artículo vamos a crear un repositorio en el que podemos poner paquetes, sean sacados del repositorio oficial (para hacer de caché), o sean paquetes creados por nosotros con aplicativos propios o empaquetados a partir de paquetes no libres.&lt;/p&gt;
&lt;p&gt;Para hacerlo, necesitamos una máquina en donde pondremos el repositorio, y a efectos de demostración, una máquina en donde instalaremos paquetes de dicho repositorio. En este caso, usaremos como &lt;em&gt;LXC&lt;/em&gt; tecnología para crear las máquina virtuales.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-ls -f
NAME        STATE    IPV4      IPV6  AUTOSTART  
----------------------------------------------
client      RUNNING  10.0.0.3  -     YES        
repository  RUNNING  10.0.0.2  -     YES        
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Montando el repositorio&lt;/h2&gt;
&lt;p&gt;Un repositorio &lt;em&gt;Debian&lt;/em&gt; no es mas que un servidor web sirviendo una estructura de ficheros con una forma concreta, que vamos a crear con &lt;strong&gt;reprepro&lt;/strong&gt; y vamos a servir con &lt;strong&gt;nginx&lt;/strong&gt;. Aís pues, los instalamos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@repository:~# apt-get install reprepro nginx-light
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
...
Se instalarán los siguientes paquetes NUEVOS:
  ca-certificates gnupg-agent gnupg2 libarchive13 libassuan0 libcurl3-gnutls libffi6 libgmp10 libgnutls-deb0-28 libgpgme11 libhogweed2 libidn11 libksba8 libldap-2.4-2
  liblzo2-2 libnettle4 libp11-kit0 libpth20 librtmp1 libsasl2-2 libsasl2-modules libsasl2-modules-db libssh2-1 libtasn1-6 libxml2 nginx-common nginx-light openssl
  pinentry-curses reprepro sgml-base xml-core
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;32&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar 7.645 kB de archivos.
Se utilizarán 21,2 MB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@repository:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Un repositorio necesita una clave &lt;strong&gt;gpg&lt;/strong&gt; para firmar los paquetes que sirve; aunque de eso se encarga &lt;strong&gt;reprepro&lt;/strong&gt;, tenemos que generarla:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@repository:~# gpg --gen-key
gpg &lt;span class="o"&gt;(&lt;/span&gt;GnuPG&lt;span class="o"&gt;)&lt;/span&gt; 1.4.18&lt;span class="p"&gt;;&lt;/span&gt; Copyright &lt;span class="o"&gt;(&lt;/span&gt;C&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="m"&gt;2014&lt;/span&gt; Free Software Foundation, Inc.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
...
gpg: /root/.gnupg/trustdb.gpg: se ha creado base de datos de confianza
gpg: clave C1B88DF7 marcada como de confianza absoluta
claves pública y secreta creadas y firmadas.
...
root@repository:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora podemos ver que las claves se han creado y podemos anotar su identificador para continuar con el procedimiento.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@repository:~# gpg --list-keys
/root/.gnupg/pubring.gpg
------------------------
pub   2048R/C1B88DF7 2016-01-07
uid                  Gerard Monells &amp;lt;gerard.monells@gmail.com&amp;gt;
sub   2048R/5C5B84E3 2016-01-07

root@repository:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a crear el repositorio en &lt;em&gt;/opt/repo/&lt;/em&gt;, con una carpeta &lt;em&gt;public&lt;/em&gt; que es lo que vamos a servir con &lt;strong&gt;nginx&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@repository:~# mkdir -p /opt/repo/&lt;span class="o"&gt;{&lt;/span&gt;conf,public&lt;span class="o"&gt;}&lt;/span&gt;
root@repository:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Por comodidad, vamos a trabajar en la carpeta base del repositorio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@repository:~# &lt;span class="nb"&gt;cd&lt;/span&gt; /opt/repo
root@repository:/opt/repo# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Un repositorio hecho con &lt;strong&gt;reprepro&lt;/strong&gt; se declara mediante un fichero de configuración, que vamos a crear en la carpeta &lt;em&gt;conf&lt;/em&gt;, declarando el nombre del repositorio, las arquitecturas y la clave con la que se firman los paquetes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@repository:/opt/repo# cat conf/distributions 
Codename: linuxsysadmin
Components: main
Architectures: i386
SignWith: C1B88DF7
root@repository:/opt/repo# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a poner la parte pública de nuestra clave &lt;strong&gt;gpg&lt;/strong&gt; en la raíz del servidor web, para que los clientes puedan agregarla a su almacén de claves, para usar sin problemas los paquetes de nuestro repositorio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@repository:/opt/repo# gpg -a --export C1B88DF7 &amp;gt; /opt/repo/public/key.gpg
root@repository:/opt/repo# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora vamos a poner una configuración a &lt;strong&gt;nginx&lt;/strong&gt; que nos permita servir la carpeta pública en el puerto web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@repository:/opt/repo# cat /etc/nginx/sites-enabled/repository
server &lt;span class="o"&gt;{&lt;/span&gt;
    server_name localhost&lt;span class="p"&gt;;&lt;/span&gt;
    root /opt/repo/public&lt;span class="p"&gt;;&lt;/span&gt;
    autoindex on&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@repository:/opt/repo# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Recargamos o reiniciamos el servicio &lt;strong&gt;nginx&lt;/strong&gt; para que la configuración surta efecto:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@repository:/opt/repo# service nginx restart
root@repository:/opt/repo# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Añadiendo paquetes al repositorio&lt;/h2&gt;
&lt;p&gt;Añadir un paquete a nuestro repositorio es tan fácil como invocar el comando &lt;em&gt;reprepro&lt;/em&gt;, con la opción &lt;em&gt;includedeb&lt;/em&gt; del paquete, en alguna carpeta de nuestra máquina. El resto son opciones que indican donde están las carpetas del repositorio.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: Si se pone un paquete empaquetado por nosotros, es importante que su fichero &lt;em&gt;control&lt;/em&gt; incluya las directivas &lt;em&gt;Section&lt;/em&gt; y &lt;em&gt;Priority&lt;/em&gt;, normalmente solo recomendadas, pero necesarias para &lt;strong&gt;reprepro&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Por ejemplo, podemos usar el paquete de un &lt;a href="http://www.linuxsysadmin.tk/2015/12/empaquetando-ficheros-punto-deb.html"&gt;artículo anterior&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@repository:/opt/repo# reprepro --distdir ./public/dists --outdir ./public includedeb linuxsysadmin /root/welcome_1.0-1_all.deb 
Exporting indices...
root@repository:/opt/repo# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: Puede que el comando falle si no se ha montado el sistema de ficheros &lt;em&gt;/dev/pts&lt;/em&gt;, especialmente en un entorno tipo &lt;strong&gt;chroot&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Usando el repositorio&lt;/h2&gt;
&lt;p&gt;Cambiamos de máquina; ahora vamos a la máquina que vaya a usar el repositorio y vamos a configurar el repositorio nuevo.&lt;/p&gt;
&lt;p&gt;Lo primero es declarar la &lt;strong&gt;source&lt;/strong&gt; de nuestro repositorio, declarando la dirección web del repositorio, el nombre del repositorio y el componente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client:~# cat /etc/apt/sources.list.d/linuxsysadmin.list 
deb http://10.0.0.2/ linuxsysadmin main
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora nos descargamos la clave pública del repositorio y la añadimos al almacén de claves de &lt;strong&gt;apt&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client:~# wget -qO- http://10.0.0.2/key.gpg &lt;span class="p"&gt;|&lt;/span&gt; apt-key add -
OK
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto ya tenemos el repositorio habilitado. A partir de aquí su uso es el mismo que el de cualquier otro repositorio. Hacemos un &lt;em&gt;apt-get update&lt;/em&gt; para descargar la lista de paquetes del repositorio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client:~# apt-get update
Des:1 http://10.0.0.2 linuxsysadmin InRelease &lt;span class="o"&gt;[&lt;/span&gt;1.340 B&lt;span class="o"&gt;]&lt;/span&gt;
...
Des:2 http://10.0.0.2 linuxsysadmin/main i386 Packages &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;333&lt;/span&gt; B&lt;span class="o"&gt;]&lt;/span&gt;
...
Descargados 2.040 B en 6s &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;330&lt;/span&gt; B/s&lt;span class="o"&gt;)&lt;/span&gt;                                                                                                                                    
Leyendo lista de paquetes... Hecho
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A partir de aquí, y sabiendo nuestro sistema los paquetes de los que dispone el nuevo repositorio, podemos buscar los paquetes que hay en él.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client:~# apt-cache search welcome &lt;span class="p"&gt;|&lt;/span&gt; grep ^welcome
welcome2l - Linux ANSI boot logo
welcome - A fancy shell script
root@client:~# apt-cache show welcome
Package: welcome
Version: 1.0-1
Architecture: all
Maintainer: Linux Sysadmin
Priority: optional
Section: main
Filename: pool/main/w/welcome/welcome_1.0-1_all.deb
Size: 786
SHA256: 2e701f7fbc090230fb7abc06597fbe5b4e9e70dcc553e749e69793a745b032f2
SHA1: 41351d1d2135bcee09e1fa3bade984ece9f23caf
MD5sum: 574fab58b3c871184047c40d0e732b35
Description: A fancy shell script
 To demonstrate how to package a .deb file
Description-md5: ed73975a1e7c5f0422fef1f624586821
Depends: bash, coreutils

root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Visto que el paquete está disponible, podemos instalarlo, usando &lt;em&gt;apt-get&lt;/em&gt; o cualquier otro frontal, gráfico o no.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client:~# apt-get install welcome
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes NUEVOS:
  welcome
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;1&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;786&lt;/span&gt; B de archivos.
Se utilizarán &lt;span class="m"&gt;0&lt;/span&gt; B de espacio de disco adicional después de esta operación.
Des:1 http://10.0.0.2/ linuxsysadmin/main welcome all 1.0-1 &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;786&lt;/span&gt; B&lt;span class="o"&gt;]&lt;/span&gt;
Descargados &lt;span class="m"&gt;786&lt;/span&gt; B en 0s &lt;span class="o"&gt;(&lt;/span&gt;37,4 kB/s&lt;span class="o"&gt;)&lt;/span&gt;
debconf: se retrasa la configuración de los paquetes, ya que «apt-utils» no está instalado
Seleccionando el paquete welcome previamente no seleccionado.
&lt;span class="o"&gt;(&lt;/span&gt;Leyendo la base de datos ... &lt;span class="m"&gt;10434&lt;/span&gt; ficheros o directorios instalados actualmente.&lt;span class="o"&gt;)&lt;/span&gt;
Preparando para desempaquetar .../archives/welcome_1.0-1_all.deb ...
Desempaquetando welcome &lt;span class="o"&gt;(&lt;/span&gt;1.0-1&lt;span class="o"&gt;)&lt;/span&gt; ...
Configurando welcome &lt;span class="o"&gt;(&lt;/span&gt;1.0-1&lt;span class="o"&gt;)&lt;/span&gt; ...
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Tal como lo esperábamos, el comando &lt;em&gt;welcome&lt;/em&gt; está instalado y funciona como esperábamos:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client:~# which welcome
/usr/bin/welcome
root@client:~# welcome
Hello world!
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto tenemos nuestro repositorio funcional.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="repositorio"></category><category term="reprepro"></category><category term="nginx"></category><category term="gpg"></category><category term="apt"></category></entry><entry><title>Utilizando apt-cacher-ng para agilizar la instalación de paquetes</title><link href="http://www.linuxsysadmin.tk/2015/12/utilizando-apt-cacher-ng-para-agilizar-la-instalacion-de-paquetes.html" rel="alternate"></link><updated>2015-12-21T10:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-12-21:2015/12/utilizando-apt-cacher-ng-para-agilizar-la-instalacion-de-paquetes.html</id><summary type="html">&lt;p&gt;Hace tiempo veo que tras usar muchas maquinas virtuales &lt;em&gt;Debian&lt;/em&gt; para el uso diario y para las demostraciones de este blog, el ancho de banda usado para bajar los paquetes se dispara. La mayoría de veces se trata de los mismos paquetes, para instalar las mismas aplicaciones, servicios o actualizaciones.&lt;/p&gt;
&lt;p&gt;En el artículo de hoy, voy a enseñar como usar un &lt;em&gt;proxy&lt;/em&gt; con una &lt;em&gt;caché&lt;/em&gt; para &lt;em&gt;apt-get&lt;/em&gt;, llamado &lt;strong&gt;apt-cacher-ng&lt;/strong&gt;, de forma que los paquetes son descargados por la primera máquina que los pida, guardados en un servidor local y aprovechados por el resto de máquinas.&lt;/p&gt;
&lt;h2&gt;Preparación de las máquinas&lt;/h2&gt;
&lt;p&gt;Partimos de la máquina habitual, llamada &lt;strong&gt;aptcacher&lt;/strong&gt;, siendo esta un contenedor LXC con una &lt;em&gt;Debian Jessie&lt;/em&gt; básica, aunque esto se podría haber puesto en una &lt;em&gt;Ubuntu&lt;/em&gt; o cualquier otra distribución que funcione con paquetes &lt;em&gt;.deb&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Otras máquinas que vamos a usar son unas máquinas cliente en donde vamos a instalar paquetes cualesquiera para demostrar el funcionamiento, llamadas &lt;strong&gt;client1&lt;/strong&gt; y &lt;strong&gt;client2&lt;/strong&gt;; estos clientes están en la misma red que la máquina &lt;strong&gt;aptcacher&lt;/strong&gt; y tienen conectividad con ella por el puerto &lt;em&gt;TCP&lt;/em&gt; 3142.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@lxc:~# lxc-ls -f
NAME       STATE    IPV4      IPV6  AUTOSTART  
---------------------------------------------
aptcacher  RUNNING  10.0.0.2  -     YES        
client1    RUNNING  10.0.0.3  -     YES        
client2    RUNNING  10.0.0.4  -     YES        
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Empezamos instalando el servicio &lt;strong&gt;apt-cacher-ng&lt;/strong&gt; en la máquina servidor &lt;strong&gt;aptcacher&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@aptcacher:~# apt-get install apt-cacher-ng
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
...  
Se instalarán los siguientes paquetes NUEVOS:
  apt-cacher-ng ed
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;2&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;500&lt;/span&gt; kB de archivos.
Se utilizarán 1.168 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@aptcacher:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Las configuraciones que vienen por defecto son bastante adecuadas y no tuve que efectuar ningún cambio.&lt;/p&gt;
&lt;p&gt;Por otra parte, hay que configurar las máquinas que se quieran beneficiar de este servidor, añadiendo una línea de configuración en su &lt;strong&gt;apt-get&lt;/strong&gt;, por ejemplo, poniendo un fichero adicional en &lt;em&gt;/etc/apt/apt.conf.d/&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@aptcacher:~# cat /etc/apt/apt.conf.d/02proxy 
Acquire::http &lt;span class="o"&gt;{&lt;/span&gt; Proxy &lt;span class="s2"&gt;&amp;quot;http://10.0.0.2:3142&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
root@aptcacher:~# 

root@client1:~# cat /etc/apt/apt.conf.d/02proxy 
Acquire::http &lt;span class="o"&gt;{&lt;/span&gt; Proxy &lt;span class="s2"&gt;&amp;quot;http://10.0.0.2:3142&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
root@client1:~# 

root@client2:~# cat /etc/apt/apt.conf.d/02proxy 
Acquire::http &lt;span class="o"&gt;{&lt;/span&gt; Proxy &lt;span class="s2"&gt;&amp;quot;http://10.0.0.2:3142&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
root@client2:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto queda montado todo el sistema.&lt;/p&gt;
&lt;h2&gt;Funcionamiento de la caché&lt;/h2&gt;
&lt;p&gt;El funcionamiento es muy simple: basta con instalar en un cliente un paquete, por ejemplo, &lt;em&gt;python&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client1:~# apt-get install python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
...  
Se instalarán los siguientes paquetes NUEVOS:
  file libexpat1 libffi6 libmagic1 libpython-stdlib libpython2.7-minimal
  libpython2.7-stdlib libsqlite3-0 mime-support python python-minimal
  python2.7 python2.7-minimal
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;13&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar 5.010 kB de archivos.
Se utilizarán 21,3 MB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
Descargados 5.010 kB en 15s &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;327&lt;/span&gt; kB/s&lt;span class="o"&gt;)&lt;/span&gt;                                        
...
root@client1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como estos paquetes no están en la &lt;em&gt;caché&lt;/em&gt; del servidor, se han descargado de internet en 15 segundos, de acuerdo a la velocidad de mi conexión de internet y de la velocidad de respuesta de los repositorios elegidos.&lt;/p&gt;
&lt;p&gt;Si revisamos la página de estadísticas de &lt;strong&gt;apt-cacher-ng&lt;/strong&gt;, disponible en &lt;em&gt;http://aptcacher:3142/acng-report.html&lt;/em&gt; podemos ver que se han descargado 4,78mb en 13 paquetes; todos son &lt;strong&gt;miss&lt;/strong&gt; de la cache, es decir, se han ido a buscar al repositorio oficial.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Estadísticas web de apt-cacher" src="http://www.linuxsysadmin.tk/images/apt-cacher-ng-1.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Ahora vamos a instalar &lt;em&gt;python&lt;/em&gt; en otro de los clientes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client2:~# apt-get install python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
...
Se instalarán los siguientes paquetes NUEVOS:
  file libexpat1 libffi6 libmagic1 libpython-stdlib libpython2.7-minimal
  libpython2.7-stdlib libsqlite3-0 mime-support python python-minimal
  python2.7 python2.7-minimal
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;13&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar 5.010 kB de archivos.
Se utilizarán 21,3 MB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
Descargados 5.010 kB en 1s &lt;span class="o"&gt;(&lt;/span&gt;3.902 kB/s&lt;span class="o"&gt;)&lt;/span&gt;
root@client2:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hemos elegido el paquete &lt;em&gt;python&lt;/em&gt; para asegurar que ambas máquinas instalan lo mismo; como se puede ver, se ha descargado la misma cantidad de datos, pero en vez de los 15 segundos anteriores, ahora se ha tardado 1 segundo. Eso es porque los paquetes solicitados estaban en el &lt;em&gt;proxy&lt;/em&gt;, es decir, en el servidor &lt;strong&gt;aptcacher&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Podemos ver en la misma página de administración el resultado: ahora hay 13 &lt;strong&gt;hits&lt;/strong&gt; adicionales, ya que los paquetes solicitados estaban en local.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Estadísticas web de apt-cacher" src="http://www.linuxsysadmin.tk/images/apt-cacher-ng-2.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;De esta forma, si tenemos un elevado número de máquinas del mismo tipo, solo consumiremos el ancho de banda necesario para traerlos de internet &lt;strong&gt;una sola vez&lt;/strong&gt;.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="apt-cacher-ng"></category><category term="cache"></category></entry><entry><title>Construyendo un RAID 10 en linux</title><link href="http://www.linuxsysadmin.tk/2015/12/construyendo-un-raid-10-en-linux.html" rel="alternate"></link><updated>2015-12-17T23:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-12-17:2015/12/construyendo-un-raid-10-en-linux.html</id><summary type="html">&lt;p&gt;El otro día estaba habilitando un servidor de &lt;em&gt;mongodb&lt;/em&gt; para un entorno de producción. Como me interesaba mejorar el rendimiento de los accesos a disco y no disponía de discos SSD con una durabilidad aceptable, me propuse montar un &lt;em&gt;array de discos&lt;/em&gt; en configuración de &lt;strong&gt;RAID 10&lt;/strong&gt;, como se recomienda.&lt;/p&gt;
&lt;p&gt;Para este tutorial vamos a tener una máquina virtual (es una &lt;em&gt;Debian&lt;/em&gt;, pero vale cualquier otra distribución) con 5 discos, 1 de sistema y otros 4 para usar en la configuración &lt;strong&gt;RAID 10&lt;/strong&gt;, cada uno con 8gb, a efecto de demostración.&lt;/p&gt;
&lt;p&gt;En este caso, el sistema operativo estaba en &lt;em&gt;/dev/sda&lt;/em&gt; y sus particiones, mientras que los discos para los datos de &lt;em&gt;mongodb&lt;/em&gt; fueron &lt;em&gt;/dev/sdb&lt;/em&gt;, &lt;em&gt;/dev/sdc&lt;/em&gt;, &lt;em&gt;/dev/sdd&lt;/em&gt;, &lt;em&gt;/dev/sde&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# ls /dev/sd* -1
/dev/sda
/dev/sda1
/dev/sdb
/dev/sdc
/dev/sdd
/dev/sde
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Creación del dispositivo RAID 10&lt;/h2&gt;
&lt;p&gt;Empezamos instalando el controlador de &lt;strong&gt;RAID&lt;/strong&gt; por software:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# apt-get install mdadm
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
..
Se instalarán los siguientes paquetes NUEVOS:
  bsd-mailx exim4-base exim4-config exim4-daemon-light liblockfile-bin
  liblockfile1 mdadm psmisc
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;8&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
...
update-initramfs: Generating /boot/initrd.img-3.16.0-4-586
W: mdadm: /etc/mdadm/mdadm.conf defines no arrays.
W: mdadm: no arrays defined in configuration file.
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Con las herramientas instaladas, procedemos a crear un &lt;em&gt;/dev/md0&lt;/em&gt; que será nuestro &lt;strong&gt;disco RAID&lt;/strong&gt;, indicando el nivel &lt;strong&gt;RAID 10&lt;/strong&gt; y los 4 discos reales que van a formarlo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mdadm -v --create /dev/md0 --level&lt;span class="o"&gt;=&lt;/span&gt;raid10 --raid-devices&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt; /dev/sdb /dev/sdc /dev/sdd /dev/sde
mdadm: layout defaults to n2
mdadm: layout defaults to n2
mdadm: chunk size defaults to 512K
mdadm: size &lt;span class="nb"&gt;set &lt;/span&gt;to 8380416K
mdadm: Defaulting to version 1.2 metadata
mdadm: array /dev/md0 started.
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para que ese array de discos sea reconocido en cada inicio del sistema, hay que añadir en &lt;em&gt;/etc/mdadm/mdadm.conf&lt;/em&gt; la información relacionada al array, de la misma forma que la tengamos en este momento.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mdadm --detail --scan --verbose &amp;gt;&amp;gt; /etc/mdadm/mdadm.conf
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y ya tenemos nuestro dispositivo &lt;strong&gt;RAID 10&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Preparación del dispositivo&lt;/h2&gt;
&lt;p&gt;Ahora disponemos de un &lt;strong&gt;RAID 10&lt;/strong&gt; de 4 discos de 8gb, que corresponden a una capacidad total de 16gb utilizables, como el dispositivo &lt;em&gt;/dev/md0&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Este dispositivo es transparente para nosotros y no es diferente de cualquier otro dispositivo de bloques, con lo que se puede particionar, formatear e incluso actuar como un &lt;em&gt;physical volume&lt;/em&gt; en caso de usar &lt;strong&gt;LVM&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Para esta demostración, se creará una única partición que ocupe todo el disco y que será montada en &lt;em&gt;/data&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Así pues, sin mas preámbulo la particionamos; en mi caso lo hice con &lt;em&gt;cfdisk&lt;/em&gt;. Este es el resultado:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# fdisk -l /dev/md0

Disco /dev/md0: &lt;span class="m"&gt;16&lt;/span&gt; GiB, &lt;span class="m"&gt;17163091968&lt;/span&gt; bytes, &lt;span class="m"&gt;33521664&lt;/span&gt; sectores
Unidades: sectores de &lt;span class="m"&gt;1&lt;/span&gt; * &lt;span class="nv"&gt;512&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;512&lt;/span&gt; bytes
Tamaño de sector &lt;span class="o"&gt;(&lt;/span&gt;lógico/físico&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;512&lt;/span&gt; bytes / &lt;span class="m"&gt;512&lt;/span&gt; bytes
Tamaño de E/S &lt;span class="o"&gt;(&lt;/span&gt;mínimo/óptimo&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;524288&lt;/span&gt; bytes / &lt;span class="m"&gt;1048576&lt;/span&gt; bytes
Tipo de etiqueta de disco: gpt
Identificador del disco: E3FE7B0A-0F5D-4151-84E8-49670C33B65E

Device     Start      End  Sectors Size Type
/dev/md0p1  &lt;span class="m"&gt;2048&lt;/span&gt; &lt;span class="m"&gt;33521630&lt;/span&gt; &lt;span class="m"&gt;33519583&lt;/span&gt;  16G Linux filesystem

root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La primera (y única partición) se llama &lt;em&gt;/dev/md0p1&lt;/em&gt; y es el dispositivo que vamos a formatear, para posteriormente montarlo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mkfs.ext4 /dev/md0p1 
mke2fs 1.42.12 &lt;span class="o"&gt;(&lt;/span&gt;29-Aug-2014&lt;span class="o"&gt;)&lt;/span&gt;
Se está creando El sistema de ficheros con &lt;span class="m"&gt;4189947&lt;/span&gt; 4k bloques y &lt;span class="m"&gt;1048576&lt;/span&gt; nodos-i

UUID del sistema de ficheros: 11e454ce-72c4-41f8-a7bc-4d4a78b873c0
Respaldo del superbloque guardado en los bloques: 
    32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 
    4096000

Reservando las tablas de grupo: hecho                           
Escribiendo las tablas de nodos-i: hecho                           
Creando el fichero de transacciones &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;32768&lt;/span&gt; bloques&lt;span class="o"&gt;)&lt;/span&gt;: hecho
Escribiendo superbloques y la información contable del sistema de ficheros:   hecho  

root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos la carpeta que va a servir de &lt;em&gt;mountpoint&lt;/em&gt; para esta nueva partición:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mkdir /data
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Añadimos la partición en el fichero &lt;em&gt;/etc/fstab&lt;/em&gt;, para que se monte automáticamente tras cada reinicio:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# grep md0p1 /etc/fstab 
/dev/md0p1 /data ext4 defaults &lt;span class="m"&gt;0&lt;/span&gt; 0
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente la montamos. Como esta información ya está en el fichero &lt;em&gt;/etc/fstab&lt;/em&gt; no es necesario especificar los detalles.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mount /data
root@server:~# df -h
S.ficheros     Tamaño Usados  Disp Uso% Montado en
/dev/sda1        2,0G   651M  1,2G  35% /
udev              10M      &lt;span class="m"&gt;0&lt;/span&gt;   10M   0% /dev
tmpfs             50M   4,4M   46M   9% /run
tmpfs            124M      &lt;span class="m"&gt;0&lt;/span&gt;  124M   0% /dev/shm
tmpfs            5,0M      &lt;span class="m"&gt;0&lt;/span&gt;  5,0M   0% /run/lock
tmpfs            124M      &lt;span class="m"&gt;0&lt;/span&gt;  124M   0% /sys/fs/cgroup
/dev/md0p1        16G    44M   15G   1% /data
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como detalle, al no tratarse de una partición raíz de sistema operativo, no hace falta reservar bloques de emergencia; se trata de un 5% de la capacidad que podemos liberar (5% de 16gb son 800mb que podemos usar).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# tune2fs -m &lt;span class="m"&gt;0&lt;/span&gt; /dev/md0p1 
tune2fs 1.42.12 &lt;span class="o"&gt;(&lt;/span&gt;29-Aug-2014&lt;span class="o"&gt;)&lt;/span&gt;
Se pone el porcentaje de bloques reservados a 0% &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; bloques&lt;span class="o"&gt;)&lt;/span&gt;
root@server:~# df -h
S.ficheros     Tamaño Usados  Disp Uso% Montado en
/dev/sda1        2,0G   651M  1,2G  35% /
udev              10M      &lt;span class="m"&gt;0&lt;/span&gt;   10M   0% /dev
tmpfs             50M   4,4M   46M   9% /run
tmpfs            124M      &lt;span class="m"&gt;0&lt;/span&gt;  124M   0% /dev/shm
tmpfs            5,0M      &lt;span class="m"&gt;0&lt;/span&gt;  5,0M   0% /run/lock
tmpfs            124M      &lt;span class="m"&gt;0&lt;/span&gt;  124M   0% /sys/fs/cgroup
/dev/md0p1        16G    44M   16G   1% /data
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Verificación&lt;/h2&gt;
&lt;p&gt;Podemos ver la información de estado del array de discos con el mismo comando &lt;em&gt;mdadm&lt;/em&gt;, como sigue:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@server:~# mdadm --detail /dev/md0
/dev/md0:
        Version : 1.2
  Creation Time : Sat Dec &lt;span class="m"&gt;12&lt;/span&gt; 21:19:42 2015
     Raid Level : raid10
     Array Size : &lt;span class="m"&gt;16760832&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;15.98 GiB 17.16 GB&lt;span class="o"&gt;)&lt;/span&gt;
  Used Dev Size : &lt;span class="m"&gt;8380416&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;7.99 GiB 8.58 GB&lt;span class="o"&gt;)&lt;/span&gt;
   Raid Devices : 4
  Total Devices : 4
    Persistence : Superblock is persistent

    Update Time : Sat Dec &lt;span class="m"&gt;12&lt;/span&gt; 21:30:11 2015
          State : clean 
 Active Devices : 4
Working Devices : 4
 Failed Devices : 0
  Spare Devices : 0

         Layout : &lt;span class="nv"&gt;near&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;2
     Chunk Size : 512K

           Name : server:0  &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;local &lt;/span&gt;to host server&lt;span class="o"&gt;)&lt;/span&gt;
           UUID : 217558a7:bc1cb1d4:9530ecda:ea477a6b
         Events : 19

    Number   Major   Minor   RaidDevice State
       &lt;span class="m"&gt;0&lt;/span&gt;       &lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;16&lt;/span&gt;        &lt;span class="m"&gt;0&lt;/span&gt;      active sync &lt;span class="nb"&gt;set&lt;/span&gt;-A   /dev/sdb
       &lt;span class="m"&gt;1&lt;/span&gt;       &lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;32&lt;/span&gt;        &lt;span class="m"&gt;1&lt;/span&gt;      active sync &lt;span class="nb"&gt;set&lt;/span&gt;-B   /dev/sdc
       &lt;span class="m"&gt;2&lt;/span&gt;       &lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;48&lt;/span&gt;        &lt;span class="m"&gt;2&lt;/span&gt;      active sync &lt;span class="nb"&gt;set&lt;/span&gt;-A   /dev/sdd
       &lt;span class="m"&gt;3&lt;/span&gt;       &lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;64&lt;/span&gt;        &lt;span class="m"&gt;3&lt;/span&gt;      active sync &lt;span class="nb"&gt;set&lt;/span&gt;-B   /dev/sde
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;RESUMEN&lt;/strong&gt;: Ahora tengo un disco doble de rápido, doble de capacidad y con doble copia de datos. Afortunadamente, los discos duros son baratos...&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="raid"></category></entry><entry><title>Construyendo una replica set en mongodb</title><link href="http://www.linuxsysadmin.tk/2015/12/construyendo-una-replica-set-en-mongodb.html" rel="alternate"></link><updated>2015-12-08T12:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.tk,2015-12-08:2015/12/construyendo-una-replica-set-en-mongodb.html</id><summary type="html">&lt;p&gt;Muchas veces nos interesa obtener alta disponibilidad en los servicios que gestionamos. No hay nada mas desagradable que una llamada a las tantas de la noche porque se ha caído un nodo de una base de datos y no damos servicio. Para eso &lt;em&gt;mongodb&lt;/em&gt; nos ofrece el mecanismo de replicación.&lt;/p&gt;
&lt;p&gt;En este artículo vamos a montar una &lt;em&gt;replica set&lt;/em&gt;, de forma que si se cayera un nodo de la base de datos, otro asumiría su rol, de forma que se seguiría dando servicio.&lt;/p&gt;
&lt;p&gt;Nuestra &lt;em&gt;replica set&lt;/em&gt; va a tener 3 nodos, que vamos a alojar en 3 máquinas distintas, de forma que la caída de una máquina afecte solamente a 1 proceso de &lt;em&gt;mongodb&lt;/em&gt;. La caonfiguración de 3 nodos nos da una tolerancia a fallos de 1 máquina; mientras queden 2, el clúster va a seguir operativo.&lt;/p&gt;
&lt;h2&gt;Descripción del entorno&lt;/h2&gt;
&lt;p&gt;Disponemos de 3 máquinas que vamos a llamar &lt;strong&gt;mongo1&lt;/strong&gt;, &lt;strong&gt;mongo2&lt;/strong&gt; y &lt;strong&gt;mongo3&lt;/strong&gt;. Cada una funciona con un sistema operativo &lt;em&gt;Debian jessie&lt;/em&gt; con &lt;em&gt;systemd&lt;/em&gt; y cuenta 1 gb de disco y con 256 mb de memoria; para esta demostración no se necesita mas.&lt;/p&gt;
&lt;p&gt;Como pequeño detalle, las máquinas se van referir entre ellas por nombre, pero como no me interesa poner una solución completa de &lt;em&gt;DNS&lt;/em&gt;, he puesto en el fichero &lt;em&gt;/etc/hosts&lt;/em&gt; de todas las máquinas las equivalencias.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# grep mongo /etc/hosts
10.0.0.2    mongo1
10.0.0.3    mongo2
10.0.0.4    mongo3
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Consideraciones de seguridad&lt;/h2&gt;
&lt;p&gt;Estas máquinas se comunican entre sí por el puerto TCP en el que corran sus procesos; para seguir con el puerto "titular" vamos a ponerlos en el puerto 27017. Es importante que las 3 máquinas puedan acceder al puerto de las otras 2. Adicionalmente, la máquina que vaya a usar este clúster también debe pode acceder al puerto 27017 de las 3 máquinas.&lt;/p&gt;
&lt;h2&gt;Preparación de las máquinas individuales&lt;/h2&gt;
&lt;p&gt;Queremos una versión de &lt;em&gt;mongodb&lt;/em&gt; un poco reciente, así que no vamos a usar los paquetes oficiales de la distribución, y la empresa de &lt;em&gt;mongodb&lt;/em&gt; no ofrece paquete para &lt;em&gt;Debian jessie&lt;/em&gt;. Por ello vamos a montar un esqueleto de ficheros como se describe en &lt;a href="http://www.linuxsysadmin.tk/2015/11/escribiendo-units-en-systemd.html"&gt;un artículo anterior&lt;/a&gt;. Vamos a describir el proceso en la máquina &lt;strong&gt;mongo1&lt;/strong&gt;, para replicarlo a posteriori en las otras 2.&lt;/p&gt;
&lt;p&gt;Creamos la estructura de carpetas que van a contener todo lo relativo a &lt;strong&gt;mongodb&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# mkdir -p /opt/mongodb/&lt;span class="o"&gt;{&lt;/span&gt;bin,conf,data/replica,logs&lt;span class="o"&gt;}&lt;/span&gt;
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Copiamos el binario &lt;strong&gt;mongod&lt;/strong&gt; que encontraremos en el fichero &lt;em&gt;.tar.gz&lt;/em&gt; de la página de descargas de la página web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cp mongod /opt/mongodb/bin/
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos un fichero de configuración con el que vamos a levantar el proceso en esta máquina.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cat /opt/mongodb/conf/replica.conf
systemLog:
    path: /opt/mongodb/logs/replica.log
    logAppend: &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nb"&gt;    &lt;/span&gt;destination: file

net:
    port: 27017
    bindIp: 0.0.0.0

storage:
    dbPath: /opt/mongodb/data/replica
    smallFiles: &lt;span class="nb"&gt;true&lt;/span&gt;

replication:
    replSetName: replica
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Por razones de seguridad vamos a lanzar el servicio con un usuario propio de sistema.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# useradd -s /usr/sbin/nologin -r -M mongo -d /opt/mongodb/
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para ahorrarnos problemas de permisos, lo hacemos propietario de todo lo referente al servicio:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# chown -R mongo:mongo /opt/mongodb/
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a crearle una &lt;strong&gt;unit&lt;/strong&gt; para que el sistema se encargue de levantar automáticamente el servicio en caso de reinicio de la máquina:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# cat /etc/systemd/system/mongo.service
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;MongoDB

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;User&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mongo
&lt;span class="nv"&gt;LimitFSIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitCPU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitNOFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;LimitNPROC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;64000
&lt;span class="nv"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/rm -f /opt/mongodb/data/replica/mongod.lock
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/opt/mongodb/bin/mongod -f /opt/mongodb/conf/replica.conf

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente activamos la &lt;strong&gt;unit&lt;/strong&gt; e iniciamos el servicio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@mongo1:~# systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mongo
Created symlink from /etc/systemd/system/multi-user.target.wants/mongo.service to /etc/systemd/system/mongo.service.
root@mongo1:~# systemctl start mongo
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora toca repetir el proceso en las otras 2 máquinas, exactamente igual.&lt;/p&gt;
&lt;h2&gt;Configuración del clúster&lt;/h2&gt;
&lt;p&gt;Accedemos a una de las máquinas del futuro clúster desde cualquier máquina que pueda hacerlo y que disponga del binario &lt;strong&gt;mongo&lt;/strong&gt; (el mongo shell), que también viene en el archivo &lt;em&gt;.tar.gz&lt;/em&gt; descargado de la página oficial; este shell no es necesario para la aplicación que use el clúster ya que el &lt;strong&gt;driver&lt;/strong&gt; de cada lenguaje suple sus funciones, pero es muy útil tenerlo a mano para tareas de administración y consultas varias.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@client:~# ./mongo --host 10.0.0.2
MongoDB shell version: 3.0.7
connecting to: 10.0.0.2:27017/test
Welcome to the MongoDB shell.
For interactive &lt;span class="nb"&gt;help&lt;/span&gt;, &lt;span class="nb"&gt;type&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;help&amp;quot;&lt;/span&gt;.
&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hay dos formas de crear la configuración del clúster: pasando el documento de configuración en el método &lt;em&gt;initiate&lt;/em&gt; o añadir los nodos a posteriori con el método &lt;em&gt;add&lt;/em&gt;. Voy a usar este método por ser mas fácil.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;gt; rs.initiate&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;info2&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;no configuration explicitly specified -- making one&amp;quot;&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;me&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : 1
&lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; rs.add&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mongo2:27017&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; rs.add&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mongo3:27017&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a lanzar el método &lt;em&gt;status&lt;/em&gt; hasta que todos los nodos sean primarios o secundarios, momento en el que la &lt;em&gt;replica&lt;/em&gt; va a quedar correctamente montada.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;replica:PRIMARY&amp;gt; rs.status&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;set&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;replica&amp;quot;&lt;/span&gt;,
...
    &lt;span class="s2"&gt;&amp;quot;members&amp;quot;&lt;/span&gt; : &lt;span class="o"&gt;[&lt;/span&gt;
        &lt;span class="o"&gt;{&lt;/span&gt;
...
            &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;PRIMARY&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;self&amp;quot;&lt;/span&gt; : &lt;span class="nb"&gt;true&lt;/span&gt;
...
        &lt;span class="o"&gt;}&lt;/span&gt;,
        &lt;span class="o"&gt;{&lt;/span&gt;
...
            &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo2:27017&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;SECONDARY&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;syncingTo&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
...
        &lt;span class="o"&gt;}&lt;/span&gt;,
        &lt;span class="o"&gt;{&lt;/span&gt;
...
            &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo3:27017&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;SECONDARY&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;syncingTo&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
...
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;]&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : 1
&lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esta salida del método &lt;em&gt;status&lt;/em&gt; ya lo tenemos todo funcionando correctamente.&lt;/p&gt;</summary><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="mongodb"></category><category term="replica set"></category><category term="systemd"></category></entry></feed>