<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Linux Sysadmin - Sistemas</title><link href="http://www.linuxsysadmin.ml/" rel="alternate"></link><link href="http://www.linuxsysadmin.ml/feeds/sistemas.atom.xml" rel="self"></link><id>http://www.linuxsysadmin.ml/</id><updated>2017-10-02T10:00:00+02:00</updated><entry><title>Un servicio casi imprescindible: NTP</title><link href="http://www.linuxsysadmin.ml/2017/10/un-servicio-casi-imprescindible-ntp.html" rel="alternate"></link><published>2017-10-02T10:00:00+02:00</published><updated>2017-10-02T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-10-02:/2017/10/un-servicio-casi-imprescindible-ntp.html</id><summary type="html">&lt;p&gt;Normalmente, me gustan los servidores con un número de servicios tirando a mezquino; menos servicios significan menos actualizaciones, menos superficie de ataque y menos recursos ocupados. Sin embargo, hay algunos que son imprescindibles, mientras que otros son altamente recomendables. Este es el caso del &lt;strong&gt;NTP&lt;/strong&gt;, que mantiene la hora actualizada …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Normalmente, me gustan los servidores con un número de servicios tirando a mezquino; menos servicios significan menos actualizaciones, menos superficie de ataque y menos recursos ocupados. Sin embargo, hay algunos que son imprescindibles, mientras que otros son altamente recomendables. Este es el caso del &lt;strong&gt;NTP&lt;/strong&gt;, que mantiene la hora actualizada.&lt;/p&gt;
&lt;p&gt;Esto es crucial para muchos servicios de &lt;em&gt;cluster&lt;/em&gt;, que necesitan una sincronización temporal estricta. Otros usos son para aplicaciones y sus &lt;em&gt;logs&lt;/em&gt;, en donde el momento exacto en el que pasan las cosas es crucial, y puede ser consultado en &lt;em&gt;logs&lt;/em&gt; de varias máquinas, que idealmente deberían coincidir. Finalmente, el otro uso que considero indispensable es para aquellas máquinas que se dedican a virtualizar contenedores u otras máquinas virtuales, ya que pagando el precio del proceso una única vez, permite a sus descendientes (por ejemplo, contenedores &lt;strong&gt;docker&lt;/strong&gt;) seguir actualizadas.&lt;/p&gt;
&lt;h2&gt;Instalación de NTP&lt;/h2&gt;
&lt;p&gt;El servicio &lt;strong&gt;NTP&lt;/strong&gt; se instala en un solo paquete, que tanto en la famíla &lt;em&gt;RedHat&lt;/em&gt; con en la família &lt;em&gt;Debian&lt;/em&gt;, se llama &lt;strong&gt;ntp&lt;/strong&gt;. Usad las herramientas que tengáis a mano en vuestra distribución.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# apt-get install ntp
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes adicionales:
  libopts25 libperl5.24 perl perl-modules-5.24 rename
Paquetes sugeridos:
  ntp-doc perl-doc libterm-readline-gnu-perl &lt;span class="p"&gt;|&lt;/span&gt; libterm-readline-perl-perl make
Se instalarán los siguientes paquetes NUEVOS:
  libopts25 libperl5.24 ntp perl perl-modules-5.24 rename
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;6&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;7&lt;/span&gt;.103 kB de archivos.
Se utilizarán &lt;span class="m"&gt;42&lt;/span&gt;,1 MB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La configuración por defecto ya viene preconfigurada con algunos servidores base contra los que sincronizar. Podemos ver que estamos sincronizando y contra qué, con el comando &lt;strong&gt;ntpq&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# ntpq -p
     remote           refid      st t when poll reach   delay   offset  &lt;span class="nv"&gt;jitter&lt;/span&gt;
&lt;span class="o"&gt;==============================================================================&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;.debian.pool.n .POOL.          &lt;span class="m"&gt;16&lt;/span&gt; p    -   &lt;span class="m"&gt;64&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;.000    &lt;span class="m"&gt;0&lt;/span&gt;.000   &lt;span class="m"&gt;0&lt;/span&gt;.000
 &lt;span class="m"&gt;1&lt;/span&gt;.debian.pool.n .POOL.          &lt;span class="m"&gt;16&lt;/span&gt; p    -   &lt;span class="m"&gt;64&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;.000    &lt;span class="m"&gt;0&lt;/span&gt;.000   &lt;span class="m"&gt;0&lt;/span&gt;.000
 &lt;span class="m"&gt;2&lt;/span&gt;.debian.pool.n .POOL.          &lt;span class="m"&gt;16&lt;/span&gt; p    -   &lt;span class="m"&gt;64&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;.000    &lt;span class="m"&gt;0&lt;/span&gt;.000   &lt;span class="m"&gt;0&lt;/span&gt;.000
 &lt;span class="m"&gt;3&lt;/span&gt;.debian.pool.n .POOL.          &lt;span class="m"&gt;16&lt;/span&gt; p    -   &lt;span class="m"&gt;64&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;.000    &lt;span class="m"&gt;0&lt;/span&gt;.000   &lt;span class="m"&gt;0&lt;/span&gt;.000
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este caso, podemos ver que, debido a la configuración de red, no llegamos a los servidores:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;El tiempo desde la última sincronización no existe (&lt;em&gt;when&lt;/em&gt; vacío)&lt;/li&gt;
&lt;li&gt;El &lt;em&gt;stratum&lt;/em&gt; de los servidores es infinito, con lo que son inaccesibles (&lt;em&gt;st&lt;/em&gt; vale 16 para marcar esta inaccesibilidad)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Así pues, vamos a cambiar la configuración del &lt;strong&gt;NTP&lt;/strong&gt; para acceder a un servidor &lt;strong&gt;NTP&lt;/strong&gt; en nuestra propia red local, y quitando los que habían.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cat /etc/ntp.conf &lt;span class="p"&gt;|&lt;/span&gt; egrep &lt;span class="s2"&gt;&amp;quot;pool.*debian|server 10&amp;quot;&lt;/span&gt;
server &lt;span class="m"&gt;10&lt;/span&gt;.0.0.1
&lt;span class="c1"&gt;# pool 0.debian.pool.ntp.org iburst&lt;/span&gt;
&lt;span class="c1"&gt;# pool 1.debian.pool.ntp.org iburst&lt;/span&gt;
&lt;span class="c1"&gt;# pool 2.debian.pool.ntp.org iburst&lt;/span&gt;
&lt;span class="c1"&gt;# pool 3.debian.pool.ntp.org iburst&lt;/span&gt;
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como no, reiniciamos el servicio para que use la nueva configuración:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# systemctl restart ntp
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Solo queda observar que estamos sincronizando contra el servidor solicitado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# ntpq -p
     remote           refid      st t when poll reach   delay   offset  &lt;span class="nv"&gt;jitter&lt;/span&gt;
&lt;span class="o"&gt;==============================================================================&lt;/span&gt;
 &lt;span class="m"&gt;10&lt;/span&gt;.0.0.1            &lt;span class="m"&gt;10&lt;/span&gt;.0.0.1    &lt;span class="m"&gt;4&lt;/span&gt; u   &lt;span class="m"&gt;28&lt;/span&gt;   &lt;span class="m"&gt;64&lt;/span&gt;    &lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;.277  -12.387   &lt;span class="m"&gt;9&lt;/span&gt;.552
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Servidor NTP&lt;/h2&gt;
&lt;p&gt;Para configurar un servidor &lt;strong&gt;NTP&lt;/strong&gt; no se necesita nada adicional. El paquete que acabamos de instalar ya ha levantado un servidor &lt;strong&gt;NTP&lt;/strong&gt; preparado para que lo usen otros servidores que lleguen a él vía red. De hecho, en el ejemplo estamos sincronizando contra otro servidor (10.0.0.1) que es idéntico al del ejemplo, solo que está sincronizando de otro servidor. A nivel de seguridad, hay que tener en cuenta que el protocolo &lt;strong&gt;NTP&lt;/strong&gt; utiliza los puertos 123 TCP y UDP y solo se necesita permitir uno de estos dos a nivel de &lt;em&gt;firewall&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;El estrato 4 (en el ejemplo) significa que estamos sincronizando contra un servidor de estrato 4, que es uno que sincroniza de uno de estrato 3. Al final de la cadena, encontraremos un reloj GPS o atómico, que es un servidor de estrato 1. El protocolo &lt;strong&gt;NTP&lt;/strong&gt; permite tener estratos hasta 15, significando el número 16 que no habría ninguna conectividad con el servidor especificado.&lt;/p&gt;</content><category term="ntp"></category><category term="servidor"></category><category term="hora"></category></entry><entry><title>Un proceso inicial para docker: tini y dumb-init</title><link href="http://www.linuxsysadmin.ml/2017/09/un-proceso-inicial-para-docker-tini-y-dumb-init.html" rel="alternate"></link><published>2017-09-11T10:00:00+02:00</published><updated>2017-09-11T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-09-11:/2017/09/un-proceso-inicial-para-docker-tini-y-dumb-init.html</id><summary type="html">&lt;p&gt;Siempre nos han vendido que &lt;strong&gt;docker&lt;/strong&gt; ejecuta un solo proceso, y que este puede ser cualquiera. Sin embargo, este proceso se ejecuta con PID 1, que es un poco especial y que tiene unas responsabilidades adicionales. Si no queremos implementarlas, podemos usar alguna solución que ya lo haga para nosotros …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Siempre nos han vendido que &lt;strong&gt;docker&lt;/strong&gt; ejecuta un solo proceso, y que este puede ser cualquiera. Sin embargo, este proceso se ejecuta con PID 1, que es un poco especial y que tiene unas responsabilidades adicionales. Si no queremos implementarlas, podemos usar alguna solución que ya lo haga para nosotros.&lt;/p&gt;
&lt;p&gt;Entre estas responsabilidades, podemos citar 3 que se consideran básicas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tiene que adoptar y controlar todos aquellos procesos que quedan huérfanos debido a una mala gestión de su anterior padre&lt;/li&gt;
&lt;li&gt;No puede dejar que ningún proceso &lt;em&gt;zombie&lt;/em&gt; quede sin su correspondiente &lt;em&gt;wait&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Debe ser capaz de progresar las señales de terminación a sus procesos hijos&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Muchos de los binarios que utilizamos habitualmente no incumplen estas responsabilidades, sea por una buena gestión, o porque directamente no levantan procesos hijos.&lt;/p&gt;
&lt;p&gt;El problema es cuando alguno de estos procesos sí que incumple. En estos casos &lt;strong&gt;docker&lt;/strong&gt; puede enviar señales de acabado, y viendo que no todos los procesos han acabado, tiene que entrar tras 10 segundos a arreglar el desaguisado. Aunque &lt;strong&gt;docker&lt;/strong&gt; hace un trabajo magnífico en este aspecto, el resultado es un contenedor que es caro de apagar, en cuanto a tiempo se refiere.&lt;/p&gt;
&lt;p&gt;Y es por eso que han habido varios intentos de crear un proceso &lt;strong&gt;init&lt;/strong&gt; que pueda levantar otro proceso único, pero cumpliendo con las responsabilidades que se le presuponen. Entre estos binarios, me gustaría mencionar dos: &lt;strong&gt;tini&lt;/strong&gt; y &lt;strong&gt;dumb-init&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;El problema&lt;/h2&gt;
&lt;p&gt;Vamos a hacer este ejemplo con un servicio afectado por el problema, para su fácil demostración. No se trata de un servicio raro o de uso minoritario, sino que estamos hablando de &lt;strong&gt;haproxy&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Vamos a partir del más simple de los balanceadores basados en &lt;strong&gt;haproxy&lt;/strong&gt; y &lt;strong&gt;alpine linux&lt;/strong&gt;, con una configuración mínima (por no decir nula).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@docker:~/docker/docker-init$ cat context/Dockerfile
FROM alpine:3.6
RUN apk add --no-cache haproxy
COPY haproxy.cfg /etc/haproxy/
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;haproxy&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;-f&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;/etc/haproxy/haproxy.cfg&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;-db&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@docker:~/docker/docker-init$ cat context/haproxy.cfg
global
    chroot /var/lib/haproxy
    user haproxy
    group haproxy

defaults
    mode http

listen stats
    &lt;span class="nb"&gt;bind&lt;/span&gt; *:8080
    stats &lt;span class="nb"&gt;enable&lt;/span&gt;
    stats uri /

&lt;span class="c1"&gt;#listen web&lt;/span&gt;
&lt;span class="c1"&gt;#    bind *:80&lt;/span&gt;
&lt;span class="c1"&gt;#    balance roundrobin&lt;/span&gt;
&lt;span class="c1"&gt;#    server web1 web1:80 check&lt;/span&gt;
&lt;span class="c1"&gt;#    server web2 web2:80 check&lt;/span&gt;
gerard@docker:~/docker/docker-init$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La vamos a construir siguiendo los comandos habituales:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@docker:~/docker/docker-init$ docker build -t balancer context/
Sending build context to Docker daemon &lt;span class="m"&gt;3&lt;/span&gt;.072 kB
...
Successfully built 499dc4873adb
gerard@docker:~/docker/docker-init$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lo que vamos a ver es que la imagen no se detiene en un tiempo adecuado. Para ellos vamos a automatizar su levantamiento y su parada con &lt;strong&gt;docker-compose&lt;/strong&gt; y vamos a cronometrar lo segundo. Os adjunto el fichero &lt;em&gt;docker-compose.yml&lt;/em&gt;, aunque es relativamente simple.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@docker:~/docker/docker-init$ cat docker-compose.yml
version: &lt;span class="s1"&gt;&amp;#39;2&amp;#39;&lt;/span&gt;
services:
  balancer:
    image: balancer
    container_name: balancer
    hostname: balancer
gerard@docker:~/docker/docker-init$ docker-compose up -d
Creating network &lt;span class="s2"&gt;&amp;quot;dockerinit_default&amp;quot;&lt;/span&gt; with the default driver
Creating balancer
gerard@docker:~/docker/docker-init$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y podemos ver que este contenedor tan simple no acaba decentemente, teniendo que esperar 10 segundos para que &lt;strong&gt;docker&lt;/strong&gt; elimine el resto, cosa que es molesta y puede llevar a problemas futuros.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@docker:~/docker/docker-init$ &lt;span class="nb"&gt;time&lt;/span&gt; docker-compose down
Stopping balancer ... &lt;span class="k"&gt;done&lt;/span&gt;
Removing balancer ... &lt;span class="k"&gt;done&lt;/span&gt;
Removing network dockerinit_default

real    0m10,486s
user    0m0,348s
sys     0m0,028s
gerard@docker:~/docker/docker-init$
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;La solución&lt;/h2&gt;
&lt;p&gt;Ambas soluciones propuestas (&lt;strong&gt;tini&lt;/strong&gt; y &lt;strong&gt;dumb-init&lt;/strong&gt;) funcionan de la misma forma: ejecutan el comando que se les pasa en los argumentos. De esta forma, el comando "peligroso" se ejecuta con PID diferente de 1, siendo el PID 1 el mismo &lt;em&gt;init&lt;/em&gt;. Podemos anteponer el &lt;em&gt;init&lt;/em&gt; sin muchas modificaciones; basta con instalar el &lt;em&gt;init&lt;/em&gt; y usar la directiva &lt;code&gt;ENTRYPOINT&lt;/code&gt; para anteponer el nuevo &lt;em&gt;init&lt;/em&gt;. Veamos ambos como ejemplo.&lt;/p&gt;
&lt;h3&gt;Usando tini&lt;/h3&gt;
&lt;p&gt;Podemos instalar el paquete &lt;strong&gt;tini&lt;/strong&gt; sin añadir una nueva línea en el &lt;em&gt;Dockerfile&lt;/em&gt;, aprovechando el &lt;code&gt;apk add&lt;/code&gt; del mismo &lt;strong&gt;haproxy&lt;/strong&gt;. Prefijamos nuestro &lt;code&gt;CMD&lt;/code&gt; con el binario &lt;strong&gt;tini&lt;/strong&gt; mediante el uso de &lt;code&gt;ENTRYPOINT&lt;/code&gt; y listo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@docker:~/docker/docker-init$ cat context/Dockerfile.2
FROM alpine:3.6
RUN apk add --no-cache haproxy tini
COPY haproxy.cfg /etc/haproxy/
ENTRYPOINT &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;tini&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;--&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;haproxy&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;-f&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;/etc/haproxy/haproxy.cfg&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;-db&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@docker:~/docker/docker-init$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Construimos la nueva imagen, y tras modificar el &lt;em&gt;docker-compose.yml&lt;/em&gt;, la levantamos. Modificad el parámetro &lt;em&gt;image&lt;/em&gt; en el &lt;em&gt;docker-compose.yml&lt;/em&gt;, para reflejar el nuevo &lt;em&gt;tag&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@docker:~/docker/docker-init$ docker build -t balancer:v2 -f context/Dockerfile.2 context/
Sending build context to Docker daemon  &lt;span class="m"&gt;5&lt;/span&gt;.12 kB
...
Successfully built 179697bbd3ed
gerard@docker:~/docker/docker-init$ docker-compose up -d
Creating network &lt;span class="s2"&gt;&amp;quot;dockerinit_default&amp;quot;&lt;/span&gt; with the default driver
Creating balancer
gerard@docker:~/docker/docker-init$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y midiendo el tiempo de parada, vemos que el problema ha desaparecido:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@docker:~/docker/docker-init$ &lt;span class="nb"&gt;time&lt;/span&gt; docker-compose down
Stopping balancer ... &lt;span class="k"&gt;done&lt;/span&gt;
Removing balancer ... &lt;span class="k"&gt;done&lt;/span&gt;
Removing network dockerinit_default

real    0m0,473s
user    0m0,284s
sys     0m0,020s
gerard@docker:~/docker/docker-init$
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Usando dumb-init&lt;/h3&gt;
&lt;p&gt;Este caso es análogo al anterior, sin más cambios que el nombre del paquete a instalar y el binario del &lt;code&gt;ENTRYPOINT&lt;/code&gt;. Es importante notar que a pesar de partir del primer ejemplo, el resultado es prácticamente idéntico al segundo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@docker:~/docker/docker-init$ cat context/Dockerfile.3
FROM alpine:3.6
RUN apk add --no-cache haproxy dumb-init
COPY haproxy.cfg /etc/haproxy/
ENTRYPOINT &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;dumb-init&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;--&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;haproxy&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;-f&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;/etc/haproxy/haproxy.cfg&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;-db&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@docker:~/docker/docker-init$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Construimos la nueva imagen, y tras modificar el &lt;em&gt;docker-compose.yml&lt;/em&gt;, la levantamos, justo como antes. Tened la precaución de usar nuevo &lt;em&gt;tag&lt;/em&gt; en el &lt;em&gt;docker-compose.yml&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@docker:~/docker/docker-init$ docker build -t balancer:v3 -f context/Dockerfile.3 context/
Sending build context to Docker daemon  &lt;span class="m"&gt;5&lt;/span&gt;.12 kB
...
Successfully built 928c992c5251
gerard@docker:~/docker/docker-init$ docker-compose up -d
Creating network &lt;span class="s2"&gt;&amp;quot;dockerinit_default&amp;quot;&lt;/span&gt; with the default driver
Creating balancer
gerard@docker:~/docker/docker-init$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y midiendo el tiempo de parada, vemos que el problema también desaparece:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@docker:~/docker/docker-init$ &lt;span class="nb"&gt;time&lt;/span&gt; docker-compose down
Stopping balancer ... &lt;span class="k"&gt;done&lt;/span&gt;
Removing balancer ... &lt;span class="k"&gt;done&lt;/span&gt;
Removing network dockerinit_default

real    0m0,520s
user    0m0,252s
sys     0m0,060s
gerard@docker:~/docker/docker-init$
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Conclusión&lt;/h2&gt;
&lt;p&gt;El hecho de tener procesos &lt;em&gt;zombie&lt;/em&gt; es más una molestia que un problema real, al menos mientras &lt;strong&gt;docker&lt;/strong&gt; pueda limpiar lo que quede al final. Sin embargo, las buenas maneras, y un proceso ágil de despliegue, nos sugieren encarecidamente que tratemos estos detalles de forma adecuada.&lt;/p&gt;
&lt;p&gt;En cuanto al peso adicional en las imágenes por poner nuestros procesos &lt;em&gt;init&lt;/em&gt;, podemos ver que es casi nula:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@docker:~/docker/docker-init$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED              SIZE
balancer            v3                  928c992c5251        About a minute ago   &lt;span class="m"&gt;5&lt;/span&gt;.674 MB
balancer            v2                  179697bbd3ed        &lt;span class="m"&gt;5&lt;/span&gt; minutes ago        &lt;span class="m"&gt;5&lt;/span&gt;.651 MB
balancer            latest              499dc4873adb        &lt;span class="m"&gt;9&lt;/span&gt; minutes ago        &lt;span class="m"&gt;5&lt;/span&gt;.631 MB
alpine              &lt;span class="m"&gt;3&lt;/span&gt;.6                 7328f6f8b418        &lt;span class="m"&gt;7&lt;/span&gt; days ago           &lt;span class="m"&gt;3&lt;/span&gt;.966 MB
gerard@docker:~/docker/docker-init$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Así pues, en caso de duda, ponerlo siempre nos puede ahorrar algunos dolores de cabeza, aunque por ahora los desconozcamos.&lt;/p&gt;</content><category term="docker"></category><category term="Dockerfile"></category><category term="tini"></category><category term="dumb-init"></category></entry><entry><title>Creando imágenes con estilo: la instrucción ONBUILD</title><link href="http://www.linuxsysadmin.ml/2017/08/creando-imagenes-con-estilo-la-instruccion-onbuild.html" rel="alternate"></link><published>2017-08-28T10:00:00+02:00</published><updated>2017-08-28T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-08-28:/2017/08/creando-imagenes-con-estilo-la-instruccion-onbuild.html</id><summary type="html">&lt;p&gt;En el día a día de mi trabajo, me encuentro con un conjunto muy variado de ficheros &lt;em&gt;Dockerfile&lt;/em&gt; que vienen a hacer lo mismo, pero de formas muy distintas. El fichero original se pasa de mano en mano, pervirtiéndose en cada paso y al final queda hecho un gran asco …&lt;/p&gt;</summary><content type="html">&lt;p&gt;En el día a día de mi trabajo, me encuentro con un conjunto muy variado de ficheros &lt;em&gt;Dockerfile&lt;/em&gt; que vienen a hacer lo mismo, pero de formas muy distintas. El fichero original se pasa de mano en mano, pervirtiéndose en cada paso y al final queda hecho un gran asco.&lt;/p&gt;
&lt;p&gt;Para evitar la reinvención de la rueda me propuse crear una imagen base, para que los desarrolladores no tuvieran que crear una imagen, que muchas veces está mal por falta de conocimiento de &lt;em&gt;Linux&lt;/em&gt;, y que reduzca al máximo su participación.&lt;/p&gt;
&lt;h2&gt;Un caso simple&lt;/h2&gt;
&lt;p&gt;Imaginemos una aplicación hecha con &lt;em&gt;NodeJS&lt;/em&gt;, que es el caso más frecuente en mi trabajo; nuestro flujo de trabajo exige el uso de &lt;em&gt;npm&lt;/em&gt; y del correspondiente &lt;em&gt;package.json&lt;/em&gt;. Una instalación básica es bastante simple: se trata de copiar la aplicación, ejecutar el &lt;code&gt;npm install&lt;/code&gt; de rigor y declarar que se va a ejecutar con &lt;code&gt;npm start&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Tomemos como ejemplo el básico de &lt;em&gt;express&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/nodetest/v1$ cat app/app.js 
const &lt;span class="nv"&gt;express&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; require&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;express&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
const &lt;span class="nv"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; express&lt;span class="o"&gt;()&lt;/span&gt;

app.get&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;, &lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;req, res&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  res.send&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Hello World!&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;})&lt;/span&gt;

app.listen&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3000&lt;/span&gt;, &lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  console.log&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Example app listening on port 3000!&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;})&lt;/span&gt;
gerard@aldebaran:~/docker/nodetest/v1$ cat app/package.json 
&lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;app&amp;quot;&lt;/span&gt;,
  &lt;span class="s2"&gt;&amp;quot;version&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;1.0.0&amp;quot;&lt;/span&gt;,
  &lt;span class="s2"&gt;&amp;quot;description&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;,
  &lt;span class="s2"&gt;&amp;quot;main&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;app.js&amp;quot;&lt;/span&gt;,
  &lt;span class="s2"&gt;&amp;quot;scripts&amp;quot;&lt;/span&gt;: &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;start&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;node app.js&amp;quot;&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;test&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;echo \&amp;quot;Error: no test specified\&amp;quot; &amp;amp;&amp;amp; exit 1&amp;quot;&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;,
  &lt;span class="s2"&gt;&amp;quot;keywords&amp;quot;&lt;/span&gt;: &lt;span class="o"&gt;[]&lt;/span&gt;,
  &lt;span class="s2"&gt;&amp;quot;author&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;,
  &lt;span class="s2"&gt;&amp;quot;license&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;ISC&amp;quot;&lt;/span&gt;,
  &lt;span class="s2"&gt;&amp;quot;dependencies&amp;quot;&lt;/span&gt;: &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;express&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;4.15.3&amp;quot;&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
gerard@aldebaran:~/docker/nodetest/v1$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Siguiendo las instrucciones descritas más arriba, el &lt;em&gt;Dockerfile&lt;/em&gt; no guarda ninguna complicación:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/nodetest/v1$ cat Dockerfile 
FROM node:6-slim
COPY app/ /srv/app/
WORKDIR /srv/app
RUN npm install --production
USER node
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;npm&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;start&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@aldebaran:~/docker/nodetest/v1$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Este &lt;em&gt;Dockerfile&lt;/em&gt; nos genera una imagen adecuada, pero este fichero peca del mismo error que el resto: va a mutar un poco por cada mano por la que pase. Sin embargo, no podemos hacer una imagen base porque necesitamos la aplicación en la primera instrucción tras el &lt;strong&gt;FROM&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;La imagen base onbuild&lt;/h2&gt;
&lt;p&gt;Si miramos &lt;a href="https://docs.docker.com/engine/reference/builder/#onbuild"&gt;la documentación&lt;/a&gt;, podemos ver que podemos declarar algunas operaciones para que se lancen automáticamente tras todo &lt;strong&gt;FROM&lt;/strong&gt; que herede de nuestra imagen base. De esta forma, podemos declarar operaciones pendientes, al no disponer todavía de la aplicación final que va a tener que ejecutar nuestro contenedor.&lt;/p&gt;
&lt;p&gt;Vamos a retrasar la ejecución de todas aquellas instrucciones que dependan de la aplicación, que por cierto no está en este contexto, al no existir todavía:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/nodetest/onbuild$ cat Dockerfile 
FROM node:6-slim
ONBUILD COPY app/ /srv/app/
ONBUILD WORKDIR /srv/app
ONBUILD RUN npm install --production
ONBUILD USER node
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;npm&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;start&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@aldebaran:~/docker/nodetest/onbuild$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Con este &lt;em&gt;Dockerfile&lt;/em&gt; podemos generar una imagen base, que registre nuestras operaciones pendientes. Si construimos la imagen, veremos que no se ejecuta el &lt;code&gt;npm install&lt;/code&gt;, ni las otras instrucciones precedidas por &lt;strong&gt;ONBUILD&lt;/strong&gt;. Cualquier &lt;em&gt;Dockerfile&lt;/em&gt; que extienda esta imagen base, conseguirá varias cosas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Va a disponer de todos los añadidos por instrucciones lanzadas sin el &lt;strong&gt;ONBUILD&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Inmediatamente tras el &lt;strong&gt;FROM&lt;/strong&gt; se van a ejecutar las operaciones indicadas en el &lt;strong&gt;ONBUILD&lt;/strong&gt; (el &lt;strong&gt;COPY&lt;/strong&gt;, el &lt;strong&gt;WORKDIR&lt;/strong&gt;, el &lt;strong&gt;RUN&lt;/strong&gt; y el &lt;strong&gt;USER&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;El desarrollador no necesita declarar todas estas operaciones; solo va a necesitar aquellas que sean específicas de su proyecto.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Veamos el mismo ejemplo de antes; creamos un contexto con la misma aplicación y un &lt;em&gt;Dockerfile&lt;/em&gt;, aunque este último queda bastante simplificado (suponiendo que la imagen base ha sido etiquetada como &lt;em&gt;gerard/node:onbuild&lt;/em&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/nodetest/v2$ tree
.
├── app
│   ├── app.js
│   └── package.json
└── Dockerfile

&lt;span class="m"&gt;1&lt;/span&gt; directory, &lt;span class="m"&gt;3&lt;/span&gt; files
gerard@aldebaran:~/docker/nodetest/v2$ cat Dockerfile 
FROM gerard/node:onbuild
gerard@aldebaran:~/docker/nodetest/v2$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Si la construimos, vemos que justo tras acabar el paso del &lt;strong&gt;FROM&lt;/strong&gt;, van a saltar de forma automática los &lt;em&gt;triggers&lt;/em&gt;  declarados por la instrucción &lt;strong&gt;ONBUILD&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/nodetest/v2$ docker build -t gerard/app:v2 .
Sending build context to Docker daemon  &lt;span class="m"&gt;4&lt;/span&gt;.608kB
Step &lt;span class="m"&gt;1&lt;/span&gt;/1 : FROM gerard/node:onbuild
&lt;span class="c1"&gt;# Executing 4 build triggers...&lt;/span&gt;
Step &lt;span class="m"&gt;1&lt;/span&gt;/1 : COPY app/ /srv/app/
Step &lt;span class="m"&gt;1&lt;/span&gt;/1 : WORKDIR /srv/app
Step &lt;span class="m"&gt;1&lt;/span&gt;/1 : RUN npm install --production
 ---&amp;gt; Running in e3fe9e739e34
...  
Step &lt;span class="m"&gt;1&lt;/span&gt;/1 : USER node
 ---&amp;gt; Running in 3725eb574aff
 ---&amp;gt; d4661e9857e8
Removing intermediate container 7c9b3293ed2f
Removing intermediate container 7976c2b5aaaa
Removing intermediate container e3fe9e739e34
Removing intermediate container 3725eb574aff
Successfully built d4661e9857e8
Successfully tagged gerard/app:v2
gerard@aldebaran:~/docker/nodetest/v2$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto aseguramos que el desarrollador pasa por el aro, usando las instrucciones que realmente necesitamos para ejecutar la aplicación.&lt;/p&gt;</content><category term="docker"></category><category term="dockerfile"></category><category term="onbuild"></category></entry><entry><title>Problemas de escritura con openshift</title><link href="http://www.linuxsysadmin.ml/2017/08/problemas-de-escritura-con-openshift.html" rel="alternate"></link><published>2017-08-21T10:00:00+02:00</published><updated>2017-08-21T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-08-21:/2017/08/problemas-de-escritura-con-openshift.html</id><summary type="html">&lt;p&gt;En mi trabajo se ha decidido por el uso de virtualización por contenedores usando &lt;strong&gt;Openshift&lt;/strong&gt;. No es nada demasiado nuevo, puesto que ya usábamos &lt;strong&gt;Docker&lt;/strong&gt; de manera habitual, pero ha habido alguna &lt;em&gt;feature&lt;/em&gt; que nos ha hecho plantearnos el modo en el que hacemos las cosas, especialmente para las escrituras …&lt;/p&gt;</summary><content type="html">&lt;p&gt;En mi trabajo se ha decidido por el uso de virtualización por contenedores usando &lt;strong&gt;Openshift&lt;/strong&gt;. No es nada demasiado nuevo, puesto que ya usábamos &lt;strong&gt;Docker&lt;/strong&gt; de manera habitual, pero ha habido alguna &lt;em&gt;feature&lt;/em&gt; que nos ha hecho plantearnos el modo en el que hacemos las cosas, especialmente para las escrituras.&lt;/p&gt;
&lt;p&gt;Todo viene por una directiva de seguridad que prohibe estrictamente ejecutar un contenedor como &lt;em&gt;root&lt;/em&gt;, y de la misma manera, ejecuta el contenedor con un usuario aleatorio para incrementar la seguridad general.&lt;/p&gt;
&lt;p&gt;El problema viene para el pobre hombre que se dedica a generar imágenes, ya que la falta de determinismo, te asegura casi al 100% que no vas a poder escribir en las carpetas del contenedor, a menos que sepas lo que estás haciendo.&lt;/p&gt;
&lt;p&gt;Sin embargo, saber lo que hace &lt;strong&gt;Openshift&lt;/strong&gt; no es tarea complicada:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Se te asegura que nunca vas a usar el &lt;em&gt;uid&lt;/em&gt; 0, sino uno aleatorio&lt;/li&gt;
&lt;li&gt;El grupo del usuario de ejecución se mantiene siempre como &lt;em&gt;root&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Un problema derivado de esto es que no podemos ejecutar nada que requiera &lt;em&gt;root&lt;/em&gt;, como por ejemplo SSH (que no podríamos exponer en &lt;strong&gt;Openshift&lt;/strong&gt; de todas formas). Otro problema es que no tendremos permisos para crear carpetas en &lt;em&gt;runtime&lt;/em&gt; o incluso para cambiar el usuario de ejecución.&lt;/p&gt;
&lt;h2&gt;Simulando el comportamiento de Openshift&lt;/h2&gt;
&lt;p&gt;Vamos a poner un ejemplo tipo para entender lo que pasa:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@atlantis:~/projects/openshift_simulator$ cat Dockerfile
FROM python:2-slim
COPY server.py /
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/server.py&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@atlantis:~/projects/openshift_simulator$ cat server.py
&lt;span class="c1"&gt;#!/usr/bin/env python&lt;/span&gt;

from wsgiref.simple_server import make_server, demo_app

&lt;span class="nv"&gt;server&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; make_server&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;0.0.0.0&amp;#39;&lt;/span&gt;, &lt;span class="m"&gt;8080&lt;/span&gt;, demo_app&lt;span class="o"&gt;)&lt;/span&gt;
server.serve_forever&lt;span class="o"&gt;()&lt;/span&gt;
gerard@atlantis:~/projects/openshift_simulator$

Y lo construimos:

&lt;span class="sb"&gt;```&lt;/span&gt;bash
gerard@atlantis:~/projects/openshift_simulator$ docker build -t openshift_simulator .
Sending build context to Docker daemon  &lt;span class="m"&gt;3&lt;/span&gt;.072kB
...
Successfully tagged openshift_simulator:latest
gerard@atlantis:~/projects/openshift_simulator$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Normalmente lo ejecutaríamos de la siguiente manera:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@atlantis:~/projects/openshift_simulator$ docker run -ti --rm -p 8888:8080 --name test1 openshift_simulator
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Podemos comprobar que los procesos, tanto nuevos como antiguos, corren con el usuario &lt;em&gt;root&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@atlantis:~$ docker &lt;span class="nb"&gt;exec&lt;/span&gt; test1 id
&lt;span class="nv"&gt;uid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;root&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;gid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;root&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;groups&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;root&lt;span class="o"&gt;)&lt;/span&gt;
gerard@atlantis:~$ docker &lt;span class="nb"&gt;exec&lt;/span&gt; test1 ps -efa
UID        PID  PPID  C STIME TTY          TIME CMD
root         &lt;span class="m"&gt;1&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;14&lt;/span&gt;:18 pts/0    &lt;span class="m"&gt;00&lt;/span&gt;:00:00 python /server.py
root        &lt;span class="m"&gt;17&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;14&lt;/span&gt;:20 ?        &lt;span class="m"&gt;00&lt;/span&gt;:00:00 ps -efa
gerard@atlantis:~$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Sin embargo, en &lt;strong&gt;openshift&lt;/strong&gt; el usuario se elige de forma aleatoria, y se impone con el &lt;em&gt;flag&lt;/em&gt; de usuario &lt;em&gt;-u&lt;/em&gt;, como sigue:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@atlantis:~/projects/openshift_simulator$ docker run -ti --rm -p &lt;span class="m"&gt;8888&lt;/span&gt;:8080 --name test2 -u &lt;span class="m"&gt;123456&lt;/span&gt; openshift_simulator
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y podemos ver que los procesos amparados por este contenedor se ejecutarían con el &lt;em&gt;uid&lt;/em&gt; especificado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@atlantis:~$ docker &lt;span class="nb"&gt;exec&lt;/span&gt; test2 id
&lt;span class="nv"&gt;uid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;123456&lt;/span&gt; &lt;span class="nv"&gt;gid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;root&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;groups&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;root&lt;span class="o"&gt;)&lt;/span&gt;
gerard@atlantis:~$ docker &lt;span class="nb"&gt;exec&lt;/span&gt; test2 ps -efa
UID        PID  PPID  C STIME TTY          TIME CMD
&lt;span class="m"&gt;123456&lt;/span&gt;       &lt;span class="m"&gt;1&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;14&lt;/span&gt;:22 pts/0    &lt;span class="m"&gt;00&lt;/span&gt;:00:00 python /server.py
&lt;span class="m"&gt;123456&lt;/span&gt;       &lt;span class="m"&gt;9&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;14&lt;/span&gt;:22 ?        &lt;span class="m"&gt;00&lt;/span&gt;:00:00 ps -efa
gerard@atlantis:~$
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Implicaciones en escritura&lt;/h2&gt;
&lt;p&gt;Como no sabemos el usuario con el que vamos a ejecutar, es especialmente interesante saber donde vamos a escribir, ya que los permisos de lectura suelen ser suficientes para todo el mundo. Sin embargo, las carpetas de escritura suelen estar más restringidas.&lt;/p&gt;
&lt;p&gt;En este caso, estas carpetas tienen dos posibles salidas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Les damos barra libre con permisos 777, que no van a gustar a ningún miembro del equipo de seguridad&lt;/li&gt;
&lt;li&gt;Afinamos los permisos aprovechándonos de que nunca vamos a ser &lt;em&gt;root&lt;/em&gt;, pero vamos a ejecutar con su grupo&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;De esta forma, podemos ver la propiedad y los permisos de forma individual:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Usuario&lt;/strong&gt;: con pertenencia a &lt;em&gt;root&lt;/em&gt; nos aseguramos de que los permisos no aplican nunca, con lo que podemos ponerlos como queramos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Grupo&lt;/strong&gt;: Esta es la mejor forma de asegurar que la carpeta nos pertenece. Aquí si que tenemos que dar permisos de escritura.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Otros&lt;/strong&gt;: Nunca hay que dar permisos de escritura a este grupo; ningún auditor de seguridad lo va a permitir.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;De esta forma, la pertenencia habuitual para carpetas de lectura y escritura que suelo poner es &lt;code&gt;root:root&lt;/code&gt;, y los permisos acostumbran a ser 575, aunque no me libro de explicaciones cuando pido las excepciones de seguridad pertinentes.&lt;/p&gt;</content><category term="docker"></category><category term="openshift"></category><category term="permisos"></category></entry><entry><title>Evitando problemas de concurrencia múltiple con flock</title><link href="http://www.linuxsysadmin.ml/2017/08/evitando-problemas-de-concurrencia-multiple-con-flock.html" rel="alternate"></link><published>2017-08-07T10:00:00+02:00</published><updated>2017-08-07T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-08-07:/2017/08/evitando-problemas-de-concurrencia-multiple-con-flock.html</id><summary type="html">&lt;p&gt;Cuando trabajas con procesos en &lt;em&gt;background&lt;/em&gt;, es fácil que algunos de los procesos hagan algo que necesite exclusividad, no siendo seguro ejecutar varios de estos procesos a la vez. Por ejemplo, archivos que se descomprimen, se procesan y luego se borran; si usan la misma carpeta suele ser un problema …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Cuando trabajas con procesos en &lt;em&gt;background&lt;/em&gt;, es fácil que algunos de los procesos hagan algo que necesite exclusividad, no siendo seguro ejecutar varios de estos procesos a la vez. Por ejemplo, archivos que se descomprimen, se procesan y luego se borran; si usan la misma carpeta suele ser un problema.&lt;/p&gt;
&lt;p&gt;No vamos a entrar en como se lanzan estos procesos, pero vamos a dar énfasis en que no deben ejecutarse a la vez. Para ello, vamos a suponer que tenemos un proceso que nos interesa ejecutar en exclusividad. Voy a sustituir este proceso por un &lt;em&gt;script&lt;/em&gt;, para que no nos distraigamos del punto importante.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/flock_test$ cat process.sh 
&lt;span class="c1"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;date +%H:%M:%S&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt; - Starting process in terminal &lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
sleep &lt;span class="m"&gt;5&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;date +%H:%M:%S&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt; - Process ended in terminal &lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
gerard@aldebaran:~/flock_test$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Muchos de los desarrolladores os propondrían miles de soluciones para evitar este caso, pero si buscamos en la &lt;em&gt;toolbox&lt;/em&gt; de Linux, podemos encontrar herramientas útiles. En mi caso concreto encontré el comando &lt;strong&gt;flock&lt;/strong&gt;, que actúa bloqueando un comando, en base a la existencia de un fichero de &lt;em&gt;lock&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Ejecutando casi concurrentemente&lt;/h2&gt;
&lt;p&gt;Para conseguirlo, voy a abrir dos terminales, uno para cada proceso. El &lt;em&gt;script&lt;/em&gt; va a recibir el numero de terminal por un parámetro, que voy a poner manualmente.&lt;/p&gt;
&lt;p&gt;Vamos al primer terminal, y ejecutamos nuestro &lt;em&gt;script&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/flock_test$ ./process.sh &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="m"&gt;12&lt;/span&gt;:43:38 - Starting process in terminal &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="m"&gt;12&lt;/span&gt;:43:43 - Process ended in terminal &lt;span class="m"&gt;1&lt;/span&gt;
gerard@aldebaran:~/flock_test$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Antes de que acabe, cambio al otro terminal y ejecuto lo mismo:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/flock_test$ ./process.sh &lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="m"&gt;12&lt;/span&gt;:43:40 - Starting process in terminal &lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="m"&gt;12&lt;/span&gt;:43:45 - Process ended in terminal &lt;span class="m"&gt;2&lt;/span&gt;
gerard@aldebaran:~/flock_test$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Si juntamos las líneas de &lt;em&gt;log&lt;/em&gt; y las ordenamos, vemos claramente que los procesos estuvieron en algún momento ejecutándose a la vez.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="m"&gt;12&lt;/span&gt;:43:38 - Starting process in terminal &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="m"&gt;12&lt;/span&gt;:43:40 - Starting process in terminal &lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="m"&gt;12&lt;/span&gt;:43:43 - Process ended in terminal &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="m"&gt;12&lt;/span&gt;:43:45 - Process ended in terminal &lt;span class="m"&gt;2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este caso, no parece peligroso que se ejecuten a la vez, pero hay que usar la imaginación y creernos que podrían dar problemas ejecutados a la vez.&lt;/p&gt;
&lt;h2&gt;Ejecución exclusiva con flock&lt;/h2&gt;
&lt;p&gt;Como puede interesarnos que no se ejecuten a la vez, podemos utilizar el comando &lt;strong&gt;flock&lt;/strong&gt; para conseguir que ambos procesos esperen ordenadamente la posibilidad de ejecutarse.&lt;/p&gt;
&lt;p&gt;El comando &lt;strong&gt;flock&lt;/strong&gt; esperaría la inexistencia de un &lt;em&gt;lock&lt;/em&gt; en el fichero indicado, momento en el que pondría dicho &lt;em&gt;lock&lt;/em&gt; para asegurar que ningún otro proceso pudiera ejecutarse. Lo siguiente sería ejecutar nuestro &lt;em&gt;script&lt;/em&gt;, y finalmente, eliminar el &lt;em&gt;lock&lt;/em&gt; puesto. Otro proceso concurrente quedaría a la espera de la liberación de &lt;em&gt;lock&lt;/em&gt; antes de poder proceder, de manera similar al anterior.&lt;/p&gt;
&lt;p&gt;El proceso va a ser el mismo: ejecutamos el &lt;em&gt;script&lt;/em&gt; en ambos terminales, prefijado esta vez por el comando &lt;strong&gt;flock&lt;/strong&gt; y el fichero sobre el que se va a poner el &lt;em&gt;lock&lt;/em&gt;. Pasamos a juntar las líneas de ambos terminales por brevedad:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="m"&gt;12&lt;/span&gt;:44:59 - Starting process in terminal &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="m"&gt;12&lt;/span&gt;:45:04 - Process ended in terminal &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="m"&gt;12&lt;/span&gt;:45:04 - Starting process in terminal &lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="m"&gt;12&lt;/span&gt;:45:09 - Process ended in terminal &lt;span class="m"&gt;2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto podemos ver que el proceso del terminal 2 ha tenido que esperar a que el comando &lt;strong&gt;flock&lt;/strong&gt; en el primer terminal acabara, antes de poder proceder a ejecutar su &lt;em&gt;script&lt;/em&gt;. Con eso se garantiza la exclusividad de ejecución y los problemas que podría haber derivados de esta situación.&lt;/p&gt;
&lt;p&gt;En un caso de &lt;em&gt;boom&lt;/em&gt; de procesos, podríamos ver un grupo de procesos esperando sin lanzar sus respectivos &lt;em&gt;scripts&lt;/em&gt;, mientras que uno solo de ello estaría ejecutando en exclusividad.&lt;/p&gt;</content><category term="flock"></category></entry><entry><title>Montando un servidor docker con Debian Stretch</title><link href="http://www.linuxsysadmin.ml/2017/07/montando-un-servidor-docker-con-debian-stretch.html" rel="alternate"></link><published>2017-07-24T10:00:00+02:00</published><updated>2017-07-24T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-07-24:/2017/07/montando-un-servidor-docker-con-debian-stretch.html</id><summary type="html">&lt;p&gt;Finalmente ha sucedido: ha llegado el esperado lanzamiento de &lt;strong&gt;Debian Stretch&lt;/strong&gt;. Como buen linuxero no me he podido resistir a hacer alguna instalación para probar, aunque solo sea como una máquina virtual. Su función, determinada por mi actual flujo de trabajo, va a ser como servidor de &lt;strong&gt;docker&lt;/strong&gt; con &lt;strong&gt;docker-compose …&lt;/strong&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Finalmente ha sucedido: ha llegado el esperado lanzamiento de &lt;strong&gt;Debian Stretch&lt;/strong&gt;. Como buen linuxero no me he podido resistir a hacer alguna instalación para probar, aunque solo sea como una máquina virtual. Su función, determinada por mi actual flujo de trabajo, va a ser como servidor de &lt;strong&gt;docker&lt;/strong&gt; con &lt;strong&gt;docker-compose&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;En este caso, lo necesito para mi uso personal, pero en el ámbito de mi trabajo. Una de las particularidades a las que me enfrento es un &lt;em&gt;proxy&lt;/em&gt; &lt;strong&gt;squid&lt;/strong&gt; no transparente, así que también voy a ponerlo como anotaciones en el artículo.&lt;/p&gt;
&lt;h2&gt;El servidor base&lt;/h2&gt;
&lt;p&gt;Se trata de instalar un sistema operativo básico con SSH, partiendo de la imagen &lt;em&gt;netinst&lt;/em&gt;, que considero suficiente para un servidor estándar, y me evita descargar una &lt;em&gt;iso&lt;/em&gt; más grande.&lt;/p&gt;
&lt;p&gt;No voy a explicar como se instala; simplemente he respondido las preguntas de la instalación tal como me las hacía. Solo hace falta tener en cuenta que se eligió el servidor &lt;strong&gt;SSH&lt;/strong&gt; durante la instalación (concretamente en el &lt;em&gt;tasksel&lt;/em&gt;) y que se indicó el &lt;em&gt;proxy&lt;/em&gt; cuando se me preguntó.&lt;/p&gt;
&lt;p&gt;Para evitar que la operación &lt;strong&gt;apt-get update&lt;/strong&gt; tarde más tiempo de lo debido, vamos a limpiar el fichero &lt;em&gt;/etc/apt/sources.list&lt;/em&gt;, eliminando las entradas que no nos interesen.&lt;/p&gt;
&lt;p&gt;Y ya para acabar, vamos a crear una carpeta &lt;em&gt;bin&lt;/em&gt; para nuestro usuario de trabajo, lo que hace especialmente fácil poner &lt;em&gt;scripts&lt;/em&gt; locales para el mismo usuario.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@atlantis:~$ mkdir bin
gerard@atlantis:~$
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Instalar docker engine y docker-compose&lt;/h2&gt;
&lt;h3&gt;Docker engine&lt;/h3&gt;
&lt;p&gt;Para instalar &lt;strong&gt;docker engine&lt;/strong&gt; vamos a seguir &lt;a href="https://docs.docker.com/engine/installation/linux/docker-ce/debian/"&gt;la documentación&lt;/a&gt;. El primer paso es descargarse la clave oficial GPG de &lt;strong&gt;docker&lt;/strong&gt;, para que &lt;strong&gt;apt&lt;/strong&gt; confíe en la fuente de &lt;em&gt;software&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTA&lt;/strong&gt;: es probable que el comando &lt;strong&gt;wget&lt;/strong&gt; falle si estamos detrás de un &lt;em&gt;proxy&lt;/em&gt;; basta con exportar la variable de entorno &lt;strong&gt;https_proxy&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@atlantis:~# apt-get install apt-transport-https
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
...
root@atlantis:~# wget -qO- https://download.docker.com/linux/debian/gpg &lt;span class="p"&gt;|&lt;/span&gt; apt-key add -
OK
root@atlantis:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Añadimos la línea adecuada para usar el repositorio oficial de &lt;strong&gt;docker&lt;/strong&gt; y, tras hacer el correspondiente &lt;em&gt;update&lt;/em&gt;, instalamos el paquete &lt;strong&gt;docker-ce&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@atlantis:~# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;deb https://download.docker.com/linux/debian stretch stable&amp;quot;&lt;/span&gt; &amp;gt; /etc/apt/sources.list.d/docker.list
root@atlantis:~# apt-get update
Obj:1 http://security.debian.org/debian-security stretch/updates InRelease
Des:2 https://download.docker.com/linux/debian stretch InRelease &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;,2 kB&lt;span class="o"&gt;]&lt;/span&gt;
Des:3 https://download.docker.com/linux/debian stretch/stable amd64 Packages &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.934 B&lt;span class="o"&gt;]&lt;/span&gt;
Ign:4 http://ftp.fr.debian.org/debian stretch InRelease
Des:5 http://ftp.fr.debian.org/debian stretch-updates InRelease &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;88&lt;/span&gt;,5 kB&lt;span class="o"&gt;]&lt;/span&gt;
Obj:6 http://ftp.fr.debian.org/debian stretch Release
Descargados &lt;span class="m"&gt;111&lt;/span&gt; kB en 5s &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;19&lt;/span&gt;,5 kB/s&lt;span class="o"&gt;)&lt;/span&gt;
Leyendo lista de paquetes... Hecho
root@atlantis:~# apt-get install docker-ce
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
...
root@atlantis:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para hacer mas fácil el acceso a &lt;strong&gt;docker&lt;/strong&gt; para el usuario de trabajo, vamos a añadirlo al mismo grupo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@atlantis:~# usermod -a -G docker gerard
root@atlantis:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Docker compose&lt;/h3&gt;
&lt;p&gt;Para instalar esta utilidad, vamos a seguir &lt;a href="https://docs.docker.com/compose/install/"&gt;su documentación&lt;/a&gt;. En esencia se limita a descargar el binario en algún lugar del &lt;em&gt;path&lt;/em&gt; y a darle permisos de ejecución.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@atlantis:~# wget -qO /usr/local/bin/docker-compose https://github.com/docker/compose/releases/download/1.14.0/docker-compose-&lt;span class="sb"&gt;`&lt;/span&gt;uname -s&lt;span class="sb"&gt;`&lt;/span&gt;-&lt;span class="sb"&gt;`&lt;/span&gt;uname -m&lt;span class="sb"&gt;`&lt;/span&gt;
root@atlantis:~# chmod &lt;span class="m"&gt;755&lt;/span&gt; /usr/local/bin/docker-compose
root@atlantis:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Sobre los servidores proxy&lt;/h2&gt;
&lt;p&gt;Trabajar detrás de un servidor &lt;em&gt;proxy&lt;/em&gt; es un problema cuando trabajamos con &lt;strong&gt;docker&lt;/strong&gt;, ya que el &lt;em&gt;proxy&lt;/em&gt; debe configurarse a nivel de servicio, luego debe especificarse en cada &lt;em&gt;docker build&lt;/em&gt; y finalmente en cada &lt;em&gt;docker run&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;La primera configuración &lt;em&gt;proxy&lt;/em&gt; necesaria es la de &lt;strong&gt;apt&lt;/strong&gt;. Por suerte para nosotros, cuando instalamos el sistema operativo y lo indicamos ya nos guardó ese parámetro en &lt;em&gt;/etc/apt/apt.conf&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@atlantis:~$ cat /etc/apt/apt.conf
Acquire::http::Proxy &lt;span class="s2"&gt;&amp;quot;http://192.168.0.2:3128&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
gerard@atlantis:~$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A veces, algunos comandos como el &lt;strong&gt;wget&lt;/strong&gt; necesitan definir el &lt;em&gt;proxy&lt;/em&gt; como una variable de sistema; por ejemplo, para poner la variable &lt;strong&gt;https_proxy&lt;/strong&gt; para esta sesión de terminal, podemos hacer algo como:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@atlantis:~# &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;https_proxy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;http://192.168.0.2:3128
root@atlantis:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El demonio de &lt;strong&gt;docker&lt;/strong&gt; utiliza el &lt;em&gt;proxy&lt;/em&gt; definido en las variables de sistema. En el caso de &lt;em&gt;systemd&lt;/em&gt; podemos añadir estas variables de forma fácil añadiendo una configuración &lt;em&gt;overlay&lt;/em&gt;. Esto hace necesario recargar las configuraciones para el demonio de &lt;strong&gt;systemd&lt;/strong&gt; y luego el mismo demonio de &lt;strong&gt;docker&lt;/strong&gt; para que utilice las nuevas variables.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@atlantis:~# mkdir /etc/systemd/system/docker.service.d
root@atlantis:~# cat /etc/systemd/system/docker.service.d/proxy.conf
&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Environment&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;HTTP_PROXY=http://192.168.0.2:3128&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;Environment&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;HTTPS_PROXY=http://192.168.0.2:3128&amp;quot;&lt;/span&gt;
root@atlantis:~# systemctl daemon-reload
root@atlantis:~# systemctl restart docker
root@atlantis:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente, y por comodidad podemos añadir estas variables de entorno de forma permanente para el usuario de trabajo en el fichero &lt;em&gt;~/.bashrc&lt;/em&gt;, de forma que en cada nueva sesión de SSH no tengamos que redefinirlas. Aprovechamos también para añadir algunos &lt;em&gt;alias&lt;/em&gt; útiles para reducir los comandos de construcción de imágenes y ejecución de contenedores, escondiendo las variables del &lt;em&gt;proxy&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@atlantis:~$ cat .bashrc
...
&lt;span class="nb"&gt;alias&lt;/span&gt; &lt;span class="nv"&gt;drun&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;docker run -e &amp;quot;http_proxy=http://192.168.0.2:3128&amp;quot; -e &amp;quot;https_proxy=http://192.168.0.2:3128&amp;quot;&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;alias&lt;/span&gt; &lt;span class="nv"&gt;dbuild&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;docker build --build-arg=&amp;quot;http_proxy=http://192.168.0.2:3128&amp;quot; --build-arg=&amp;quot;https_proxy=http://192.168.0.2:3128&amp;quot;&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;HTTP_PROXY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;http://192.168.0.2:3128
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;HTTPS_PROXY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;HTTP_PROXY&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;http_proxy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;HTTP_PROXY&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;https_proxy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;HTTP_PROXY&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;NO_PROXY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;127.0.0.1,localhost&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;no_proxy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;NO_PROXY&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
gerard@atlantis:~$
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Siguientes pasos&lt;/h2&gt;
&lt;p&gt;Es probable que este servidor necesite algunas utilidades que no hayan venido con los paquetes base. Nada nos impide ponerlos nosotros a mano, con los correspondientes &lt;em&gt;apt-get install&lt;/em&gt;. A partir de aquí, solo nos queda disfrutar de nuestro nuevo servidor &lt;strong&gt;docker&lt;/strong&gt; mínimo.&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="stretch"></category><category term="docker"></category><category term="docker-compose"></category></entry><entry><title>Autenticación centralizada por claves SSH</title><link href="http://www.linuxsysadmin.ml/2017/07/autenticacion-centralizada-por-claves-ssh.html" rel="alternate"></link><published>2017-07-17T10:00:00+02:00</published><updated>2017-07-17T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-07-17:/2017/07/autenticacion-centralizada-por-claves-ssh.html</id><summary type="html">&lt;p&gt;Ya vimos en &lt;a href="http://www.linuxsysadmin.ml/2016/05/autenticacion-ssh-por-claves.html"&gt;un artículo anterior&lt;/a&gt; como autenticar las sesiones &lt;strong&gt;SSH&lt;/strong&gt; mediante claves locales en la máquina. Sin embargo, esto no es práctico cuando tenemos muchos servidores, y hay que replicar esas claves en todos ellos. Hoy vamos a ver como usar un &lt;em&gt;script&lt;/em&gt; que pueda sacar las claves dinámicamente …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Ya vimos en &lt;a href="http://www.linuxsysadmin.ml/2016/05/autenticacion-ssh-por-claves.html"&gt;un artículo anterior&lt;/a&gt; como autenticar las sesiones &lt;strong&gt;SSH&lt;/strong&gt; mediante claves locales en la máquina. Sin embargo, esto no es práctico cuando tenemos muchos servidores, y hay que replicar esas claves en todos ellos. Hoy vamos a ver como usar un &lt;em&gt;script&lt;/em&gt; que pueda sacar las claves dinámicamente.&lt;/p&gt;
&lt;p&gt;Empezamos teniendo un servidor con el servicio &lt;strong&gt;SSH&lt;/strong&gt; levantado; vamos a crear un usuario &lt;em&gt;guest&lt;/em&gt; en él para que pueda abrir una sesión en él.&lt;/p&gt;
&lt;h2&gt;Estado inicial&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@sshserver:~# adduser guest
Adding user &lt;span class="sb"&gt;`&lt;/span&gt;guest&lt;span class="s1"&gt;&amp;#39; ...&lt;/span&gt;
&lt;span class="s1"&gt;Adding new group `guest&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1000&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; ...
Adding new user &lt;span class="sb"&gt;`&lt;/span&gt;guest&lt;span class="s1"&gt;&amp;#39; (1000) with group `guest&amp;#39;&lt;/span&gt; ...
Creating home directory &lt;span class="sb"&gt;`&lt;/span&gt;/home/guest&lt;span class="s1"&gt;&amp;#39; ...&lt;/span&gt;
&lt;span class="s1"&gt;Copying files from `/etc/skel&amp;#39;&lt;/span&gt; ...
Enter new UNIX password: 
Retype new UNIX password: 
passwd: password updated successfully
Changing the user information &lt;span class="k"&gt;for&lt;/span&gt; guest
Enter the new value, or press ENTER &lt;span class="k"&gt;for&lt;/span&gt; the default
    Full Name &lt;span class="o"&gt;[]&lt;/span&gt;: 
    Room Number &lt;span class="o"&gt;[]&lt;/span&gt;: 
    Work Phone &lt;span class="o"&gt;[]&lt;/span&gt;: 
    Home Phone &lt;span class="o"&gt;[]&lt;/span&gt;: 
    Other &lt;span class="o"&gt;[]&lt;/span&gt;: 
Is the information correct? &lt;span class="o"&gt;[&lt;/span&gt;Y/n&lt;span class="o"&gt;]&lt;/span&gt; y
root@sshserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Por supuesto, este usuario pueden entrar con su contraseña sin problemas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/docker/ssh$ ssh guest@sshserver
guest@sshserver&amp;#39;s password: 

The programs included with the Debian GNU/Linux system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
guest@sshserver:~$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;El script&lt;/h2&gt;
&lt;p&gt;La idea es que necesitamos un &lt;em&gt;script&lt;/em&gt; que reciba como primer parámetro el usuario del que queremos las claves, y este &lt;em&gt;script&lt;/em&gt; nos va a dar una salida con el mismo formato que pondríamos en el &lt;em&gt;authorized_keys&lt;/em&gt;. Eso significa que podemos devolver 0, 1 o mas líneas, con una clave pública por línea.&lt;/p&gt;
&lt;p&gt;No es importante de donde saque este &lt;em&gt;script&lt;/em&gt; la información; puede ser de un campo LDAP, de una base de datos, o de una llamada a un &lt;em&gt;webservice&lt;/em&gt;. Para evitar complicaciones innecesarias, para este artículo y a modo de ejemplo, vamos a poner los valores en el mismo &lt;em&gt;script&lt;/em&gt;. Echad un poco de imaginación si lo reproducís.&lt;/p&gt;
&lt;p&gt;Supongamos que queremos entrar con el usuario &lt;em&gt;guest&lt;/em&gt;, y disponemos en la máquina inicial la clave privada &lt;em&gt;id_rsa&lt;/em&gt;, habiendo generado una clave pública correspondiente. Creamos un &lt;em&gt;script&lt;/em&gt; que nos vuelque esta clave si el usuario solicitado es &lt;em&gt;guest&lt;/em&gt;, siempre con permisos de ejecución.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@sshserver:~# cat /usr/bin/authorized_keys_by_user.sh 
&lt;span class="c1"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;guest&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC9heqwqgv+O9aekeCpETDR/6BdTQWDOrSlNN/tnZeZZa8/qjf0JEF4r8jSA/MquPQog1tpOXM0XUEY9YWNphARAmZ/gV1IiNJZmqQJSb2pk2/nQLq9nCqWoHBgKHKINUKfgmsiopGz9IjnZw5BBZKrloE9ZU0oApduxnVUTl/G71OWH/SdCbef08zvwVvLxv3zAWEKSnRvnSn5Q/FkRNb4Qe09po8ePgMqpZWKUvEpAntOvokI7uid300mmZjiUL8EMbJo4oJ3ONOnDbH8FNKEmGI4q2UK5HbDIUm8SJcmyJXvoo6xabApkc2AcM7X2tXRd8wiYS0p7YjLVMcIJ/NR gerard@sirius&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;
root@sshserver:~# chmod &lt;span class="m"&gt;755&lt;/span&gt; /usr/bin/authorized_keys_by_user.sh 
root@sshserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Podemos comprobar que nos da la clave pública para el usuario &lt;em&gt;guest&lt;/em&gt; y ninguna para otros usuarios.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@sshserver:~# /usr/bin/authorized_keys_by_user.sh guest
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC9heqwqgv+O9aekeCpETDR/6BdTQWDOrSlNN/tnZeZZa8/qjf0JEF4r8jSA/MquPQog1tpOXM0XUEY9YWNphARAmZ/gV1IiNJZmqQJSb2pk2/nQLq9nCqWoHBgKHKINUKfgmsiopGz9IjnZw5BBZKrloE9ZU0oApduxnVUTl/G71OWH/SdCbef08zvwVvLxv3zAWEKSnRvnSn5Q/FkRNb4Qe09po8ePgMqpZWKUvEpAntOvokI7uid300mmZjiUL8EMbJo4oJ3ONOnDbH8FNKEmGI4q2UK5HbDIUm8SJcmyJXvoo6xabApkc2AcM7X2tXRd8wiYS0p7YjLVMcIJ/NR gerard@sirius
root@sshserver:~# /usr/bin/authorized_keys_by_user.sh other
root@sshserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este caso hemos puesto una sola clave, pero podrían haber sido varias, igual que cuando usamos el fichero &lt;em&gt;authorized_keys&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Configuración SSH&lt;/h2&gt;
&lt;p&gt;Por una limitación del servicio &lt;strong&gt;SSH&lt;/strong&gt;, es necesario que tanto el &lt;em&gt;script&lt;/em&gt; como todas las carpetas en el &lt;em&gt;path&lt;/em&gt;, pertenezcan al usuario &lt;em&gt;root&lt;/em&gt; y que solo este tenga permisos de escritura. Aunque nos saldría un mensaje de error en el &lt;em&gt;log&lt;/em&gt; del &lt;strong&gt;SSH&lt;/strong&gt;, cuesta poco de comprobarlo antes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@sshserver:~# &lt;span class="k"&gt;for&lt;/span&gt; folder in / /usr /usr/bin /usr/bin/authorized_keys_by_user.sh&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; stat --printf &lt;span class="s2"&gt;&amp;quot;%U:%G\t%A %n\n&amp;quot;&lt;/span&gt; &lt;span class="nv"&gt;$folder&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;done&lt;/span&gt;
root:root   drwxr-xr-x /
root:root   drwxr-xr-x /usr
root:root   drwxr-xr-x /usr/bin
root:root   -rwxr-xr-x /usr/bin/authorized_keys_by_user.sh
root@sshserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El truco consiste en indicar dos directivas al demonio &lt;strong&gt;SSH&lt;/strong&gt;, para que sepa que debe ejecutar este &lt;em&gt;script&lt;/em&gt; para sacar el &lt;em&gt;authorized_keys&lt;/em&gt; de cada usuario.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@sshserver:~# tail -2 /etc/ssh/sshd_config 
AuthorizedKeysCommand /usr/bin/authorized_keys_by_user.sh
AuthorizedKeysCommandUser nobody
root@sshserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Recargamos la configuración del demonio &lt;strong&gt;SSH&lt;/strong&gt;, para que relea la configuración nueva que acabamos de poner.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@sshserver:~# service ssh reload
Reloading OpenBSD Secure Shell server&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s configuration: sshd.
root@sshserver:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y solo nos queda comprobar que podemos entrar con el usuario &lt;em&gt;guest&lt;/em&gt; usando la clave privada. En este ejemplo no se indica porque la clave &lt;em&gt;.ssh/id_rsa&lt;/em&gt; es ofrecida por defecto, y es la parte privada de la clave que pusimos en el &lt;em&gt;script&lt;/em&gt; remoto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/docker/ssh$ ssh guest@sshserver

The programs included with the Debian GNU/Linux system are free software&lt;span class="p"&gt;;&lt;/span&gt;
the exact distribution terms &lt;span class="k"&gt;for&lt;/span&gt; each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
Last login: Thu Jul &lt;span class="m"&gt;21&lt;/span&gt; &lt;span class="m"&gt;08&lt;/span&gt;:39:21 &lt;span class="m"&gt;2016&lt;/span&gt; from &lt;span class="m"&gt;172&lt;/span&gt;.20.0.1
guest@sshserver:~$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A partir de aquí, podéis modificar el &lt;em&gt;script&lt;/em&gt; remoto para que saque la información de las claves de algún sitio centralizado (LDAP, base de datos, &lt;em&gt;webservice&lt;/em&gt;, ...).&lt;/p&gt;</content><category term="ssh"></category><category term="autenticación"></category><category term="password"></category><category term="passphrase"></category><category term="centralizado"></category></entry><entry><title>Desactivando nuestras APIs con un frontal nginx</title><link href="http://www.linuxsysadmin.ml/2017/07/desactivando-nuestras-apis-con-un-frontal-nginx.html" rel="alternate"></link><published>2017-07-10T10:00:00+02:00</published><updated>2017-07-10T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-07-10:/2017/07/desactivando-nuestras-apis-con-un-frontal-nginx.html</id><summary type="html">&lt;p&gt;El otro día recibí una petición algo atípica en mi trabajo: querían activar y desactivar en un único punto centralizado cada una de las varias APIs que tenemos. Se trata de poner un &lt;strong&gt;nginx&lt;/strong&gt; frontal que gestione los &lt;em&gt;virtualhosts&lt;/em&gt; existentes y haga &lt;em&gt;proxy_pass&lt;/em&gt; o no en función de un &lt;em&gt;flag …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;El otro día recibí una petición algo atípica en mi trabajo: querían activar y desactivar en un único punto centralizado cada una de las varias APIs que tenemos. Se trata de poner un &lt;strong&gt;nginx&lt;/strong&gt; frontal que gestione los &lt;em&gt;virtualhosts&lt;/em&gt; existentes y haga &lt;em&gt;proxy_pass&lt;/em&gt; o no en función de un &lt;em&gt;flag&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;La propuesta me pareció bastante interesante, así que decidí hacer una prueba de concepto que aquí queda reflejada. Se trata de ofrecer un frontal web (por ejemplo un &lt;strong&gt;jenkins&lt;/strong&gt;) mediante el cual se puedan poner los ficheros cuya presencia le indican a &lt;strong&gt;nginx&lt;/strong&gt; si ese &lt;em&gt;virtualhost&lt;/em&gt; concreto debe dar un error o no.&lt;/p&gt;
&lt;h2&gt;Simulando las APIs&lt;/h2&gt;
&lt;p&gt;Vamos a poner un par de contenedores &lt;strong&gt;docker&lt;/strong&gt; con &lt;strong&gt;nginx&lt;/strong&gt;, que sirvan una página personalizada y nos sirva para simular la API. No es especialmente complejo, así que solo se adjunta por completitud.&lt;/p&gt;
&lt;p&gt;el único punto interesante es que, para no repetirnos, vamos a pasar el contenido del fichero &lt;em&gt;index.html&lt;/em&gt; como una variable de entorno. Así no hay que construir varias imágenes.&lt;/p&gt;
&lt;p&gt;Empezamos con un &lt;em&gt;Dockerfile&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gw-poc$ cat api/Dockerfile 
FROM alpine:3.5
RUN apk add --no-cache nginx &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    ln -s /dev/stdout /var/log/nginx/access.log &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    ln -s /dev/stderr /var/log/nginx/error.log &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    mkdir /run/nginx &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    mkdir /srv/www &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    rm /etc/nginx/conf.d/default.conf
COPY nginx.conf /etc/nginx/
COPY conf.d/* /etc/nginx/conf.d/
COPY start.sh /
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/start.sh&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@aldebaran:~/docker/gw-poc$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y lo acompañamos con sus ficheros auxiliares.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gw-poc$ cat api/nginx.conf 
worker_processes  &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
events &lt;span class="o"&gt;{&lt;/span&gt;
    worker_connections  &lt;span class="m"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
http &lt;span class="o"&gt;{&lt;/span&gt;
    include mime.types&lt;span class="p"&gt;;&lt;/span&gt;
    default_type application/octet-stream&lt;span class="p"&gt;;&lt;/span&gt;
    sendfile on&lt;span class="p"&gt;;&lt;/span&gt;
    keepalive_timeout &lt;span class="m"&gt;65&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    include conf.d/*&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
gerard@aldebaran:~/docker/gw-poc$ cat api/conf.d/api 
server &lt;span class="o"&gt;{&lt;/span&gt;
    server_name _&lt;span class="p"&gt;;&lt;/span&gt;
    listen &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    root /srv/www&lt;span class="p"&gt;;&lt;/span&gt;
    index index.html&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
gerard@aldebaran:~/docker/gw-poc$ cat api/start.sh 
&lt;span class="c1"&gt;#!/bin/sh&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;GREETING&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &amp;gt; /srv/www/index.html
&lt;span class="nb"&gt;exec&lt;/span&gt; /usr/sbin/nginx -g &lt;span class="s2"&gt;&amp;quot;daemon off;&amp;quot;&lt;/span&gt;
gerard@aldebaran:~/docker/gw-poc$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto tenemos nuestra imagen lista para ser construida.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gw-poc$ dbuild -t api api/
Sending build context to Docker daemon &lt;span class="m"&gt;5&lt;/span&gt;.632 kB
...  
Successfully built c91adbf6534e
gerard@aldebaran:~/docker/gw-poc$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Creando un proxy como fachada&lt;/h2&gt;
&lt;p&gt;Esta es la piedra angular de la solución. Vamos a empezar con un &lt;strong&gt;nginx&lt;/strong&gt;, pero la novedad es que cada &lt;em&gt;virtualhost&lt;/em&gt; va a incluir una condición nueva: si existe un fichero con el mismo nombre que el dominio en la carpeta raíz (la misma para todos los dominios vale), devolveremos un error 503 en JSON sin pasar la petición a nuestro &lt;em&gt;backend&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gw-poc$ cat gw/Dockerfile 
FROM alpine:3.5
RUN apk add --no-cache nginx &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    ln -s /dev/stdout /var/log/nginx/access.log &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    ln -s /dev/stderr /var/log/nginx/error.log &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    mkdir /run/nginx &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    mkdir /srv/www &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    rm /etc/nginx/conf.d/default.conf
COPY nginx.conf /etc/nginx/
COPY conf.d/* /etc/nginx/conf.d/
COPY start.sh /
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/start.sh&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@aldebaran:~/docker/gw-poc$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y también ponemos las configuraciones necesarias para dos APIs de &lt;em&gt;backend&lt;/em&gt;, que nos basta para ver si funciona.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gw-poc$ cat gw/nginx.conf 
worker_processes  &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
events &lt;span class="o"&gt;{&lt;/span&gt;
    worker_connections  &lt;span class="m"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
http &lt;span class="o"&gt;{&lt;/span&gt;
    include mime.types&lt;span class="p"&gt;;&lt;/span&gt;
    default_type application/octet-stream&lt;span class="p"&gt;;&lt;/span&gt;
    sendfile on&lt;span class="p"&gt;;&lt;/span&gt;
    keepalive_timeout &lt;span class="m"&gt;65&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    include conf.d/*&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
gerard@aldebaran:~/docker/gw-poc$ cat gw/conf.d/api1 
server &lt;span class="o"&gt;{&lt;/span&gt;
    server_name api1&lt;span class="p"&gt;;&lt;/span&gt;
    listen &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    root /srv/www&lt;span class="p"&gt;;&lt;/span&gt;

    location / &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;-f &lt;span class="nv"&gt;$document_root&lt;/span&gt;/&lt;span class="nv"&gt;$host&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="m"&gt;503&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
        proxy_pass http://api1:80&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    error_page &lt;span class="m"&gt;503&lt;/span&gt; @maintenance&lt;span class="p"&gt;;&lt;/span&gt;

    location @maintenance &lt;span class="o"&gt;{&lt;/span&gt;
        default_type application/json&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="m"&gt;503&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{&amp;quot;message&amp;quot;:&amp;quot;Sorry you! This entity (api1) is in maintenance mode&amp;quot;}&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
gerard@aldebaran:~/docker/gw-poc$ cat gw/conf.d/api2 
server &lt;span class="o"&gt;{&lt;/span&gt;
    server_name api2&lt;span class="p"&gt;;&lt;/span&gt;
    listen &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    root /srv/www&lt;span class="p"&gt;;&lt;/span&gt;

    location / &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;-f &lt;span class="nv"&gt;$document_root&lt;/span&gt;/&lt;span class="nv"&gt;$host&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="m"&gt;503&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
        proxy_pass http://api2:80&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    error_page &lt;span class="m"&gt;503&lt;/span&gt; @maintenance&lt;span class="p"&gt;;&lt;/span&gt;

    location @maintenance &lt;span class="o"&gt;{&lt;/span&gt;
        default_type application/json&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="m"&gt;503&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{&amp;quot;message&amp;quot;:&amp;quot;Sorry you! This entity (api2) is in maintenance mode&amp;quot;}&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
gerard@aldebaran:~/docker/gw-poc$ cat gw/start.sh 
&lt;span class="c1"&gt;#!/bin/sh&lt;/span&gt;

&lt;span class="nb"&gt;exec&lt;/span&gt; /usr/sbin/nginx -g &lt;span class="s2"&gt;&amp;quot;daemon off;&amp;quot;&lt;/span&gt;
gerard@aldebaran:~/docker/gw-poc$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y construimos la imagen.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gw-poc$ dbuild -t gw gw/
Sending build context to Docker daemon &lt;span class="m"&gt;6&lt;/span&gt;.656 kB
...
Successfully built ddf3f294c99c
gerard@aldebaran:~/docker/gw-poc$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Ponemos todo junto&lt;/h2&gt;
&lt;p&gt;El último paso es montar un entorno que nos permita lanzar pruebas y ver que funciona. Para ello, vamos a usar &lt;strong&gt;docker-compose&lt;/strong&gt; por la comodidad que supone.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gw-poc$ cat docker-compose.yml 
version: &lt;span class="s1"&gt;&amp;#39;2&amp;#39;&lt;/span&gt;
services:
  gw:
    image: gw
    container_name: gw
    hostname: gw
    volumes:
      - ./volume:/srv/www
    ports:
      - &lt;span class="s2"&gt;&amp;quot;80:80&amp;quot;&lt;/span&gt;
    depends_on:
      - api1
      - api2
  api1:
    image: api
    container_name: api1
    hostname: api1
    environment:
      GREETING: &lt;span class="s2"&gt;&amp;quot;Hello from api1&amp;quot;&lt;/span&gt;
  api2:
    image: api
    container_name: api2
    hostname: api2
    environment:
      GREETING: &lt;span class="s2"&gt;&amp;quot;Bye from api2&amp;quot;&lt;/span&gt;
gerard@aldebaran:~/docker/gw-poc$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Levantamos el entorno entero con los comandos habituales:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gw-poc$ docker-compose up -d
Creating network &lt;span class="s2"&gt;&amp;quot;gwpoc_default&amp;quot;&lt;/span&gt; with the default driver
Creating api1
Creating api2
Creating gw
gerard@aldebaran:~/docker/gw-poc$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Tras levantar el entorno, podemos hacer algunas peticiones, tanto a los contenedores que sirven la API, como al &lt;em&gt;gateway&lt;/em&gt; que las engloba.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gw-poc$ curl http://172.18.0.2/
Hello from api1
gerard@aldebaran:~/docker/gw-poc$ curl http://172.18.0.3/
Bye from api2
gerard@aldebaran:~/docker/gw-poc$ curl -H &lt;span class="s2"&gt;&amp;quot;Host: api1&amp;quot;&lt;/span&gt; http://localhost/
Hello from api1
gerard@aldebaran:~/docker/gw-poc$ curl -H &lt;span class="s2"&gt;&amp;quot;Host: api2&amp;quot;&lt;/span&gt; http://localhost/
Bye from api2
gerard@aldebaran:~/docker/gw-poc$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y ahora solo nos falta la magia: tiramos un fichero en &lt;em&gt;/srv/www/&lt;/em&gt;, cómodamente mapeados como un &lt;em&gt;host volume&lt;/em&gt; en la carpeta &lt;em&gt;volume/&lt;/em&gt;. Un fichero con el nombre del &lt;em&gt;virtualhost&lt;/em&gt; va a deshabilitar dicho &lt;em&gt;virtualhost&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gw-poc$ touch volume/api2
gerard@aldebaran:~/docker/gw-poc$ curl -H &lt;span class="s2"&gt;&amp;quot;Host: api1&amp;quot;&lt;/span&gt; http://localhost/
Hello from api1
gerard@aldebaran:~/docker/gw-poc$ curl -H &lt;span class="s2"&gt;&amp;quot;Host: api2&amp;quot;&lt;/span&gt; http://localhost/
&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;message&amp;quot;&lt;/span&gt;:&lt;span class="s2"&gt;&amp;quot;Sorry you! This entity (api2) is in maintenance mode&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;
gerard@aldebaran:~/docker/gw-poc$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;De la misma manera, podemos rehabilitarlo quitando ese fichero de ahí.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gw-poc$ rm volume/api2 
gerard@aldebaran:~/docker/gw-poc$ curl -H &lt;span class="s2"&gt;&amp;quot;Host: api1&amp;quot;&lt;/span&gt; http://localhost/
Hello from api1
gerard@aldebaran:~/docker/gw-poc$ curl -H &lt;span class="s2"&gt;&amp;quot;Host: api2&amp;quot;&lt;/span&gt; http://localhost/
Bye from api2
gerard@aldebaran:~/docker/gw-poc$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y lo mismo aplica para el primer dominio, aunque no lo repito por brevedad.&lt;/p&gt;
&lt;h2&gt;Siguientes pasos&lt;/h2&gt;
&lt;p&gt;El hecho de habilitar y deshabilitar las APIs se necesitaba hacer por parte de gente que no tiene necesariamente conocimientos técnicos para acceder al entorno, o no queremos simplemente por seguridad. La solución cómoda es una bonita interfaz web que les permita hacerlo a golpe de click y con una gestión de permisos adecuada ya incorporada.&lt;/p&gt;
&lt;p&gt;Como no queremos inventar la rueda nuevamente, podemos usar algo que ya esté hecho, como por ejemplo un &lt;strong&gt;jenkins&lt;/strong&gt;. De hecho, nada nos impide que el &lt;strong&gt;jenkins&lt;/strong&gt; lance &lt;em&gt;playbooks&lt;/em&gt; de &lt;strong&gt;ansible&lt;/strong&gt;. Sin embargo este ya es otro proyecto y en caso de que os interese, &lt;a href="http://www.linuxsysadmin.ml/2016/09/lanzando-playbooks-de-ansible-desde-jenkins.html"&gt;ya he escrito sobre esto&lt;/a&gt;.&lt;/p&gt;</content><category term="api"></category><category term="gateway"></category><category term="proxy"></category><category term="nginx"></category></entry><entry><title>El concepto del servidor fachada con Docker</title><link href="http://www.linuxsysadmin.ml/2017/07/el-concepto-del-servidor-fachada-con-docker.html" rel="alternate"></link><published>2017-07-03T10:00:00+02:00</published><updated>2017-07-03T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-07-03:/2017/07/el-concepto-del-servidor-fachada-con-docker.html</id><summary type="html">&lt;p&gt;Muchos de nosotros tenemos un servidor en casa o en algún &lt;em&gt;hosting&lt;/em&gt;. Como no tenemos mucho tráfico y cada servidor tiene un coste, acabamos llenándolo con un conjunto de servicios bastante grande. Esto supone un problema para actualizar el sistema operativo, suponiendo que los servicios no se molesten entre sí …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Muchos de nosotros tenemos un servidor en casa o en algún &lt;em&gt;hosting&lt;/em&gt;. Como no tenemos mucho tráfico y cada servidor tiene un coste, acabamos llenándolo con un conjunto de servicios bastante grande. Esto supone un problema para actualizar el sistema operativo, suponiendo que los servicios no se molesten entre sí.&lt;/p&gt;
&lt;p&gt;En estos casos podemos valernos de &lt;strong&gt;docker&lt;/strong&gt; (o de cualquier otro sistema de contenedores) para aislar cada servicio en su propio contenedor y para facilitar su portabilidad hacia un nuevo servidor. Con un poco de habilidad con reglas de &lt;em&gt;networking&lt;/em&gt;, podemos hacer esta transición sin cortes y poco a poco.&lt;/p&gt;
&lt;p&gt;El truco es utilizar el concepto &lt;strong&gt;fachada&lt;/strong&gt;, es decir, nuestro servidor es solo la fachada de cada una de nuestros contenedores. Estos exponen su servicio como un puerto en la máquina &lt;em&gt;host&lt;/em&gt; y así parece que el &lt;em&gt;host&lt;/em&gt; es un único servidor. Este &lt;em&gt;host&lt;/em&gt; también nos puede servir para albergar los &lt;em&gt;host volumes&lt;/em&gt; y para hacer tareas de mantenimiento tales como &lt;em&gt;backups&lt;/em&gt; o &lt;em&gt;logrotate&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Un ejemplo práctico&lt;/h2&gt;
&lt;p&gt;Supongamos que queremos un servidor casero con 3 servicios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Un servidor &lt;strong&gt;mariadb&lt;/strong&gt; y su interfaz de administración web &lt;strong&gt;adminer&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Un servidor de &lt;strong&gt;mongodb&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Un servidor web &lt;strong&gt;nginx&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En vez de instalarlo todo en nuestro servidor, vamos a aplicar la técnica antes descrita, de mapear en los puertos oficiales los puertos de los contenedores que ejecutan los servicios. Para simplificar el artículo, vamos a utilizar las imágenes oficiales en &lt;em&gt;DockerHub&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Para su fácil lanzamiento, vamos a usar &lt;strong&gt;docker-compose&lt;/strong&gt;, que nos simplifica bastante la línea de comandos, ocultando en el fichero &lt;em&gt;docker-compose.yml&lt;/em&gt; cosas como las variables de entorno, el mapeo de puertos o los volúmenes.&lt;/p&gt;
&lt;h3&gt;MariaDB y Adminer&lt;/h3&gt;
&lt;p&gt;Necesitaremos un &lt;em&gt;docker-compose.yml&lt;/em&gt; para levantar los contenedores de &lt;strong&gt;mariadb&lt;/strong&gt; y &lt;strong&gt;adminer&lt;/strong&gt;. En el caso de &lt;strong&gt;mariadb&lt;/strong&gt;, tiene una parte de datos persistentes, que vamos a dejar como un &lt;em&gt;host volume&lt;/em&gt; local.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/homeserver$ tree mariadb/
mariadb/
├── data
└── docker-compose.yml

&lt;span class="m"&gt;1&lt;/span&gt; directory, &lt;span class="m"&gt;1&lt;/span&gt; file
gerard@aldebaran:~/docker/homeserver$ cat mariadb/docker-compose.yml 
version: &lt;span class="s1"&gt;&amp;#39;3&amp;#39;&lt;/span&gt;
services:
  mariadb:
    image: mariadb
    container_name: mariadb
    hostname: mariadb
    volumes:
      - ./data:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: root1234
    ports:
      - &lt;span class="s2"&gt;&amp;quot;3306:3306&amp;quot;&lt;/span&gt;
  adminer:
    image: adminer
    container_name: adminer
    hostname: adminer
    ports:
      - &lt;span class="m"&gt;8080&lt;/span&gt;:8080
gerard@aldebaran:~/docker/homeserver$ docker-compose -f mariadb/docker-compose.yml up -d
Creating network &lt;span class="s2"&gt;&amp;quot;mariadb_default&amp;quot;&lt;/span&gt; with the default driver
Creating mariadb
Creating adminer
gerard@aldebaran:~/docker/homeserver$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;MongoDB&lt;/h3&gt;
&lt;p&gt;De forma análoga, vamos a usar un &lt;em&gt;docker-compose.yml&lt;/em&gt;, mapeando el puerto de &lt;strong&gt;mongodb&lt;/strong&gt; y su carpeta de datos en el &lt;em&gt;host&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/homeserver$ tree mongodb/
mongodb/
├── data
└── docker-compose.yml

&lt;span class="m"&gt;1&lt;/span&gt; directory, &lt;span class="m"&gt;1&lt;/span&gt; file
gerard@aldebaran:~/docker/homeserver$ cat mongodb/docker-compose.yml 
version: &lt;span class="s1"&gt;&amp;#39;3&amp;#39;&lt;/span&gt;
services:
  mongodb:
    image: mongo
    container_name: mongodb
    hostname: mongodb
    volumes:
      - ./data:/data/db
    ports:
      - &lt;span class="s2"&gt;&amp;quot;27017:27017&amp;quot;&lt;/span&gt;
gerard@aldebaran:~/docker/homeserver$ docker-compose -f mongodb/docker-compose.yml up -d
Creating network &lt;span class="s2"&gt;&amp;quot;mongodb_default&amp;quot;&lt;/span&gt; with the default driver
Creating mongodb
gerard@aldebaran:~/docker/homeserver$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Nginx&lt;/h3&gt;
&lt;p&gt;Y volvemos a repetir el proceso; un &lt;em&gt;docker-compose.yml&lt;/em&gt;, un puerto mapeado, y un &lt;em&gt;host volume&lt;/em&gt; para albergar el contenido web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/homeserver$ tree nginx/
nginx/
├── www
│   └── index.html
└── docker-compose.yml

&lt;span class="m"&gt;1&lt;/span&gt; directory, &lt;span class="m"&gt;2&lt;/span&gt; files
gerard@aldebaran:~/docker/homeserver$ cat nginx/docker-compose.yml 
version: &lt;span class="s1"&gt;&amp;#39;3&amp;#39;&lt;/span&gt;
services:
  nginx:
    image: nginx
    container_name: nginx
    hostname: nginx
    volumes:
      - ./www:/usr/share/nginx/html:ro
    ports:
      - &lt;span class="s2"&gt;&amp;quot;80:80&amp;quot;&lt;/span&gt;
gerard@aldebaran:~/docker/homeserver$ docker-compose -f nginx/docker-compose.yml up -d
Creating network &lt;span class="s2"&gt;&amp;quot;nginx_default&amp;quot;&lt;/span&gt; with the default driver
Creating nginx
gerard@aldebaran:~/docker/homeserver$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;El resultado&lt;/h3&gt;
&lt;p&gt;Si miramos los puertos abiertos en nuestro servidor, podemos ver fácilmente que responde los 4 puertos que suministran los servicios antes citados, y nada nos impide seguir creando servicios para ofrecer más puertos en nuestro servidor. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/homeserver$ netstat -lnt
Active Internet connections &lt;span class="o"&gt;(&lt;/span&gt;only servers&lt;span class="o"&gt;)&lt;/span&gt;
Proto Recv-Q Send-Q Local Address           Foreign Address         State      
tcp6       &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; :::27017                :::*                    LISTEN     
tcp6       &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; :::3306                 :::*                    LISTEN     
tcp6       &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; :::80                   :::*                    LISTEN     
tcp6       &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; :::8080                 :::*                    LISTEN     
gerard@aldebaran:~/docker/homeserver$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En caso de querer actualizar el sistema operativo base, solo tenemos que crear un nuevo servidor y levantar los contenedores de servicio, uno por uno; si usamos algún elemento de red como un &lt;em&gt;firewall&lt;/em&gt;, podemos desviar tráfico sin que se note, hasta que estemos preparados para reemplazar el servidor viejo con el nuevo.&lt;/p&gt;
&lt;p&gt;Al tratarse de contenedores individuales, lo que pase en un contendedor no va a interferir en lo que pase en otro, ganando así el concepto de aislamiento, pudiendo convivir varias versiones de un mismo &lt;em&gt;software&lt;/em&gt; o diversos servicios que ofrezcan el mismo protocolo. solo hay que tener en cuenta que los puertos mapeados en el &lt;em&gt;host&lt;/em&gt; deben ser únicos.&lt;/p&gt;</content><category term="docker"></category><category term="fachada"></category><category term="docker-compose"></category></entry><entry><title>Un servidor de git local con gitolite</title><link href="http://www.linuxsysadmin.ml/2017/06/un-servidor-de-git-local-con-gitolite.html" rel="alternate"></link><published>2017-06-26T10:00:00+02:00</published><updated>2017-06-26T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-06-26:/2017/06/un-servidor-de-git-local-con-gitolite.html</id><summary type="html">&lt;p&gt;A todos nos encanta el sistema de control de versiones &lt;strong&gt;git&lt;/strong&gt;. Tanto a nivel local como a nivel público en &lt;em&gt;GitHub&lt;/em&gt; es una maravilla; lo que no me gusta tanto es el precio que suelen tener las soluciones privadas. Sin embargo, y con un poco de habilidad, podemos encontrar alternativas …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A todos nos encanta el sistema de control de versiones &lt;strong&gt;git&lt;/strong&gt;. Tanto a nivel local como a nivel público en &lt;em&gt;GitHub&lt;/em&gt; es una maravilla; lo que no me gusta tanto es el precio que suelen tener las soluciones privadas. Sin embargo, y con un poco de habilidad, podemos encontrar alternativas.&lt;/p&gt;
&lt;p&gt;Existen varias alternativas tipo web, como por ejemplo &lt;a href="https://github.com/gitlabhq/gitlabhq"&gt;GitLab&lt;/a&gt; (imagen para &lt;strong&gt;docker&lt;/strong&gt; en &lt;a href="https://hub.docker.com/r/gitlab/gitlab-ce/"&gt;DockerHub&lt;/a&gt;); sin embargo, como amante del terminal me decanto por &lt;a href="http://gitolite.com/gitolite/index.html"&gt;Gitolite&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Además de las virtudes propias de &lt;strong&gt;git&lt;/strong&gt;, &lt;strong&gt;gitolite&lt;/strong&gt; nos ofrece un sistema de control de permisos en los repositorios bajo su administración, usando un usuario remoto SSH único y diferenciando quien es el usuario mediante la clave SSH que use para establecer la conexión.&lt;/p&gt;
&lt;p&gt;Otro punto interesante es que el servidor (usuarios, repositorios y permisos) se administra mediante &lt;strong&gt;git&lt;/strong&gt;, existiendo el usuario &lt;em&gt;admin&lt;/em&gt; con permisos sobre el repositorio &lt;em&gt;gitolite-admin&lt;/em&gt;. Este tiene la responsabilidad de clonar el repositorio, añadir los cambios y empujarlos con un &lt;em&gt;git push&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Montando el servidor&lt;/h2&gt;
&lt;p&gt;Como viene siendo tradición, vamos a aislar nuestro servicio de &lt;strong&gt;gitolite&lt;/strong&gt; en un contenedor &lt;strong&gt;docker&lt;/strong&gt;. Para ello vamos a utilizar una base de &lt;em&gt;Alpine Linux&lt;/em&gt; que nos va a dar un conjunto de paquetes bastante actualizados, a un tamaño bastante pequeño.&lt;/p&gt;
&lt;p&gt;Vamos a crear una imagen y le vamos a poner un &lt;em&gt;tag&lt;/em&gt; para diferenciarla del resto, por ejemplo, &lt;em&gt;gitolite&lt;/em&gt;. Aquí os paso el contexto para su construcción:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gitolite$ cat Dockerfile 
FROM alpine:3.5
RUN apk add --no-cache openssh gitolite &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    passwd -u git
COPY start.sh /
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/start.sh&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@aldebaran:~/docker/gitolite$ cat start.sh 
&lt;span class="c1"&gt;#!/bin/sh&lt;/span&gt;

ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key -N &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$SSH_PUBKEY&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &amp;gt; /tmp/admin.pub
su git -c &lt;span class="s2"&gt;&amp;quot;gitolite setup -pk /tmp/admin.pub&amp;quot;&lt;/span&gt;
rm /tmp/admin.pub

&lt;span class="nb"&gt;exec&lt;/span&gt; /usr/sbin/sshd -D -e
gerard@aldebaran:~/docker/gitolite$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El &lt;em&gt;script&lt;/em&gt; de inicialización &lt;em&gt;start.sh&lt;/em&gt; va a iniciar el demonio de SSH, no sin antes generar las claves de &lt;em&gt;host&lt;/em&gt; nuevas e inicializar &lt;strong&gt;gitolite&lt;/strong&gt;. Un pequeño detalle interesante es que &lt;strong&gt;gitolite&lt;/strong&gt; exige una clave pública SSH para que el usuario &lt;em&gt;admin&lt;/em&gt; pueda modificar el repositorio de administración; por comodidad la vamos a pasar mediante la variable de entorno &lt;em&gt;SSH_PUBKEY&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;La forma más fácil de levantar el servidor es con &lt;strong&gt;docker compose&lt;/strong&gt;, y aunque este varia según vuestros gustos personales, yo he usado algo así:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gitolite$ cat docker-compose.yml 
version: &lt;span class="s1"&gt;&amp;#39;3&amp;#39;&lt;/span&gt;
services:
  gitolite:
    image: gitolite
    container_name: gitolite
    hostname: gitolite
    environment:
      SSH_PUBKEY: &lt;span class="s2"&gt;&amp;quot;ssh-rsa ...&amp;quot;&lt;/span&gt;
    ports:
      - &lt;span class="s2"&gt;&amp;quot;22:22&amp;quot;&lt;/span&gt;
gerard@aldebaran:~/docker/gitolite$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: Para evitar indicar el usuario, la dirección IP y la clave SSH a usar, podemos definir algunos &lt;em&gt;hosts&lt;/em&gt; en el fichero &lt;em&gt;~/.ssh/config&lt;/em&gt;, que también nos va a ser útil en el momento de las operaciones &lt;strong&gt;git&lt;/strong&gt; remotas, que no aceptan parámetros.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~$ cat .ssh/config 
...
Host gitolite-admin
    Hostname &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1
    User git
    IdentityFile ~/docker/gitolite/keys/admin

Host gitolite-gerard
    Hostname &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1
    User git
    IdentityFile ~/docker/gitolite/keys/gerard
gerard@aldebaran:~$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Administrando gitolite&lt;/h2&gt;
&lt;p&gt;Como ya se ha indicado, el usuario &lt;em&gt;admin&lt;/em&gt; debe clonar el repositorio &lt;em&gt;gitolite-admin&lt;/em&gt; para editar los cambios. En principio es el único usuario y tiene permisos sobre el repositorio mencionado. Podemos ver sus permisos intentando entrar al servidor por SSH (recordad que lo he mapeado al puerto 22 de mi máquina).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gitolite/workspace$ ssh -i ../keys/admin git@localhost
Warning: Permanently added &lt;span class="s1"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;RSA&lt;span class="o"&gt;)&lt;/span&gt; to the list of known hosts.
PTY allocation request failed on channel &lt;span class="m"&gt;0&lt;/span&gt;
hello admin, this is git@gitolite running gitolite3 v3.4.0-4380-g8bd1571 on git &lt;span class="m"&gt;2&lt;/span&gt;.11.2

 R W    gitolite-admin
 R W    testing
Connection to localhost closed.
gerard@aldebaran:~/docker/gitolite/workspace$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Alternativamente podemos usar el &lt;em&gt;host&lt;/em&gt; declarado en la configuración SSH cliente (el truco está más arriba):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gitolite/workspace$ ssh gitolite-admin
Warning: Permanently added &lt;span class="s1"&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;RSA&lt;span class="o"&gt;)&lt;/span&gt; to the list of known hosts.
PTY allocation request failed on channel &lt;span class="m"&gt;0&lt;/span&gt;
hello admin, this is git@gitolite running gitolite3 v3.4.0-4380-g8bd1571 on git &lt;span class="m"&gt;2&lt;/span&gt;.11.2

 R W    gitolite-admin
 R W    testing
Connection to &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1 closed.
gerard@aldebaran:~/docker/gitolite/workspace$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La sesión se cierra, ya que la función de este SSH es solamente hacer las operaciones remotas de &lt;em&gt;clone&lt;/em&gt;, &lt;em&gt;pull&lt;/em&gt; y &lt;em&gt;push&lt;/em&gt;. Cualquier otro usuario va a fallar si intenta entrar al servidor de la misma forma, ya que no hay nadie más autorizado.&lt;/p&gt;
&lt;p&gt;Para realizar modificaciones tenemos que clonar el repositorio de administración:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gitolite/workspace$ git clone gitolite-admin:gitolite-admin.git
Cloning into &lt;span class="s1"&gt;&amp;#39;gitolite-admin&amp;#39;&lt;/span&gt;...
Warning: Permanently added &lt;span class="s1"&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;RSA&lt;span class="o"&gt;)&lt;/span&gt; to the list of known hosts.
remote: Counting objects: &lt;span class="m"&gt;6&lt;/span&gt;, &lt;span class="k"&gt;done&lt;/span&gt;.
remote: Compressing objects: &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;/4&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="k"&gt;done&lt;/span&gt;.
remote: Total &lt;span class="m"&gt;6&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;delta &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, reused &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;delta &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
Receiving objects: &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;/6&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="k"&gt;done&lt;/span&gt;.
Checking connectivity... &lt;span class="k"&gt;done&lt;/span&gt;.
gerard@aldebaran:~/docker/gitolite/workspace$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Esto nos da el repositorio de administración, que de por sí, es bastante intuitivo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ tree
.
├── conf
│   └── gitolite.conf
└── keydir
    └── admin.pub

&lt;span class="m"&gt;2&lt;/span&gt; directories, &lt;span class="m"&gt;2&lt;/span&gt; files
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La carpeta &lt;em&gt;keydir&lt;/em&gt; es donde hay que poner las claves de los usuarios SSH para que puedan entrar en la máquina. Es importante poner el formato &lt;code&gt;&amp;lt;usuario&amp;gt;.pub&lt;/code&gt; donde &lt;code&gt;usuario&lt;/code&gt; es el usuario tal como lo conoce &lt;strong&gt;gitolite&lt;/strong&gt; y como hay que indicar en los permisos; da igual como se llama la clave privada en la máquina del usuario (por ejemplo, &lt;em&gt;id_rsa&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;El fichero &lt;em&gt;conf/gitolite.conf&lt;/em&gt; tiene la especificación de los repositorios y los permisos que tienen los usuarios sobre ellos.&lt;/p&gt;
&lt;h3&gt;Añadiendo usuarios&lt;/h3&gt;
&lt;p&gt;Para añadir o retirar usuarios, basta con añadir o quitar su clave de la carpeta &lt;em&gt;keydir&lt;/em&gt; en nuestro repositorio local, para posteriormente hacer el correspondiente &lt;em&gt;push&lt;/em&gt;. Por ejemplo, añado la clave para mi usuario:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ tree
.
├── conf
│   └── gitolite.conf
└── keydir
    ├── admin.pub
    └── gerard.pub

&lt;span class="m"&gt;2&lt;/span&gt; directories, &lt;span class="m"&gt;3&lt;/span&gt; files
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ git add keydir/gerard.pub 
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ git commit -m &lt;span class="s2"&gt;&amp;quot;Add user gerard&amp;quot;&lt;/span&gt;
...
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Podemos ver que ahora puedo usar el usuario &lt;em&gt;gerard&lt;/em&gt; para hacer SSH, pero que los repositorios a los que tiene acceso no son los mismos; de hecho, viene uno llamado &lt;em&gt;testing&lt;/em&gt; por defecto. Recordad que &lt;strong&gt;gitolite&lt;/strong&gt; decide el usuario en función de la clave SSH usada, y esta la he puesto en la configuración SSH cliente en &lt;em&gt;~/.ssh/config&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ ssh gitolite-admin
Warning: Permanently added &lt;span class="s1"&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;RSA&lt;span class="o"&gt;)&lt;/span&gt; to the list of known hosts.
PTY allocation request failed on channel &lt;span class="m"&gt;0&lt;/span&gt;
hello admin, this is git@gitolite running gitolite3 v3.4.0-4380-g8bd1571 on git &lt;span class="m"&gt;2&lt;/span&gt;.11.2

 R W    gitolite-admin
 R W    testing
Connection to &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1 closed.
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ ssh gitolite-gerard
Warning: Permanently added &lt;span class="s1"&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;RSA&lt;span class="o"&gt;)&lt;/span&gt; to the list of known hosts.
PTY allocation request failed on channel &lt;span class="m"&gt;0&lt;/span&gt;
hello gerard, this is git@gitolite running gitolite3 v3.4.0-4380-g8bd1571 on git &lt;span class="m"&gt;2&lt;/span&gt;.11.2

 R W    testing
Connection to &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1 closed.
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El punto interesante de todo esto es que todos los usuarios utilizan un &lt;em&gt;shell&lt;/em&gt; restringido, pero este acepta un parámetro, que es el usuario. Este parámetro es forzado por SSH cuando alguna de las líneas del fichero &lt;em&gt;authorized_keys&lt;/em&gt; da positivo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ docker &lt;span class="nb"&gt;exec&lt;/span&gt; gitolite cat /var/lib/git/.ssh/authorized_keys
&lt;span class="c1"&gt;# gitolite start&lt;/span&gt;
&lt;span class="nv"&gt;command&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/usr/lib/gitolite/gitolite-shell admin&amp;quot;&lt;/span&gt;,no-port-forwarding,no-X11-forwarding,no-agent-forwarding,no-pty ssh-rsa ...  
&lt;span class="nv"&gt;command&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/usr/lib/gitolite/gitolite-shell gerard&amp;quot;&lt;/span&gt;,no-port-forwarding,no-X11-forwarding,no-agent-forwarding,no-pty ssh-rsa ...  
&lt;span class="c1"&gt;# gitolite end&lt;/span&gt;
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Administrando repositorios y permisos&lt;/h3&gt;
&lt;p&gt;El fichero clave para esto es &lt;em&gt;conf/gitolite.conf&lt;/em&gt;. Si vemos lo que tiene, comprenderemos inmediatamente lo que hay que hacer.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ cat conf/gitolite.conf 
repo gitolite-admin
    RW+     &lt;span class="o"&gt;=&lt;/span&gt;   admin

repo testing
    RW+     &lt;span class="o"&gt;=&lt;/span&gt;   @all
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Se trata de repositorios (o grupos) con una lista tabulada de permisos y usuarios o grupos a los que afectan. Más información en &lt;a href="http://gitolite.com/gitolite/conf/"&gt;la documentación&lt;/a&gt;. El grupo &lt;em&gt;all&lt;/em&gt; es especial y viene predefinido.&lt;/p&gt;
&lt;p&gt;Vamos a poner algunos repositorios, grupos y permisos:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ cat conf/gitolite.conf 
@devs &lt;span class="o"&gt;=&lt;/span&gt; dev1 dev2 dev3
@ops &lt;span class="o"&gt;=&lt;/span&gt; ops1
@staff &lt;span class="o"&gt;=&lt;/span&gt; @devs @ops

@blog &lt;span class="o"&gt;=&lt;/span&gt;  blog-public blog-admin
@shop &lt;span class="o"&gt;=&lt;/span&gt; shop-public shop-admin shop-api

repo gitolite-admin
    RW+ &lt;span class="o"&gt;=&lt;/span&gt; admin

repo @blog
    RW+ &lt;span class="o"&gt;=&lt;/span&gt; gerard
    &lt;span class="nv"&gt;RW&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; @devs
    &lt;span class="nv"&gt;R&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; @ops

repo @shop
    RW+ &lt;span class="o"&gt;=&lt;/span&gt; @staff
    &lt;span class="nv"&gt;R&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; gerard
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ git add conf/gitolite.conf 
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ git commit -m &lt;span class="s2"&gt;&amp;quot;Added some projects and permissions&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;master f8fe801&lt;span class="o"&gt;]&lt;/span&gt; Added some projects and permissions
 &lt;span class="m"&gt;1&lt;/span&gt; file changed, &lt;span class="m"&gt;16&lt;/span&gt; insertions&lt;span class="o"&gt;(&lt;/span&gt;+&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;3&lt;/span&gt; deletions&lt;span class="o"&gt;(&lt;/span&gt;-&lt;span class="o"&gt;)&lt;/span&gt;
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ git push
...  
Warning: Permanently added &lt;span class="s1"&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;RSA&lt;span class="o"&gt;)&lt;/span&gt; to the list of known hosts.
Counting objects: &lt;span class="m"&gt;4&lt;/span&gt;, &lt;span class="k"&gt;done&lt;/span&gt;.
Delta compression using up to &lt;span class="m"&gt;4&lt;/span&gt; threads.
Compressing objects: &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;/3&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="k"&gt;done&lt;/span&gt;.
Writing objects: &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;/4&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;474&lt;/span&gt; bytes &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; bytes/s, &lt;span class="k"&gt;done&lt;/span&gt;.
Total &lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;delta &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, reused &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;delta &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
remote: Initialized empty Git repository in /var/lib/git/repositories/blog-admin.git/
remote: Initialized empty Git repository in /var/lib/git/repositories/blog-public.git/
remote: Initialized empty Git repository in /var/lib/git/repositories/shop-admin.git/
remote: Initialized empty Git repository in /var/lib/git/repositories/shop-api.git/
remote: Initialized empty Git repository in /var/lib/git/repositories/shop-public.git/
To gitolite-admin:gitolite-admin.git
   &lt;span class="m"&gt;5114865&lt;/span&gt;..f8fe801  master -&amp;gt; master
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y solo nos queda ver los permisos que tenemos ahora con los diferentes usuarios:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ ssh gitolite-admin
Warning: Permanently added &lt;span class="s1"&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;RSA&lt;span class="o"&gt;)&lt;/span&gt; to the list of known hosts.
PTY allocation request failed on channel &lt;span class="m"&gt;0&lt;/span&gt;
hello admin, this is git@gitolite running gitolite3 v3.4.0-4380-g8bd1571 on git &lt;span class="m"&gt;2&lt;/span&gt;.11.2

 R W    gitolite-admin
Connection to &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1 closed.
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ ssh gitolite-gerard
Warning: Permanently added &lt;span class="s1"&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;RSA&lt;span class="o"&gt;)&lt;/span&gt; to the list of known hosts.
PTY allocation request failed on channel &lt;span class="m"&gt;0&lt;/span&gt;
hello gerard, this is git@gitolite running gitolite3 v3.4.0-4380-g8bd1571 on git &lt;span class="m"&gt;2&lt;/span&gt;.11.2

 R W    blog-admin
 R W    blog-public
 R      shop-admin
 R      shop-api
 R      shop-public
Connection to &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1 closed.
gerard@aldebaran:~/docker/gitolite/workspace/gitolite-admin$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El repositorio &lt;em&gt;testing&lt;/em&gt; no aparece en la configuración, pero sus datos siguen en el servidor. En caso de querer eliminarlo definitivamente, necesitamos eliminar su carpeta entrando en el servidor.&lt;/p&gt;</content><category term="git"></category><category term="gitolite"></category></entry><entry><title>Generación fácil de certificados con easyrsa</title><link href="http://www.linuxsysadmin.ml/2017/05/generacion-facil-de-certificados-con-easyrsa.html" rel="alternate"></link><published>2017-05-29T10:00:00+02:00</published><updated>2017-05-29T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-05-29:/2017/05/generacion-facil-de-certificados-con-easyrsa.html</id><summary type="html">&lt;p&gt;Ya vimos en &lt;a href="http://www.linuxsysadmin.ml/2016/02/restringiendo-accesos-mediante-certificados-de-cliente.html"&gt;otro artículo&lt;/a&gt; como restringir los accesos a una web usando certificados SSL. Sin embargo, la generación de los mismos era un poco confusa. Sin embargo, existe una herramienta llamada &lt;strong&gt;easyrsa&lt;/strong&gt; que nos permite generar peticiones de forma fácil, firmarlas con nuestra CA y obtener el producto final …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Ya vimos en &lt;a href="http://www.linuxsysadmin.ml/2016/02/restringiendo-accesos-mediante-certificados-de-cliente.html"&gt;otro artículo&lt;/a&gt; como restringir los accesos a una web usando certificados SSL. Sin embargo, la generación de los mismos era un poco confusa. Sin embargo, existe una herramienta llamada &lt;strong&gt;easyrsa&lt;/strong&gt; que nos permite generar peticiones de forma fácil, firmarlas con nuestra CA y obtener el producto final.&lt;/p&gt;
&lt;p&gt;Vamos a intentar seguir los pasos del citado artículo, solo en la parte de generación de los certificados. Si no se necesitara, se puede obviar la parte del certificado cliente, o porque no, generar certificados para decenas o cientos de usuarios de forma fácil.&lt;/p&gt;
&lt;p&gt;Vamos a partir de una distribución &lt;a href="https://alpinelinux.org/"&gt;Alpine Linux&lt;/a&gt;. Para los que no lo sospechen ya es un contenedor &lt;strong&gt;Docker&lt;/strong&gt; por la facilidad de crearlo y de destruirlo al acabar el artículo. Además, esta distribución nos ofrece la herramienta en la versión 3, que me ha parecido más intuitiva que la versión anterior. Asumo también que se dispone del paquete &lt;strong&gt;easy-rsa&lt;/strong&gt;, que se puede instalar con &lt;code&gt;apk add easy-rsa&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Preparando la CA&lt;/h2&gt;
&lt;p&gt;lo primero para hacer una CA es copiar la estructura base a cualquier sitio. La idea es que tenemos una copia para cada CA que tengamos en el servidor, y no quiero trabajar en las carpetas de sistema para no destruir la plantilla.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rsa:~# cp -R /usr/share/easy-rsa/* .
rsa:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Otro paso necesario es inicializar las estructura de PKI, que básicamente es crear un esqueleto de carpetas para contener nuestros ficheros.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rsa:~# easyrsa init-pki

init-pki complete&lt;span class="p"&gt;;&lt;/span&gt; you may now create a CA or requests.
Your newly created PKI dir is: /root/pki

rsa:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente creamos los certificados y claves necesarios para la CA con un simple comando único.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rsa:~# easyrsa build-ca
Generating a &lt;span class="m"&gt;2048&lt;/span&gt; bit RSA private key
........................+++
...............................................+++
writing new private key to &lt;span class="s1"&gt;&amp;#39;/root/pki/private/ca.key.XXXXPPMHOb&amp;#39;&lt;/span&gt;
Enter PEM pass phrase:
Verifying - Enter PEM pass phrase:
-----
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter &lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;, the field will be left blank.
-----
Common Name &lt;span class="o"&gt;(&lt;/span&gt;eg: your user, host, or server name&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;Easy-RSA CA&lt;span class="o"&gt;]&lt;/span&gt;:

CA creation &lt;span class="nb"&gt;complete&lt;/span&gt; and you may now import and sign cert requests.
Your new CA certificate file &lt;span class="k"&gt;for&lt;/span&gt; publishing is at:
/root/pki/ca.crt

rsa:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El resultado que deberemos exportar a nuestro servidor es el certificado de la CA, cuya localización es &lt;em&gt;/root/pki/ca.crt&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Generando el certificado de nuestro servidor&lt;/h2&gt;
&lt;p&gt;Este paso se debe repetir tantas veces como servidores queramos que utilicen un certificado SSL. De momento, nos basta con uno. Además, lo vamos a crear sin contraseña porque no queremos tener que introducirla cada vez que se reinicie el servidor.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rsa:~# easyrsa gen-req private nopass
Generating a &lt;span class="m"&gt;2048&lt;/span&gt; bit RSA private key
......................................................+++
.+++
writing new private key to &lt;span class="s1"&gt;&amp;#39;/root/pki/private/private.key.XXXXhfGNmO&amp;#39;&lt;/span&gt;
-----
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter &lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;, the field will be left blank.
-----
Common Name &lt;span class="o"&gt;(&lt;/span&gt;eg: your user, host, or server name&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;private&lt;span class="o"&gt;]&lt;/span&gt;:

Keypair and certificate request completed. Your files are:
req: /root/pki/reqs/private.req
key: /root/pki/private/private.key

rsa:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;IMPORTANTE&lt;/strong&gt;: el &lt;em&gt;Common Name&lt;/em&gt; es el parámetro mas importante; debe coincidir con el dominio para que se dé por bueno.&lt;/p&gt;
&lt;p&gt;Lo firmamos con nuestra CA y ya habremos acabado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rsa:~# easyrsa sign-req server private


You are about to sign the following certificate.
Please check over the details shown below &lt;span class="k"&gt;for&lt;/span&gt; accuracy. Note that this request
has not been cryptographically verified. Please be sure it came from a trusted
&lt;span class="nb"&gt;source&lt;/span&gt; or that you have verified the request checksum with the sender.

Request subject, to be signed as a server certificate &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="m"&gt;3650&lt;/span&gt; days:

&lt;span class="nv"&gt;subject&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
    &lt;span class="nv"&gt;commonName&lt;/span&gt;                &lt;span class="o"&gt;=&lt;/span&gt; private


Type the word &lt;span class="s1"&gt;&amp;#39;yes&amp;#39;&lt;/span&gt; to &lt;span class="k"&gt;continue&lt;/span&gt;, or any other input to abort.
  Confirm request details: yes
Using configuration from /root/openssl-1.0.cnf
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; /root/pki/private/ca.key:
Check that the request matches the signature
Signature ok
The Subject&lt;span class="s1"&gt;&amp;#39;s Distinguished Name is as follows&lt;/span&gt;
&lt;span class="s1"&gt;commonName            :ASN.1 12:&amp;#39;&lt;/span&gt;private&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
Certificate is to be certified &lt;span class="k"&gt;until&lt;/span&gt; Nov  &lt;span class="m"&gt;9&lt;/span&gt; &lt;span class="m"&gt;11&lt;/span&gt;:24:39 &lt;span class="m"&gt;2026&lt;/span&gt; GMT &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3650&lt;/span&gt; days&lt;span class="o"&gt;)&lt;/span&gt;

Write out database with &lt;span class="m"&gt;1&lt;/span&gt; new entries
Data Base Updated

Certificate created at: /root/pki/issued/private.crt

rsa:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a necesitar los ficheros &lt;em&gt;/root/pki/private/private.key&lt;/em&gt; y &lt;em&gt;/root/pki/private/private.crt&lt;/em&gt; para ponerlos en nuestro servidor, juntamente con el certificado de la CA.&lt;/p&gt;
&lt;h2&gt;Generando certificados cliente (opcional)&lt;/h2&gt;
&lt;p&gt;Se trata de la misma filosofía; generamos una &lt;em&gt;request&lt;/em&gt;, la firmamos y finalmente la vamos a empaquetar en un fichero &lt;em&gt;.p12&lt;/em&gt; para su fácil y segura distribución.&lt;/p&gt;
&lt;p&gt;Repetimos la generación de la &lt;em&gt;request&lt;/em&gt; de la misma manera:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rsa:~# easyrsa gen-req gerard
Generating a &lt;span class="m"&gt;2048&lt;/span&gt; bit RSA private key
............................................+++
...........+++
writing new private key to &lt;span class="s1"&gt;&amp;#39;/root/pki/private/gerard.key.XXXXfHJDkE&amp;#39;&lt;/span&gt;
Enter PEM pass phrase:
Verifying - Enter PEM pass phrase:
-----
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter &lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;, the field will be left blank.
-----
Common Name &lt;span class="o"&gt;(&lt;/span&gt;eg: your user, host, or server name&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;gerard&lt;span class="o"&gt;]&lt;/span&gt;:

Keypair and certificate request completed. Your files are:
req: /root/pki/reqs/gerard.req
key: /root/pki/private/gerard.key

rsa:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Firmamos la petición. Es especialmente importante el parámetro &lt;em&gt;client&lt;/em&gt;, ya que sino, no va a funcionar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rsa:~# easyrsa sign-req client gerard


You are about to sign the following certificate.
Please check over the details shown below &lt;span class="k"&gt;for&lt;/span&gt; accuracy. Note that this request
has not been cryptographically verified. Please be sure it came from a trusted
&lt;span class="nb"&gt;source&lt;/span&gt; or that you have verified the request checksum with the sender.

Request subject, to be signed as a client certificate &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="m"&gt;3650&lt;/span&gt; days:

&lt;span class="nv"&gt;subject&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
    &lt;span class="nv"&gt;commonName&lt;/span&gt;                &lt;span class="o"&gt;=&lt;/span&gt; gerard


Type the word &lt;span class="s1"&gt;&amp;#39;yes&amp;#39;&lt;/span&gt; to &lt;span class="k"&gt;continue&lt;/span&gt;, or any other input to abort.
  Confirm request details: yes
Using configuration from /root/openssl-1.0.cnf
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; /root/pki/private/ca.key:
Check that the request matches the signature
Signature ok
The Subject&lt;span class="s1"&gt;&amp;#39;s Distinguished Name is as follows&lt;/span&gt;
&lt;span class="s1"&gt;commonName            :ASN.1 12:&amp;#39;&lt;/span&gt;gerard&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
Certificate is to be certified &lt;span class="k"&gt;until&lt;/span&gt; Nov  &lt;span class="m"&gt;9&lt;/span&gt; &lt;span class="m"&gt;11&lt;/span&gt;:42:10 &lt;span class="m"&gt;2026&lt;/span&gt; GMT &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3650&lt;/span&gt; days&lt;span class="o"&gt;)&lt;/span&gt;

Write out database with &lt;span class="m"&gt;1&lt;/span&gt; new entries
Data Base Updated

Certificate created at: /root/pki/issued/gerard.crt

rsa:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente tenemos los ficheros &lt;em&gt;gerard.key&lt;/em&gt; y &lt;em&gt;gerard.crt&lt;/em&gt;, que no son lo que solemos importar en nuestro navegador. Para ellos lo empaquetamos en un fichero &lt;em&gt;gerard.12&lt;/em&gt; que está protegido por contraseña y es el que deberá importar el usuario de nuestra web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rsa:~# openssl pkcs12 -export -in pki/issued/gerard.crt -inkey pki/private/gerard.key -out gerard.p12
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; pki/private/gerard.key:
Enter Export Password:
Verifying - Enter Export Password:
rsa:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Un ejemplo de servidor nginx funcional&lt;/h2&gt;
&lt;p&gt;Tenemos 3 ficheros para nuestro servidor, que son &lt;em&gt;ca.crt&lt;/em&gt;, &lt;em&gt;server.crt&lt;/em&gt; y &lt;em&gt;server.key&lt;/em&gt;, con los que podemos montar un dominio estándar, como en el artículo citado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cat /etc/nginx/sites-enabled/private.linuxsysadmin.tk
server &lt;span class="o"&gt;{&lt;/span&gt;
    listen                      &lt;span class="m"&gt;443&lt;/span&gt; ssl&lt;span class="p"&gt;;&lt;/span&gt;
    server_name                 private&lt;span class="p"&gt;;&lt;/span&gt;
    root                        /srv/www&lt;span class="p"&gt;;&lt;/span&gt;

    ssl_certificate             /etc/ssl/certs/server.crt&lt;span class="p"&gt;;&lt;/span&gt;
    ssl_certificate_key         /etc/ssl/private/server.key&lt;span class="p"&gt;;&lt;/span&gt;
    ssl_client_certificate      /etc/ssl/certs/ca.crt&lt;span class="p"&gt;;&lt;/span&gt;
    ssl_verify_client           on&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y suponiendo que el cliente ha importado su clave con éxito, ya tenemos el dominio montado.&lt;/p&gt;</content><category term="easyrsa"></category><category term="openssl"></category><category term="ssl"></category><category term="2 way ssl"></category><category term="certificado"></category></entry><entry><title>Un entorno web estático con nginx, rsync y docker</title><link href="http://www.linuxsysadmin.ml/2017/03/un-entorno-web-estatico-con-nginx-rsync-y-docker.html" rel="alternate"></link><published>2017-03-27T10:00:00+02:00</published><updated>2017-03-27T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-03-27:/2017/03/un-entorno-web-estatico-con-nginx-rsync-y-docker.html</id><summary type="html">&lt;p&gt;Hemos hablado de generar nuestro contenido HTML estático con otras herramientas, y finalmente ha llegado la hora de servirlo. Normalmente, los ficheros que cambian tal y como vamos generando páginas son pocos y nos interesa copiarlo de forma remota, pero no podemos hacerlo con &lt;strong&gt;docker&lt;/strong&gt; porque hacen falta dos servicios …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Hemos hablado de generar nuestro contenido HTML estático con otras herramientas, y finalmente ha llegado la hora de servirlo. Normalmente, los ficheros que cambian tal y como vamos generando páginas son pocos y nos interesa copiarlo de forma remota, pero no podemos hacerlo con &lt;strong&gt;docker&lt;/strong&gt; porque hacen falta dos servicios.&lt;/p&gt;
&lt;p&gt;Si has asentido con la cabeza, mal. Es verdad que se necesitan dos servicios, pero hay maneras de ejecutar dos procesos en un mismo contenedor, por ejemplo &lt;a href="http://www.linuxsysadmin.ml/2017/03/multiples-servicios-en-un-mismo-contenedor-docker.html"&gt;con un gestor de procesos&lt;/a&gt;. Sin embargo, esa no es la filosofía de &lt;strong&gt;docker&lt;/strong&gt;. Un contenedor solo debería ejecutar un proceso, simplificando su contenido y siendo necesarios varios contenedores para hacer nuestro sistema modular.&lt;/p&gt;
&lt;p&gt;Así que solo nos queda pensar las partes que tiene nuestro pequeño entorno, para luego levantar contenedores que ejecuten todos los servicios necesarios, posiblemente con &lt;strong&gt;docker-compose&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Un servidor web&lt;/li&gt;
&lt;li&gt;Un servicio de transferencia de archivos&lt;/li&gt;
&lt;li&gt;Algún sitio compartido para dejar los ficheros&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: Puesto que ambos servicios van a necesitar acceder al mismo sitio, necesitamos volúmenes. Sin embargo, no queremos mezclar los datos con ninguno de los otros contenedores, ya que en caso de actualizarlos, perderíamos el volumen. Eso nos deja dos opciones: un &lt;em&gt;host volume&lt;/em&gt; o un &lt;em&gt;data container&lt;/em&gt;, que usaremos por portabilidad.&lt;/p&gt;
&lt;h2&gt;El servidor web&lt;/h2&gt;
&lt;p&gt;Vamos a utilizar &lt;strong&gt;nginx&lt;/strong&gt; por su eficiencia y velocidad. Consume poco, ocupa poco, y es simple de configurar. Como ligereza adicional, vamos a partir de una imagen de &lt;em&gt;Alpine Linux&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;La imagen no tiene misterio: un &lt;em&gt;Dockerfile&lt;/em&gt;, un fichero de arranque ejecutable y dos ficheros de configuración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/syncweb/web$ cat Dockerfile 
FROM alpine:3.5
RUN apk add --no-cache nginx tini &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    ln -s /dev/stdout /var/log/nginx/access.log &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    ln -s /dev/stderr /var/log/nginx/error.log &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    mkdir /run/nginx &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    mkdir /srv/www &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    rm /etc/nginx/conf.d/default.conf
COPY nginx.conf /etc/nginx/
COPY conf.d/* /etc/nginx/conf.d/
COPY start.sh /
ENTRYPOINT &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/sbin/tini&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;--&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/start.sh&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@aldebaran:~/docker/syncweb/web$ cat start.sh 
&lt;span class="c1"&gt;#!/bin/sh&lt;/span&gt;

&lt;span class="nb"&gt;exec&lt;/span&gt; /usr/sbin/nginx -g &lt;span class="s2"&gt;&amp;quot;daemon off;&amp;quot;&lt;/span&gt;
gerard@aldebaran:~/docker/syncweb/web$ cat nginx.conf 
worker_processes &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
events &lt;span class="o"&gt;{&lt;/span&gt;
    worker_connections &lt;span class="m"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
http &lt;span class="o"&gt;{&lt;/span&gt;
    include mime.types&lt;span class="p"&gt;;&lt;/span&gt;
    default_type application/octet-stream&lt;span class="p"&gt;;&lt;/span&gt;
    sendfile on&lt;span class="p"&gt;;&lt;/span&gt;
    keepalive_timeout &lt;span class="m"&gt;65&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    include conf.d/*&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
gerard@aldebaran:~/docker/syncweb/web$ cat conf.d/web 
server &lt;span class="o"&gt;{&lt;/span&gt;
    server_name _&lt;span class="p"&gt;;&lt;/span&gt;
    listen &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    root /srv/www&lt;span class="p"&gt;;&lt;/span&gt;
    index index.html&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
gerard@aldebaran:~/docker/syncweb/web$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a asumir que la carpeta &lt;code&gt;/srv/www/&lt;/code&gt; existe, puesto que la montaremos como un volumen.&lt;/p&gt;
&lt;h2&gt;Transfiriendo ficheros&lt;/h2&gt;
&lt;p&gt;Dada la naturaleza incremental de nuestro contenido HTML, nos viene muy bien utilizar &lt;strong&gt;rsync&lt;/strong&gt;, que funciona sobre &lt;strong&gt;ssh&lt;/strong&gt; y nos aporta encriptación, compresión y copia diferencial. Vamos a restringir el uso del &lt;strong&gt;ssh&lt;/strong&gt; mediante &lt;strong&gt;rssh&lt;/strong&gt;, permitiendo solamente usar &lt;strong&gt;rsync&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Nuevamente vamos a partir de una imagen &lt;em&gt;Alpine Linux&lt;/em&gt;, que es pequeña, segura y en este caso nos sirve de maravilla. Creamos la imagen con un simple &lt;em&gt;Dockerfile&lt;/em&gt; y un fichero de arranque, con permiso de ejecución.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/syncweb/rsync$ cat Dockerfile 
FROM alpine:3.5
RUN apk add --no-cache openssh rsync rssh tini &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    sed &lt;span class="s1"&gt;&amp;#39;s/^#allowrsync/allowrsync/g&amp;#39;&lt;/span&gt; /etc/rssh.conf.default &amp;gt; /etc/rssh.conf &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    adduser web -s /usr/bin/rssh -D -H &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;web:web&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; chpasswd
COPY start.sh /
ENTRYPOINT &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/sbin/tini&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;--&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/start.sh&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@aldebaran:~/docker/syncweb/rsync$ cat start.sh 
&lt;span class="c1"&gt;#!/bin/sh&lt;/span&gt;

chown -R web:web /srv/www
ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key -N &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;exec&lt;/span&gt; /usr/sbin/sshd -D -e
gerard@aldebaran:~/docker/syncweb/rsync$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lo más interesante de decir es que la carpeta &lt;code&gt;/srv/www/&lt;/code&gt; va a ser montada como volumen. Como no podemos asegurar que los permisos sean correctos, los forzamos al usuario &lt;em&gt;web&lt;/em&gt;, que es el que va a poder entrar por &lt;strong&gt;rsync&lt;/strong&gt;. Otro punto a tener en cuenta es que se ha movido la creación de la clave de &lt;em&gt;host&lt;/em&gt; al fichero &lt;em&gt;start.sh&lt;/em&gt; para evitar duplicarla a base de crear contenedores a partir de la clave de la imagen.&lt;/p&gt;
&lt;h2&gt;El contenedor de datos&lt;/h2&gt;
&lt;p&gt;Se trata de un contenedor que va a acabar tras levantar. Su única función es albergar un volumen de datos para exportarlo a otros contenedores.&lt;/p&gt;
&lt;p&gt;Lo crearemos usando una imagen mínima, que solo tiene el comando &lt;em&gt;true&lt;/em&gt;, así podemos ejecutar un comando que no hace nada y no cargamos nada adicional. Le ponemos un contenido básico, que nos permite ver que todo funciona y que luego será sustituido mediante &lt;strong&gt;rsync&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/syncweb/data$ cat Dockerfile 
FROM tianon/true
COPY index.html /srv/www/
gerard@aldebaran:~/docker/syncweb/data$ cat index.html 
&amp;lt;h1&amp;gt;Hello world&amp;lt;/h1&amp;gt;
&amp;lt;p&amp;gt;This is a placeholder file&amp;lt;/p&amp;gt;
gerard@aldebaran:~/docker/syncweb/data$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Este contenedor solamente ejecuta &lt;em&gt;true&lt;/em&gt; y acaba. Sin embargo, su volumen sigue siendo accesible por aquellos contenedores que lo exporten.&lt;/p&gt;
&lt;h2&gt;Todo junto&lt;/h2&gt;
&lt;p&gt;Antes que nada creamos las imágenes, según los comandos habituales:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/syncweb$ docker build -t data data/
...  
gerard@aldebaran:~/docker/syncweb$ docker build -t web web/
...  
gerard@aldebaran:~/docker/syncweb$ docker build -t rsync rsync/
...  
gerard@aldebaran:~/docker/syncweb$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Comprobamos las imágenes que hemos creado, viendo que se han hecho bien y que ocupan una cantidad de espacio razonable.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/syncweb$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED              SIZE
rsync               latest              cb33669eb5f6        &lt;span class="m"&gt;54&lt;/span&gt; seconds ago       &lt;span class="m"&gt;8&lt;/span&gt;.77 MB
web                 latest              1ae71f497ae0        About a minute ago   &lt;span class="m"&gt;5&lt;/span&gt;.75 MB
data                latest              cc6555822fd9        About a minute ago   &lt;span class="m"&gt;180&lt;/span&gt; B
gerard@aldebaran:~/docker/syncweb$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y ya solo nos queda levantar el entorno con &lt;strong&gt;docker-compose&lt;/strong&gt;, por ejemplo con un &lt;em&gt;docker-compose.yml&lt;/em&gt; como el que sigue:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/syncweb$ cat docker-compose.yml 
version: &lt;span class="s1"&gt;&amp;#39;2&amp;#39;&lt;/span&gt;
services:
  data:
    image: data
    hostname: data
    container_name: data
    volumes:
      - /srv/www
  rsync:
    image: rsync
    hostname: rsync
    container_name: rsync
    ports:
      - &lt;span class="s2"&gt;&amp;quot;22:22&amp;quot;&lt;/span&gt;
    volumes_from:
      - data
  web:
    image: web
    hostname: web
    container_name: web
    ports:
      - &lt;span class="s2"&gt;&amp;quot;8000:80&amp;quot;&lt;/span&gt;
    volumes_from:
      - data
gerard@aldebaran:~/docker/syncweb$ docker-compose up -d
Creating network &lt;span class="s2"&gt;&amp;quot;syncweb_default&amp;quot;&lt;/span&gt; with the default driver
Creating data
Creating rsync
Creating web
gerard@aldebaran:~/docker/syncweb$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;De esta forma, todos importan el contenedor de datos, y podemos copiar ficheros por &lt;strong&gt;rsync&lt;/strong&gt; al puerto 22, y ver la web en el puerto 8000. Cambiad estos valores según vuestras necesidades.&lt;/p&gt;
&lt;h2&gt;Comprobaciones&lt;/h2&gt;
&lt;p&gt;Vemos que si hacemos una petición normal, nos devuelve el contenido inicial.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/syncweb$ curl http://localhost:8000/
&amp;lt;h1&amp;gt;Hello world&amp;lt;/h1&amp;gt;
&amp;lt;p&amp;gt;This is a placeholder file&amp;lt;/p&amp;gt;
gerard@aldebaran:~/docker/syncweb$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Eso significa que el servidor web funciona y está sirviendo el contenido del contenedor de datos. Ahora vamos a probar que el contenedor &lt;strong&gt;rsync&lt;/strong&gt; puede actualizar este contenido. Para comodidad lo he puesto en un &lt;em&gt;script&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/syncweb$ cat sync.sh 
&lt;span class="c1"&gt;#!/bin/bash&lt;/span&gt;

rsync -rvzc --delete content/ web@localhost:/srv/www/
gerard@aldebaran:~/docker/syncweb$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Asumimos que tenemos la carpeta &lt;code&gt;content/&lt;/code&gt; con otro fichero &lt;em&gt;index.html&lt;/em&gt;. Lo he creado a mano para la prueba, pero esto podría aparecer generado por un &lt;a href="http://www.linuxsysadmin.ml/2017/03/generadores-de-contenido-web-estaticos.html"&gt;generador de contenido estático&lt;/a&gt;. Lanzamos el &lt;em&gt;script&lt;/em&gt; por primera vez:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/syncweb$ ./sync.sh 
Warning: Permanently added &lt;span class="s1"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;RSA&lt;span class="o"&gt;)&lt;/span&gt; to the list of known hosts.
web@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
Could not chdir to home directory /home/web: No such file or directory
sending incremental file list
index.html

sent &lt;span class="m"&gt;182&lt;/span&gt; bytes  received &lt;span class="m"&gt;41&lt;/span&gt; bytes  &lt;span class="m"&gt;63&lt;/span&gt;.71 bytes/sec
total size is &lt;span class="m"&gt;60&lt;/span&gt;  speedup is &lt;span class="m"&gt;0&lt;/span&gt;.27
gerard@aldebaran:~/docker/syncweb$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El fichero &lt;em&gt;index.html&lt;/em&gt; ha cambiado, así que lo vuelve a enviar, y por supuesto, es lo que el servidor web va a servir, cosa que demuestra que también hace uso del contenedor de datos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/syncweb$ curl http://localhost:8000/
&amp;lt;h1&amp;gt;My autogenerated blog&amp;lt;/h1&amp;gt;
&amp;lt;p&amp;gt;This is the home page&amp;lt;/p&amp;gt;
gerard@aldebaran:~/docker/syncweb$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para comprobar el carácter incremental de &lt;strong&gt;rsync&lt;/strong&gt;, vamos a añadir un nuevo fichero &lt;em&gt;.html&lt;/em&gt; y a ejecutar de nuevo. En caso de un generador estático, veremos que solo se enviarían las nuevas páginas y aquellos índices que hayan cambiado, resultando en una ganancia alta, a nivel de tamaño enviado y tiempo invertido.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/syncweb$ ./sync.sh 
Warning: Permanently added &lt;span class="s1"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;RSA&lt;span class="o"&gt;)&lt;/span&gt; to the list of known hosts.
web@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
Could not chdir to home directory /home/web: No such file or directory
sending incremental file list
newpage.html

sent &lt;span class="m"&gt;179&lt;/span&gt; bytes  received &lt;span class="m"&gt;35&lt;/span&gt; bytes  &lt;span class="m"&gt;47&lt;/span&gt;.56 bytes/sec
total size is &lt;span class="m"&gt;71&lt;/span&gt;  speedup is &lt;span class="m"&gt;0&lt;/span&gt;.33
gerard@aldebaran:~/docker/syncweb$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Solo ha enviado el fichero nuevo, puesto que es un cambio con respecto a lo que ya tiene. De hecho, de no haber cambios, no se enviaría nada.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/syncweb$ ./sync.sh 
Warning: Permanently added &lt;span class="s1"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;RSA&lt;span class="o"&gt;)&lt;/span&gt; to the list of known hosts.
web@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
Could not chdir to home directory /home/web: No such file or directory
sending incremental file list

sent &lt;span class="m"&gt;128&lt;/span&gt; bytes  received &lt;span class="m"&gt;12&lt;/span&gt; bytes  &lt;span class="m"&gt;56&lt;/span&gt;.00 bytes/sec
total size is &lt;span class="m"&gt;71&lt;/span&gt;  speedup is &lt;span class="m"&gt;0&lt;/span&gt;.51
gerard@aldebaran:~/docker/syncweb$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto tenemos nuestro pequeño entorno funcional.&lt;/p&gt;</content><category term="docker"></category><category term="docker-compose"></category><category term="nginx"></category><category term="volumenes"></category><category term="rsync"></category><category term="rssh"></category></entry><entry><title>Múltiples servicios en un mismo contenedor Docker</title><link href="http://www.linuxsysadmin.ml/2017/03/multiples-servicios-en-un-mismo-contenedor-docker.html" rel="alternate"></link><published>2017-03-06T10:00:00+01:00</published><updated>2017-03-06T10:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-03-06:/2017/03/multiples-servicios-en-un-mismo-contenedor-docker.html</id><summary type="html">&lt;p&gt;Como ya sabemos, un contenedor &lt;strong&gt;docker&lt;/strong&gt; solo puede ejecutar un proceso, y su finalización implica la parada del contenedor. Sin embargo, a veces nos puede interesar cargar los contenedores con algún servicio más, para hacerlos autosuficientes. Para ello, nos podemos ayudar de un &lt;em&gt;gestor de procesos&lt;/em&gt;, como por ejemplo, &lt;strong&gt;runit …&lt;/strong&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Como ya sabemos, un contenedor &lt;strong&gt;docker&lt;/strong&gt; solo puede ejecutar un proceso, y su finalización implica la parada del contenedor. Sin embargo, a veces nos puede interesar cargar los contenedores con algún servicio más, para hacerlos autosuficientes. Para ello, nos podemos ayudar de un &lt;em&gt;gestor de procesos&lt;/em&gt;, como por ejemplo, &lt;strong&gt;runit&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Antes de nada, &lt;a href="https://blog.docker.com/2014/06/why-you-dont-need-to-run-sshd-in-docker/"&gt;una referencia en contra&lt;/a&gt;; esto complica nuestro contenedor de una forma no recomendad por el propia autor de &lt;strong&gt;docker&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you need multiple processes, you need to add one at the top-level to take care of the others. In other words, you’re turning a lean and simple container into something much more complicated.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Avisados quedáis; a partir de aquí, vamos a ver como hacerlo con un ejemplo bastante extendido: un servidor &lt;a href="https://es.wikipedia.org/wiki/LAMP"&gt;LAMP&lt;/a&gt;. La idea es que usaremos un &lt;em&gt;gestor de procesos&lt;/em&gt; llamado &lt;strong&gt;runit&lt;/strong&gt; (aunque hay otros candidatos), que me gusta por su simplicidad.&lt;/p&gt;
&lt;h2&gt;Ejemplo: El contenedor LAMP&lt;/h2&gt;
&lt;p&gt;Nuestro contenedor va a ser un servidor muy clásico, con un &lt;strong&gt;apache&lt;/strong&gt;, un &lt;strong&gt;mysql&lt;/strong&gt;, &lt;strong&gt;php5&lt;/strong&gt; y los paquetes que esta configuración requiera, como por ejemplo, el driver de la base de datos &lt;strong&gt;php5-mysql&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AVISO&lt;/strong&gt;: No voy a añadir las instrucciones de &lt;em&gt;docker build&lt;/em&gt; ni de &lt;em&gt;docker run&lt;/em&gt; porque no aportan nada nuevo. Mejor centrémonos en las partes importantes.&lt;/p&gt;
&lt;p&gt;Vamos a utilizar la siguiente topología en la carpeta del &lt;em&gt;Dockerfile&lt;/em&gt;. La idea es que vamos a alojar el código &lt;strong&gt;php&lt;/strong&gt; en la carpeta &lt;em&gt;www&lt;/em&gt;, las configuraciones del &lt;strong&gt;apache&lt;/strong&gt; en la carpeta &lt;em&gt;apache2&lt;/em&gt; y las configuraciones de &lt;strong&gt;runit&lt;/strong&gt; en &lt;em&gt;services&lt;/em&gt;. No hay configuración específica para el &lt;strong&gt;mysql&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@antares:~/docker/lamp$ tree
.
├── apache2
│   ├── custom.conf
│   └── site.conf
├── services
│   ├── apache2
│   │   └── run
│   └── mysql
│       └── run
├── www
│   └── adminer.php
└── Dockerfile

&lt;span class="m"&gt;5&lt;/span&gt; directories, &lt;span class="m"&gt;6&lt;/span&gt; files
gerard@antares:~/docker/lamp$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y como no, el &lt;em&gt;Dockerfile&lt;/em&gt; usado:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@antares:~/docker/lamp$ cat Dockerfile 
FROM debian:jessie
ENV DEBIAN_FRONTEND noninteractive

&lt;span class="c1"&gt;# Paquetes necesarios&lt;/span&gt;
RUN apt-get update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    apt-get install -y runit php5 php5-mysql mysql-server &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    rm -rf /var/lib/apt/lists/*

&lt;span class="c1"&gt;# Configuracion de runit&lt;/span&gt;
COPY services /etc/service

&lt;span class="c1"&gt;# Configuracion de apache&lt;/span&gt;
RUN unlink /etc/apache2/sites-enabled/000-default.conf
COPY apache2/custom.conf /etc/apache2/conf-enabled

&lt;span class="c1"&gt;# Configuracion y contenido del sitio&lt;/span&gt;
COPY apache2/site.conf /etc/apache2/sites-enabled
COPY www /srv/www

CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/usr/bin/runsvdir&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;/etc/service&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@antares:~/docker/lamp$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Runit&lt;/h3&gt;
&lt;p&gt;El proceso principal, que se va a dedicar a controlar los otros procesos es &lt;strong&gt;runit&lt;/strong&gt;, concretamente mediante el binario &lt;em&gt;runsvdir&lt;/em&gt;. De acuerdo a nuestro &lt;em&gt;Dockerfile&lt;/em&gt;, va a gestionar un proceso por carpeta en &lt;em&gt;/etc/service&lt;/em&gt;. Dentro de esta carpeta va a tener información de ejecución e información de estado.&lt;/p&gt;
&lt;p&gt;Es importante poner un &lt;em&gt;script&lt;/em&gt; llamado &lt;em&gt;run&lt;/em&gt; con permisos de ejecución, que es el &lt;em&gt;script&lt;/em&gt; que &lt;strong&gt;runit&lt;/strong&gt; va a ejecutar y monitorizar, reiniciándolo en caso de caerse. No hay sorpresas en estos &lt;em&gt;scripts&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@antares:~/docker/lamp$ cat services/apache2/run 
&lt;span class="c1"&gt;#!/bin/sh&lt;/span&gt;

&lt;span class="nb"&gt;exec&lt;/span&gt; /usr/sbin/apache2ctl -D FOREGROUND
gerard@antares:~/docker/lamp$ cat services/mysql/run 
&lt;span class="c1"&gt;#!/bin/sh&lt;/span&gt;

&lt;span class="nb"&gt;exec&lt;/span&gt; /usr/bin/mysqld_safe
gerard@antares:~/docker/lamp$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Apache&lt;/h3&gt;
&lt;p&gt;El &lt;strong&gt;apache&lt;/strong&gt; necesita la configuración del &lt;em&gt;virtualhost&lt;/em&gt; que le indica lo que debe servir, y donde está; esto debe ir en &lt;em&gt;/etc/apache2/sites-enabled&lt;/em&gt;, de acuerdo con el &lt;em&gt;layout&lt;/em&gt; de directorios que utiliza la distribución usada (&lt;strong&gt;Debian&lt;/strong&gt; en este caso). Hemos eliminado el &lt;em&gt;virtualhost&lt;/em&gt; que viene por defecto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@antares:~/docker/lamp$ cat apache2/site.conf 
&amp;lt;VirtualHost *:80&amp;gt;
    DocumentRoot /srv/www
    LogLevel info
    ErrorLog &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;APACHE_LOG_DIR&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;/error.log
    CustomLog &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;APACHE_LOG_DIR&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;/access.log combined
&amp;lt;/VirtualHost&amp;gt;
gerard@antares:~/docker/lamp$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El otro punto conflictivo es que el fichero de configuración base no lleva permisos para servir nada en &lt;em&gt;/srv/www&lt;/em&gt;, sino en &lt;em&gt;/var/www&lt;/em&gt;. Personalmente creo que el contenido debería estar en &lt;em&gt;/srv/www&lt;/em&gt;, así que tengo que añadir estos permisos, que se puede hacer cómodamente con un fichero adicional en la carpeta &lt;em&gt;/etc/apache2/conf-enabled&lt;/em&gt;, que se incluye desde el fichero &lt;em&gt;/etc/apache2/apache2.conf&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@antares:~/docker/lamp$ cat apache2/custom.conf 
&amp;lt;Directory /srv/&amp;gt;
    Options Indexes FollowSymLinks
    AllowOverride None
    Require all granted
&amp;lt;/Directory&amp;gt;
gerard@antares:~/docker/lamp$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;MySQL&lt;/h3&gt;
&lt;p&gt;No hay nada especial para &lt;strong&gt;mysql&lt;/strong&gt;. Simplemente dejamos que la variable de entorno &lt;em&gt;DEBIAN_FRONTEND&lt;/em&gt; indique a &lt;strong&gt;apt-get&lt;/strong&gt; que no pregunte una contraseña para el usuario &lt;em&gt;root&lt;/em&gt;, quedando este usuario sin contraseña. Esto debe ser revisado con esmero.&lt;/p&gt;
&lt;h3&gt;Contenido web&lt;/h3&gt;
&lt;p&gt;Para mantener limpia la carpeta de &lt;em&gt;build&lt;/em&gt;, he decidido poner el contenido web en una carpeta &lt;em&gt;www&lt;/em&gt; aparte. Simplemente se trata del &lt;em&gt;document root&lt;/em&gt; de nuestro &lt;em&gt;virtualhost&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;En este caso se ha usado &lt;a href="https://www.adminer.org/"&gt;Adminer&lt;/a&gt; que es una aplicación prefabricada de un solo fichero para administrar nuestra base de datos. La parte interesante es que se trata de algo hecho en &lt;strong&gt;php&lt;/strong&gt; que se conecta a nuestro &lt;strong&gt;mysql&lt;/strong&gt;, y nos demuestra que todo funciona. Reemplazad el contenido de esta carpeta por vuestro código final.&lt;/p&gt;
&lt;h3&gt;Más servicios&lt;/h3&gt;
&lt;p&gt;Se necesita subir código mediante un servidor &lt;strong&gt;FTP&lt;/strong&gt; o &lt;strong&gt;SFTP&lt;/strong&gt;, algún &lt;strong&gt;cron job&lt;/strong&gt;, &lt;strong&gt;logrotate&lt;/strong&gt; o lo que sea? Pues usad la misma filosofía: instalad, configurad e instruid a &lt;strong&gt;runit&lt;/strong&gt; para que levante el proceso. Sin límites.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RESULTADO&lt;/strong&gt;: Tras construir la imagen y ejecutarla, ya tenemos nuestro servidor funcionando en un solo contenedor.&lt;/p&gt;</content><category term="docker"></category><category term="runit"></category><category term="LAMP"></category><category term="apache"></category><category term="mysql"></category><category term="php"></category></entry><entry><title>Alta disponibilidad con Keepalived</title><link href="http://www.linuxsysadmin.ml/2017/02/alta-disponibilidad-con-keepalived.html" rel="alternate"></link><published>2017-02-27T10:00:00+01:00</published><updated>2017-02-27T10:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-02-27:/2017/02/alta-disponibilidad-con-keepalived.html</id><summary type="html">&lt;p&gt;Cuando tenemos un servicio balanceado, los &lt;em&gt;backends&lt;/em&gt; no tienen relación entre sí y podemos poner tantos como queramos, sin miedo a que alguno se caiga. Sin embargo, para los servicios tipo "ventanilla única" interesa tener varios dispuestos a dar un servicio &lt;em&gt;failover&lt;/em&gt;; si uno se cae, otro asume la carga …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Cuando tenemos un servicio balanceado, los &lt;em&gt;backends&lt;/em&gt; no tienen relación entre sí y podemos poner tantos como queramos, sin miedo a que alguno se caiga. Sin embargo, para los servicios tipo "ventanilla única" interesa tener varios dispuestos a dar un servicio &lt;em&gt;failover&lt;/em&gt;; si uno se cae, otro asume la carga.&lt;/p&gt;
&lt;p&gt;La idea general es que existe una dirección IP flotante y existe un servicio que se dedica a decidir quién la tiene asignada. Uno de estos servicios es &lt;strong&gt;keepalived&lt;/strong&gt;, que es sencillo y fácil de montar.&lt;/p&gt;
&lt;h2&gt;El entorno de trabajo&lt;/h2&gt;
&lt;p&gt;Para hacer este ejemplo, he dispuesto dos máquinas, una como prioritaria, y una de &lt;em&gt;failover&lt;/em&gt;, que va a asumir el servicio siempre que la otra no pueda hacerlo.&lt;/p&gt;
&lt;p&gt;Para mi comodidad, he dispuesto contenedores &lt;strong&gt;docker&lt;/strong&gt;, como se describe en &lt;a href="http://www.linuxsysadmin.ml/2016/06/controlando-contenedores-docker-con-ansible.html"&gt;otro artículo&lt;/a&gt; y voy a hacer la instalación por &lt;strong&gt;ansible&lt;/strong&gt;. Aunque el entorno no es muy complejo, por comodidad lo he levantado con &lt;strong&gt;docker-compose&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@gatria:~/docker/keepalived$ cat docker-compose.yml 
version: &lt;span class="s1"&gt;&amp;#39;2&amp;#39;&lt;/span&gt;
services:
  gemini:
    image: master
    hostname: gemini
    container_name: gemini
    volumes:
      - ./playbooks:/root/playbooks:ro
      - ./inventory/hosts:/root/inventory/hosts:ro
    ports:
      - &lt;span class="s2"&gt;&amp;quot;22:22&amp;quot;&lt;/span&gt;
  castor:
    image: slave
    hostname: castor
    container_name: castor
    privileged: &lt;span class="nb"&gt;true&lt;/span&gt;
  pollux:
    image: slave
    hostname: pollux
    container_name: pollux
    privileged: &lt;span class="nb"&gt;true&lt;/span&gt;
gerard@gatria:~/docker/keepalived$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La diferencia radica en que he puesto un servidor &lt;strong&gt;SSH&lt;/strong&gt; en la máquina &lt;em&gt;master&lt;/em&gt; para poder acceder fácilmente a ella y que los &lt;em&gt;playbooks&lt;/em&gt; y parte del inventario vienen de la máquina &lt;em&gt;host&lt;/em&gt;, para su fácil edición con un editor adecuado.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AVISO&lt;/strong&gt;: Las máquinas &lt;em&gt;slave&lt;/em&gt; van a disputarse la dirección flotante; esto no es posible en un contenedor normal. Para evitar ese problema, les he puesto el &lt;em&gt;flag privilieged&lt;/em&gt;, para que puedan hacer lo que quieran.&lt;/p&gt;
&lt;p&gt;Finalmente creamos el entorno, con el comando adecuado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@gatria:~/docker/keepalived$ docker-compose up -d
Creating network &lt;span class="s2"&gt;&amp;quot;keepalived_default&amp;quot;&lt;/span&gt; with the default driver
Creating gemini
Creating castor
Creating pollux
gerard@gatria:~/docker/keepalived$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Todos los comandos a partir de ahora se vana ejecutar en &lt;em&gt;gemini&lt;/em&gt;, que es el &lt;em&gt;master&lt;/em&gt; de &lt;strong&gt;ansible&lt;/strong&gt;, y al que vamos a acceder por &lt;strong&gt;SSH&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@gatria:~/docker/keepalived$ ssh root@localhost
Warning: Permanently added &lt;span class="s1"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;ECDSA&lt;span class="o"&gt;)&lt;/span&gt; to the list of known hosts.
root@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 

The programs included with the Debian GNU/Linux system are free software&lt;span class="p"&gt;;&lt;/span&gt;
the exact distribution terms &lt;span class="k"&gt;for&lt;/span&gt; each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
root@gemini:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El fichero de &lt;em&gt;hosts&lt;/em&gt; no tiene ningún secreto (aparte de las variables dependientes de cada máquina, que ya veremos), pero lo ponemos por completitud:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~# cat inventory/hosts 
&lt;span class="o"&gt;[&lt;/span&gt;gemini&lt;span class="o"&gt;]&lt;/span&gt;
castor &lt;span class="nv"&gt;keepalived_priority&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;101&lt;/span&gt;
pollux &lt;span class="nv"&gt;keepalived_priority&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;
root@gemini:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Ofreciendo un servicio cualquiera&lt;/h2&gt;
&lt;p&gt;Normalmente, las máquinas en configuración de &lt;em&gt;failover&lt;/em&gt; suelen ser balanceadores o servidores web. En realidad, esto es irrelevante para &lt;strong&gt;keepalived&lt;/strong&gt;, así que vamos a poner cualquiera.&lt;/p&gt;
&lt;p&gt;Nos hemos decantado por un servidor &lt;strong&gt;nginx&lt;/strong&gt; en configuración de servidor web estático, para que no absorba la atención del artículo. En la vida real, estaría en configuración de balanceador web, o sería directamente un &lt;strong&gt;haproxy&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Nos movemos a la carpeta de trabajo para este &lt;em&gt;playbook&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~# &lt;span class="nb"&gt;cd&lt;/span&gt; ~/playbooks/webserver/
root@gemini:~/playbooks/webserver# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El &lt;em&gt;playbook&lt;/em&gt; en sí no tiene mucho misterio; instala &lt;strong&gt;nginx&lt;/strong&gt;, lo levanta con una configuración propia y pone un fichero &lt;strong&gt;HTML&lt;/strong&gt; con una plantilla indicando el nombre de la máquina que ha servido la petición, a modo de chivato.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/webserver# cat webserver.yml 
- hosts: gemini
  gather_facts: &lt;span class="nb"&gt;false&lt;/span&gt;
  tasks:
    - apt: &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;nginx-light &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;present
    - file: &lt;span class="nv"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/etc/nginx/sites-enabled/default &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;absent
    - file: &lt;span class="nv"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/www &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;directory
    - template: &lt;span class="nv"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;web.j2 &lt;span class="nv"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/etc/nginx/sites-enabled/web
    - template: &lt;span class="nv"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;index.html.j2 &lt;span class="nv"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/www/index.html
    - service: &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;nginx &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;started
    - service: &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;nginx &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;reloaded
root@gemini:~/playbooks/webserver# cat web.j2 
server &lt;span class="o"&gt;{&lt;/span&gt;
    listen &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    server_name _&lt;span class="p"&gt;;&lt;/span&gt;
    root /www&lt;span class="p"&gt;;&lt;/span&gt;
    index index.html&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@gemini:~/playbooks/webserver# cat index.html.j2 
&amp;lt;p&amp;gt;Hello from &amp;lt;em&amp;gt;&lt;span class="o"&gt;{{&lt;/span&gt; inventory_hostname &lt;span class="o"&gt;}}&lt;/span&gt;&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;
root@gemini:~/playbooks/webserver# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lo lanzamos y ya tenemos dos servidores web para nuestra demostración:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/webserver# ansible-playbook webserver.yml 

PLAY &lt;span class="o"&gt;[&lt;/span&gt;gemini&lt;span class="o"&gt;]&lt;/span&gt; ******************************************************************

TASK &lt;span class="o"&gt;[&lt;/span&gt;apt&lt;span class="o"&gt;]&lt;/span&gt; *********************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;castor&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;pollux&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;file&lt;span class="o"&gt;]&lt;/span&gt; ********************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;castor&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;pollux&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;file&lt;span class="o"&gt;]&lt;/span&gt; ********************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;pollux&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;castor&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;template&lt;span class="o"&gt;]&lt;/span&gt; ****************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;pollux&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;castor&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;template&lt;span class="o"&gt;]&lt;/span&gt; ****************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;castor&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;pollux&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;service&lt;span class="o"&gt;]&lt;/span&gt; *****************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;castor&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;pollux&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;service&lt;span class="o"&gt;]&lt;/span&gt; *****************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;pollux&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;castor&lt;span class="o"&gt;]&lt;/span&gt;

PLAY RECAP *********************************************************************
castor                     : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;   
pollux                     : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;   

root@gemini:~/playbooks/webserver# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Comprobamos que funciona, y con esto estamos:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/webserver# wget -qO- http://castor/
&amp;lt;p&amp;gt;Hello from &amp;lt;em&amp;gt;castor&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;
root@gemini:~/playbooks/webserver# wget -qO- http://pollux/
&amp;lt;p&amp;gt;Hello from &amp;lt;em&amp;gt;pollux&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;
root@gemini:~/playbooks/webserver# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Keepalived, o como compartir una dirección IP&lt;/h2&gt;
&lt;p&gt;Ante nada, nos movemos a la carpeta de trabajo:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/webserver# &lt;span class="nb"&gt;cd&lt;/span&gt; ~/playbooks/keepalived/
root@gemini:~/playbooks/keepalived# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Realmente, el servicio &lt;strong&gt;keepalived&lt;/strong&gt; es como cualquier otro: instalar, configurar y recargar la configuración. Lo importante en este caso son las configuraciones. Así que el &lt;em&gt;playbook&lt;/em&gt; queda un poco simple, pero mejor. Solo cabe destacar que he instalado también &lt;strong&gt;rsyslog&lt;/strong&gt; que me va a proporcionar capacidades de &lt;em&gt;syslog&lt;/em&gt;, que es donde &lt;strong&gt;keepalived&lt;/strong&gt; deja lo &lt;em&gt;logs&lt;/em&gt;. Gracias este &lt;em&gt;log&lt;/em&gt;, pude ver que hacía una operación no permitida para un contenedor normal.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/keepalived# cat keepalived.yml 
- hosts: gemini
  gather_facts: &lt;span class="nb"&gt;false&lt;/span&gt;
  tasks:
    - apt: &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;rsyslog &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;present
    - service: &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;rsyslog &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;started
- hosts: gemini
  gather_facts: &lt;span class="nb"&gt;false&lt;/span&gt;
  tasks:
    - apt: &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;keepalived &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;present
    - template: &lt;span class="nv"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;keepalived.conf.j2 &lt;span class="nv"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/etc/keepalived/keepalived.conf
    - service: &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;keepalived &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;restarted
root@gemini:~/playbooks/keepalived# cat keepalived.conf.j2 
vrrp_script chk_nginx &lt;span class="o"&gt;{&lt;/span&gt;
      script &lt;span class="s2"&gt;&amp;quot;killall -0 nginx&amp;quot;&lt;/span&gt;
      interval &lt;span class="m"&gt;2&lt;/span&gt;
      weight &lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

vrrp_instance VI_1 &lt;span class="o"&gt;{&lt;/span&gt;
      interface eth0
      state MASTER
      virtual_router_id &lt;span class="m"&gt;51&lt;/span&gt;
      priority &lt;span class="o"&gt;{{&lt;/span&gt; keepalived_priority &lt;span class="o"&gt;}}&lt;/span&gt;
      virtual_ipaddress &lt;span class="o"&gt;{&lt;/span&gt;
           &lt;span class="m"&gt;172&lt;/span&gt;.18.0.10
      &lt;span class="o"&gt;}&lt;/span&gt;
      track_script &lt;span class="o"&gt;{&lt;/span&gt;
           chk_nginx
      &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@gemini:~/playbooks/keepalived# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La idea es que cada máquina del &lt;em&gt;cluster&lt;/em&gt; tiene una prioridad, y la máquina con mas prioridad va a obtener la IP flotante, dando el servicio efectivo. Esta prioridad se ve afectada por los &lt;em&gt;checks&lt;/em&gt; que pongamos, sumando el &lt;em&gt;weight&lt;/em&gt; de cada &lt;em&gt;check&lt;/em&gt; que devuelva un código de retorno 0 (se considera un OK).&lt;/p&gt;
&lt;p&gt;Con los valores 101 y 100 (que salen del fichero de &lt;em&gt;hosts&lt;/em&gt;) y el propio funcionamiento de &lt;strong&gt;keepalived&lt;/strong&gt;, nos aseguramos de que:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Si una máquina está caída no es candidata a tener la IP flotante (las dos caídas son un tema serio).&lt;/li&gt;
&lt;li&gt;Si &lt;em&gt;castor&lt;/em&gt; tiene el &lt;strong&gt;nginx&lt;/strong&gt; funcional, suma 103, y gana a &lt;em&gt;pollux&lt;/em&gt; (102 o 100, dependiendo si corre o no el &lt;strong&gt;nginx&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;Si el &lt;strong&gt;nginx&lt;/strong&gt; de &lt;em&gt;castor&lt;/em&gt; no funciona, depende; si el de &lt;em&gt;pollux funciona, pasa este a ser el &lt;/em&gt;MASTER&lt;em&gt; del &lt;/em&gt;cluster&lt;em&gt; (101 vs 102); sino, gana &lt;/em&gt;castor* (101 vs 100), aunque este caso también es un problema.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lanzamos el &lt;em&gt;playbook&lt;/em&gt; para instalar &lt;strong&gt;keepalived&lt;/strong&gt; y su configuración:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/keepalived# ansible-playbook keepalived.yml 

PLAY &lt;span class="o"&gt;[&lt;/span&gt;gemini&lt;span class="o"&gt;]&lt;/span&gt; ******************************************************************

TASK &lt;span class="o"&gt;[&lt;/span&gt;apt&lt;span class="o"&gt;]&lt;/span&gt; *********************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;castor&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;pollux&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;service&lt;span class="o"&gt;]&lt;/span&gt; *****************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;pollux&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;castor&lt;span class="o"&gt;]&lt;/span&gt;

PLAY &lt;span class="o"&gt;[&lt;/span&gt;gemini&lt;span class="o"&gt;]&lt;/span&gt; ******************************************************************

TASK &lt;span class="o"&gt;[&lt;/span&gt;apt&lt;span class="o"&gt;]&lt;/span&gt; *********************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;pollux&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;castor&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;template&lt;span class="o"&gt;]&lt;/span&gt; ****************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;castor&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;pollux&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;service&lt;span class="o"&gt;]&lt;/span&gt; *****************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;castor&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;pollux&lt;span class="o"&gt;]&lt;/span&gt;

PLAY RECAP *********************************************************************
castor                     : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;   
pollux                     : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;   

root@gemini:~/playbooks/keepalived# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y solo nos queda observar quien tiene la IP flotante (es &lt;em&gt;castor&lt;/em&gt; porque ambos &lt;strong&gt;nginx&lt;/strong&gt; funcionan y es un 103 vs 102).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/keepalived# ansible -m raw -a &lt;span class="s1"&gt;&amp;#39;ip addr | grep &amp;quot;inet &amp;quot;&amp;#39;&lt;/span&gt; gemini
castor &lt;span class="p"&gt;|&lt;/span&gt; SUCCESS &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &amp;gt;&amp;gt;

    inet &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1/8 scope host lo
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.3/16 scope global eth0
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.10/32 scope global eth0


pollux &lt;span class="p"&gt;|&lt;/span&gt; SUCCESS &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &amp;gt;&amp;gt;

    inet &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1/8 scope host lo
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.4/16 scope global eth0


root@gemini:~/playbooks/keepalived# wget -qO- http://172.18.0.10/
&amp;lt;p&amp;gt;Hello from &amp;lt;em&amp;gt;castor&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;
root@gemini:~/playbooks/keepalived# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Pruebas de alta disponibilidad&lt;/h2&gt;
&lt;p&gt;Vamos a simular una caída de &lt;em&gt;castor&lt;/em&gt; o de su &lt;strong&gt;nginx&lt;/strong&gt; (el resultado es el mismo):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/keepalived# ansible -m service -a &lt;span class="s2"&gt;&amp;quot;name=nginx state=stopped&amp;quot;&lt;/span&gt; castor
castor &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;SUCCESS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;changed&amp;quot;&lt;/span&gt;: true, 
    &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;nginx&amp;quot;&lt;/span&gt;, 
    &lt;span class="s2"&gt;&amp;quot;state&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;stopped&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@gemini:~/playbooks/keepalived# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;¿Que pasa con la IP flotante? Por supuesto, la hereda &lt;em&gt;pollux&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/keepalived# ansible -m raw -a &lt;span class="s1"&gt;&amp;#39;ip addr | grep &amp;quot;inet &amp;quot;&amp;#39;&lt;/span&gt; gemini
castor &lt;span class="p"&gt;|&lt;/span&gt; SUCCESS &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &amp;gt;&amp;gt;

    inet &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1/8 scope host lo
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.3/16 scope global eth0


pollux &lt;span class="p"&gt;|&lt;/span&gt; SUCCESS &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &amp;gt;&amp;gt;


    inet &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1/8 scope host lo
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.4/16 scope global eth0
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.10/32 scope global eth0


root@gemini:~/playbooks/keepalived# wget -qO- http://172.18.0.10/
&amp;lt;p&amp;gt;Hello from &amp;lt;em&amp;gt;pollux&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;
root@gemini:~/playbooks/keepalived# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora simularemos que se cae &lt;em&gt;pollux&lt;/em&gt;. Esto nos deja sin servicio...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/keepalived# ansible -m service -a &lt;span class="s2"&gt;&amp;quot;name=nginx state=stopped&amp;quot;&lt;/span&gt; pollux
pollux &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;SUCCESS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;changed&amp;quot;&lt;/span&gt;: true, 
    &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;nginx&amp;quot;&lt;/span&gt;, 
    &lt;span class="s2"&gt;&amp;quot;state&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;stopped&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@gemini:~/playbooks/keepalived# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como las dos máquinas están levantadas, se trata de un 101 vs 100, lo que le da la IP a &lt;em&gt;castor&lt;/em&gt;. El servicio no responde porque el &lt;strong&gt;nginx&lt;/strong&gt; de &lt;em&gt;castor&lt;/em&gt; está caído. Mal asunto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/keepalived# ansible -m raw -a &lt;span class="s1"&gt;&amp;#39;ip addr | grep &amp;quot;inet &amp;quot;&amp;#39;&lt;/span&gt; gemini
pollux &lt;span class="p"&gt;|&lt;/span&gt; SUCCESS &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &amp;gt;&amp;gt;

    inet &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1/8 scope host lo
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.4/16 scope global eth0


castor &lt;span class="p"&gt;|&lt;/span&gt; SUCCESS &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &amp;gt;&amp;gt;

    inet &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1/8 scope host lo
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.3/16 scope global eth0
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.10/32 scope global eth0


root@gemini:~/playbooks/keepalived# wget -O- http://172.18.0.10/
converted &lt;span class="s1"&gt;&amp;#39;http://172.18.0.10/&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;ANSI_X3.4-1968&lt;span class="o"&gt;)&lt;/span&gt; -&amp;gt; &lt;span class="s1"&gt;&amp;#39;http://172.18.0.10/&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;UTF-8&lt;span class="o"&gt;)&lt;/span&gt;
--2016-10-14 &lt;span class="m"&gt;11&lt;/span&gt;:00:08--  http://172.18.0.10/
Connecting to &lt;span class="m"&gt;172&lt;/span&gt;.18.0.10:80... failed: Connection refused.
root@gemini:~/playbooks/keepalived# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora, supongamos que &lt;em&gt;pollux&lt;/em&gt; se recupera.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/keepalived# ansible -m service -a &lt;span class="s2"&gt;&amp;quot;name=nginx state=started&amp;quot;&lt;/span&gt; pollux
pollux &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;SUCCESS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;changed&amp;quot;&lt;/span&gt;: true, 
    &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;nginx&amp;quot;&lt;/span&gt;, 
    &lt;span class="s2"&gt;&amp;quot;state&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;started&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@gemini:~/playbooks/keepalived# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Sin sorpresas, asume la IP flotante (101 vs 102).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/keepalived# ansible -m raw -a &lt;span class="s1"&gt;&amp;#39;ip addr | grep &amp;quot;inet &amp;quot;&amp;#39;&lt;/span&gt; gemini
pollux &lt;span class="p"&gt;|&lt;/span&gt; SUCCESS &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &amp;gt;&amp;gt;

    inet &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1/8 scope host lo
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.4/16 scope global eth0
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.10/32 scope global eth0


castor &lt;span class="p"&gt;|&lt;/span&gt; SUCCESS &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &amp;gt;&amp;gt;

    inet &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1/8 scope host lo
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.3/16 scope global eth0


root@gemini:~/playbooks/keepalived# wget -qO- http://172.18.0.10/
&amp;lt;p&amp;gt;Hello from &amp;lt;em&amp;gt;pollux&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;
root@gemini:~/playbooks/keepalived# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y finalmente se recupera &lt;em&gt;castor&lt;/em&gt;, lo que le da la prioridad para asumir su posición como &lt;em&gt;master&lt;/em&gt; del &lt;em&gt;cluster&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/keepalived# ansible -m service -a &lt;span class="s2"&gt;&amp;quot;name=nginx state=started&amp;quot;&lt;/span&gt; castor
castor &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;SUCCESS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;changed&amp;quot;&lt;/span&gt;: true, 
    &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;nginx&amp;quot;&lt;/span&gt;, 
    &lt;span class="s2"&gt;&amp;quot;state&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;started&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@gemini:~/playbooks/keepalived# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y sin sorpresas, recibe las peticiones para sí mismo:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@gemini:~/playbooks/keepalived# ansible -m raw -a &lt;span class="s1"&gt;&amp;#39;ip addr | grep &amp;quot;inet &amp;quot;&amp;#39;&lt;/span&gt; gemini
castor &lt;span class="p"&gt;|&lt;/span&gt; SUCCESS &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &amp;gt;&amp;gt;

    inet &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1/8 scope host lo
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.3/16 scope global eth0
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.10/32 scope global eth0


pollux &lt;span class="p"&gt;|&lt;/span&gt; SUCCESS &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &amp;gt;&amp;gt;

    inet &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1/8 scope host lo
    inet &lt;span class="m"&gt;172&lt;/span&gt;.18.0.4/16 scope global eth0


root@gemini:~/playbooks/keepalived# wget -qO- http://172.18.0.10/
&amp;lt;p&amp;gt;Hello from &amp;lt;em&amp;gt;castor&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;
root@gemini:~/playbooks/keepalived# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En caso de haberse levantado antes &lt;em&gt;castor&lt;/em&gt;, habría ejercido como &lt;em&gt;master&lt;/em&gt; enseguida, y el levantamiento de &lt;em&gt;pollux&lt;/em&gt; no habría provocado un &lt;em&gt;failover&lt;/em&gt; nuevo (103 vs 100 y 103 vs 102, respectivamente).&lt;/p&gt;
&lt;p&gt;Y con esto ya podemos tener nuestros servicios y balanceadores tipo "ventanilla única" redundados y con alta disponibilidad. Cabe indicar que esto no es útil ni con los &lt;em&gt;bakcends&lt;/em&gt; (el balanceador ya suele controlar si una de ellos está caído o no), ni con los &lt;em&gt;clusters&lt;/em&gt; con tecnología de &lt;em&gt;clustering&lt;/em&gt; propia (bases de datos, colas, ...).&lt;/p&gt;</content><category term="keepalived"></category><category term="failover"></category><category term="ansible"></category><category term="ip flotante"></category></entry><entry><title>Compartiendo carpetas con NFS</title><link href="http://www.linuxsysadmin.ml/2017/02/compartiendo-carpetas-con-nfs.html" rel="alternate"></link><published>2017-02-06T10:00:00+01:00</published><updated>2017-02-06T10:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-02-06:/2017/02/compartiendo-carpetas-con-nfs.html</id><summary type="html">&lt;p&gt;Son muchas las veces que queremos tener una carpeta disponible en todas las máquinas que usamos habitualmente, sea una unidad de &lt;em&gt;backup&lt;/em&gt;, o sea una carpeta de intercambio de fotos. Disponemos de servidores tipo FTP, pero es mas cómodo tener una unidad remota como una carpeta mas de nuestra máquina …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Son muchas las veces que queremos tener una carpeta disponible en todas las máquinas que usamos habitualmente, sea una unidad de &lt;em&gt;backup&lt;/em&gt;, o sea una carpeta de intercambio de fotos. Disponemos de servidores tipo FTP, pero es mas cómodo tener una unidad remota como una carpeta mas de nuestra máquina.&lt;/p&gt;
&lt;p&gt;Para esta guía, vamos a utilizar dos máquinas &lt;em&gt;Debian Jessie&lt;/em&gt;, actuando como el servidor (el que tiene las carpetas compartidas) y como el cliente (el ordenador de un usuario concreto).&lt;/p&gt;
&lt;p&gt;Un &lt;em&gt;setup&lt;/em&gt; mas realista sería poner el servidor en un servidor casero (tipo &lt;em&gt;Raspberry Pi&lt;/em&gt;), mientras que los ordenadores cliente serían los de los diferentes usuarios de casa.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CUIDADO&lt;/strong&gt;: El servidor NFS de &lt;em&gt;linux&lt;/em&gt; va por &lt;em&gt;kernel&lt;/em&gt;, así que nos os va a funcionar desde un contenedor, por ejemplo &lt;em&gt;LXC&lt;/em&gt; o &lt;em&gt;Docker&lt;/em&gt;. En este caso, las máquinas disponen de &lt;em&gt;kernel&lt;/em&gt; completo, porque se han utilizado &lt;em&gt;VirtualBox&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Así pues, disponemos de 2 máquinas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;server&lt;/strong&gt; &amp;rarr; 10.0.0.2&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;client&lt;/strong&gt; &amp;rarr; 10.0.0.3&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Preparando el servidor&lt;/h2&gt;
&lt;p&gt;Para preparar el servidor, necesitamos instalar el paquete que provee el servidor de &lt;strong&gt;NFS&lt;/strong&gt;, que en este caso es &lt;strong&gt;nfs-kernel-server&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# apt-get install -y nfs-kernel-server
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  file libevent-2.0-5 libldap-2.4-2 libmagic1 libnfsidmap2 libpython-stdlib libpython2.7-minimal libpython2.7-stdlib libsasl2-2
  libsasl2-modules libsasl2-modules-db libsqlite3-0 libtirpc1 mime-support nfs-common python python-minimal python2.7
  python2.7-minimal rpcbind
Paquetes sugeridos:
  libsasl2-modules-otp libsasl2-modules-ldap libsasl2-modules-sql libsasl2-modules-gssapi-mit libsasl2-modules-gssapi-heimdal
  open-iscsi watchdog python-doc python-tk python2.7-doc binutils binfmt-support
Se instalarán los siguientes paquetes NUEVOS:
  file libevent-2.0-5 libldap-2.4-2 libmagic1 libnfsidmap2 libpython-stdlib libpython2.7-minimal libpython2.7-stdlib libsasl2-2
  libsasl2-modules libsasl2-modules-db libsqlite3-0 libtirpc1 mime-support nfs-common nfs-kernel-server python python-minimal
  python2.7 python2.7-minimal rpcbind
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;21&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;6&lt;/span&gt;.072 kB de archivos.
Se utilizarán &lt;span class="m"&gt;23&lt;/span&gt;,7 MB de espacio de disco adicional después de esta operación.
...
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Supongamos que queremos compartir la carpeta &lt;em&gt;/shared/&lt;/em&gt;, lo que significa que tenemos que crearla si no existiera, y hay que darle los permisos adecuados al uso que se le vaya a dar. A modo de ejemplo, vamos a dar todos los permisos posibles a todo el mundo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mkdir /shared
root@server:~# chmod &lt;span class="m"&gt;777&lt;/span&gt; /shared/
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a declarar este punto &lt;em&gt;exportable&lt;/em&gt;, con permisos de escritura para las máquinas que lo necesiten.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cat /etc/exports
/shared &lt;span class="m"&gt;10&lt;/span&gt;.0.0.3&lt;span class="o"&gt;(&lt;/span&gt;rw,sync&lt;span class="o"&gt;)&lt;/span&gt;
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente hacemos un &lt;em&gt;restart&lt;/em&gt; o un &lt;em&gt;reload&lt;/em&gt; del servicio de &lt;strong&gt;NFS&lt;/strong&gt; para que recargue la configuración.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AVISO&lt;/strong&gt;: Este servicio no arranca en contenedores.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# systemctl restart nfs-kernel-server
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto ya tenemos nuestra carpeta &lt;em&gt;exportable&lt;/em&gt; disponible para los clientes definidos en &lt;em&gt;/etc/exports&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Preparando una de las máquinas cliente&lt;/h2&gt;
&lt;p&gt;El primer paso consiste en instalar el paquete &lt;strong&gt;nfs-common&lt;/strong&gt;, que nos va a proveer de las utilidades necesarias para montar el sistema de ficheros remoto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# apt-get install -y nfs-common
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  file libevent-2.0-5 libldap-2.4-2 libmagic1 libnfsidmap2 libpython-stdlib libpython2.7-minimal libpython2.7-stdlib libsasl2-2
  libsasl2-modules libsasl2-modules-db libsqlite3-0 libtirpc1 mime-support python python-minimal python2.7 python2.7-minimal
  rpcbind
Paquetes sugeridos:
  libsasl2-modules-otp libsasl2-modules-ldap libsasl2-modules-sql libsasl2-modules-gssapi-mit libsasl2-modules-gssapi-heimdal
  open-iscsi watchdog python-doc python-tk python2.7-doc binutils binfmt-support
Se instalarán los siguientes paquetes NUEVOS:
  file libevent-2.0-5 libldap-2.4-2 libmagic1 libnfsidmap2 libpython-stdlib libpython2.7-minimal libpython2.7-stdlib libsasl2-2
  libsasl2-modules libsasl2-modules-db libsqlite3-0 libtirpc1 mime-support nfs-common python python-minimal python2.7
  python2.7-minimal rpcbind
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;20&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;5&lt;/span&gt;.954 kB de archivos.
Se utilizarán &lt;span class="m"&gt;23&lt;/span&gt;,3 MB de espacio de disco adicional después de esta operación.
...
root@client:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos un punto de montaje para la carpeta remota, en caso de necesitarla.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# mkdir /compartida
root@client:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y montamos la carpeta remota, usando las herramientas estándar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# mount -t nfs &lt;span class="m"&gt;10&lt;/span&gt;.0.0.2:/shared /compartida
root@client:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Si nos gustara el resultado, podemos hacer el montaje automático añadiendo una línea en &lt;em&gt;/etc/fstab&lt;/em&gt;, que podéis copiar tal cual de &lt;em&gt;/etc/mtab&lt;/em&gt; cuando la carpeta remota esté montada.&lt;/p&gt;
&lt;h2&gt;Algunas pruebas de funcionamiento&lt;/h2&gt;
&lt;p&gt;Partimos de una carpeta compartida vacía, y vemos que también está vacía en el cliente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# ls /shared/
root@server:~#

root@client:~# ls /compartida/
root@client:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora podemos crear un fichero cualquiera en la máquina cliente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# touch /compartida/client_data
root@client:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Podemos ver que no hay ningún problema por trabajar en la carpeta desde otra máquina, por ejemplo, creando un fichero en la máquina servidor.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# touch /shared/server_data
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente vemos que la carpeta, sea la carpeta local del servidor o la carpeta montada remotamente del cliente, reflejan ambos cambios aplicados anteriormente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# ls /shared/
client_data  server_data
root@server:~#

root@client:~# ls /compartida/
client_data  server_data
root@client:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto vemos que funciona como debe.&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="NFS"></category></entry><entry><title>Un registro local de Docker</title><link href="http://www.linuxsysadmin.ml/2017/01/un-registro-local-de-docker.html" rel="alternate"></link><published>2017-01-09T10:00:00+01:00</published><updated>2017-01-09T10:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2017-01-09:/2017/01/un-registro-local-de-docker.html</id><summary type="html">&lt;p&gt;He llegado a ese momento en el que el número de imágenes &lt;strong&gt;docker&lt;/strong&gt; que he construido se me ha ido de las manos. Ya no pueden seguir ocupando espacio en mi local, así que me he decidido a montar mi propio registro de imágenes, para mi uso y disfrute privado …&lt;/p&gt;</summary><content type="html">&lt;p&gt;He llegado a ese momento en el que el número de imágenes &lt;strong&gt;docker&lt;/strong&gt; que he construido se me ha ido de las manos. Ya no pueden seguir ocupando espacio en mi local, así que me he decidido a montar mi propio registro de imágenes, para mi uso y disfrute privado.&lt;/p&gt;
&lt;p&gt;Si miramos en &lt;a href="https://hub.docker.com/_/registry/"&gt;DockerHub&lt;/a&gt; no nos va a costar demasiado encontrar una imagen que nos proporciones este servicio. Ejecutar esta imagen para uso local no tiene ninguna complicación, y basta con seguir las instrucciones. La cosa se complica si queremos sacarlo de nuestra infraestructura, pero no va a ser el caso de hoy.&lt;/p&gt;
&lt;h2&gt;Levantando un registro local&lt;/h2&gt;
&lt;p&gt;Siguiendo las instrucciones, lanzamos el comando indicado en la documentación:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/registry$ docker run -d -p &lt;span class="m"&gt;5000&lt;/span&gt;:5000 registry
735016f722f25c0d8a8f09c1e2b856011d46fa4efd3a4d6c7846405140443128
gerard@aldebaran:~/docker/registry$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Solo necesitamos exponer el puerto 5000 que, por comodidad, va a usar el mismo puerto en mi máquina local. La única parte con estado de la imagen es &lt;em&gt;/var/lib/registry&lt;/em&gt;, y puede resultar interesante saberlo para hacer copias de seguridad; no voy a hacerlo porque la imagen ya lleva por defecto un &lt;em&gt;container volume&lt;/em&gt; declarado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/registry$ docker &lt;span class="nb"&gt;history&lt;/span&gt; registry
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
c9bd19d022f6        &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         /bin/sh -c &lt;span class="c1"&gt;#(nop)  CMD [&amp;quot;/etc/docker/registry   0 B                 &lt;/span&gt;
&amp;lt;missing&amp;gt;           &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         /bin/sh -c &lt;span class="c1"&gt;#(nop)  ENTRYPOINT [&amp;quot;/entrypoint.s   0 B                 &lt;/span&gt;
&amp;lt;missing&amp;gt;           &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         /bin/sh -c &lt;span class="c1"&gt;#(nop) COPY file:7b57f7ab1a8cf85c0   155 B               &lt;/span&gt;
&amp;lt;missing&amp;gt;           &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         /bin/sh -c &lt;span class="c1"&gt;#(nop)  EXPOSE 5000/tcp              0 B                 &lt;/span&gt;
&amp;lt;missing&amp;gt;           &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         /bin/sh -c &lt;span class="c1"&gt;#(nop)  VOLUME [/var/lib/registry]   0 B                 &lt;/span&gt;
&amp;lt;missing&amp;gt;           &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         /bin/sh -c &lt;span class="c1"&gt;#(nop) COPY file:6c4758d509045dc45   295 B               &lt;/span&gt;
&amp;lt;missing&amp;gt;           &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         /bin/sh -c &lt;span class="c1"&gt;#(nop) COPY file:3f73dd916d906a0db   27.21 MB            &lt;/span&gt;
&amp;lt;missing&amp;gt;           &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         /bin/sh -c &lt;span class="nb"&gt;set&lt;/span&gt; -ex     &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; apk add --no-cache    &lt;span class="m"&gt;1&lt;/span&gt;.287 MB            
&amp;lt;missing&amp;gt;           &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         /bin/sh -c &lt;span class="c1"&gt;#(nop) ADD file:7afbc23fda8b0b3872   4.803 MB            &lt;/span&gt;
gerard@aldebaran:~/docker/registry$ docker inspect 735016f722f2
&lt;span class="o"&gt;[&lt;/span&gt;
    &lt;span class="o"&gt;{&lt;/span&gt;
...  
        &lt;span class="s2"&gt;&amp;quot;Mounts&amp;quot;&lt;/span&gt;: &lt;span class="o"&gt;[&lt;/span&gt;
            &lt;span class="o"&gt;{&lt;/span&gt;
                &lt;span class="s2"&gt;&amp;quot;Name&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;875b58044b85426eb82b5ea74f51f22865994d1bb84d26317c91abaaf1d5f83c&amp;quot;&lt;/span&gt;,
                &lt;span class="s2"&gt;&amp;quot;Source&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;/var/lib/docker/volumes/875b58044b85426eb82b5ea74f51f22865994d1bb84d26317c91abaaf1d5f83c/_data&amp;quot;&lt;/span&gt;,
                &lt;span class="s2"&gt;&amp;quot;Destination&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;/var/lib/registry&amp;quot;&lt;/span&gt;,
                &lt;span class="s2"&gt;&amp;quot;Driver&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;local&amp;quot;&lt;/span&gt;,
                &lt;span class="s2"&gt;&amp;quot;Mode&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;,
                &lt;span class="s2"&gt;&amp;quot;RW&amp;quot;&lt;/span&gt;: true,
                &lt;span class="s2"&gt;&amp;quot;Propagation&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
            &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="o"&gt;]&lt;/span&gt;,
...  
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;]&lt;/span&gt;
gerard@aldebaran:~/docker/registry$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Si preferís la versión usando &lt;strong&gt;docker-compose&lt;/strong&gt;, no difiere demasiado:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/registry$ cat docker-compose.yml 
version: &lt;span class="s1"&gt;&amp;#39;2&amp;#39;&lt;/span&gt;
services:
  registry:
    image: registry
    hostname: registry
    container_name: registry
    volumes:
      - ./data:/var/lib/registry
    ports:
      - &lt;span class="s2"&gt;&amp;quot;5000:5000&amp;quot;&lt;/span&gt;
gerard@aldebaran:~/docker/registry$ docker-compose up -d
Creating network &lt;span class="s2"&gt;&amp;quot;registry_default&amp;quot;&lt;/span&gt; with the default driver
Creating registry
gerard@aldebaran:~/docker/registry$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este caso, se ha optado por mapear el volumen &lt;em&gt;/var/lib/registry&lt;/em&gt; en una carpeta local, para poder inspeccionarlo fácilmente y para sacar &lt;em&gt;backups&lt;/em&gt; con mas facilidad todavía.&lt;/p&gt;
&lt;h2&gt;Uso de nuestro registro local&lt;/h2&gt;
&lt;p&gt;Se puede trabajar con nuestro registro de la misma forma con la que lo haríamos con &lt;em&gt;DockerHub&lt;/em&gt;, a base de usar el comando &lt;em&gt;docker push&lt;/em&gt; y &lt;em&gt;docker pull&lt;/em&gt;. Solo hay que mencionar que el registro destino viene especificado en el nombre de la imagen, en el formato &lt;code&gt;&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;imagen&amp;gt;:&amp;lt;tag&amp;gt;&lt;/code&gt;. Por ejemplo, vamos a subir una imagen &lt;em&gt;alpine:3.4&lt;/em&gt;, aunque podría ser una imagen nuestra.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/registry$ docker tag alpine:3.4 localhost:5000/alpine:3.4
gerard@aldebaran:~/docker/registry$ docker images
REPOSITORY                                                                                      TAG                 IMAGE ID            CREATED             SIZE
alpine                                                                                          &lt;span class="m"&gt;3&lt;/span&gt;.4                 baa5d63471ea        &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         &lt;span class="m"&gt;4&lt;/span&gt;.803 MB
localhost:5000/alpine                                                                           &lt;span class="m"&gt;3&lt;/span&gt;.4                 baa5d63471ea        &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         &lt;span class="m"&gt;4&lt;/span&gt;.803 MB
gerard@aldebaran:~/docker/registry$ docker push localhost:5000/alpine:3.4
The push refers to a repository &lt;span class="o"&gt;[&lt;/span&gt;localhost:5000/alpine&lt;span class="o"&gt;]&lt;/span&gt;
011b303988d2: Pushed 
&lt;span class="m"&gt;3&lt;/span&gt;.4: digest: sha256:1354db23ff5478120c980eca1611a51c9f2b88b61f24283ee8200bf9a54f2e5c size: &lt;span class="m"&gt;528&lt;/span&gt;
gerard@aldebaran:~/docker/registry$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y las capas que conforman nuestra imagen, quedan guardadas en nuestro registro local, como podemos ver:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/registry$ tree data/
data/
└── docker
    └── registry
        └── v2
            ├── blobs
            │   └── sha256
            │       ├── &lt;span class="m"&gt;13&lt;/span&gt;
            │       │   └── 1354db23ff5478120c980eca1611a51c9f2b88b61f24283ee8200bf9a54f2e5c
            │       │       └── data
            │       ├── &lt;span class="m"&gt;36&lt;/span&gt;
            │       │   └── 3690ec4760f95690944da86dc4496148a63d85c9e3100669a318110092f6862f
            │       │       └── data
            │       └── ba
            │           └── baa5d63471ead618ff91ddfacf1e2c81bf0612bfeb1daf00eb0843a41fbfade3
            │               └── data
            └── repositories
                └── alpine
                    ├── _layers
                    │   └── sha256
                    │       ├── 3690ec4760f95690944da86dc4496148a63d85c9e3100669a318110092f6862f
                    │       │   └── link
                    │       └── baa5d63471ead618ff91ddfacf1e2c81bf0612bfeb1daf00eb0843a41fbfade3
                    │           └── link
                    ├── _manifests
                    │   ├── revisions
                    │   │   └── sha256
                    │   │       └── 1354db23ff5478120c980eca1611a51c9f2b88b61f24283ee8200bf9a54f2e5c
                    │   │           └── link
                    │   └── tags
                    │       └── &lt;span class="m"&gt;3&lt;/span&gt;.4
                    │           ├── current
                    │           │   └── link
                    │           └── index
                    │               └── sha256
                    │                   └── 1354db23ff5478120c980eca1611a51c9f2b88b61f24283ee8200bf9a54f2e5c
                    │                       └── link
                    └── _uploads

&lt;span class="m"&gt;28&lt;/span&gt; directories, &lt;span class="m"&gt;8&lt;/span&gt; files
gerard@aldebaran:~/docker/registry$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Nada nos impediría hacer un &lt;code&gt;docker pull localhost:5000/alpine:3.4&lt;/code&gt; en el futuro.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: En caso de querer hacer un &lt;em&gt;push&lt;/em&gt; de un tag &lt;em&gt;default&lt;/em&gt; de la imagen &lt;code&gt;tools/tsung&lt;/code&gt;, bastaría con que usar &lt;code&gt;localhost:5000/tools/tsung&lt;/code&gt;; el nombre de la imagen puede contener el separador &lt;code&gt;/&lt;/code&gt; y el &lt;em&gt;tag&lt;/em&gt; es opcional, usando el &lt;em&gt;tag&lt;/em&gt; por defecto &lt;em&gt;default&lt;/em&gt;, justo como pasa con &lt;em&gt;DockerHub&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Consultando el contenido de nuestro registro&lt;/h2&gt;
&lt;p&gt;Ahora mismo nuestro registro solo tiene guardado un &lt;em&gt;alpine:3.4&lt;/em&gt;. Para poder ver una salida mas interesante de la API del registro, subo una &lt;em&gt;alpine:edge&lt;/em&gt; y una &lt;em&gt;debian:jessie&lt;/em&gt;. Así podemos apreciar dos imágenes, y una de ellas, con dos &lt;em&gt;tags&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Empezamos dando un nombre que contenga &lt;em&gt;localhost:5000&lt;/em&gt; como ya hemos visto más arriba:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/registry$ docker tag &lt;span class="o"&gt;{&lt;/span&gt;,localhost:5000/&lt;span class="o"&gt;}&lt;/span&gt;alpine:edge
gerard@aldebaran:~/docker/registry$ docker tag &lt;span class="o"&gt;{&lt;/span&gt;,localhost:5000/&lt;span class="o"&gt;}&lt;/span&gt;debian:jessie
gerard@aldebaran:~/docker/registry$ docker images &lt;span class="p"&gt;|&lt;/span&gt; grep localhost
localhost:5000/debian                                                                           jessie              73e72bf822ca        &lt;span class="m"&gt;4&lt;/span&gt; weeks ago         &lt;span class="m"&gt;123&lt;/span&gt; MB
localhost:5000/alpine                                                                           edge                a1a3cae7a75e        &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         &lt;span class="m"&gt;3&lt;/span&gt;.979 MB
localhost:5000/alpine                                                                           &lt;span class="m"&gt;3&lt;/span&gt;.4                 baa5d63471ea        &lt;span class="m"&gt;7&lt;/span&gt; weeks ago         &lt;span class="m"&gt;4&lt;/span&gt;.803 MB
gerard@aldebaran:~/docker/registry$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y los empujamos al registro:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/registry$ docker push localhost:5000/alpine:edge
The push refers to a repository &lt;span class="o"&gt;[&lt;/span&gt;localhost:5000/alpine&lt;span class="o"&gt;]&lt;/span&gt;
6f4ada5745cd: Pushed 
edge: digest: sha256:cd9c03c2d382fcf00c31dc1635445163ec185dfffb51242d9e097892b3b0d5b4 size: &lt;span class="m"&gt;528&lt;/span&gt;
gerard@aldebaran:~/docker/registry$ docker push localhost:5000/debian:jessie
The push refers to a repository &lt;span class="o"&gt;[&lt;/span&gt;localhost:5000/debian&lt;span class="o"&gt;]&lt;/span&gt;
fe4c16cbf7a4: Pushed 
jessie: digest: sha256:c1ce85a0f7126a3b5cbf7c57676b01b37c755b9ff9e2f39ca88181c02b985724 size: &lt;span class="m"&gt;529&lt;/span&gt;
gerard@aldebaran:~/docker/registry$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Disponemos de una API con -al menos- dos métodos que nos sirven para ver lo que hay en el registro:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Listar las imágenes de nuestro repositorio -&amp;gt; &lt;code&gt;GET /v2/_catalog&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Listar los &lt;em&gt;tags&lt;/em&gt; de una imagen concreta -&amp;gt; &lt;code&gt;GET /v2/&amp;lt;imagen&amp;gt;/tags/list&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Así, podemos ver lo que hay con las siguientes invocaciones:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/registry$ curl http://localhost:5000/v2/_catalog
&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;repositories&amp;quot;&lt;/span&gt;:&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;alpine&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;debian&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]}&lt;/span&gt;
gerard@aldebaran:~/docker/registry$ curl http://localhost:5000/v2/alpine/tags/list
&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;:&lt;span class="s2"&gt;&amp;quot;alpine&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;tags&amp;quot;&lt;/span&gt;:&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;edge&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;3.4&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]}&lt;/span&gt;
gerard@aldebaran:~/docker/registry$ curl http://localhost:5000/v2/debian/tags/list
&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;:&lt;span class="s2"&gt;&amp;quot;debian&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;tags&amp;quot;&lt;/span&gt;:&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;jessie&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]}&lt;/span&gt;
gerard@aldebaran:~/docker/registry$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Se puede automatizar esta salida con un simple &lt;em&gt;script&lt;/em&gt;, que he escrito en &lt;strong&gt;python&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/registry$ cat list_registry.py 
&lt;span class="c1"&gt;#!/usr/bin/env python&lt;/span&gt;

import httplib
import json

def get_json_response&lt;span class="o"&gt;(&lt;/span&gt;host, port, uri&lt;span class="o"&gt;)&lt;/span&gt;:
    &lt;span class="nv"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; httplib.HTTPConnection&lt;span class="o"&gt;(&lt;/span&gt;host, port&lt;span class="o"&gt;)&lt;/span&gt;
    c.request&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;GET&amp;#39;&lt;/span&gt;, uri&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; c.getresponse&lt;span class="o"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; json.load&lt;span class="o"&gt;(&lt;/span&gt;r&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="nv"&gt;catalog&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; get_json_response&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt;, &lt;span class="m"&gt;5000&lt;/span&gt;, &lt;span class="s1"&gt;&amp;#39;/v2/_catalog&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; image in catalog&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;repositories&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;:
    print &lt;span class="s1"&gt;&amp;#39;* %s&amp;#39;&lt;/span&gt; % image
    &lt;span class="nv"&gt;taginfo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; get_json_response&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt;, &lt;span class="m"&gt;5000&lt;/span&gt;, &lt;span class="s1"&gt;&amp;#39;/v2/%s/tags/list&amp;#39;&lt;/span&gt; % image&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; tag in taginfo&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tags&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;:
        print &lt;span class="s1"&gt;&amp;#39;    * %s:%s&amp;#39;&lt;/span&gt; % &lt;span class="o"&gt;(&lt;/span&gt;taginfo&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;, tag&lt;span class="o"&gt;)&lt;/span&gt;
gerard@aldebaran:~/docker/registry$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto vemos una salida bastante legible.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@aldebaran:~/docker/registry$ ./list_registry.py 
* alpine
    * alpine:edge
    * alpine:3.4
* debian
    * debian:jessie
gerard@aldebaran:~/docker/registry$ 
&lt;/pre&gt;&lt;/div&gt;</content><category term="registro"></category><category term="docker"></category></entry><entry><title>Disparando acciones en respuesta a modificaciones en el sistema de fichero con incron</title><link href="http://www.linuxsysadmin.ml/2016/10/disparando-acciones-en-respuesta-a-modificaciones-en-el-sistema-de-fichero-con-incron.html" rel="alternate"></link><published>2016-10-03T08:00:00+02:00</published><updated>2016-10-03T08:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-10-03:/2016/10/disparando-acciones-en-respuesta-a-modificaciones-en-el-sistema-de-fichero-con-incron.html</id><summary type="html">&lt;p&gt;El otro día recibí una petición diferente en mi trabajo. Se necesitaba monitorizar una carpeta, de forma que cuando alguien dejara ficheros, se lanzara una tarea para procesarlos. Tras buscar un poco por internet, topé con una herramienta tipo &lt;em&gt;cron&lt;/em&gt;, que ejecutaba comandos ante eventos en el sistema de ficheros …&lt;/p&gt;</summary><content type="html">&lt;p&gt;El otro día recibí una petición diferente en mi trabajo. Se necesitaba monitorizar una carpeta, de forma que cuando alguien dejara ficheros, se lanzara una tarea para procesarlos. Tras buscar un poco por internet, topé con una herramienta tipo &lt;em&gt;cron&lt;/em&gt;, que ejecutaba comandos ante eventos en el sistema de ficheros.&lt;/p&gt;
&lt;p&gt;Como me pareció interesante, me puse a investigar como funcionaba y, aunque no sirvió para cubrir nuestras necesidades, decidí apuntarla por sus usos potenciales en el futuro.&lt;/p&gt;
&lt;p&gt;Como no podía ser de otra forma, vamos a empezar instalando el paquete que lo contiene:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@65b056d5d699:~# apt-get install -y incron
Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following NEW packages will be installed:
  incron
&lt;span class="m"&gt;0&lt;/span&gt; upgraded, &lt;span class="m"&gt;1&lt;/span&gt; newly installed, &lt;span class="m"&gt;0&lt;/span&gt; to remove and &lt;span class="m"&gt;0&lt;/span&gt; not upgraded.
Need to get &lt;span class="m"&gt;68&lt;/span&gt;.8 kB of archives.
After this operation, &lt;span class="m"&gt;321&lt;/span&gt; kB of additional disk space will be used.
...  
Processing triggers &lt;span class="k"&gt;for&lt;/span&gt; systemd &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;215&lt;/span&gt;-17+deb8u4&lt;span class="o"&gt;)&lt;/span&gt; ...
root@65b056d5d699:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Normalmente, los servicios se levantan solos en &lt;strong&gt;Debian&lt;/strong&gt;, pero como estamos trabajando con un contenedor &lt;strong&gt;docker&lt;/strong&gt; mediante &lt;strong&gt;SSH&lt;/strong&gt;, vamos a tener que hacerlo manualmente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@65b056d5d699:~# service incron start
&lt;span class="o"&gt;[&lt;/span&gt; ok &lt;span class="o"&gt;]&lt;/span&gt; Starting File system events scheduler: incron.
root@65b056d5d699:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Esta herramienta se puede configurar de forma similar al &lt;strong&gt;cron&lt;/strong&gt;; tenemos la opción de poner ficheros de configuración en &lt;em&gt;/etc/incron.d/&lt;/em&gt; o podemos usar comandos de &lt;strong&gt;incron&lt;/strong&gt; por usuario, mediante el comando &lt;em&gt;incron&lt;/em&gt;, con los flags correspondientes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;incron -l&lt;/strong&gt; &amp;rarr; lista la tabla de incron del usuario actual&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;incron -e&lt;/strong&gt; &amp;rarr; edita la tabla de incron del usuario actual&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;incron -r&lt;/strong&gt; &amp;rarr; elimina la tabla de incron del usuario actual&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Para usar &lt;strong&gt;incron&lt;/strong&gt; a nivel de usuario, este debe aparecer en &lt;em&gt;/etc/incron.allow&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Un caso práctico&lt;/h2&gt;
&lt;p&gt;Supongamos que tenemos un servidor web &lt;strong&gt;nginx&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@65b056d5d699:/etc/nginx/sites-enabled# netstat -lntp
Active Internet connections &lt;span class="o"&gt;(&lt;/span&gt;only servers&lt;span class="o"&gt;)&lt;/span&gt;
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:80              &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:*               LISTEN      &lt;span class="m"&gt;249&lt;/span&gt;/nginx       
tcp        &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:22              &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:*               LISTEN      &lt;span class="m"&gt;1&lt;/span&gt;/sshd          
tcp6       &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; :::22                   :::*                    LISTEN      &lt;span class="m"&gt;1&lt;/span&gt;/sshd          
root@65b056d5d699:/etc/nginx/sites-enabled# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Estamos cansados de recargar la configuración cada vez que modificamos alguno de los ficheros de configuración, así que vamos a delegar esta tarea a &lt;strong&gt;incron&lt;/strong&gt;. Concretamente queremos que cada vez que se modifique el fichero &lt;em&gt;/etc/nginx/nginx.conf&lt;/em&gt; o algunos de los &lt;em&gt;virtualhosts&lt;/em&gt; en &lt;em&gt;/etc/nginx/sites-enabled/&lt;/em&gt;, se haga un &lt;em&gt;reload&lt;/em&gt; del servicio.&lt;/p&gt;
&lt;p&gt;Miramos la tabla de eventos posibles a monitorizar y vemos que nos interesa el evento &lt;strong&gt;IN_MODIFY&lt;/strong&gt;. Se pueden monitorizar varios eventos uniéndolos con un &lt;strong&gt;OR&lt;/strong&gt; lógico, pero no se pueden poner mas de una línea por carpeta monitorizada.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;IN_ACCESS&lt;/strong&gt; &amp;rarr; Se ha accedido al fichero o directorio.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_ATTRIB&lt;/strong&gt; &amp;rarr; Se han cambiado los &lt;em&gt;metadatos&lt;/em&gt; (o los &lt;em&gt;timestamps&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_CLOSE_WRITE&lt;/strong&gt; &amp;rarr; Se ha cerrado un fichero abierto en modo distinto al de escritura.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_CLOSE_NOWRITE&lt;/strong&gt; &amp;rarr; Se ha cerrado un fichero abierto en modo de escritura.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_CREATE&lt;/strong&gt; &amp;rarr; Se ha creado un fichero en el directorio monitorizado.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_DELETE&lt;/strong&gt; &amp;rarr; Se ha borrado un fichero en la carpeta.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_DELETE_SELF&lt;/strong&gt; &amp;rarr; El fichero o directorio monitorizado ha sido borrado.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_MODIFY&lt;/strong&gt; &amp;rarr; El fichero ha sido modificado.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_MOVE_SELF&lt;/strong&gt; &amp;rarr; El fichero o carpeta monitorizado se ha movido.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_MOVED_FROM&lt;/strong&gt; &amp;rarr; Un fichero se ha movido desde la carpeta monitorizada.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_MOVED_TO&lt;/strong&gt; &amp;rarr; Un fichero se ha movido hacia la carpeta monitorizada.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_OPEN&lt;/strong&gt; &amp;rarr; Se ha abierto un fichero en la carpeta monitorizada.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_MOVE&lt;/strong&gt; &amp;rarr; Combinación de IN_MOVED_FROM y de IN_MOVED_TO.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_CLOSE&lt;/strong&gt; &amp;rarr; Combinación de IN_CLOSE_WRITE y IN_CLOSE_NOWRITE.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IN_ALL_EVENTS&lt;/strong&gt; &amp;rarr; Todos los eventos anteriores.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Así pues, ponemos la tripleta &lt;em&gt;carpeta, evento, acción&lt;/em&gt;, ya sea con el comando &lt;em&gt;incron -e&lt;/em&gt; o mediante un fichero en &lt;em&gt;/etc/incron.d/&lt;/em&gt;. Es importante indicar que la salida del comando no se puede recoger en este fichero; si es necesario, habría que llamar a un &lt;em&gt;script&lt;/em&gt; que tuviera la redirección.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@65b056d5d699:~# cat /etc/incron.d/nginx 
/etc/nginx/nginx.conf IN_MODIFY /usr/sbin/service nginx reload
/etc/nginx/sites-enabled/ IN_MODIFY /usr/sbin/service nginx reload
root@65b056d5d699:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este punto no hay que recargar nada; &lt;strong&gt;incron&lt;/strong&gt; ha detectado el cambio y se ha recargado solo.&lt;/p&gt;
&lt;p&gt;Vamos a cambiar, por ejemplo, el puerto en el que escucha nuestra web.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ANTES:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@65b056d5d699:~# cat /etc/nginx/sites-enabled/mysite 
server &lt;span class="o"&gt;{&lt;/span&gt;
    listen &lt;span class="m"&gt;80&lt;/span&gt; default_server&lt;span class="p"&gt;;&lt;/span&gt;
    root /var/www/html&lt;span class="p"&gt;;&lt;/span&gt;
    server_name _&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;DESPUES:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@65b056d5d699:~# cat /etc/nginx/sites-enabled/mysite 
server &lt;span class="o"&gt;{&lt;/span&gt;
    listen &lt;span class="m"&gt;8080&lt;/span&gt; default_server&lt;span class="p"&gt;;&lt;/span&gt;
    root /var/www/html&lt;span class="p"&gt;;&lt;/span&gt;
    server_name _&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@65b056d5d699:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y sin recargar la configuración de &lt;strong&gt;nginx&lt;/strong&gt; -puesto que ya lo ha hecho &lt;strong&gt;incron&lt;/strong&gt;-, vemos que se ha puesto a escuchar en el nuevo puerto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@65b056d5d699:~# netstat -lntp
Active Internet connections &lt;span class="o"&gt;(&lt;/span&gt;only servers&lt;span class="o"&gt;)&lt;/span&gt;
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:8080            &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:*               LISTEN      &lt;span class="m"&gt;249&lt;/span&gt;/nginx       
tcp        &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:22              &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:*               LISTEN      &lt;span class="m"&gt;1&lt;/span&gt;/sshd          
tcp6       &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; :::22                   :::*                    LISTEN      &lt;span class="m"&gt;1&lt;/span&gt;/sshd          
root@65b056d5d699:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Ejecución parametrizada de nuestras tareas&lt;/h2&gt;
&lt;p&gt;El proceso de &lt;strong&gt;incron&lt;/strong&gt; nos ofrece unos parámetros para discernir cual de los eventos disparó el &lt;em&gt;trigger&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;$$&lt;/strong&gt; &amp;rarr; Símbolo de dólar.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$@&lt;/strong&gt; &amp;rarr; Ruta de la carpeta monitorizada.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$#&lt;/strong&gt; &amp;rarr; Fichero modificado.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$%&lt;/strong&gt; &amp;rarr; Evento que disparó la acción, en texto.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$&amp;amp;&lt;/strong&gt; &amp;rarr; Evento que disparó la acción, en número.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Si quisiéramos procesar un fichero tal como nos lo dejen en una carpeta, podemos usar un &lt;em&gt;script&lt;/em&gt; con parámetros que haga lo que deba con el mismo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@65b056d5d699:~# cat /etc/incron.d/batch_process 
/opt/batch_process/inbox/ IN_WRITE_CLOSE /opt/batch_process/process_file.py &lt;span class="nv"&gt;$@&lt;/span&gt; &lt;span class="nv"&gt;$#&lt;/span&gt;
root@65b056d5d699:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Este &lt;em&gt;script&lt;/em&gt; recibe la ruta de la carpeta monitorizada y el fichero. Lo que hace el &lt;em&gt;script&lt;/em&gt; se deja a la imaginación del lector. Como punto adicional, recalcar que se ha usado el evento &lt;strong&gt;IN_WRITE_CLOSE&lt;/strong&gt; en vez de &lt;strong&gt;IN_CREATE&lt;/strong&gt; porque este último salta inmediatamente, y podríamos encontrarnos con un fichero a medio subir, en caso de ser puesto por un protocolo remoto.&lt;/p&gt;
&lt;p&gt;Estoy seguro que en un futuro no muy lejano, esta herramienta me va a ser de gran utilidad.&lt;/p&gt;</content><category term="incron"></category></entry><entry><title>Un servidor pypi local</title><link href="http://www.linuxsysadmin.ml/2016/09/un-servidor-pypi-local.html" rel="alternate"></link><published>2016-09-05T08:00:00+02:00</published><updated>2016-09-05T08:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-09-05:/2016/09/un-servidor-pypi-local.html</id><summary type="html">&lt;p&gt;Cuando trabajamos con &lt;strong&gt;python&lt;/strong&gt;, muchas veces necesitamos instalar librerías con &lt;em&gt;pip&lt;/em&gt; o &lt;em&gt;easy_install&lt;/em&gt;. Dependiendo de la naturaleza de nuestros proyectos, las librerías suelen variar, pero siempre solemos utilizar los mismos. En estos casos puede ser útil tenerlos cerca, cacheados en un servidor en nuestra red local, para su rápido acceso …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Cuando trabajamos con &lt;strong&gt;python&lt;/strong&gt;, muchas veces necesitamos instalar librerías con &lt;em&gt;pip&lt;/em&gt; o &lt;em&gt;easy_install&lt;/em&gt;. Dependiendo de la naturaleza de nuestros proyectos, las librerías suelen variar, pero siempre solemos utilizar los mismos. En estos casos puede ser útil tenerlos cerca, cacheados en un servidor en nuestra red local, para su rápido acceso.&lt;/p&gt;
&lt;p&gt;Para estos casos podemos montar un servidor exactamente igual que el de &lt;a href="https://pypi.python.org/pypi"&gt;PyPI&lt;/a&gt;, que se distribuye como una librería &lt;strong&gt;python&lt;/strong&gt; adicional, que nos ofrece una aplicación &lt;strong&gt;WSGI&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Nuestro despliegue es bastante básico; con un solo servidor nos basta, y puede estar compartido con otros usos. El único servicio que vamos a poner es un servidor &lt;strong&gt;WSGI&lt;/strong&gt; capaz de servir la aplicación. En nuestro caso vamos a usar &lt;strong&gt;uwsgi&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Así pues, creamos dos máquinas, una va a ser el servidor y la otra, un cliente de ejemplo que necesite los paquetes locales.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# lxc-ls -f
NAME        STATE    IPV4      IPV6  AUTOSTART
----------------------------------------------
pyclient    RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.3  -     NO
pypiserver  RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.2  -     NO
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Montando el servidor&lt;/h2&gt;
&lt;p&gt;Como decisión de diseño, he optado por instalar el paquete &lt;em&gt;pypiserver&lt;/em&gt; en un &lt;em&gt;virtualenv&lt;/em&gt;, para no interferir con otros paquetes que pudiera haber en el servidor.&lt;/p&gt;
&lt;p&gt;Empezaremos creando una carpeta contenedora, en donde va a ir el &lt;em&gt;virtualenv&lt;/em&gt;, la aplicación y el índice de paquetes disponibles en el servidor.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pypiserver:~# mkdir /opt/pypi &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;cd&lt;/span&gt; /opt/pypi
root@pypiserver:/opt/pypi#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a descargar &lt;em&gt;virtualenv&lt;/em&gt;, sin instalarlo, para "usar y tirar". Para ello vamos a necesitar alguna herramienta para descargarlo de la red, por ejemplo, &lt;strong&gt;wget&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pypiserver:/opt/pypi# apt-get install -y wget
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
...
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;13&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;9&lt;/span&gt;.875 kB de archivos.
Se utilizarán &lt;span class="m"&gt;35&lt;/span&gt;,7 MB de espacio de disco adicional después de esta operación.
...
root@pypiserver:/opt/pypi#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Tanto la herramienta &lt;em&gt;virtualenv&lt;/em&gt; como la herramienta &lt;em&gt;pip&lt;/em&gt; que vamos a necesitar mas adelante, usan &lt;strong&gt;python&lt;/strong&gt;. Es un buen momento para asegurar que esté instalado, y si no lo está, lo instalamos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pypiserver:/opt/pypi# apt-get install -y python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
...
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;12&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;4&lt;/span&gt;.991 kB de archivos.
Se utilizarán &lt;span class="m"&gt;21&lt;/span&gt;,2 MB de espacio de disco adicional después de esta operación.
...
root@pypiserver:/opt/pypi#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Descargamos el paquete &lt;em&gt;virtualenv&lt;/em&gt; y lo descomprimimos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pypiserver:/opt/pypi# wget -q https://pypi.python.org/packages/5c/79/5dae7494b9f5ed061cff9a8ab8d6e1f02db352f3facf907d9eb614fb80e9/virtualenv-15.0.2.tar.gz
root@pypiserver:/opt/pypi# tar xzf virtualenv-15.0.2.tar.gz
root@pypiserver:/opt/pypi#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a crear el &lt;em&gt;virtualenv&lt;/em&gt; dentro de nuestra carpeta contenedora. Luego instalamos el paquete &lt;em&gt;pypiserver&lt;/em&gt;, previo activado del &lt;em&gt;virtualenv&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pypiserver:/opt/pypi# ./virtualenv-15.0.2/virtualenv.py env
New python executable in /opt/pypi/env/bin/python
Installing setuptools, pip, wheel...done.
root@pypiserver:/opt/pypi# . env/bin/activate
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@pypiserver:/opt/pypi# pip install pypiserver
Collecting pypiserver
  Downloading pypiserver-1.1.10-py2.py3-none-any.whl &lt;span class="o"&gt;(&lt;/span&gt;75kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 81kB 632kB/s
Installing collected packages: pypiserver
Successfully installed pypiserver-1.1.10
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@pypiserver:/opt/pypi# deactivate
root@pypiserver:/opt/pypi#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto tenemos el &lt;em&gt;virtualenv&lt;/em&gt;. Si no ha habido problemas, y no lo pensamos reconstruir, es un buen momento para eliminar los &lt;em&gt;scripts&lt;/em&gt; de creación del mismo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pypiserver:/opt/pypi# rm -R virtualenv-15.0.2*
root@pypiserver:/opt/pypi#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a hacer que nuestro servidor sirva los paquetes de una carpeta &lt;em&gt;packages&lt;/em&gt;, dentro de la carpeta contenedora. Como no existe esta carpeta &lt;em&gt;packages&lt;/em&gt;, la creamos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pypiserver:/opt/pypi# mkdir packages
root@pypiserver:/opt/pypi#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y finalmente creamos una aplicación &lt;strong&gt;WSGI&lt;/strong&gt; para poder servir nuestros paquetes. Realmente es una instancia de la aplicación que ofrece el paquete &lt;em&gt;pypiserver&lt;/em&gt;, con la única diferencia que consiste en especificar la raíz de los paquetes servidos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pypiserver:/opt/pypi# cat app.py
import pypiserver
&lt;span class="nv"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; pypiserver.app&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;root&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/opt/pypi/packages&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
root@pypiserver:/opt/pypi#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lo único que queda es servir la aplicación en un servidor de nuestra preferencia. En mi caso he optado por &lt;strong&gt;uwsgi&lt;/strong&gt;, por lo que lo instalo. Se va a usar el modo &lt;em&gt;emperor&lt;/em&gt; por comodidad.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pypiserver:/opt/pypi# apt-get install -y uwsgi-emperor uwsgi-plugin-python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
...
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;13&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;3&lt;/span&gt;.452 kB de archivos.
Se utilizarán &lt;span class="m"&gt;9&lt;/span&gt;.799 kB de espacio de disco adicional después de esta operación.
...
root@pypiserver:/opt/pypi#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;De acuerdo con el modo &lt;em&gt;emperor&lt;/em&gt;, necesitamos declarar la aplicación mediante un fichero de configuración. Con esto el &lt;em&gt;emperor&lt;/em&gt; la tiene fichada y se encarga de mantenerla levantada.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pypiserver:/opt/pypi# cat /etc/uwsgi-emperor/vassals/pypiserver.ini
&lt;span class="o"&gt;[&lt;/span&gt;uwsgi&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;plugins&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; python
http-socket &lt;span class="o"&gt;=&lt;/span&gt; :8080
&lt;span class="nv"&gt;master&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nv"&gt;workers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="nv"&gt;chdir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/pypi
&lt;span class="nv"&gt;virtualenv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/pypi/env/
&lt;span class="nv"&gt;module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; app:app
root@pypiserver:/opt/pypi#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Añadiendo paquetes a nuestro servidor&lt;/h2&gt;
&lt;p&gt;Esta es la parte mas fácil de todas; basta con dejar nuestros paquetes &lt;strong&gt;python&lt;/strong&gt; en la carpeta &lt;em&gt;/opt/pypi/packages/&lt;/em&gt;. Así de fácil.&lt;/p&gt;
&lt;p&gt;El formato es cualquiera aceptado por &lt;em&gt;pip&lt;/em&gt; o &lt;em&gt;easy_install&lt;/em&gt;, pudiendo ser ficheros &lt;em&gt;.zip&lt;/em&gt;, &lt;em&gt;.egg&lt;/em&gt; o &lt;em&gt;.whl&lt;/em&gt; entre otros; pueden ser descargados, compilados, o creados por nosotros mismos.&lt;/p&gt;
&lt;p&gt;Para ver un ejemplo, voy a generar unos ficheros &lt;em&gt;.whl&lt;/em&gt;, mediante el uso de &lt;em&gt;pip&lt;/em&gt;. Esto nos garantiza que los tendremos cerca, pero que también van a estar ya compilados para la arquitectura concreta del servidor (presumiblemente la misma que van a usar los clientes).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pypiserver:~# /opt/pypi/env/bin/pip wheel -w /opt/pypi/packages/ flask mongoengine
Collecting flask
  Downloading Flask-0.11.1-py2.py3-none-any.whl &lt;span class="o"&gt;(&lt;/span&gt;80kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 81kB 599kB/s
  Saved /opt/pypi/packages/Flask-0.11.1-py2.py3-none-any.whl
Collecting mongoengine
  Downloading mongoengine-0.10.6.tar.gz &lt;span class="o"&gt;(&lt;/span&gt;346kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 348kB 560kB/s
Collecting click&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.0 &lt;span class="o"&gt;(&lt;/span&gt;from flask&lt;span class="o"&gt;)&lt;/span&gt;
  Downloading click-6.6.tar.gz &lt;span class="o"&gt;(&lt;/span&gt;283kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 286kB &lt;span class="m"&gt;2&lt;/span&gt;.0MB/s
Collecting Werkzeug&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.7 &lt;span class="o"&gt;(&lt;/span&gt;from flask&lt;span class="o"&gt;)&lt;/span&gt;
  Downloading Werkzeug-0.11.10-py2.py3-none-any.whl &lt;span class="o"&gt;(&lt;/span&gt;306kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 307kB &lt;span class="m"&gt;1&lt;/span&gt;.0MB/s
  Saved /opt/pypi/packages/Werkzeug-0.11.10-py2.py3-none-any.whl
Collecting Jinja2&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.4 &lt;span class="o"&gt;(&lt;/span&gt;from flask&lt;span class="o"&gt;)&lt;/span&gt;
  Downloading Jinja2-2.8-py2.py3-none-any.whl &lt;span class="o"&gt;(&lt;/span&gt;263kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 266kB &lt;span class="m"&gt;2&lt;/span&gt;.1MB/s
  Saved /opt/pypi/packages/Jinja2-2.8-py2.py3-none-any.whl
Collecting itsdangerous&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.21 &lt;span class="o"&gt;(&lt;/span&gt;from flask&lt;span class="o"&gt;)&lt;/span&gt;
  Downloading itsdangerous-0.24.tar.gz &lt;span class="o"&gt;(&lt;/span&gt;46kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 51kB &lt;span class="m"&gt;2&lt;/span&gt;.3MB/s
Collecting pymongo&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.7.1 &lt;span class="o"&gt;(&lt;/span&gt;from mongoengine&lt;span class="o"&gt;)&lt;/span&gt;
  Downloading pymongo-3.2.2.tar.gz &lt;span class="o"&gt;(&lt;/span&gt;504kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 512kB 657kB/s
Collecting MarkupSafe &lt;span class="o"&gt;(&lt;/span&gt;from Jinja2&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.4-&amp;gt;flask&lt;span class="o"&gt;)&lt;/span&gt;
  Downloading MarkupSafe-0.23.tar.gz
Skipping flask, due to already being wheel.
Skipping Werkzeug, due to already being wheel.
Skipping Jinja2, due to already being wheel.
Building wheels &lt;span class="k"&gt;for&lt;/span&gt; collected packages: mongoengine, click, itsdangerous, pymongo, MarkupSafe
  Running setup.py bdist_wheel &lt;span class="k"&gt;for&lt;/span&gt; mongoengine ... &lt;span class="k"&gt;done&lt;/span&gt;
  Stored in directory: /opt/pypi/packages
  Running setup.py bdist_wheel &lt;span class="k"&gt;for&lt;/span&gt; click ... &lt;span class="k"&gt;done&lt;/span&gt;
  Stored in directory: /opt/pypi/packages
  Running setup.py bdist_wheel &lt;span class="k"&gt;for&lt;/span&gt; itsdangerous ... &lt;span class="k"&gt;done&lt;/span&gt;
  Stored in directory: /opt/pypi/packages
  Running setup.py bdist_wheel &lt;span class="k"&gt;for&lt;/span&gt; pymongo ... &lt;span class="k"&gt;done&lt;/span&gt;
  Stored in directory: /opt/pypi/packages
  Running setup.py bdist_wheel &lt;span class="k"&gt;for&lt;/span&gt; MarkupSafe ... &lt;span class="k"&gt;done&lt;/span&gt;
  Stored in directory: /opt/pypi/packages
Successfully built mongoengine click itsdangerous pymongo MarkupSafe
root@pypiserver:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y podemos ver que tenemos varios paquetes en la carpeta, algunos de ellos descargados ya en formato &lt;em&gt;wheel&lt;/em&gt; (por ejemplo &lt;em&gt;flask&lt;/em&gt;), y otros que se descargaron en formato &lt;em&gt;source&lt;/em&gt; y se compilaron (por ejemplo &lt;em&gt;pymongo&lt;/em&gt;).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pypiserver:~# ls -1 /opt/pypi/packages/
click-6.6-py2.py3-none-any.whl
Flask-0.11.1-py2.py3-none-any.whl
itsdangerous-0.24-py2-none-any.whl
Jinja2-2.8-py2.py3-none-any.whl
MarkupSafe-0.23-py2-none-any.whl
mongoengine-0.10.6-py2-none-any.whl
pymongo-3.2.2-cp27-cp27mu-linux_i686.whl
Werkzeug-0.11.10-py2.py3-none-any.whl
root@pypiserver:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Usando el servidor desde un cliente&lt;/h2&gt;
&lt;p&gt;Ya que vamos a trabajar con &lt;strong&gt;python&lt;/strong&gt;, aseguramos que lo tenemos instalado, o lo instalamos. Vamos a poner también la herramienta &lt;strong&gt;wget&lt;/strong&gt; porque la vamos a necesitar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pyclient:~# apt-get install -y wget python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
...
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;25&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;14&lt;/span&gt;,9 MB de archivos.
Se utilizarán &lt;span class="m"&gt;56&lt;/span&gt;,9 MB de espacio de disco adicional después de esta operación.
...
root@pyclient:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Una prueba rápida: hay que ver que llegamos al servidor creado, y que este ofrece los paquetes en un formato adecuado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pyclient:~# wget -qO- http://10.0.0.2:8080/simple/&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
    &amp;lt;html&amp;gt;
        &amp;lt;head&amp;gt;
            &amp;lt;title&amp;gt;Simple Index&amp;lt;/title&amp;gt;
        &amp;lt;/head&amp;gt;
        &amp;lt;body&amp;gt;
            &amp;lt;h1&amp;gt;Simple Index&amp;lt;/h1&amp;gt;
                 &amp;lt;a &lt;span class="nv"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Flask/&amp;quot;&lt;/span&gt;&amp;gt;Flask&amp;lt;/a&amp;gt;&amp;lt;br&amp;gt;
                 &amp;lt;a &lt;span class="nv"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Jinja2/&amp;quot;&lt;/span&gt;&amp;gt;Jinja2&amp;lt;/a&amp;gt;&amp;lt;br&amp;gt;
                 &amp;lt;a &lt;span class="nv"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;MarkupSafe/&amp;quot;&lt;/span&gt;&amp;gt;MarkupSafe&amp;lt;/a&amp;gt;&amp;lt;br&amp;gt;
                 &amp;lt;a &lt;span class="nv"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Werkzeug/&amp;quot;&lt;/span&gt;&amp;gt;Werkzeug&amp;lt;/a&amp;gt;&amp;lt;br&amp;gt;
                 &amp;lt;a &lt;span class="nv"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;click/&amp;quot;&lt;/span&gt;&amp;gt;click&amp;lt;/a&amp;gt;&amp;lt;br&amp;gt;
                 &amp;lt;a &lt;span class="nv"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;itsdangerous/&amp;quot;&lt;/span&gt;&amp;gt;itsdangerous&amp;lt;/a&amp;gt;&amp;lt;br&amp;gt;
                 &amp;lt;a &lt;span class="nv"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mongoengine/&amp;quot;&lt;/span&gt;&amp;gt;mongoengine&amp;lt;/a&amp;gt;&amp;lt;br&amp;gt;
                 &amp;lt;a &lt;span class="nv"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pymongo/&amp;quot;&lt;/span&gt;&amp;gt;pymongo&amp;lt;/a&amp;gt;&amp;lt;br&amp;gt;
        &amp;lt;/body&amp;gt;
    &amp;lt;/html&amp;gt;

root@pyclient:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Descargamos los &lt;em&gt;scripts&lt;/em&gt; de creación del &lt;em&gt;virtualenv&lt;/em&gt;, tal como lo hacemos mas arriba.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pyclient:~# wget -q https://pypi.python.org/packages/5c/79/5dae7494b9f5ed061cff9a8ab8d6e1f02db352f3facf907d9eb614fb80e9/virtualenv-15.0.2.tar.gz
root@pyclient:~# tar xzf virtualenv-15.0.2.tar.gz
root@pyclient:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos un &lt;em&gt;virtualenv&lt;/em&gt; en donde instalar los paquetes y lo activamos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pyclient:~# ./virtualenv-15.0.2/virtualenv.py env
New python executable in /root/env/bin/python
Installing setuptools, pip, wheel...done.
root@pyclient:~# . env/bin/activate
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@pyclient:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y lo usamos para instalar alguno de los paquetes. Es importante ver que modificamos el &lt;em&gt;index url&lt;/em&gt;, para usar nuestro servidor, y que debemos indicarle que confíe en nuestro servidor.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@pyclient:~# pip install --trusted-host &lt;span class="m"&gt;10&lt;/span&gt;.0.0.2 -i http://10.0.0.2:8080/simple/ mongoengine
Collecting mongoengine
  Downloading http://10.0.0.2:8080/packages/mongoengine-0.10.6-py2-none-any.whl &lt;span class="o"&gt;(&lt;/span&gt;90kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 92kB &lt;span class="m"&gt;10&lt;/span&gt;.9MB/s
Collecting pymongo&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.7.1 &lt;span class="o"&gt;(&lt;/span&gt;from mongoengine&lt;span class="o"&gt;)&lt;/span&gt;
  Downloading http://10.0.0.2:8080/packages/pymongo-3.2.2-cp27-cp27mu-linux_i686.whl &lt;span class="o"&gt;(&lt;/span&gt;209kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 215kB &lt;span class="m"&gt;9&lt;/span&gt;.9MB/s
Installing collected packages: pymongo, mongoengine
Successfully installed mongoengine-0.10.6 pymongo-3.2.2
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@pyclient:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: Podemos crear un fichero de configuración de &lt;em&gt;pip&lt;/em&gt; para que esos parámetros queden ocultos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@pyclient:~# mkdir -p /root/.config/pip/
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@pyclient:~# cat /root/.config/pip/pip.conf
&lt;span class="o"&gt;[&lt;/span&gt;global&lt;span class="o"&gt;]&lt;/span&gt;
index-url &lt;span class="o"&gt;=&lt;/span&gt; http://10.0.0.2:8080/simple/
trusted-host &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;.0.0.2
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@pyclient:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Tras aplicar el truco, nos queda una orden &lt;em&gt;pip&lt;/em&gt; bastante mas bonita, sin tantos parámetros que recordar y nos permite trabajar como la haríamos sin el servidor intermedio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@pyclient:~# pip install flask
Collecting flask
  Downloading http://10.0.0.2:8080/packages/Flask-0.11.1-py2.py3-none-any.whl &lt;span class="o"&gt;(&lt;/span&gt;80kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 81kB &lt;span class="m"&gt;10&lt;/span&gt;.5MB/s
Collecting click&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.0 &lt;span class="o"&gt;(&lt;/span&gt;from flask&lt;span class="o"&gt;)&lt;/span&gt;
  Downloading http://10.0.0.2:8080/packages/click-6.6-py2.py3-none-any.whl &lt;span class="o"&gt;(&lt;/span&gt;71kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 71kB &lt;span class="m"&gt;11&lt;/span&gt;.3MB/s
Collecting Werkzeug&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.7 &lt;span class="o"&gt;(&lt;/span&gt;from flask&lt;span class="o"&gt;)&lt;/span&gt;
  Retrying &lt;span class="o"&gt;(&lt;/span&gt;Retry&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;total&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;, &lt;span class="nv"&gt;connect&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None, &lt;span class="nv"&gt;read&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None, &lt;span class="nv"&gt;redirect&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None&lt;span class="o"&gt;))&lt;/span&gt; after connection broken by &lt;span class="s1"&gt;&amp;#39;ProtocolError(&amp;#39;&lt;/span&gt;Connection aborted.&lt;span class="s1"&gt;&amp;#39;, error(104, &amp;#39;&lt;/span&gt;Conexi&lt;span class="se"&gt;\x&lt;/span&gt;c3&lt;span class="se"&gt;\x&lt;/span&gt;b3n reinicializada por la m&lt;span class="se"&gt;\x&lt;/span&gt;c3&lt;span class="se"&gt;\x&lt;/span&gt;a1quina remota&lt;span class="s1"&gt;&amp;#39;))&amp;#39;&lt;/span&gt;: /packages/Werkzeug-0.11.10-py2.py3-none-any.whl
  Downloading http://10.0.0.2:8080/packages/Werkzeug-0.11.10-py2.py3-none-any.whl &lt;span class="o"&gt;(&lt;/span&gt;306kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 307kB &lt;span class="m"&gt;8&lt;/span&gt;.3MB/s
Collecting Jinja2&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.4 &lt;span class="o"&gt;(&lt;/span&gt;from flask&lt;span class="o"&gt;)&lt;/span&gt;
  Downloading http://10.0.0.2:8080/packages/Jinja2-2.8-py2.py3-none-any.whl &lt;span class="o"&gt;(&lt;/span&gt;263kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 266kB &lt;span class="m"&gt;9&lt;/span&gt;.0MB/s
Collecting itsdangerous&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.21 &lt;span class="o"&gt;(&lt;/span&gt;from flask&lt;span class="o"&gt;)&lt;/span&gt;
  Downloading http://10.0.0.2:8080/packages/itsdangerous-0.24-py2-none-any.whl
Collecting MarkupSafe &lt;span class="o"&gt;(&lt;/span&gt;from Jinja2&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.4-&amp;gt;flask&lt;span class="o"&gt;)&lt;/span&gt;
  Downloading http://10.0.0.2:8080/packages/MarkupSafe-0.23-py2-none-any.whl
Installing collected packages: click, Werkzeug, MarkupSafe, Jinja2, itsdangerous, flask
Successfully installed Jinja2-2.8 MarkupSafe-0.23 Werkzeug-0.11.10 click-6.6 flask-0.11.1 itsdangerous-0.24
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@pyclient:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente salimos del &lt;em&gt;virtualenv&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@pyclient:~# deactivate
root@pyclient:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como punto final, queda indicar que si el paquete no está en nuestro servidor, no pasa nada; nuestro servidor va a pasar la petición al índica &lt;em&gt;pypi&lt;/em&gt; titular, de forma transparente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@pyclient:~# ./env/bin/pip install requests
Collecting requests
  Downloading requests-2.10.0-py2.py3-none-any.whl &lt;span class="o"&gt;(&lt;/span&gt;506kB&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="p"&gt;|&lt;/span&gt;████████████████████████████████&lt;span class="p"&gt;|&lt;/span&gt; 512kB &lt;span class="m"&gt;1&lt;/span&gt;.0MB/s
Installing collected packages: requests
Successfully installed requests-2.10.0
root@pyclient:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: Activar un &lt;em&gt;virtualenv&lt;/em&gt; solo pone su carpeta &lt;em&gt;bin&lt;/em&gt; en el &lt;em&gt;PATH&lt;/em&gt;. Podemos ahorrarnos comandos invocando directamente esos binarios, por ejemplo &lt;em&gt;pip&lt;/em&gt;. Esto es lo que se ha hecho en el comando anterior.&lt;/p&gt;</content><category term="python"></category><category term="PyPI"></category><category term="wheel"></category><category term="virtualenv"></category><category term="uWSGI"></category></entry><entry><title>El servidor de aplicaciones uWSGI</title><link href="http://www.linuxsysadmin.ml/2016/08/el-servidor-de-aplicaciones-uwsgi.html" rel="alternate"></link><published>2016-08-01T10:00:00+02:00</published><updated>2016-08-01T10:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-08-01:/2016/08/el-servidor-de-aplicaciones-uwsgi.html</id><summary type="html">&lt;p&gt;Estaba yo el otro día buscando un servidor de aplicaciones para aplicaciones &lt;em&gt;python&lt;/em&gt;, y entre todas las opciones encontré uno que es una auténtica joya: &lt;strong&gt;uWSGI&lt;/strong&gt;. Se trata de un servidor modular, que permite servir un amplio abanico de posibilidades en cuanto a lenguajes se refiere, usando un &lt;em&gt;plugin&lt;/em&gt; adecuado …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Estaba yo el otro día buscando un servidor de aplicaciones para aplicaciones &lt;em&gt;python&lt;/em&gt;, y entre todas las opciones encontré uno que es una auténtica joya: &lt;strong&gt;uWSGI&lt;/strong&gt;. Se trata de un servidor modular, que permite servir un amplio abanico de posibilidades en cuanto a lenguajes se refiere, usando un &lt;em&gt;plugin&lt;/em&gt; adecuado.&lt;/p&gt;
&lt;p&gt;Concretamente me llamó la atención el modo de funcionamiento llamado &lt;em&gt;emperor&lt;/em&gt;, que es un proceso que se dedica a monitorizar una carpeta concreta, de forma que se asegura de que cada fichero de configuración mantiene levantada una instancia que la sirva.&lt;/p&gt;
&lt;p&gt;Si levantamos el &lt;em&gt;emperor&lt;/em&gt;, leerá la carpeta de &lt;em&gt;vassals&lt;/em&gt;, levantando todos los que entienda. Si añadimos un fichero de configuración nuevo en caliente, levantará una instancia nueva. Si eliminamos un fichero de configuración, matará la instancia referida. Finalmente, si ese mismo fichero de configuración se modifica (un &lt;em&gt;touch&lt;/em&gt; vale), se adaptará a las nuevas directrices, recargando el código de nuestra aplicación.&lt;/p&gt;
&lt;p&gt;Vamos a empezar instalando la variante &lt;em&gt;emperor&lt;/em&gt;, que no es mas que el &lt;strong&gt;uwsgi&lt;/strong&gt; básico, con una configuración de &lt;em&gt;emperor&lt;/em&gt; y un &lt;em&gt;init script&lt;/em&gt; adecuado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# apt-get install -y uwsgi-emperor
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
...  
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;11&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;2&lt;/span&gt;.258 kB de archivos.
Se utilizarán &lt;span class="m"&gt;5&lt;/span&gt;.724 kB de espacio de disco adicional después de esta operación.
..  
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para entender un lenguaje cualquiera, hay que declarar el uso de un &lt;em&gt;plugin&lt;/em&gt; para ese lenguaje. Vamos a poner los &lt;em&gt;plugins&lt;/em&gt; para tres de los lenguajes mas utilizados, que nos van a servir como demostración para este artículo: &lt;strong&gt;python&lt;/strong&gt;, &lt;strong&gt;PHP&lt;/strong&gt; y &lt;strong&gt;ruby&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# apt-get install -y uwsgi-plugin-python uwsgi-plugin-php uwsgi-plugin-rack-ruby2.1
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
...  
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;22&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;12&lt;/span&gt;,0 MB de archivos.
Se utilizarán &lt;span class="m"&gt;49&lt;/span&gt;,9 MB de espacio de disco adicional después de esta operación.
...  
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Adicionalmente, el &lt;em&gt;plugin&lt;/em&gt; de &lt;strong&gt;ruby&lt;/strong&gt; necesita tener el paquete &lt;em&gt;rack&lt;/em&gt; instalado, así que lo ponemos también.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# apt-get install -y ruby-rack
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
...  
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;8&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;1&lt;/span&gt;.354 kB de archivos.
Se utilizarán &lt;span class="m"&gt;2&lt;/span&gt;.687 kB de espacio de disco adicional después de esta operación.
...  
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En todos los casos, bastará con poner un fichero de configuración en &lt;em&gt;/etc/uwsgi-emperor/vassals/&lt;/em&gt; para activar cada una de las aplicaciones.&lt;/p&gt;
&lt;h2&gt;Sirviendo ficheros PHP&lt;/h2&gt;
&lt;p&gt;Crearemos una carpeta contenedora para nuestros ficheros &lt;strong&gt;PHP&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mkdir /opt/php/
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En esa carpeta vamos a poner algún fichero &lt;em&gt;.php&lt;/em&gt; para tener algo que servir y demostrar que funciona. Con algo simple nos vale.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cat /opt/php/index.php
Hello from PHP, version &amp;lt;?php &lt;span class="nb"&gt;echo&lt;/span&gt; phpversion&lt;span class="o"&gt;()&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; ?&amp;gt;
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a poner un fichero de configuración que sirva &lt;strong&gt;PHP&lt;/strong&gt;, prácticamente copiado de la documentación.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cat /etc/uwsgi-emperor/vassals/php.ini
&lt;span class="o"&gt;[&lt;/span&gt;uwsgi&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;plugins&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;:php
http-socket &lt;span class="o"&gt;=&lt;/span&gt; :8080
&lt;span class="nv"&gt;master&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nv"&gt;workers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="nv"&gt;project_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/php/
check-static &lt;span class="o"&gt;=&lt;/span&gt; %&lt;span class="o"&gt;(&lt;/span&gt;project_dir&lt;span class="o"&gt;)&lt;/span&gt;
static-skip-ext &lt;span class="o"&gt;=&lt;/span&gt; .php
static-skip-ext &lt;span class="o"&gt;=&lt;/span&gt; .inc
php-docroot &lt;span class="o"&gt;=&lt;/span&gt; %&lt;span class="o"&gt;(&lt;/span&gt;project_dir&lt;span class="o"&gt;)&lt;/span&gt;
php-allowed-ext &lt;span class="o"&gt;=&lt;/span&gt; .php
php-index &lt;span class="o"&gt;=&lt;/span&gt; index.php
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y el &lt;em&gt;emperor&lt;/em&gt; se dedicará a levantar un proceso para servir esta aplicación. No hay que reiniciar nada. Lo comprobamos con una petición desde una máquina que vea a nuestro servidor:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# wget -qO- http://10.0.0.2:8080/&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Hello from PHP, version &lt;span class="m"&gt;5&lt;/span&gt;.6.20-0+deb8u1
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Sirviendo una aplicación ruby mediante el protocolo rack&lt;/h2&gt;
&lt;p&gt;Siguiendo los mismos pasos que en el paso anterior, creamos la carpeta contenedora.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mkdir /opt/ruby/
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En esta carpeta ponemos una aplicación &lt;em&gt;rack&lt;/em&gt; mínima, que he copiado de internet. Normalmente, la gente suele usar &lt;em&gt;frameworks&lt;/em&gt;, pero el resultado es el mismo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cat /opt/ruby/ruby.ru
&lt;span class="nv"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; lambda &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt;env&lt;span class="p"&gt;|&lt;/span&gt;
  &lt;span class="nv"&gt;body&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Hello, World!&amp;quot;&lt;/span&gt;
  &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;200&lt;/span&gt;, &lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Content-Type&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; &lt;span class="s2"&gt;&amp;quot;text/plain&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;Content-Length&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; body.length.to_s&lt;span class="o"&gt;}&lt;/span&gt;, &lt;span class="o"&gt;[&lt;/span&gt;body&lt;span class="o"&gt;]]&lt;/span&gt; end
run app
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y basta con declarar un fichero de configuración para que se active la nueva aplicación.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cat /etc/uwsgi-emperor/vassals/ruby.ini
&lt;span class="o"&gt;[&lt;/span&gt;uwsgi&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;plugins&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; rack_ruby21
http-socket &lt;span class="o"&gt;=&lt;/span&gt; :3031
&lt;span class="nv"&gt;master&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nv"&gt;workers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="nv"&gt;rack&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/ruby/ruby.ru
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Nuevamente podemos comprobar que el resultado es el esperado:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# wget -qO- http://10.0.0.2:3031/&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Hello, World!
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Sirviendo una aplicación python mediante el protocolo WSGI&lt;/h2&gt;
&lt;p&gt;Supongamos que tenemos una carpeta contenedora para nuestra aplicación, como en los casos anteriores:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mkdir /opt/py/
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En ella tenemos una aplicación que cumple con el protocolo &lt;strong&gt;WSGI&lt;/strong&gt;. Nuevamente vamos a simplificar el ejemplo a base de no utilizar ningún &lt;em&gt;framework&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cat /opt/py/app.py
def application&lt;span class="o"&gt;(&lt;/span&gt;environ, start_response&lt;span class="o"&gt;)&lt;/span&gt;:
    start_response&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;200 OK&amp;#39;&lt;/span&gt;, &lt;span class="o"&gt;[(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Content-Type&amp;#39;&lt;/span&gt;, &lt;span class="s1"&gt;&amp;#39;text/plain&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)])&lt;/span&gt;
    yield &lt;span class="s1"&gt;&amp;#39;Hello World from python&amp;#39;&lt;/span&gt;
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Configuramos el &lt;em&gt;vassal&lt;/em&gt; que va a dar a conocer la aplicación al &lt;em&gt;emperor&lt;/em&gt;, de forma que este la pueda levantar automáticamente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cat /etc/uwsgi-emperor/vassals/py.ini
&lt;span class="o"&gt;[&lt;/span&gt;uwsgi&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;plugins&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; python
http-socket &lt;span class="o"&gt;=&lt;/span&gt; :5000
&lt;span class="nv"&gt;master&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nv"&gt;workers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="nv"&gt;chdir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/py/
&lt;span class="nv"&gt;module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; app:application
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y vemos como todo funciona como debe:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# wget -qO- http://10.0.0.2:5000/&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Hello World from python
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Es importante indicar que el &lt;em&gt;plugin&lt;/em&gt; de &lt;strong&gt;python&lt;/strong&gt; soporta muchas mas directivas, entre ellas, la posibilidad de añadir variables de sistema como el &lt;em&gt;PYTHONPATH&lt;/em&gt;, o la de usar un &lt;em&gt;virtualenv&lt;/em&gt; propio para nuestra aplicación. Es por este motivo que me enamoré de este servidor de aplicaciones.&lt;/p&gt;</content><category term="uWSGI"></category><category term="plugins"></category><category term="PHP"></category><category term="ruby"></category><category term="python"></category></entry><entry><title>Instalando una máquina con Archlinux</title><link href="http://www.linuxsysadmin.ml/2016/07/instalando-una-maquina-con-archlinux.html" rel="alternate"></link><published>2016-07-04T20:00:00+02:00</published><updated>2016-07-04T20:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-07-04:/2016/07/instalando-una-maquina-con-archlinux.html</id><summary type="html">&lt;p&gt;Hoy quiero presentar una distribución de &lt;em&gt;linux&lt;/em&gt; que es una maravilla; es rápida, altamente actualizada, y lo último en innovación. Se trata de una distribución tipo &lt;em&gt;rolling&lt;/em&gt;, con una filosofía de última tendencia que es especialmente útil en un entorno no tan crítico, como puede ser una máquina tipo escritorio …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Hoy quiero presentar una distribución de &lt;em&gt;linux&lt;/em&gt; que es una maravilla; es rápida, altamente actualizada, y lo último en innovación. Se trata de una distribución tipo &lt;em&gt;rolling&lt;/em&gt;, con una filosofía de última tendencia que es especialmente útil en un entorno no tan crítico, como puede ser una máquina tipo escritorio.&lt;/p&gt;
&lt;p&gt;La parte menos buena, a parte del hecho de que los paquetes cambian mucho y pueden entrar algunos con algún fallo menor, es que la instalación no cuenta con un &lt;em&gt;wizard&lt;/em&gt;, aunque en el proceso podemos aprender como funciona fácilmente.&lt;/p&gt;
&lt;p&gt;Vamos a seguir bastante el procedimiento oficial de instalación, que podemos encontrar &lt;a href="https://wiki.archlinux.org/index.php/installation_guide"&gt;aquí&lt;/a&gt;. Este procedimiento de instalación lo vamos a lanzar sobre una máquina virtual, con un disco de 4gb y 512mb de memoria, aunque sin entorno gráfico necesita muchos menos recursos.&lt;/p&gt;
&lt;p&gt;El primer paso consiste en descargar una imagen de instalación que vamos a introducir (o montar, que es el equivalente en &lt;em&gt;VirtualBox&lt;/em&gt;), previo encendido de la máquina.&lt;/p&gt;
&lt;p&gt;Un detalle es que la imagen de instalación lleva instalado un servidor &lt;em&gt;SSH&lt;/em&gt;, que nos viene muy bien para capturar la salida de los diferentes comandos. Solo hay que levantar el servicio y darle una contraseña al usuario &lt;strong&gt;root&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@archiso ~ &lt;span class="c1"&gt;# passwd&lt;/span&gt;
Enter new UNIX password:
Retype new UNIX password:
passwd: password updated successfully
root@archiso ~ &lt;span class="c1"&gt;# systemctl start sshd&lt;/span&gt;
root@archiso ~ &lt;span class="c1"&gt;# &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A partir de aquí, sigo el procedimiento desde una sesión &lt;em&gt;SSH&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Preparaciones&lt;/h2&gt;
&lt;p&gt;Aunque esto no es necesario, es recomendable usar nuestro teclado favorito. No hay nada mas frustrante que darle a una tecla pensando en un carácter y que te salga otro. Así que vamos a cargar la distribución de teclado que nos parezca.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@archiso ~ &lt;span class="c1"&gt;# loadkeys es&lt;/span&gt;
root@archiso ~ &lt;span class="c1"&gt;#&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El siguiente paso consiste en configurar la red que se va a usar durante la instalación. Por defecto viene preparado para usar &lt;em&gt;DHCP&lt;/em&gt;, que nos vale, así que la dejamos como está.&lt;/p&gt;
&lt;p&gt;Uno de los pasos mas importantes de toda la instalación es el particionado. Hacerlo mal en este punto es un problema futuro, y de hecho, mucha gente utiliza tecnologías como &lt;em&gt;LVM&lt;/em&gt; que les dan cierta flexibilidad para cambios futuros.&lt;/p&gt;
&lt;p&gt;En nuestro caso concreto, se trata de una máquina virtual que no va a durar mucho, así que nos basta con hacerlo a un nivel aceptable. Como disponemos de un solo disco de 4gb, vamos a particionarlo en dos, uno para el disco local, y otro para la partición de &lt;em&gt;swap&lt;/em&gt; (una pequeña, que no nos sobra el disco). Personalmente he usado &lt;strong&gt;cfdisk&lt;/strong&gt;, que me parece mas intuitivo que el resto, dejando las particiones de esta manera:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@archiso ~ &lt;span class="c1"&gt;# fdisk -l&lt;/span&gt;
Disk /dev/sda: &lt;span class="m"&gt;4&lt;/span&gt; GiB, &lt;span class="m"&gt;4294967296&lt;/span&gt; bytes, &lt;span class="m"&gt;8388608&lt;/span&gt; sectors
Units: sectors of &lt;span class="m"&gt;1&lt;/span&gt; * &lt;span class="nv"&gt;512&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;512&lt;/span&gt; bytes
Sector size &lt;span class="o"&gt;(&lt;/span&gt;logical/physical&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;512&lt;/span&gt; bytes / &lt;span class="m"&gt;512&lt;/span&gt; bytes
I/O size &lt;span class="o"&gt;(&lt;/span&gt;minimum/optimal&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;512&lt;/span&gt; bytes / &lt;span class="m"&gt;512&lt;/span&gt; bytes
Disklabel type: gpt
Disk identifier: A45FE619-7FFC-4EA2-8253-628FD2138198

Device       Start     End Sectors  Size Type
/dev/sda1     &lt;span class="m"&gt;2048&lt;/span&gt; &lt;span class="m"&gt;7317503&lt;/span&gt; &lt;span class="m"&gt;7315456&lt;/span&gt;  &lt;span class="m"&gt;3&lt;/span&gt;.5G Linux filesystem
/dev/sda2  &lt;span class="m"&gt;7317504&lt;/span&gt; &lt;span class="m"&gt;8388574&lt;/span&gt; &lt;span class="m"&gt;1071071&lt;/span&gt;  523M Linux swap


Disk /dev/loop0: &lt;span class="m"&gt;318&lt;/span&gt;.9 MiB, &lt;span class="m"&gt;334385152&lt;/span&gt; bytes, &lt;span class="m"&gt;653096&lt;/span&gt; sectors
Units: sectors of &lt;span class="m"&gt;1&lt;/span&gt; * &lt;span class="nv"&gt;512&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;512&lt;/span&gt; bytes
Sector size &lt;span class="o"&gt;(&lt;/span&gt;logical/physical&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;512&lt;/span&gt; bytes / &lt;span class="m"&gt;512&lt;/span&gt; bytes
I/O size &lt;span class="o"&gt;(&lt;/span&gt;minimum/optimal&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;512&lt;/span&gt; bytes / &lt;span class="m"&gt;512&lt;/span&gt; bytes
root@archiso ~ &lt;span class="c1"&gt;#&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Siguiendo el manual, necesitamos formatear las particiones según las funciones que van a desempeñar, montando los discos en &lt;em&gt;/mnt/&lt;/em&gt; y sus subcarpetas. Como no tenemos particiones para &lt;em&gt;/home/&lt;/em&gt;, &lt;em&gt;/var/&lt;/em&gt; y &lt;em&gt;/tmp/&lt;/em&gt;, con montar la primera nos basta.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@archiso ~ &lt;span class="c1"&gt;# mkfs.ext4 /dev/sda1&lt;/span&gt;
mke2fs &lt;span class="m"&gt;1&lt;/span&gt;.42.13 &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;17&lt;/span&gt;-May-2015&lt;span class="o"&gt;)&lt;/span&gt;
Creating filesystem with &lt;span class="m"&gt;914432&lt;/span&gt; 4k blocks and &lt;span class="m"&gt;228928&lt;/span&gt; inodes
Filesystem UUID: 295665be-7b09-4cad-9689-7fed5471bf25
Superblock backups stored on blocks:
        &lt;span class="m"&gt;32768&lt;/span&gt;, &lt;span class="m"&gt;98304&lt;/span&gt;, &lt;span class="m"&gt;163840&lt;/span&gt;, &lt;span class="m"&gt;229376&lt;/span&gt;, &lt;span class="m"&gt;294912&lt;/span&gt;, &lt;span class="m"&gt;819200&lt;/span&gt;, &lt;span class="m"&gt;884736&lt;/span&gt;

Allocating group tables: &lt;span class="k"&gt;done&lt;/span&gt;
Writing inode tables: &lt;span class="k"&gt;done&lt;/span&gt;
Creating journal &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;16384&lt;/span&gt; blocks&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="k"&gt;done&lt;/span&gt;
Writing superblocks and filesystem accounting information: &lt;span class="k"&gt;done&lt;/span&gt;

root@archiso ~ &lt;span class="c1"&gt;# mount /dev/sda1 /mnt&lt;/span&gt;
root@archiso ~ &lt;span class="c1"&gt;#&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Preparamos la partición de &lt;em&gt;swap&lt;/em&gt; y la dejamos activada. Eso nos permitirá utilizarla durante la instalación, y que esta la detecte automáticamente para crear el fichero &lt;em&gt;/etc/fstab&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@archiso ~ &lt;span class="c1"&gt;# mkswap /dev/sda2&lt;/span&gt;
Setting up swapspace version &lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;523&lt;/span&gt; MiB &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;548380672&lt;/span&gt; bytes&lt;span class="o"&gt;)&lt;/span&gt;
no label, &lt;span class="nv"&gt;UUID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;85cf7f55-cd3c-4002-9729-2d89ebadf942
root@archiso ~ &lt;span class="c1"&gt;# swapon /dev/sda2&lt;/span&gt;
root@archiso ~ &lt;span class="c1"&gt;#&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Podemos verificar que está activada con un comando &lt;strong&gt;free&lt;/strong&gt;, por ejemplo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@archiso ~ &lt;span class="c1"&gt;# free -m&lt;/span&gt;
              total        used        free      shared  buff/cache   available
Mem:            &lt;span class="m"&gt;498&lt;/span&gt;          &lt;span class="m"&gt;20&lt;/span&gt;         &lt;span class="m"&gt;252&lt;/span&gt;          &lt;span class="m"&gt;44&lt;/span&gt;         &lt;span class="m"&gt;224&lt;/span&gt;         &lt;span class="m"&gt;413&lt;/span&gt;
Swap:           &lt;span class="m"&gt;522&lt;/span&gt;           &lt;span class="m"&gt;0&lt;/span&gt;         &lt;span class="m"&gt;522&lt;/span&gt;
root@archiso ~ &lt;span class="c1"&gt;#&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Instalación y configuración&lt;/h2&gt;
&lt;p&gt;El primer paso es descargar todos los paquetes de internet, mediante el comando &lt;strong&gt;pacstrap&lt;/strong&gt;. Para ello se recomienda editar el fichero &lt;em&gt;/etc/pacman.d/mirrorlist&lt;/em&gt; para utilizar los &lt;em&gt;mirrors&lt;/em&gt; que nos convengan, y que serán también los que use el sistema instalado. Como se pueden cambiar a &lt;em&gt;posteriori&lt;/em&gt; y los que hay me parecen bien, no vamos a cambiar nada.&lt;/p&gt;
&lt;p&gt;Así pues, lanzamos el &lt;strong&gt;pacstrap&lt;/strong&gt; tal como indica el manual de instalación.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@archiso ~ &lt;span class="c1"&gt;# pacstrap /mnt base&lt;/span&gt;
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; Creating install root at /mnt
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; Installing packages to /mnt
:: Synchronizing package databases...
 core                                                 &lt;span class="m"&gt;119&lt;/span&gt;.7 KiB   783K/s &lt;span class="m"&gt;00&lt;/span&gt;:00 &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="c1"&gt;############################################] 100%&lt;/span&gt;
 extra                                               &lt;span class="m"&gt;1755&lt;/span&gt;.7 KiB   810K/s &lt;span class="m"&gt;00&lt;/span&gt;:02 &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="c1"&gt;############################################] 100%&lt;/span&gt;
 community                                              &lt;span class="m"&gt;3&lt;/span&gt;.5 MiB   851K/s &lt;span class="m"&gt;00&lt;/span&gt;:04 &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="c1"&gt;############################################] 100%&lt;/span&gt;
:: There are &lt;span class="m"&gt;50&lt;/span&gt; members in group base:
:: Repository core
   &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; bash  &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; bzip2  &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; coreutils  &lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; cryptsetup  &lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; device-mapper  &lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; dhcpcd  &lt;span class="m"&gt;7&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; diffutils  &lt;span class="m"&gt;8&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; e2fsprogs  &lt;span class="m"&gt;9&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; file
   &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; filesystem  &lt;span class="m"&gt;11&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; findutils  &lt;span class="m"&gt;12&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; gawk  &lt;span class="m"&gt;13&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; gcc-libs  &lt;span class="m"&gt;14&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; gettext  &lt;span class="m"&gt;15&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; glibc  &lt;span class="m"&gt;16&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; grep  &lt;span class="m"&gt;17&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; gzip  &lt;span class="m"&gt;18&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; inetutils  &lt;span class="m"&gt;19&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; iproute2
   &lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; iputils  &lt;span class="m"&gt;21&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; jfsutils  &lt;span class="m"&gt;22&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; less  &lt;span class="m"&gt;23&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; licenses  &lt;span class="m"&gt;24&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; linux  &lt;span class="m"&gt;25&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; logrotate  &lt;span class="m"&gt;26&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; lvm2  &lt;span class="m"&gt;27&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; man-db  &lt;span class="m"&gt;28&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; man-pages  &lt;span class="m"&gt;29&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; mdadm
   &lt;span class="m"&gt;30&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; nano  &lt;span class="m"&gt;31&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; netctl  &lt;span class="m"&gt;32&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; pacman  &lt;span class="m"&gt;33&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; pciutils  &lt;span class="m"&gt;34&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; pcmciautils  &lt;span class="m"&gt;35&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; perl  &lt;span class="m"&gt;36&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; procps-ng  &lt;span class="m"&gt;37&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; psmisc  &lt;span class="m"&gt;38&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; reiserfsprogs
   &lt;span class="m"&gt;39&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; s-nail  &lt;span class="m"&gt;40&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; sed  &lt;span class="m"&gt;41&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; shadow  &lt;span class="m"&gt;42&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; sysfsutils  &lt;span class="m"&gt;43&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; systemd-sysvcompat  &lt;span class="m"&gt;44&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; tar  &lt;span class="m"&gt;45&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; texinfo  &lt;span class="m"&gt;46&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; usbutils  &lt;span class="m"&gt;47&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; util-linux
   &lt;span class="m"&gt;48&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; vi  &lt;span class="m"&gt;49&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; which  &lt;span class="m"&gt;50&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; xfsprogs

Enter a selection &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;all&lt;span class="o"&gt;)&lt;/span&gt;:
...  
Total Download Size:   &lt;span class="m"&gt;185&lt;/span&gt;.14 MiB
Total Installed Size:  &lt;span class="m"&gt;572&lt;/span&gt;.80 MiB

:: Proceed with installation? &lt;span class="o"&gt;[&lt;/span&gt;Y/n&lt;span class="o"&gt;]&lt;/span&gt;
...
pacstrap /mnt base  &lt;span class="m"&gt;51&lt;/span&gt;.53s user &lt;span class="m"&gt;124&lt;/span&gt;.01s system &lt;span class="m"&gt;39&lt;/span&gt;% cpu &lt;span class="m"&gt;7&lt;/span&gt;:25.44 total
root@archiso ~ &lt;span class="c1"&gt;#&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con todos los paquetes instalados, empezaremos a configurar el sistema. El primer candidato es generar el fichero &lt;em&gt;/etc/fstab&lt;/em&gt;. Existe un &lt;em&gt;script&lt;/em&gt; llamado &lt;strong&gt;genfstab&lt;/strong&gt; que va a generar un fichero &lt;em&gt;fstab&lt;/em&gt; basado en lo que tenemos ahora mismo activado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@archiso ~ &lt;span class="c1"&gt;# genfstab -p /mnt &amp;gt;&amp;gt; /mnt/etc/fstab&lt;/span&gt;
root@archiso ~ &lt;span class="c1"&gt;#&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El resto de configuración se hace en un entorno &lt;strong&gt;chroot&lt;/strong&gt; sobre la carpeta instalada, que es donde tenemos montado el disco raíz. La imagen de instalación nos ofrece un &lt;em&gt;script&lt;/em&gt; de &lt;strong&gt;chroot&lt;/strong&gt; que ya se encarga de montar los sistemas de ficheros especiales como &lt;em&gt;/proc/&lt;/em&gt;, &lt;em&gt;/dev/&lt;/em&gt; o &lt;em&gt;/sys/&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@archiso ~ &lt;span class="c1"&gt;# arch-chroot /mnt&lt;/span&gt;
sh-4.3#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Los siguientes pasos son burocráticos y los mismos que en otras distribuciones: poner un nombre a la máquina, configurar el huso horario, generar &lt;em&gt;locales&lt;/em&gt; y configurar el teclado a nivel permanente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sh-4.3# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;archlinux&amp;quot;&lt;/span&gt; &amp;gt; /etc/hostname
sh-4.3# ln -s /usr/share/zoneinfo/Europe/Madrid /etc/localtime
sh-4.3# grep -v ^# /etc/locale.gen
es_ES.UTF-8 UTF-8
sh-4.3# locale-gen
Generating locales...
  es_ES.UTF-8... &lt;span class="k"&gt;done&lt;/span&gt;
Generation complete.
sh-4.3# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;LANG=es_ES.UTF-8&amp;quot;&lt;/span&gt; &amp;gt; /etc/locale.conf
sh-4.3# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;KEYMAP=es&amp;quot;&lt;/span&gt; &amp;gt; /etc/vconsole.conf
sh-4.3#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El siguiente paso no es fácil, y aunque puede hacerse a &lt;em&gt;posteriori&lt;/em&gt;, merece la pena prestar atención. Para la configuración de red, necesitamos activar el servicio &lt;em&gt;systemd-networkd&lt;/em&gt;, que va a leer los ficheros de configuración en &lt;em&gt;/etc/systemd/network/&lt;/em&gt; para levantar las interfaces con los parámetros adecuados.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sh-4.3# systemctl &lt;span class="nb"&gt;enable&lt;/span&gt; systemd-networkd
Created symlink /etc/systemd/system/multi-user.target.wants/systemd-networkd.service → /usr/lib/systemd/system/systemd-networkd.service.
Created symlink /etc/systemd/system/sockets.target.wants/systemd-networkd.socket → /usr/lib/systemd/system/systemd-networkd.socket.
sh-4.3# cat /etc/systemd/network/wired.network
&lt;span class="o"&gt;[&lt;/span&gt;Match&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;enp0s3

&lt;span class="o"&gt;[&lt;/span&gt;Network&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;DHCP&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;ipv4
sh-4.3#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En caso de querer obtener los &lt;em&gt;DNS&lt;/em&gt; de forma automática necesitamos habilitar el servicio &lt;em&gt;systemd-resolved&lt;/em&gt;, que nos va a dejar un &lt;em&gt;resolv.conf&lt;/em&gt; en &lt;em&gt;/run/systemd/resolve/&lt;/em&gt;; con un simple enlace va a ser suficiente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sh-4.3# systemctl &lt;span class="nb"&gt;enable&lt;/span&gt; systemd-resolved
Created symlink /etc/systemd/system/multi-user.target.wants/systemd-resolved.service → /usr/lib/systemd/system/systemd-resolved.service.
sh-4.3# rm /etc/resolv.conf
sh-4.3# ln -s /run/systemd/resolve/resolv.conf /etc/resolv.conf
sh-4.3#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Generamos un &lt;em&gt;initramfs&lt;/em&gt; para que en el siguiente arranque podamos disfrutar de todo lo nuevo que hemos configurado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sh-4.3# mkinitcpio -p &lt;span class="nv"&gt;linux&lt;/span&gt;
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; Building image from preset: /etc/mkinitcpio.d/linux.preset: &lt;span class="s1"&gt;&amp;#39;default&amp;#39;&lt;/span&gt;
  -&amp;gt; -k /boot/vmlinuz-linux -c /etc/mkinitcpio.conf -g /boot/initramfs-linux.img
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; Starting build: &lt;span class="m"&gt;4&lt;/span&gt;.5.4-1-ARCH
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;base&lt;span class="o"&gt;]&lt;/span&gt;
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;udev&lt;span class="o"&gt;]&lt;/span&gt;
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;autodetect&lt;span class="o"&gt;]&lt;/span&gt;
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;modconf&lt;span class="o"&gt;]&lt;/span&gt;
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;block&lt;span class="o"&gt;]&lt;/span&gt;
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;filesystems&lt;span class="o"&gt;]&lt;/span&gt;
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;keyboard&lt;span class="o"&gt;]&lt;/span&gt;
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;fsck&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; Generating module &lt;span class="nv"&gt;dependencies&lt;/span&gt;
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; Creating gzip-compressed initcpio image: /boot/initramfs-linux.img
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; Image generation &lt;span class="nv"&gt;successful&lt;/span&gt;
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; Building image from preset: /etc/mkinitcpio.d/linux.preset: &lt;span class="s1"&gt;&amp;#39;fallback&amp;#39;&lt;/span&gt;
  -&amp;gt; -k /boot/vmlinuz-linux -c /etc/mkinitcpio.conf -g /boot/initramfs-linux-fallback.img -S &lt;span class="nv"&gt;autodetect&lt;/span&gt;
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; Starting build: &lt;span class="m"&gt;4&lt;/span&gt;.5.4-1-ARCH
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;base&lt;span class="o"&gt;]&lt;/span&gt;
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;udev&lt;span class="o"&gt;]&lt;/span&gt;
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;modconf&lt;span class="o"&gt;]&lt;/span&gt;
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;block&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; WARNING: Possibly missing firmware &lt;span class="k"&gt;for&lt;/span&gt; module: &lt;span class="nv"&gt;aic94xx&lt;/span&gt;
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; WARNING: Possibly missing firmware &lt;span class="k"&gt;for&lt;/span&gt; module: wd719x
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;filesystems&lt;span class="o"&gt;]&lt;/span&gt;
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;keyboard&lt;span class="o"&gt;]&lt;/span&gt;
  -&amp;gt; Running build hook: &lt;span class="o"&gt;[&lt;/span&gt;fsck&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; Generating module &lt;span class="nv"&gt;dependencies&lt;/span&gt;
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; Creating gzip-compressed initcpio image: /boot/initramfs-linux-fallback.img
&lt;span class="o"&gt;==&lt;/span&gt;&amp;gt; Image generation successful
sh-4.3#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y finalmente nos podemos dedicar a administrar usuarios y sus contraseñas. Como esto también se puede hacer a &lt;em&gt;posteriori&lt;/em&gt;, voy solo a desbloquear al usuario &lt;strong&gt;root&lt;/strong&gt;, dándole una &lt;em&gt;password&lt;/em&gt; adecuada.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sh-4.3# passwd
Enter new UNIX password:
Retype new UNIX password:
passwd: password updated successfully
sh-4.3#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto tenemos el disco raíz perfectamente preparado, y un &lt;em&gt;kernel&lt;/em&gt; listo para el arranque.&lt;/p&gt;
&lt;h2&gt;Instalando el bootloader&lt;/h2&gt;
&lt;p&gt;Para que el &lt;em&gt;kernel&lt;/em&gt;, &lt;em&gt;initrd&lt;/em&gt; y el disco puedan funcionar, es necesario que el disco tenga algún tipo de estructura que le indique como hacerlo. El nombre genérico para esta pieza de &lt;em&gt;software&lt;/em&gt; es &lt;em&gt;bootloader&lt;/em&gt;. De todos los que hay (que no son pocos), vamos a usar un viejo amigo: &lt;strong&gt;GRUB&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sh-4.3# pacman -S grub
resolving dependencies...
looking &lt;span class="k"&gt;for&lt;/span&gt; conflicting packages...

Packages &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; grub-1:2.02.beta2-6

Total Download Size:    &lt;span class="m"&gt;5&lt;/span&gt;.27 MiB
Total Installed Size:  &lt;span class="m"&gt;25&lt;/span&gt;.27 MiB

:: Proceed with installation? &lt;span class="o"&gt;[&lt;/span&gt;Y/n&lt;span class="o"&gt;]&lt;/span&gt; y
...
sh-4.3#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Instalamos el código de &lt;em&gt;boot&lt;/em&gt; en el &lt;em&gt;MBR&lt;/em&gt; con la herramienta que &lt;strong&gt;GRUB&lt;/strong&gt; nos ofrece, siguiendo el manual.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sh-4.3# grub-install --target&lt;span class="o"&gt;=&lt;/span&gt;i386-pc /dev/sda
Installing &lt;span class="k"&gt;for&lt;/span&gt; i386-pc platform.
grub-install: warning: this GPT partition label contains no BIOS Boot Partition&lt;span class="p"&gt;;&lt;/span&gt; embedding won&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;t be possible.
grub-install: warning: Embedding is not possible.  GRUB can only be installed in this setup by using blocklists.  However, blocklists are UNRELIABLE and their use is discouraged..
grub-install: error: will not proceed with blocklists.
sh-4.3#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este caso ha fallado, pero siguiendo el manual de instalación, eso se corrige mediante el uso del &lt;em&gt;flag&lt;/em&gt; &lt;strong&gt;--force&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sh-4.3# grub-install --target&lt;span class="o"&gt;=&lt;/span&gt;i386-pc /dev/sda --force
Installing &lt;span class="k"&gt;for&lt;/span&gt; i386-pc platform.
grub-install: warning: this GPT partition label contains no BIOS Boot Partition&lt;span class="p"&gt;;&lt;/span&gt; embedding won&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;t be possible.
grub-install: warning: Embedding is not possible.  GRUB can only be installed in this setup by using blocklists.  However, blocklists are UNRELIABLE and their use is discouraged..
Installation finished. No error reported.
sh-4.3#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como ya hemos conseguido instalar &lt;strong&gt;GRUB&lt;/strong&gt; de forma exitosa, nos queda generar un fichero de configuración del &lt;em&gt;bootloader&lt;/em&gt;, tal como dice el manual de instalación.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sh-4.3# grub-mkconfig -o /boot/grub/grub.cfg
Generating grub configuration file ...
Found linux image: /boot/vmlinuz-linux
Found initrd image: /boot/initramfs-linux.img
Found fallback initramfs image: /boot/initramfs-linux-fallback.img
&lt;span class="k"&gt;done&lt;/span&gt;
sh-4.3#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto queda una instalación básica. Solo nos queda salir del entorno enjaulado, apagar la máquina, quitar el disco de instalación y encender.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sh-4.3# &lt;span class="nb"&gt;exit&lt;/span&gt;
&lt;span class="nb"&gt;exit&lt;/span&gt;
arch-chroot /mnt  &lt;span class="m"&gt;10&lt;/span&gt;.17s user &lt;span class="m"&gt;19&lt;/span&gt;.71s system &lt;span class="m"&gt;3&lt;/span&gt;% cpu &lt;span class="m"&gt;14&lt;/span&gt;:10.46 total
root has logged on pts/1 from &lt;span class="m"&gt;10&lt;/span&gt;.0.2.2.
root@archiso ~ &lt;span class="c1"&gt;# reboot&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Resultado final&lt;/h2&gt;
&lt;p&gt;Tras actualizar y limpiar caché de paquetes, vemos que tenemos una distribución minimalista con 743mb de disco ocupados y 10mb de memoria.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;root@archlinux ~&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="c1"&gt;# df -h&lt;/span&gt;
S.ficheros     Tamaño Usados  Disp Uso% Montado en
dev              247M      &lt;span class="m"&gt;0&lt;/span&gt;  247M   &lt;span class="m"&gt;0&lt;/span&gt;% /dev
run              250M   292K  249M   &lt;span class="m"&gt;1&lt;/span&gt;% /run
/dev/sda1        &lt;span class="m"&gt;3&lt;/span&gt;,4G   743M  &lt;span class="m"&gt;2&lt;/span&gt;,5G  &lt;span class="m"&gt;23&lt;/span&gt;% /
tmpfs            250M      &lt;span class="m"&gt;0&lt;/span&gt;  250M   &lt;span class="m"&gt;0&lt;/span&gt;% /dev/shm
tmpfs            250M      &lt;span class="m"&gt;0&lt;/span&gt;  250M   &lt;span class="m"&gt;0&lt;/span&gt;% /sys/fs/cgroup
tmpfs            250M      &lt;span class="m"&gt;0&lt;/span&gt;  250M   &lt;span class="m"&gt;0&lt;/span&gt;% /tmp
tmpfs             50M      &lt;span class="m"&gt;0&lt;/span&gt;   50M   &lt;span class="m"&gt;0&lt;/span&gt;% /run/user/0
&lt;span class="o"&gt;[&lt;/span&gt;root@archlinux ~&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="c1"&gt;# free -m&lt;/span&gt;
              total        used        free      shared  buff/cache   available
Mem:            &lt;span class="m"&gt;498&lt;/span&gt;          &lt;span class="m"&gt;10&lt;/span&gt;         &lt;span class="m"&gt;441&lt;/span&gt;           &lt;span class="m"&gt;0&lt;/span&gt;          &lt;span class="m"&gt;46&lt;/span&gt;         &lt;span class="m"&gt;470&lt;/span&gt;
Swap:           &lt;span class="m"&gt;522&lt;/span&gt;           &lt;span class="m"&gt;0&lt;/span&gt;         &lt;span class="m"&gt;522&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;root@archlinux ~&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A partir de aquí podemos construir a base de instalar aquellos paquetes que necesitemos (escritorio, servicios, ...); sin embargo, esto queda para futuros artículos.&lt;/p&gt;</content><category term="linux"></category><category term="archlinux"></category><category term="distribución"></category></entry><entry><title>Balanceando peticiones con HAProxy</title><link href="http://www.linuxsysadmin.ml/2016/06/balanceando-peticiones-con-haproxy.html" rel="alternate"></link><published>2016-06-27T08:00:00+02:00</published><updated>2016-06-27T08:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-06-27:/2016/06/balanceando-peticiones-con-haproxy.html</id><summary type="html">&lt;p&gt;Cuando tenemos un entorno grande o con previsiones de crecimiento, nos interesa poder poner a trabajar varios servidores similares. En casos así nos hace falta un &lt;strong&gt;balanceador de carga&lt;/strong&gt;, que actúa como un agente de tráfico, dirigiendo las peticiones que él mismo recibe a los diferentes servidores, por ejemplo, &lt;strong&gt;haproxy …&lt;/strong&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Cuando tenemos un entorno grande o con previsiones de crecimiento, nos interesa poder poner a trabajar varios servidores similares. En casos así nos hace falta un &lt;strong&gt;balanceador de carga&lt;/strong&gt;, que actúa como un agente de tráfico, dirigiendo las peticiones que él mismo recibe a los diferentes servidores, por ejemplo, &lt;strong&gt;haproxy&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;En este artículo vamos a montar el balanceador &lt;strong&gt;haproxy&lt;/strong&gt;, usando &lt;strong&gt;ansible&lt;/strong&gt;, basándonos en las imágenes &lt;strong&gt;docker&lt;/strong&gt; de &lt;a href="http://www.linuxsysadmin.ml/2016/06/controlando-contenedores-docker-con-ansible.html"&gt;otro artículo&lt;/a&gt;. La ideas es que vamos a poner un único balanceador que va a escuchar en dos puertos, balanceando dos &lt;em&gt;backends&lt;/em&gt; en cada uno, por ejemplo una web y una &lt;em&gt;api&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
slave               latest              22a9312a1315        About an hour ago   &lt;span class="m"&gt;186&lt;/span&gt; MB
ansible             latest              225b431d2133        About an hour ago   &lt;span class="m"&gt;245&lt;/span&gt;.5 MB
debian              latest              bb5d89f9b6cb        &lt;span class="m"&gt;2&lt;/span&gt; weeks ago         &lt;span class="m"&gt;125&lt;/span&gt;.1 MB
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Preparando el entorno&lt;/h2&gt;
&lt;p&gt;El primer paso es disponer de una red para que todos los servidores implicados se puedan comunicar entre ellos. La red que viene por defecto nos permite eso, pero vamos a crear una red &lt;em&gt;user defined&lt;/em&gt; que nos va a permitir que los contenedores &lt;strong&gt;docker&lt;/strong&gt; se conozcan entre ellos por su nombre.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ docker network create --subnet&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;172&lt;/span&gt;.20.0.0/16 balancing
4585a1abd0ed69bc9d1daf0dd019e1f129a9e7328471da77541f5b4a54c19626
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Se trata de levantar 5 servidores: 1 para &lt;strong&gt;haproxy&lt;/strong&gt; y otros 4 para representar los servidores de &lt;em&gt;backend&lt;/em&gt;, que vamos a trucar para que parezca lo que no son. Es importante &lt;em&gt;publicar&lt;/em&gt; los puertos que queramos exponer, para ver que funciona la solución final; si queremos balancear los puertos 8080 (web), 8081 (api) y 1936 (haproxy stats), pondríamos algo como esto:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~$ docker run -d -h balancer --name balancer --net balancing -p &lt;span class="m"&gt;8080&lt;/span&gt;:8080 -p &lt;span class="m"&gt;8081&lt;/span&gt;:8081 -p &lt;span class="m"&gt;1936&lt;/span&gt;:1936 slave
70e4811e6a498c7ecdec11ed91609d43749c327e33bd3b06b1532b507f3f2141
gerard@sirius:~/build$ &lt;span class="k"&gt;for&lt;/span&gt; host in web1 web2 api1 api2&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; docker run -d -h &lt;span class="nv"&gt;$host&lt;/span&gt; --name &lt;span class="nv"&gt;$host&lt;/span&gt; --net balancing slave&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;done&lt;/span&gt;
82be4f7788f0186834311fe625f4ae24908a59a25df8b246aeb18d13cdff7b3d
a0514880a44ed9109d19dc594ae991245e052554d91f0b08da80d57808df3d29
1217fd05aa321e52e0038e4870dd29776e843d88de03520ad0bffee6cb786b54
635c9b2d04482018053dca4b4225a34d3a11be1c366e372b9536fcadea12a15a
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Verificamos que tenemos todos nuestros contenedores corriendo:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ docker ps
CONTAINER ID        IMAGE               COMMAND               CREATED              STATUS              PORTS                                                      NAMES
635c9b2d0448        slave               &amp;quot;/usr/sbin/sshd -D&amp;quot;   10 seconds ago       Up 8 seconds                                                                   api2
1217fd05aa32        slave               &amp;quot;/usr/sbin/sshd -D&amp;quot;   11 seconds ago       Up 9 seconds                                                                   api1
a0514880a44e        slave               &amp;quot;/usr/sbin/sshd -D&amp;quot;   12 seconds ago       Up 10 seconds                                                                  web2
82be4f7788f0        slave               &amp;quot;/usr/sbin/sshd -D&amp;quot;   13 seconds ago       Up 12 seconds                                                                  web1
70e4811e6a49        slave               &amp;quot;/usr/sbin/sshd -D&amp;quot;   About a minute ago   Up About a minute   0.0.0.0:1936-&amp;gt;1936/tcp, 0.0.0.0:8080-8081-&amp;gt;8080-8081/tcp   balancer
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Preparando las herramientas&lt;/h2&gt;
&lt;p&gt;Como ya hemos comentado, vamos a utilizar &lt;strong&gt;ansible&lt;/strong&gt;. Para ejecutar los &lt;em&gt;playbooks&lt;/em&gt;, vamos a levantar una máquina para usar y tirar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ docker run -ti --rm --net balancing -h ansible --name ansible ansible
root@ansible:/# &lt;span class="nb"&gt;cd&lt;/span&gt; /root
root@ansible:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Especificamos un fichero de &lt;em&gt;hosts&lt;/em&gt; que va a servir para indicar los contenedores que tenemos y vamos a instalar paquetes en función de su grupo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# cat hosts 
&lt;span class="o"&gt;[&lt;/span&gt;all:vars&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;ansible_user&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; ansible
&lt;span class="nv"&gt;ansible_ssh_pass&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; s3cr3t
&lt;span class="nv"&gt;ansible_become&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nv"&gt;ansible_become_method&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; sudo
&lt;span class="nv"&gt;ansible_become_user&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; root
&lt;span class="nv"&gt;ansible_become_pass&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; s3cr3t

&lt;span class="o"&gt;[&lt;/span&gt;balancers&lt;span class="o"&gt;]&lt;/span&gt;
balancer

&lt;span class="o"&gt;[&lt;/span&gt;webs&lt;span class="o"&gt;]&lt;/span&gt;
web1
web2

&lt;span class="o"&gt;[&lt;/span&gt;apis&lt;span class="o"&gt;]&lt;/span&gt;
api1
api2
root@ansible:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Opcionalmente, verificamos que todos los contenedores son accesibles desde &lt;strong&gt;ansible&lt;/strong&gt;. Eso nos puede evitar sorpresas futuras.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# ansible -i hosts -m ping all
balancer &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;SUCCESS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;changed&amp;quot;&lt;/span&gt;: false, 
    &lt;span class="s2"&gt;&amp;quot;ping&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;pong&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
api2 &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;SUCCESS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;changed&amp;quot;&lt;/span&gt;: false, 
    &lt;span class="s2"&gt;&amp;quot;ping&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;pong&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
api1 &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;SUCCESS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;changed&amp;quot;&lt;/span&gt;: false, 
    &lt;span class="s2"&gt;&amp;quot;ping&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;pong&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
web2 &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;SUCCESS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;changed&amp;quot;&lt;/span&gt;: false, 
    &lt;span class="s2"&gt;&amp;quot;ping&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;pong&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
web1 &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;SUCCESS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;changed&amp;quot;&lt;/span&gt;: false, 
    &lt;span class="s2"&gt;&amp;quot;ping&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;pong&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@ansible:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Instalando unos backends sustitutos&lt;/h2&gt;
&lt;p&gt;Sea lo que sea que vayan a ejecutar los &lt;em&gt;backends&lt;/em&gt; reales, los podemos ver como una caja negra que ofrecen sus servicios mediante protocolo TCP/IP en un puerto concreto.&lt;/p&gt;
&lt;p&gt;Como no nos importa demasiado lo que hagan, y para simplificar el artículo, los vamos a reemplazar con servidores web &lt;strong&gt;nginx&lt;/strong&gt;, sirviendo un fichero HTML con su nombre (para poder distinguirlos en las pruebas). De esta forma, podremos ver el tipo de servidor que responde (api o web) y su número, ya que ambos datos están en su &lt;em&gt;hostname&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Así pues, basta con un &lt;em&gt;playbook&lt;/em&gt; que instale el servidor web y ponga el fichero &lt;em&gt;.html&lt;/em&gt; en su sitio. Como &lt;strong&gt;docker&lt;/strong&gt; está ejecutando el servidor &lt;strong&gt;ssh&lt;/strong&gt; y no &lt;strong&gt;systemd&lt;/strong&gt;, el &lt;strong&gt;nginx&lt;/strong&gt; no se levanta. Con otra tarea para asegurar que está corriendo, basta.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# cat backends.yml 
- hosts: webs, apis
  tasks:
    - apt: &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;nginx-light &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;present
    - copy: &lt;span class="nv"&gt;content&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Content from {{ inventory_hostname }}&amp;quot;&lt;/span&gt; &lt;span class="nv"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/var/www/html/index.html
    - service: &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;nginx &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;started
root@ansible:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lanzamos el &lt;em&gt;playbook&lt;/em&gt;, y los dejamos preparados para que el balanceador los pueda usar. En un entorno real, dedicaríamos mas tiempo en poner servidores de aplicaciones normales, con aplicaciones adecuadas, y que posiblemente usarían algún tipo de base de datos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# ansible-playbook -i hosts backends.yml 

PLAY &lt;span class="o"&gt;[&lt;/span&gt;webs, apis&lt;span class="o"&gt;]&lt;/span&gt; **************************************************************

TASK &lt;span class="o"&gt;[&lt;/span&gt;setup&lt;span class="o"&gt;]&lt;/span&gt; *******************************************************************
ok: &lt;span class="o"&gt;[&lt;/span&gt;web2&lt;span class="o"&gt;]&lt;/span&gt;
ok: &lt;span class="o"&gt;[&lt;/span&gt;api1&lt;span class="o"&gt;]&lt;/span&gt;
ok: &lt;span class="o"&gt;[&lt;/span&gt;web1&lt;span class="o"&gt;]&lt;/span&gt;
ok: &lt;span class="o"&gt;[&lt;/span&gt;api2&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;apt&lt;span class="o"&gt;]&lt;/span&gt; *********************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;api1&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;api2&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;web1&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;web2&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;copy&lt;span class="o"&gt;]&lt;/span&gt; ********************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;web1&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;web2&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;api2&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;api1&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;service&lt;span class="o"&gt;]&lt;/span&gt; *****************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;web1&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;web2&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;api1&lt;span class="o"&gt;]&lt;/span&gt;
changed: &lt;span class="o"&gt;[&lt;/span&gt;api2&lt;span class="o"&gt;]&lt;/span&gt;

PLAY RECAP *********************************************************************
api1                       : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;   
api2                       : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;   
web1                       : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;   
web2                       : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;   

root@ansible:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Montando el balanceador&lt;/h2&gt;
&lt;p&gt;Para obtener un balanceador HTTP (o TCP, si lo necesitáramos), basta con elegir uno. Normalmente yo usaría un servidor &lt;strong&gt;nginx&lt;/strong&gt; para balancear HTTP (que además ofrece otras funcionalidades, aunque no soporte TCP directo); en este caso, y para variar un poco, vamos a poner &lt;strong&gt;haproxy&lt;/strong&gt;, que nos ofrece una bonita página de estadísticas.&lt;/p&gt;
&lt;p&gt;El truco está en instalar &lt;strong&gt;haproxy&lt;/strong&gt;, darle un fichero de configuración adecuado y recargar su configuración. Nuevamente, al tratarse de &lt;strong&gt;docker&lt;/strong&gt; hay que asegurarse que el servicio esté levantado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# cat balancer.yml 
- hosts: balancer
  tasks:
    - apt: &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;haproxy &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;present
    - service: &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;haproxy &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;started
    - copy: &lt;span class="nv"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;haproxy.cfg &lt;span class="nv"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/etc/haproxy/haproxy.cfg
    - service: &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;haproxy &lt;span class="nv"&gt;state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;reloaded
root@ansible:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La funcionalidad con la que cumpla el balanceador se controla en &lt;em&gt;/etc/haproxy/haproxy.cfg&lt;/em&gt;, que el &lt;em&gt;playbook&lt;/em&gt; pone en su sitio, desde una carpeta en el contexto.&lt;/p&gt;
&lt;p&gt;HAProxy funciona mapeando &lt;em&gt;frontends&lt;/em&gt; (entradas del balanceador) con sus respectivos &lt;em&gt;backends&lt;/em&gt; (servidores que atienden peticiones).&lt;/p&gt;
&lt;p&gt;Disponemos de varios algoritmos de balanceo, así que vamos a poner uno distinto para cada &lt;em&gt;backend&lt;/em&gt;. Para la web, vamos a usar &lt;em&gt;roundrobin&lt;/em&gt;, que básicamente se trata de una petición a cada uno por turnos; la &lt;em&gt;api&lt;/em&gt; va a contar con el algoritmo &lt;em&gt;leastconn&lt;/em&gt;, que significa darle una petición al servidor que menos conexiones tiene abiertas.&lt;/p&gt;
&lt;p&gt;Como &lt;em&gt;bonus track&lt;/em&gt;, vamos a habilitar la página de estadísticas, siempre que la queramos, claro. La he copiado tal cual de la documentación de &lt;strong&gt;haproxy&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# cat haproxy.cfg 
listen stats :1936
    mode http
    stats enable
    stats hide-version
    stats uri /

frontend web
    bind :8080
    default_backend webs

backend webs
    balance roundrobin
    server web1 web1:80
    server web2 web2:80

frontend api
    bind :8081
    default_backend apis

backend apis
    balance leastconn
    server api1 api1:80
    server api2 api2:80
root@ansible:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Solo nos faltaría lanzar el &lt;em&gt;playbook&lt;/em&gt; para que quede todo correctamente montado. Si la configuración cambiara o hubiera que corregirla, se debe modificar el fichero local &lt;em&gt;haproxy.cfg&lt;/em&gt; y relanzar el &lt;em&gt;playbook&lt;/em&gt;. &lt;strong&gt;Ansible&lt;/strong&gt; no intentará cambiar nada que ya esté como debía; no instalará &lt;strong&gt;haproxy&lt;/strong&gt; de nuevo, no lo levantará si ya estaba corriendo, no copiará el fichero a menos que haya cambiado, y siempre va a recargar la configuración del servicio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# ansible-playbook -i hosts balancer.yml 

PLAY &lt;span class="o"&gt;[&lt;/span&gt;balancer&lt;span class="o"&gt;]&lt;/span&gt; ****************************************************************

TASK &lt;span class="o"&gt;[&lt;/span&gt;setup&lt;span class="o"&gt;]&lt;/span&gt; *******************************************************************
ok: &lt;span class="o"&gt;[&lt;/span&gt;balancer&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;apt&lt;span class="o"&gt;]&lt;/span&gt; *********************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;balancer&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;service&lt;span class="o"&gt;]&lt;/span&gt; *****************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;balancer&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;copy&lt;span class="o"&gt;]&lt;/span&gt; ********************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;balancer&lt;span class="o"&gt;]&lt;/span&gt;

TASK &lt;span class="o"&gt;[&lt;/span&gt;service&lt;span class="o"&gt;]&lt;/span&gt; *****************************************************************
changed: &lt;span class="o"&gt;[&lt;/span&gt;balancer&lt;span class="o"&gt;]&lt;/span&gt;

PLAY RECAP *********************************************************************
balancer                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;   

root@ansible:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comprobando el funcionamiento&lt;/h2&gt;
&lt;p&gt;Si hacemos peticiones individuales, vemos que cada servidor funciona, pero lo que nos importa es el conjunto. Para ello vamos a solicitar peticiones a cada uno de los puertos que representan el &lt;em&gt;cluster&lt;/em&gt; de web y de &lt;em&gt;api&lt;/em&gt;. Puesto que los hemos publicado con el mismo número de puerto en la máquina anfitriona, lo podemos lanzar ahí mismo.&lt;/p&gt;
&lt;p&gt;Hacemos unas peticines al &lt;em&gt;cluster&lt;/em&gt; de web, que se esconde detrás del puerto 8080, y comprobamos que van alternando un &lt;em&gt;backend&lt;/em&gt; u otro por turnos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~$ curl http://localhost:8080/ &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Content from web1
gerard@sirius:~$ curl http://localhost:8080/ &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Content from web2
gerard@sirius:~$ curl http://localhost:8080/ &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Content from web1
gerard@sirius:~$ curl http://localhost:8080/ &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Content from web2
gerard@sirius:~$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Repetimos el procedimiento para la &lt;em&gt;api&lt;/em&gt;, que se esconde en el puerto 8081 del balanceador:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~$ curl http://localhost:8081/ &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Content from api1
gerard@sirius:~$ curl http://localhost:8081/ &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Content from api2
gerard@sirius:~$ curl http://localhost:8081/ &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Content from api1
gerard@sirius:~$ curl http://localhost:8081/ &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Content from api2
gerard@sirius:~$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y solo nos queda ver que la página de estadísticas funciona y nos resulta útil. Puesto que devuelve una página web completa, lo vamos a ver en un navegador cualquiera.&lt;/p&gt;
&lt;p&gt;&lt;img alt="HAProxy Stats" src="http://www.linuxsysadmin.ml/images/haproxy-stats.jpg"&gt;&lt;/p&gt;</content><category term="balanceador"></category><category term="haproxy"></category><category term="ansible"></category><category term="docker"></category></entry><entry><title>Preparando un servidor de repositorios GIT</title><link href="http://www.linuxsysadmin.ml/2016/06/preparando-un-servidor-de-repositorios-git.html" rel="alternate"></link><published>2016-06-20T08:30:00+02:00</published><updated>2016-06-20T08:30:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-06-20:/2016/06/preparando-un-servidor-de-repositorios-git.html</id><summary type="html">&lt;p&gt;Algunas veces tenemos necesidad de crear un proyecto con un equipo pequeño y necesitamos versionarlo en un sitio accesible para todos los participantes involucrados. El precio de soluciones en la nube suele ser prohibitivo, y montar una solución gráfica puede ser demasiado. Lo podemos hacer simplemente usando &lt;strong&gt;git&lt;/strong&gt; y &lt;strong&gt;ssh …&lt;/strong&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Algunas veces tenemos necesidad de crear un proyecto con un equipo pequeño y necesitamos versionarlo en un sitio accesible para todos los participantes involucrados. El precio de soluciones en la nube suele ser prohibitivo, y montar una solución gráfica puede ser demasiado. Lo podemos hacer simplemente usando &lt;strong&gt;git&lt;/strong&gt; y &lt;strong&gt;ssh&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;La idea es muy simple; solo se necesita un servidor de &lt;strong&gt;ssh&lt;/strong&gt;, que es la forma de transportar los datos, y los binarios de &lt;strong&gt;git&lt;/strong&gt; para que los organice a placer. También vamos a necesitar un usuario &lt;strong&gt;git&lt;/strong&gt;, que es el que vamos a usar para entrar, ya sea para crear y borrar repositorios, como para las operaciones remotas recibidas por el repositorio.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: Podemos eliminar la petición de &lt;em&gt;password&lt;/em&gt; para todos los accesos que se hagan por &lt;strong&gt;SSH&lt;/strong&gt;, sean para entrar en las máquinas por &lt;strong&gt;SSH&lt;/strong&gt; mediante cualquier &lt;em&gt;shell&lt;/em&gt; de este artículo, o como resultado de una operación remota de &lt;strong&gt;git&lt;/strong&gt;. Esto se puede hacer usando autenticación &lt;strong&gt;SSH&lt;/strong&gt; por claves, como se explica en un &lt;a href="http://www.linuxsysadmin.ml/2016/05/autenticacion-ssh-por-claves.html"&gt;artículo anterior&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Montando el servidor&lt;/h2&gt;
&lt;p&gt;Para crear la máquina base, vamos a utilizar &lt;strong&gt;Docker&lt;/strong&gt; por comodidad. Aprovechando esta tecnología, podemos crear el contenedor partiendo de una imagen creada con un &lt;em&gt;Dockerfile&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ cat Dockerfile
FROM debian:jessie
RUN apt-get update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    apt-get install -y git openssh-server &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    mkdir /var/run/sshd
RUN useradd git -G sudo -s /bin/bash -m &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;git:git&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; chpasswd
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/usr/sbin/sshd&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;-D&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Construimos la imagen, basándonos en el anterior &lt;em&gt;Dockerfile&lt;/em&gt;, y le añadimos el &lt;em&gt;tag&lt;/em&gt; "gitserver".&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ docker build -t gitserver .
Sending build context to Docker daemon &lt;span class="m"&gt;5&lt;/span&gt;.632 kB
Step &lt;span class="m"&gt;1&lt;/span&gt; : FROM debian:jessie
 ---&amp;gt; bb5d89f9b6cb
Step &lt;span class="m"&gt;2&lt;/span&gt; : RUN apt-get update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     apt-get install -y git openssh-server &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     mkdir /var/run/sshd
 ---&amp;gt; Running in 6b612781b788
...
 ---&amp;gt; e88e644b0a53
Removing intermediate container 6b612781b788
Step &lt;span class="m"&gt;3&lt;/span&gt; : RUN useradd git -G sudo -s /bin/bash -m &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;git:git&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; chpasswd
 ---&amp;gt; Running in 0e865bda447e
 ---&amp;gt; 81d111c19c71
Removing intermediate container 0e865bda447e
Step &lt;span class="m"&gt;4&lt;/span&gt; : CMD /usr/sbin/sshd -D
 ---&amp;gt; Running in 67bbebe61c74
 ---&amp;gt; 81c2dd7b156a
Removing intermediate container 67bbebe61c74
Successfully built 81c2dd7b156a
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lanzamos una instancia del contenedor para que podamos utilizarla. La parte importante es el &lt;em&gt;flag&lt;/em&gt; &lt;strong&gt;-d&lt;/strong&gt; para ejecutar el contenedor en &lt;em&gt;background&lt;/em&gt;, y el &lt;em&gt;flag&lt;/em&gt; &lt;strong&gt;-p&lt;/strong&gt; que nos permite publicar el puerto 22 del contenedor en el puerto 22222 de la máquina &lt;em&gt;host&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ docker run -d --name gitserver1 -h gitserver1 -p &lt;span class="m"&gt;22222&lt;/span&gt;:22 gitserver
c26f30a94bb75b35c6d6cfe6a6bc5b1ef6929aafe1b5636acd207e019743540b
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a entrar en el servidor &lt;strong&gt;SSH&lt;/strong&gt; para crear el repositorio &lt;em&gt;myrepo.git&lt;/em&gt; que nos va a servir de ejemplo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ ssh git@localhost -p &lt;span class="m"&gt;22222&lt;/span&gt;
git@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 

The programs included with the Debian GNU/Linux system are free software&lt;span class="p"&gt;;&lt;/span&gt;
the exact distribution terms &lt;span class="k"&gt;for&lt;/span&gt; each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
git@gitserver1:~$ git init --bare myrepo.git
Initialized empty Git repository in /home/git/myrepo.git/
git@gitserver1:~$ &lt;span class="nb"&gt;exit&lt;/span&gt;
&lt;span class="nb"&gt;logout&lt;/span&gt;
Connection to localhost closed.
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Desde la máquina &lt;em&gt;host&lt;/em&gt; (o desde cualquier otra), podemos clonar el repositorio. Como tenemos el puerto del contenedor publicado en el puerto 22222 de la máquina &lt;em&gt;host&lt;/em&gt; (la de trabajo, en este caso), la usamos tal cual para clonar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ git clone ssh://git@localhost:22222/home/git/myrepo.git
Cloning into &lt;span class="s1"&gt;&amp;#39;myrepo&amp;#39;&lt;/span&gt;...
git@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
warning: You appear to have cloned an empty repository.
Checking connectivity... &lt;span class="k"&gt;done&lt;/span&gt;.
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hacemos un poco de trabajo local, con sus respectivos &lt;em&gt;commits&lt;/em&gt;. Finalmente podemos hacer un &lt;em&gt;push&lt;/em&gt; a nuestro repositorio remoto, siguiendo el &lt;em&gt;workflow&lt;/em&gt; de trabajo que queramos seguir.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ &lt;span class="nb"&gt;cd&lt;/span&gt; myrepo/
gerard@sirius:~/build/myrepo$ &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.0.1 &amp;gt; VERSION
gerard@sirius:~/build/myrepo$ git add VERSION 
gerard@sirius:~/build/myrepo$ git commit -m &lt;span class="s2"&gt;&amp;quot;Initial commit&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;master &lt;span class="o"&gt;(&lt;/span&gt;root-commit&lt;span class="o"&gt;)&lt;/span&gt; f30b82a&lt;span class="o"&gt;]&lt;/span&gt; Initial commit
 &lt;span class="m"&gt;1&lt;/span&gt; file changed, &lt;span class="m"&gt;1&lt;/span&gt; insertion&lt;span class="o"&gt;(&lt;/span&gt;+&lt;span class="o"&gt;)&lt;/span&gt;
 create mode &lt;span class="m"&gt;100644&lt;/span&gt; VERSION
gerard@sirius:~/build/myrepo$ git push -u origin master
git@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
Counting objects: &lt;span class="m"&gt;3&lt;/span&gt;, &lt;span class="k"&gt;done&lt;/span&gt;.
Writing objects: &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;/3&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;222&lt;/span&gt; bytes &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; bytes/s, &lt;span class="k"&gt;done&lt;/span&gt;.
Total &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;delta &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, reused &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;delta &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
To ssh://git@localhost:22222/home/git/myrepo.git
 * &lt;span class="o"&gt;[&lt;/span&gt;new branch&lt;span class="o"&gt;]&lt;/span&gt;      master -&amp;gt; master
Branch master &lt;span class="nb"&gt;set&lt;/span&gt; up to track remote branch master from origin.
gerard@sirius:~/build/myrepo$ &lt;span class="nb"&gt;cd&lt;/span&gt; ..
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Añadiendo restricciones a la sesión SSH&lt;/h2&gt;
&lt;p&gt;Es un poco peligroso permitir que el usuario &lt;em&gt;git&lt;/em&gt; entre mediante una sesión &lt;strong&gt;SSH&lt;/strong&gt; para hacer lo que le parezca.&lt;/p&gt;
&lt;p&gt;Los mismos binarios de &lt;strong&gt;git&lt;/strong&gt; incluyen &lt;strong&gt;git-shell&lt;/strong&gt;, que es un &lt;em&gt;shell&lt;/em&gt; que limita lo que puede hacer el usuario, aunque solo permitiría hacer las operaciones &lt;em&gt;push&lt;/em&gt; y &lt;em&gt;pull&lt;/em&gt; propias del trabajo remoto con &lt;strong&gt;git&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;¿Y como podemos crear y destruir repositorios? En principio, no se puede. Sin embargo, si creamos una carpeta &lt;em&gt;/home/git/git-shell-commands/&lt;/em&gt;, el usuario va a poder ejecutar los &lt;em&gt;scripts&lt;/em&gt; que allí pongamos.&lt;/p&gt;
&lt;p&gt;Siguiendo esta idea, vamos a mejorar el &lt;em&gt;Dockerfile&lt;/em&gt; para asignar &lt;strong&gt;git-shell&lt;/strong&gt; al usuario &lt;em&gt;git&lt;/em&gt; y para ponerle un par de comandos.&lt;/p&gt;
&lt;p&gt;Vamos a crear dos &lt;em&gt;scripts&lt;/em&gt; que nos permitan crear y destruir repositorios, que son los siguientes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ cat create 
&lt;span class="c1"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="si"&gt;${#}&lt;/span&gt; -ne &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[ERROR] Syntax: create &amp;lt;repository&amp;gt;&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; -1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; -e &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.git &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[ERROR] Repository &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; exists&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; -1
&lt;span class="k"&gt;fi&lt;/span&gt;

git init --bare &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.git
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[OK] Repository &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; created&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
gerard@sirius:~/build$ cat destroy 
&lt;span class="c1"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="si"&gt;${#}&lt;/span&gt; -ne &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[ERROR] Syntax: destroy &amp;lt;repository&amp;gt;&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; -1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; -e &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.git &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    rm -Rf &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.git
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[OK] Repository &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; deleted&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[ERROR] Repository &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; does not exist&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;exit&lt;/span&gt; -1
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;También vamos a reescribir el &lt;em&gt;Dockerfile&lt;/em&gt; con las nuevas modificaciones.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ cat Dockerfile.shell 
FROM debian:jessie
RUN apt-get update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    apt-get install -y git openssh-server &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    mkdir /var/run/sshd
RUN useradd git -G sudo -s /usr/bin/git-shell -m &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;git:git&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; chpasswd &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    mkdir /home/git/git-shell-commands
COPY create destroy /home/git/git-shell-commands/
RUN cp /usr/share/doc/git/contrib/git-shell-commands/help /home/git/git-shell-commands/ &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    cp /usr/share/doc/git/contrib/git-shell-commands/list /home/git/git-shell-commands/ &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    chmod &lt;span class="m"&gt;755&lt;/span&gt; /home/git/git-shell-commands/*
CMD &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/usr/sbin/sshd&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;-D&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos la imagen usando el &lt;em&gt;Dockerfile&lt;/em&gt; antes mencionado, siguiendo el mismo procedimiento de la versión básica. Le ponemos un &lt;em&gt;tag&lt;/em&gt; distinto para tener ambas imágenes funcionales.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ docker build -f Dockerfile.shell -t gitserver:shell .
Sending build context to Docker daemon &lt;span class="m"&gt;53&lt;/span&gt;.25 kB
Step &lt;span class="m"&gt;1&lt;/span&gt; : FROM debian:jessie
 ---&amp;gt; bb5d89f9b6cb
Step &lt;span class="m"&gt;2&lt;/span&gt; : RUN apt-get update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     apt-get install -y git openssh-server &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     mkdir /var/run/sshd
 ---&amp;gt; Using cache
 ---&amp;gt; e88e644b0a53
Step &lt;span class="m"&gt;3&lt;/span&gt; : RUN useradd git -G sudo -s /usr/bin/git-shell -m &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;git:git&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; chpasswd &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     mkdir /home/git/git-shell-commands
 ---&amp;gt; Running in 387d2791d63f
 ---&amp;gt; 0ab419cdfc2d
Removing intermediate container 387d2791d63f
Step &lt;span class="m"&gt;4&lt;/span&gt; : COPY create destroy /home/git/git-shell-commands/
 ---&amp;gt; e1aa5fa9cb44
Removing intermediate container 92fd282c6979
Step &lt;span class="m"&gt;5&lt;/span&gt; : RUN cp /usr/share/doc/git/contrib/git-shell-commands/help /home/git/git-shell-commands/ &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     cp /usr/share/doc/git/contrib/git-shell-commands/list /home/git/git-shell-commands/ &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;     chmod &lt;span class="m"&gt;755&lt;/span&gt; /home/git/git-shell-commands/*
 ---&amp;gt; Running in 45ed8f24a547
 ---&amp;gt; 2237b87165bc
Removing intermediate container 45ed8f24a547
Step &lt;span class="m"&gt;6&lt;/span&gt; : CMD /usr/sbin/sshd -D
 ---&amp;gt; Running in b94b8c1ddf8a
 ---&amp;gt; e484e1465480
Removing intermediate container b94b8c1ddf8a
Successfully built e484e1465480
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lanzamos una instancia de la imagen creada. Es importante cambiar el puerto; puesto que el 22222 está ocupado por la instancia anterior, usaré el siguiente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ docker run -d --name gitserver2 -h gitserver2 -p &lt;span class="m"&gt;22223&lt;/span&gt;:22 gitserver:shell
e732027d11b90657ff109a455f032327f0e24eebe54a7e121d86eff6eab1bc4b
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Entramos por &lt;strong&gt;SSH&lt;/strong&gt;. Nos podemos dar cuenta de que el &lt;em&gt;prompt&lt;/em&gt; ha cambiado; estamos en el &lt;strong&gt;git-shell&lt;/strong&gt; y tenemos limitados los comandos a los que añadimos en el &lt;em&gt;Dockerfile&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ ssh git@localhost -p &lt;span class="m"&gt;22223&lt;/span&gt;
git@localhost&lt;span class="s1"&gt;&amp;#39;s password: &lt;/span&gt;

&lt;span class="s1"&gt;The programs included with the Debian GNU/Linux system are free software;&lt;/span&gt;
&lt;span class="s1"&gt;the exact distribution terms for each program are described in the&lt;/span&gt;
&lt;span class="s1"&gt;individual files in /usr/share/doc/*/copyright.&lt;/span&gt;

&lt;span class="s1"&gt;Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent&lt;/span&gt;
&lt;span class="s1"&gt;permitted by applicable law.&lt;/span&gt;
&lt;span class="s1"&gt;Run &amp;#39;&lt;/span&gt;help&lt;span class="s1"&gt;&amp;#39; for help, or &amp;#39;&lt;/span&gt;exit&lt;span class="err"&gt;&amp;#39;&lt;/span&gt; to leave.  Available commands:
create
destroy
list
git&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Usamos el comando &lt;em&gt;create&lt;/em&gt; para crear el repositorio y verificamos que está usando el comando &lt;em&gt;list&lt;/em&gt;. Tendríamos disponible el comando &lt;em&gt;destroy&lt;/em&gt;, pero de momento no lo vamos a utilizar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&amp;gt; create myrepo2
Initialized empty Git repository in /home/git/myrepo2.git/
&lt;span class="o"&gt;[&lt;/span&gt;OK&lt;span class="o"&gt;]&lt;/span&gt; Repository myrepo2 created
git&amp;gt; list
myrepo2.git
git&amp;gt; &lt;span class="nb"&gt;exit&lt;/span&gt;
Connection to localhost closed.
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Verificamos que funciona, clonando el repositorio como hemos hecho antes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ git clone ssh://git@localhost:22223/home/git/myrepo2.git
Cloning into &lt;span class="s1"&gt;&amp;#39;myrepo2&amp;#39;&lt;/span&gt;...
git@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
warning: You appear to have cloned an empty repository.
Checking connectivity... &lt;span class="k"&gt;done&lt;/span&gt;.
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hacemos algunos &lt;em&gt;commits&lt;/em&gt; locales y finalmente los pasamos al repositorio remoto mediante un &lt;em&gt;push&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@sirius:~/build$ &lt;span class="nb"&gt;cd&lt;/span&gt; myrepo2/
gerard@sirius:~/build/myrepo2$ &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.0.1 &amp;gt; VERSION
gerard@sirius:~/build/myrepo2$ git add VERSION
gerard@sirius:~/build/myrepo2$ git commit -m &lt;span class="s2"&gt;&amp;quot;Initial commit&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;master &lt;span class="o"&gt;(&lt;/span&gt;root-commit&lt;span class="o"&gt;)&lt;/span&gt; fd40f39&lt;span class="o"&gt;]&lt;/span&gt; Initial commit
 &lt;span class="m"&gt;1&lt;/span&gt; file changed, &lt;span class="m"&gt;1&lt;/span&gt; insertion&lt;span class="o"&gt;(&lt;/span&gt;+&lt;span class="o"&gt;)&lt;/span&gt;
 create mode &lt;span class="m"&gt;100644&lt;/span&gt; VERSION
gerard@sirius:~/build/myrepo2$ git push -u origin master
git@localhost&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s password: 
Counting objects: &lt;span class="m"&gt;3&lt;/span&gt;, &lt;span class="k"&gt;done&lt;/span&gt;.
Writing objects: &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;/3&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;222&lt;/span&gt; bytes &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; bytes/s, &lt;span class="k"&gt;done&lt;/span&gt;.
Total &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;delta &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, reused &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;delta &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
To ssh://git@localhost:22223/home/git/myrepo2.git
 * &lt;span class="o"&gt;[&lt;/span&gt;new branch&lt;span class="o"&gt;]&lt;/span&gt;      master -&amp;gt; master
Branch master &lt;span class="nb"&gt;set&lt;/span&gt; up to track remote branch master from origin.
gerard@sirius:~/build/myrepo2$ &lt;span class="nb"&gt;cd&lt;/span&gt; ..
gerard@sirius:~/build$ 
&lt;/pre&gt;&lt;/div&gt;</content><category term="linux"></category><category term="git"></category><category term="ssh"></category><category term="docker"></category></entry><entry><title>MongoDB sharding con ansible</title><link href="http://www.linuxsysadmin.ml/2016/05/mongodb-sharding-con-ansible.html" rel="alternate"></link><published>2016-05-02T00:00:00+02:00</published><updated>2016-05-02T00:00:00+02:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-05-02:/2016/05/mongodb-sharding-con-ansible.html</id><summary type="html">&lt;p&gt;Como ya vimos en un artículo anterior, los &lt;em&gt;replica sets&lt;/em&gt; nos ofrecen alta disponibilidad para nuestros despliegues de &lt;strong&gt;mongodb&lt;/strong&gt;. Sin embargo, algunas veces, necesitamos que nuestro &lt;em&gt;cluster&lt;/em&gt; ofrezca alto rendimiento, y esto se consigue mediante &lt;em&gt;sharding&lt;/em&gt;. Como no queremos renunciar a la alta disponibilidad, podemos aplicar ambas; hoy explicamos como …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Como ya vimos en un artículo anterior, los &lt;em&gt;replica sets&lt;/em&gt; nos ofrecen alta disponibilidad para nuestros despliegues de &lt;strong&gt;mongodb&lt;/strong&gt;. Sin embargo, algunas veces, necesitamos que nuestro &lt;em&gt;cluster&lt;/em&gt; ofrezca alto rendimiento, y esto se consigue mediante &lt;em&gt;sharding&lt;/em&gt;. Como no queremos renunciar a la alta disponibilidad, podemos aplicar ambas; hoy explicamos como.&lt;/p&gt;
&lt;p&gt;El mecanismo de &lt;em&gt;sharding&lt;/em&gt; es bastante simple: tenemos nuestros datos repartidos entre uno o mas &lt;em&gt;shards&lt;/em&gt;, que se van a repartir los datos del &lt;em&gt;cluster&lt;/em&gt;. Para mantener un control de donde están los datos, también vamos a necesitar unos procesos especiales llamados &lt;em&gt;config servers&lt;/em&gt;. Finalmente, habrá que poner algunos procesos &lt;em&gt;mongos&lt;/em&gt; que son unos &lt;em&gt;proxies&lt;/em&gt; al &lt;em&gt;cluster&lt;/em&gt; y sirven para ocultar la complejidad del mismo.&lt;/p&gt;
&lt;h2&gt;Visión del conjunto&lt;/h2&gt;
&lt;p&gt;Hay que decir que el mecanismo de &lt;em&gt;sharding&lt;/em&gt; permite poner y quitar &lt;em&gt;shards&lt;/em&gt; a &lt;em&gt;posteriori&lt;/em&gt;, igual que con los procesos &lt;em&gt;mongos&lt;/em&gt;, pero para empezar vamos a necesitar una arquitectura inicial que es lo que vamos a montar.&lt;/p&gt;
&lt;p&gt;Para empezar se ha decidido por un &lt;em&gt;cluster&lt;/em&gt; de 3 &lt;em&gt;shards&lt;/em&gt;, siendo cada uno de ellos un &lt;em&gt;replica set&lt;/em&gt; de dos nodos de datos y un árbitro cada uno. Usaremos la cantidad de &lt;em&gt;config servers&lt;/em&gt; que se recomienda en la documentación oficial.&lt;/p&gt;
&lt;p&gt;Así pues, y tras elegir nombres para los &lt;em&gt;shards&lt;/em&gt;, podemos pintar un esquema de nuestro &lt;em&gt;cluster&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Arquitectura lógica" src="http://www.linuxsysadmin.ml/images/sharding_arquitectura_logica.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Para repartir los procesos entre las máquinas, hay dos reglas que hay que respetar a rajatabla:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Los procesos de datos necesitan una máquina propia, para que no se disputen los recursos de disco y memoria.&lt;/li&gt;
&lt;li&gt;No hay que poner nunca dos o mas procesos de cada &lt;em&gt;shard&lt;/em&gt;, ya que la no disponibilidad de la máquina supondría la pérdida de la mayoría de las &lt;em&gt;replica sets&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El resto de procesos pueden compartir servidor con los de datos. Hay muchas formas de cumplir con las dos reglas, por ejemplo, la que vamos a montar:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Arquitectura física" src="http://www.linuxsysadmin.ml/images/sharding_arquitectura_fisica.jpg"&gt;&lt;/p&gt;
&lt;h2&gt;Ansible al rescate&lt;/h2&gt;
&lt;p&gt;Debido a la gran cantidad de procesos que hay que levantar, se ha decidido por automatizar su despliegue mediante &lt;strong&gt;ansible&lt;/strong&gt;. El proceso es bastante similar a &lt;a href="http://www.linuxsysadmin.ml/2015/12/construyendo-una-replica-set-en-mongodb.html"&gt;otro de nuestros artículos&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Se ha utilizado el mecanismo de &lt;strong&gt;roles&lt;/strong&gt; de &lt;strong&gt;ansible&lt;/strong&gt;, para poder desplegar todos los procesos del mismo tipo; el detalle es que se han usado los parámetros en los &lt;strong&gt;roles&lt;/strong&gt; para los cambios menores. Si queréis intentarlo o entender como funcionan los despliegues, podéis encontrar los &lt;strong&gt;playbooks&lt;/strong&gt; &lt;a href="http://www.linuxsysadmin.ml/downloads/sharding_playbooks.tar.gz"&gt;aquí&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;El fichero comprimido no incluye los binarios de &lt;strong&gt;mongodb&lt;/strong&gt; para reducir tamaño, así que hay que añadirlos en las respectivas carpetas &lt;em&gt;files&lt;/em&gt;. Tras descomprimir el fichero &lt;em&gt;.tar.gz&lt;/em&gt; y poner los binarios ausentes, nos debería quedar algo como esto:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# tree
.
├── aquila_shard.yaml
├── clients.yaml
├── config_servers.yaml
├── cygnus_shard.yaml
├── hosts.yaml
├── lyra_shard.yaml
├── mongos_servers.yaml
└── roles
    ├── client
    │   ├── files
    │   │   └── mongo
    │   └── tasks
    │       └── main.yaml
    ├── config
    │   ├── meta
    │   │   └── main.yaml
    │   ├── tasks
    │   │   └── main.yaml
    │   └── templates
    │       ├── config.conf
    │       └── config.service
    ├── mongod
    │   ├── files
    │   │   └── mongod
    │   └── tasks
    │       └── main.yaml
    ├── mongos
    │   ├── files
    │   │   └── mongos
    │   ├── tasks
    │   │   └── main.yaml
    │   └── templates
    │       ├── mongos.conf
    │       └── mongos.service
    └── shard
        ├── meta
        │   └── main.yaml
        ├── tasks
        │   └── main.yaml
        └── templates
            ├── shard.conf
            └── shard.service

&lt;span class="m"&gt;19&lt;/span&gt; directories, &lt;span class="m"&gt;23&lt;/span&gt; files
root@ansible:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Preparación de las máquinas&lt;/h2&gt;
&lt;p&gt;De acuerdo con la arquitectura propuesta, vamos a necesitar 6 servidores para el &lt;em&gt;cluster&lt;/em&gt;, que vamos a montar como contenedores LXC y, aunque no es lo ideal, nos vale como demostración. En la séptima máquina es donde tenemos las herramientas de configuración, en este caso, &lt;strong&gt;ansible&lt;/strong&gt; y los &lt;strong&gt;playbooks&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# lxc-ls -f
NAME     STATE    IPV4        IPV6  AUTOSTART
---------------------------------------------
ansible  RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.254  -     NO
mongo01  RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.2    -     NO
mongo02  RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.3    -     NO
mongo03  RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.4    -     NO
mongo04  RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.5    -     NO
mongo05  RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.6    -     NO
mongo06  RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.7    -     NO
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a declarar todas las máquina usadas en el fichero &lt;em&gt;hosts&lt;/em&gt; de &lt;strong&gt;ansible&lt;/strong&gt;. Ya de paso, los vamos a catalogar en grupos, para que los &lt;strong&gt;playbooks&lt;/strong&gt; se puedan lanzar a los grupos, indistintamente de los servidores que los formen.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# cat ansible/etc/hosts
&lt;span class="o"&gt;[&lt;/span&gt;mongo_servers&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.2
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.3
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.4
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.5
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.6
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.7

&lt;span class="o"&gt;[&lt;/span&gt;config_servers&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.2
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.3
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.4

&lt;span class="o"&gt;[&lt;/span&gt;aquila_shard_data&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.2
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.5

&lt;span class="o"&gt;[&lt;/span&gt;aquila_shard_arbiters&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.6

&lt;span class="o"&gt;[&lt;/span&gt;lyra_shard_data&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.3
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.6

&lt;span class="o"&gt;[&lt;/span&gt;lyra_shard_arbiters&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.7

&lt;span class="o"&gt;[&lt;/span&gt;cygnus_shard_data&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.4
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.7

&lt;span class="o"&gt;[&lt;/span&gt;cygnus_shard_arbiters&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.5

&lt;span class="o"&gt;[&lt;/span&gt;mongos_servers&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.2

&lt;span class="o"&gt;[&lt;/span&gt;clients&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.2
root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Por comodidad, vamos a referirnos a las máquinas por su nombre, y a falta de un servidor DNS adecuado, vamos a rellenar sus ficheros &lt;em&gt;/etc/hosts&lt;/em&gt;; para ello vamos a usar un &lt;strong&gt;playbook&lt;/strong&gt; que se asegure que esas líneas están en el fichero.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# ansible-playbook hosts.yaml

...

PLAY RECAP *********************************************************************
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.2                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.3                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.4                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.5                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.6                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.7                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Los config servers&lt;/h2&gt;
&lt;p&gt;Los &lt;em&gt;config servers&lt;/em&gt; son procesos &lt;strong&gt;mongod&lt;/strong&gt; con una configuración concreta. El &lt;strong&gt;playbook&lt;/strong&gt; se limita a crear una estructura en &lt;em&gt;/opt/mongodb/&lt;/em&gt; asegurándose que hay el binario &lt;strong&gt;mongod&lt;/strong&gt;, la configuración, la carpeta de datos y la &lt;em&gt;unit&lt;/em&gt; de &lt;strong&gt;systemd&lt;/strong&gt; activa.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# ansible-playbook config_servers.yaml

...

PLAY RECAP *********************************************************************
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.2                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.3                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.4                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Un acceso al cluster&lt;/h2&gt;
&lt;p&gt;Para poder configurar el &lt;em&gt;cluster&lt;/em&gt; y para un uso futuro, hemos decidido poner un proceso &lt;strong&gt;mongos&lt;/strong&gt; y el binario &lt;strong&gt;mongo&lt;/strong&gt; para poder acceder al &lt;em&gt;mongo shell&lt;/em&gt;. Se ha optado por separar los &lt;strong&gt;playbooks&lt;/strong&gt;; así se podrá utilizar para desplegarlos por separado en futuras máquinas que los puedan usar.&lt;/p&gt;
&lt;p&gt;De hecho, la recomendación oficial es poner un &lt;strong&gt;mongos&lt;/strong&gt; en cada &lt;em&gt;backend&lt;/em&gt;, aunque no necesitan el binario &lt;strong&gt;mongo&lt;/strong&gt; porque disponen de los &lt;em&gt;drivers&lt;/em&gt; oficiales del lenguaje que utilicen.&lt;/p&gt;
&lt;p&gt;Empezaremos desplegando los procesos &lt;strong&gt;mongos&lt;/strong&gt; en donde toque (de momento solo en el servidor &lt;em&gt;mongo01&lt;/em&gt;). Este &lt;strong&gt;playbook&lt;/strong&gt; se limita a poner el binario &lt;strong&gt;mongos&lt;/strong&gt; y su respectiva &lt;em&gt;unit&lt;/em&gt; para &lt;strong&gt;systemd&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# ansible-playbook mongos_servers.yaml

...

PLAY RECAP *********************************************************************
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.2                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para nuestra comodidad, también vamos a desplegar el &lt;em&gt;mongo shell&lt;/em&gt;. Este &lt;strong&gt;playbook&lt;/strong&gt; se limita a poner el binario &lt;strong&gt;mongo&lt;/strong&gt; en su sitio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# ansible-playbook clients.yaml

...

PLAY RECAP *********************************************************************
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.2                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Los procesos de los shards&lt;/h2&gt;
&lt;p&gt;Tenemos 9 procesos de este tipo, así que los &lt;strong&gt;roles&lt;/strong&gt; de &lt;strong&gt;ansible&lt;/strong&gt; tienen un protagonismo especial. Los cambios entre los procesos son mínimos, y se pasan por parámetro para que el rol cree los ficheros necesarios a partir de una plantilla. El rol se encarga solamente de poner el binario &lt;strong&gt;mongod&lt;/strong&gt; en &lt;em&gt;/opt/mongodb/bin&lt;/em&gt;, crear la carpeta de datos y configurar el servicio como una &lt;em&gt;unit&lt;/em&gt; de &lt;strong&gt;systemd&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Se ha decidido separar los &lt;em&gt;shards&lt;/em&gt; en diferentes &lt;strong&gt;playbooks&lt;/strong&gt; para simplificar la creación de futuros nuevos &lt;em&gt;shards&lt;/em&gt;; así pues, lanzamos el &lt;strong&gt;playbook&lt;/strong&gt; para el primer &lt;em&gt;shard&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# ansible-playbook aquila_shard.yaml

...

PLAY RECAP *********************************************************************
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.2                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.5                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.6                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Acto seguido, lanzamos el &lt;strong&gt;playbook&lt;/strong&gt; responsable de montar los procesos del segundo &lt;em&gt;shard&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# ansible-playbook lyra_shard.yaml

...

PLAY RECAP *********************************************************************
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.3                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.6                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.7                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y finalmente, lanzamos el tercer &lt;strong&gt;playbook&lt;/strong&gt; para desplegar los procesos del último &lt;em&gt;shard&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@ansible:~# ansible-playbook cygnus_shard.yaml

...

PLAY RECAP *********************************************************************
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.4                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.5                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.7                   : &lt;span class="nv"&gt;ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="nv"&gt;changed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="nv"&gt;unreachable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="nv"&gt;failed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;

root@ansible:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Atando los replica sets&lt;/h2&gt;
&lt;p&gt;El paso anterior nos ha dejado todos los procesos en funcionamiento, pero no hemos iniciado los &lt;em&gt;replica sets&lt;/em&gt;. Para que funcionen como tal, tenemos que configurarlos uno por uno como ya sabemos hacer, usando &lt;em&gt;rs.status()&lt;/em&gt; para verificar que ha quedado todo como debe.&lt;/p&gt;
&lt;p&gt;Empezaremos con una máquina cualquiera del primer &lt;em&gt;shard&lt;/em&gt;; la configuración se propagará al resto sin nuestra intervención.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo01:~# /opt/mongodb/bin/mongo --host &lt;span class="m"&gt;10&lt;/span&gt;.0.0.5 --port &lt;span class="m"&gt;27018&lt;/span&gt;
MongoDB shell version: &lt;span class="m"&gt;3&lt;/span&gt;.2.5
connecting to: &lt;span class="m"&gt;10&lt;/span&gt;.0.0.5:27018/test
...
&amp;gt; &lt;span class="nv"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
...     _id : &lt;span class="s2"&gt;&amp;quot;aquila&amp;quot;&lt;/span&gt;,
...      members : &lt;span class="o"&gt;[&lt;/span&gt;
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : &lt;span class="m"&gt;0&lt;/span&gt;, host : &lt;span class="s2"&gt;&amp;quot;mongo01:27018&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : &lt;span class="m"&gt;1&lt;/span&gt;, host : &lt;span class="s2"&gt;&amp;quot;mongo04:27018&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : &lt;span class="m"&gt;2&lt;/span&gt;, host : &lt;span class="s2"&gt;&amp;quot;mongo05:27020&amp;quot;&lt;/span&gt;, arbiterOnly: true&lt;span class="o"&gt;}&lt;/span&gt;,
...      &lt;span class="o"&gt;]&lt;/span&gt;
... &lt;span class="o"&gt;}&lt;/span&gt;
...
&amp;gt; rs.initiate&lt;span class="o"&gt;(&lt;/span&gt;config&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
aquila:OTHER&amp;gt; rs.status&lt;span class="o"&gt;()&lt;/span&gt;
...
aquila:PRIMARY&amp;gt; &lt;span class="nb"&gt;exit&lt;/span&gt;
bye
root@mongo01:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Seguimos con el segundo &lt;em&gt;shard&lt;/em&gt;, entrando en una de sus máquinas y lanzando el comando de configuración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo01:~# /opt/mongodb/bin/mongo --host &lt;span class="m"&gt;10&lt;/span&gt;.0.0.6 --port &lt;span class="m"&gt;27018&lt;/span&gt;
MongoDB shell version: &lt;span class="m"&gt;3&lt;/span&gt;.2.5
connecting to: &lt;span class="m"&gt;10&lt;/span&gt;.0.0.6:27018/test
...
&amp;gt; &lt;span class="nv"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
...     _id : &lt;span class="s2"&gt;&amp;quot;lyra&amp;quot;&lt;/span&gt;,
...      members : &lt;span class="o"&gt;[&lt;/span&gt;
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : &lt;span class="m"&gt;0&lt;/span&gt;, host : &lt;span class="s2"&gt;&amp;quot;mongo02:27018&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : &lt;span class="m"&gt;1&lt;/span&gt;, host : &lt;span class="s2"&gt;&amp;quot;mongo05:27018&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : &lt;span class="m"&gt;2&lt;/span&gt;, host : &lt;span class="s2"&gt;&amp;quot;mongo06:27020&amp;quot;&lt;/span&gt;, arbiterOnly: true&lt;span class="o"&gt;}&lt;/span&gt;,
...      &lt;span class="o"&gt;]&lt;/span&gt;
... &lt;span class="o"&gt;}&lt;/span&gt;
...
&amp;gt; rs.initiate&lt;span class="o"&gt;(&lt;/span&gt;config&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
lyra:OTHER&amp;gt; rs.status&lt;span class="o"&gt;()&lt;/span&gt;
...
lyra:PRIMARY&amp;gt; &lt;span class="nb"&gt;exit&lt;/span&gt;
bye
root@mongo01:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y montamos el tercer &lt;em&gt;shard&lt;/em&gt; desde una cualquiera de sus &lt;em&gt;replicas&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo01:~# /opt/mongodb/bin/mongo --host &lt;span class="m"&gt;10&lt;/span&gt;.0.0.7 --port &lt;span class="m"&gt;27018&lt;/span&gt;
MongoDB shell version: &lt;span class="m"&gt;3&lt;/span&gt;.2.5
connecting to: &lt;span class="m"&gt;10&lt;/span&gt;.0.0.7:27018/test
...
&amp;gt; &lt;span class="nv"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
...     _id : &lt;span class="s2"&gt;&amp;quot;cygnus&amp;quot;&lt;/span&gt;,
...      members : &lt;span class="o"&gt;[&lt;/span&gt;
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : &lt;span class="m"&gt;0&lt;/span&gt;, host : &lt;span class="s2"&gt;&amp;quot;mongo03:27018&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : &lt;span class="m"&gt;1&lt;/span&gt;, host : &lt;span class="s2"&gt;&amp;quot;mongo06:27018&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;,
...          &lt;span class="o"&gt;{&lt;/span&gt;_id : &lt;span class="m"&gt;2&lt;/span&gt;, host : &lt;span class="s2"&gt;&amp;quot;mongo04:27020&amp;quot;&lt;/span&gt;, arbiterOnly: true&lt;span class="o"&gt;}&lt;/span&gt;,
...      &lt;span class="o"&gt;]&lt;/span&gt;
... &lt;span class="o"&gt;}&lt;/span&gt;
...
&amp;gt; rs.initiate&lt;span class="o"&gt;(&lt;/span&gt;config&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
cygnus:OTHER&amp;gt; rs.status&lt;span class="o"&gt;()&lt;/span&gt;
...
cygnus:PRIMARY&amp;gt; &lt;span class="nb"&gt;exit&lt;/span&gt;
bye
root@mongo01:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Añadiendo los shards al cluster&lt;/h2&gt;
&lt;p&gt;Ahora tenemos un grupo de &lt;em&gt;config servers&lt;/em&gt;, que forman un &lt;em&gt;cluster&lt;/em&gt; de 0 &lt;em&gt;shards&lt;/em&gt; (válido pero inútil, ya que no tenemos donde guardar los datos). También disponemos de 3 &lt;em&gt;replica sets&lt;/em&gt; independientes, que se convertirán en los futuros &lt;em&gt;shards&lt;/em&gt;. Solo falta asociar los &lt;em&gt;shards&lt;/em&gt; al resto del &lt;em&gt;cluster&lt;/em&gt;, mediante el comando &lt;em&gt;sh.addShard()&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Para ello entramos en un &lt;strong&gt;mongos&lt;/strong&gt; desde donde lanzaremos los comandos. De hecho, solo tenemos uno, en &lt;em&gt;mongo01&lt;/em&gt;. Puesto que está en la misma máquina que el cliente &lt;strong&gt;mongo&lt;/strong&gt; y corre en el puerto estándar 27017, no hace falta especificar ni el &lt;em&gt;host&lt;/em&gt; ni el puerto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo01:~# /opt/mongodb/bin/mongo
MongoDB shell version: &lt;span class="m"&gt;3&lt;/span&gt;.2.5
connecting to: &lt;span class="nb"&gt;test&lt;/span&gt;
...
mongos&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Veamos como está el cluster antes de añadir los &lt;em&gt;shards&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mongos&amp;gt; printShardingStatus&lt;span class="o"&gt;()&lt;/span&gt;
--- Sharding Status ---
  sharding version: &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt;,
        &lt;span class="s2"&gt;&amp;quot;minCompatibleVersion&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;5&lt;/span&gt;,
        &lt;span class="s2"&gt;&amp;quot;currentVersion&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;6&lt;/span&gt;,
        &lt;span class="s2"&gt;&amp;quot;clusterId&amp;quot;&lt;/span&gt; : ObjectId&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;571dd47adbda7a5a80047a5d&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
  shards:
  active mongoses:
        &lt;span class="s2"&gt;&amp;quot;3.2.5&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt;
  balancer:
        Currently enabled:  yes
        Currently running:  no
        Failed balancer rounds in last &lt;span class="m"&gt;5&lt;/span&gt; attempts:  &lt;span class="m"&gt;0&lt;/span&gt;
        Migration Results &lt;span class="k"&gt;for&lt;/span&gt; the last &lt;span class="m"&gt;24&lt;/span&gt; hours:
                No recent migrations
  databases:

mongos&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Procedemos a lanzar el comando para añadir cada &lt;em&gt;shard&lt;/em&gt;. Es interesante saber que el proceso &lt;strong&gt;mongos&lt;/strong&gt; puede reconocer la forma de cada &lt;em&gt;replica set&lt;/em&gt; a partir de cualquiera de sus procesos. Podemos dar la URL con una sola máquina, o con varias de ellas. Lo importante es que alguna de ellas esté levantada, para que el proceso &lt;strong&gt;mongos&lt;/strong&gt; pueda descubrir el resto a partir de su configuración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mongos&amp;gt; sh.addShard&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;aquila/mongo01:27018&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;shardAdded&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;aquila&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
mongos&amp;gt; sh.addShard&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lyra/mongo02:27018,mongo05:27018,mongo06:27020&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;shardAdded&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;lyra&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
mongos&amp;gt; sh.addShard&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;cygnus/mongo06:27018&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;shardAdded&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;cygnus&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
mongos&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Después de añadir los &lt;em&gt;shards&lt;/em&gt;, podemos ver como queda el &lt;em&gt;cluster&lt;/em&gt; con una sola consulta.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mongos&amp;gt; printShardingStatus&lt;span class="o"&gt;()&lt;/span&gt;
--- Sharding Status ---
  sharding version: &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt;,
        &lt;span class="s2"&gt;&amp;quot;minCompatibleVersion&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;5&lt;/span&gt;,
        &lt;span class="s2"&gt;&amp;quot;currentVersion&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;6&lt;/span&gt;,
        &lt;span class="s2"&gt;&amp;quot;clusterId&amp;quot;&lt;/span&gt; : ObjectId&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;571dd47adbda7a5a80047a5d&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
  shards:
        &lt;span class="o"&gt;{&lt;/span&gt;  &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;aquila&amp;quot;&lt;/span&gt;,  &lt;span class="s2"&gt;&amp;quot;host&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;aquila/mongo01:27018,mongo04:27018&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="o"&gt;{&lt;/span&gt;  &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;cygnus&amp;quot;&lt;/span&gt;,  &lt;span class="s2"&gt;&amp;quot;host&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;cygnus/mongo03:27018,mongo06:27018&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="o"&gt;{&lt;/span&gt;  &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;lyra&amp;quot;&lt;/span&gt;,  &lt;span class="s2"&gt;&amp;quot;host&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;lyra/mongo02:27018,mongo05:27018&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
  active mongoses:
        &lt;span class="s2"&gt;&amp;quot;3.2.5&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt;
  balancer:
        Currently enabled:  yes
        Currently running:  no
        Failed balancer rounds in last &lt;span class="m"&gt;5&lt;/span&gt; attempts:  &lt;span class="m"&gt;0&lt;/span&gt;
        Migration Results &lt;span class="k"&gt;for&lt;/span&gt; the last &lt;span class="m"&gt;24&lt;/span&gt; hours:
                No recent migrations
  databases:

mongos&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y como todo funciona como debe, salimos del &lt;em&gt;mongo shell&lt;/em&gt; para evitar meter la pata.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mongos&amp;gt; &lt;span class="nb"&gt;exit&lt;/span&gt;
bye
root@mongo01:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto, tenemos nuestro &lt;em&gt;cluster&lt;/em&gt; listo y preparado para su uso.&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="mongodb"></category><category term="replica set"></category><category term="sharding"></category><category term="ansible"></category><category term="playbook"></category><category term="systemd"></category></entry><entry><title>Creando un entorno escalable (IV)</title><link href="http://www.linuxsysadmin.ml/2016/03/creando-un-entorno-escalable-4.html" rel="alternate"></link><published>2016-03-21T08:00:00+01:00</published><updated>2016-03-21T08:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-03-21:/2016/03/creando-un-entorno-escalable-4.html</id><summary type="html">&lt;p&gt;Acabamos el artículo anterior de esta serie con las aplicaciones corriendo en sus respectivas máquinas. En este artículo vamos a poner una fachada a todo el sistema, mediante un &lt;em&gt;proxy HTTP&lt;/em&gt; que haga las funciones de terminación &lt;em&gt;SSL&lt;/em&gt; y de &lt;em&gt;balanceador&lt;/em&gt;, exponiendo todo el sistema en una sola dirección IP …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Acabamos el artículo anterior de esta serie con las aplicaciones corriendo en sus respectivas máquinas. En este artículo vamos a poner una fachada a todo el sistema, mediante un &lt;em&gt;proxy HTTP&lt;/em&gt; que haga las funciones de terminación &lt;em&gt;SSL&lt;/em&gt; y de &lt;em&gt;balanceador&lt;/em&gt;, exponiendo todo el sistema en una sola dirección IP.&lt;/p&gt;
&lt;p&gt;Como &lt;em&gt;proxy HTTP&lt;/em&gt; tenemos varias opciones; solo se necesita un servidor web que soporte &lt;em&gt;virtual hosts&lt;/em&gt;, protocolo HTTP sobre SSL, capacidad de hacer de &lt;em&gt;proxy&lt;/em&gt; y capacidad para balancear las peticiones entre varias opciones.&lt;/p&gt;
&lt;p&gt;Si analizamos estos requisitos, podemos comprobar que las opciones son muchas; desde el todopoderoso &lt;strong&gt;apache&lt;/strong&gt; al &lt;strong&gt;nginx&lt;/strong&gt;, pasando por soluciones de balanceador puro como &lt;strong&gt;haproxy&lt;/strong&gt;, u opciones mas esotéricas como &lt;strong&gt;squid&lt;/strong&gt;. En este caso, se utiliza &lt;strong&gt;nginx&lt;/strong&gt; por su facilidad de uso y su bajo consumo de recursos. Cumple con el subconjunto básico de funcionalidades necesario, pero no dispone de tantos algoritmos de balanceo como otras opciones.&lt;/p&gt;
&lt;h2&gt;Instalación de paquetes&lt;/h2&gt;
&lt;p&gt;Empezamos instalando los requisitos para nuestra fachada; en principio solo se necesitaría el servidor web &lt;strong&gt;nginx&lt;/strong&gt; (en la versión mínima) y &lt;strong&gt;openssl&lt;/strong&gt; para generar los certificados. Adicionalmente instalaremos &lt;strong&gt;curl&lt;/strong&gt; para comprobar que el resultado es correcto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@frontend:~# apt-get install nginx-light curl
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  ca-certificates libcurl3 libffi6 libgmp10 libgnutls-deb0-28 libhogweed2 libidn11 libldap-2.4-2 libnettle4 libp11-kit0 librtmp1
  libsasl2-2 libsasl2-modules libsasl2-modules-db libssh2-1 libtasn1-6 nginx-common openssl
Paquetes sugeridos:
  gnutls-bin libsasl2-modules-otp libsasl2-modules-ldap libsasl2-modules-sql libsasl2-modules-gssapi-mit
  libsasl2-modules-gssapi-heimdal fcgiwrap nginx-doc ssl-cert
Se instalarán los siguientes paquetes NUEVOS:
  ca-certificates curl libcurl3 libffi6 libgmp10 libgnutls-deb0-28 libhogweed2 libidn11 libldap-2.4-2 libnettle4 libp11-kit0
  librtmp1 libsasl2-2 libsasl2-modules libsasl2-modules-db libssh2-1 libtasn1-6 nginx-common nginx-light openssl
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;20&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;4&lt;/span&gt;.077 kB de archivos.
Se utilizarán &lt;span class="m"&gt;8&lt;/span&gt;.832 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El paquete &lt;strong&gt;nginx&lt;/strong&gt; de la distribución &lt;em&gt;Debian&lt;/em&gt; viene con una configuración por defecto en &lt;em&gt;/etc/nginx/sites-enabled/&lt;/em&gt;, que vamos a eliminar para evitar que se pise con nuestras configuraciones.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@frontend:~# ls -lh /etc/nginx/sites-enabled/
total &lt;span class="m"&gt;0&lt;/span&gt;
lrwxrwxrwx &lt;span class="m"&gt;1&lt;/span&gt; root root &lt;span class="m"&gt;34&lt;/span&gt; feb &lt;span class="m"&gt;26&lt;/span&gt; &lt;span class="m"&gt;11&lt;/span&gt;:28 default -&amp;gt; /etc/nginx/sites-available/default
root@frontend:~# unlink /etc/nginx/sites-enabled/default
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Consideraciones de seguridad&lt;/h2&gt;
&lt;p&gt;Cuando nuestro servidor web recibe una petición, va a iniciar una nueva conexión contra el servidor de &lt;em&gt;backend&lt;/em&gt; que toque o el de &lt;em&gt;backoffice&lt;/em&gt;. Para habilitar esto, se necesitan nuevas reglas en el &lt;em&gt;firewall&lt;/em&gt;, que en este caso es &lt;strong&gt;firehol&lt;/strong&gt;, instalado en la máquina anfitriona.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# cat /etc/firehol/firehol.conf
...  
&lt;span class="nv"&gt;app_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;10.0.0.3 10.0.0.4 10.0.0.5&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;frontend_server&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;10.0.0.2&amp;quot;&lt;/span&gt;
...
router internal inface lxc0 outface lxc0
...  
    route webcache accept src &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$frontend_server&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; dst &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$app_servers&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;No os olvidéis de reiniciar &lt;strong&gt;firehol&lt;/strong&gt;, para que se apliquen las nuevas reglas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# service firehol restart
...  
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Montando los virtualhosts de ambas aplicaciones&lt;/h2&gt;
&lt;p&gt;La parte privada va a estar escondida tras una terminación &lt;strong&gt;HTTPS&lt;/strong&gt;. Esa aplicación se podría esconder tras una &lt;a href="http://www.linuxsysadmin.ml/2016/02/restringiendo-accesos-mediante-certificados-de-cliente.html"&gt;autenticación de certificados cliente&lt;/a&gt; o mediante &lt;a href="http://www.linuxsysadmin.ml/2016/02/restringiendo-accesos-web-mediante-autenticacion-basica.html"&gt;autenticación básica&lt;/a&gt;. Por simplicidad vamos a usar esta última.&lt;/p&gt;
&lt;p&gt;Empezamos generando un certificado autofirmado para el servidor web, directamente firmado, y su clave. Fijaos que no generamos ningún certificado de CA, ya que no tenemos ninguna intención de generar autenticación cliente en el futuro.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@frontend:~# openssl req -new -newkey rsa:2048 -days &lt;span class="m"&gt;365&lt;/span&gt; -nodes -x509 -keyout server.key -out server.crt -subj &lt;span class="s2"&gt;&amp;quot;/C=ES/ST=Spain/L=Barcelona/O=LinuxSysadmin/CN=shop.linuxsysadmin.tk&amp;quot;&lt;/span&gt;
Generating a &lt;span class="m"&gt;2048&lt;/span&gt; bit RSA private key
.......................................+++
.................................................................................................................................................................+++
writing new private key to &lt;span class="s1"&gt;&amp;#39;server.key&amp;#39;&lt;/span&gt;
-----
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ponemos la clave y el certificado generado en sus respectivas localizaciones, de acuerdo a los estándares.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@frontend:~# cp server.key /etc/ssl/private/
root@frontend:~# cp server.crt /etc/ssl/certs/
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como verificación, así quedaría la carpeta &lt;em&gt;/etc/ssl/&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@frontend:~# tree /etc/ssl/
/etc/ssl/
├── certs
│   └── server.crt
├── openssl.cnf
└── private
    └── server.key

&lt;span class="m"&gt;2&lt;/span&gt; directories, &lt;span class="m"&gt;3&lt;/span&gt; files
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para poder autenticar mediante autenticación básica, generamos un usuario en un fichero tipo &lt;strong&gt;htpasswd&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@frontend:~# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;admin:&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;openssl passwd -crypt s3cr3t&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &amp;gt; /etc/nginx/shop.basic_auth
root@frontend:~# cat /etc/nginx/shop.basic_auth
admin:rOU9H0ABEB2H6
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con todas las piezas listas, montamos los virtualhosts, en un fichero de configuración o en varios, según nos apetezca.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@frontend:~# cat /etc/nginx/sites-enabled/shop
upstream backends &lt;span class="o"&gt;{&lt;/span&gt;
        server backend1:8080&lt;span class="p"&gt;;&lt;/span&gt;
        server backend2:8080&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

server &lt;span class="o"&gt;{&lt;/span&gt;
        listen &lt;span class="m"&gt;80&lt;/span&gt; default_server&lt;span class="p"&gt;;&lt;/span&gt;
        server_name _&lt;span class="p"&gt;;&lt;/span&gt;

        location / &lt;span class="o"&gt;{&lt;/span&gt;
                proxy_pass http://backends&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

server &lt;span class="o"&gt;{&lt;/span&gt;
        listen &lt;span class="m"&gt;443&lt;/span&gt; ssl&lt;span class="p"&gt;;&lt;/span&gt;
        server_name _&lt;span class="p"&gt;;&lt;/span&gt;

        ssl_certificate /etc/ssl/certs/server.crt&lt;span class="p"&gt;;&lt;/span&gt;
        ssl_certificate_key /etc/ssl/private/server.key&lt;span class="p"&gt;;&lt;/span&gt;

        auth_basic &lt;span class="s2"&gt;&amp;quot;Admin Area&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        auth_basic_user_file /etc/nginx/shop.basic_auth&lt;span class="p"&gt;;&lt;/span&gt;

        location / &lt;span class="o"&gt;{&lt;/span&gt;
                proxy_pass http://backoffice:8080&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La configuración es bastante estándar; se trata de un &lt;em&gt;server&lt;/em&gt; (equivalente en &lt;strong&gt;nginx&lt;/strong&gt; a un &lt;em&gt;virtualhost&lt;/em&gt; de &lt;strong&gt;apache&lt;/strong&gt;) para cada protocolo. La parte de administración es solamente la mediación &lt;strong&gt;SSL&lt;/strong&gt; y un &lt;em&gt;proxy_pass&lt;/em&gt; hacia el &lt;em&gt;backoffice&lt;/em&gt;. La parte de la API pública también se limita a hacer un &lt;em&gt;proxy_pass&lt;/em&gt;, solo que se hace contra &lt;em&gt;backends&lt;/em&gt; que es un objeto &lt;strong&gt;upstream&lt;/strong&gt;, que es el que define el balanceador.&lt;/p&gt;
&lt;p&gt;Ahora solo queda reiniciar el servidor web para aplicar los cambios. De acuerdo a la documentación, habría bastado un &lt;em&gt;reload&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@frontend:~# service nginx restart
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comprobando que las aplicaciones funcionan&lt;/h2&gt;
&lt;p&gt;Para comprobar que la parte de la API funciona y balancea adecuadamente, basta con hacer peticiones. Podemos comprobar el &lt;em&gt;backend&lt;/em&gt; que la ha servido porque la aplicación pone una cabecera que especifica el nombre del &lt;em&gt;host&lt;/em&gt; que la resolvió. Con dos peticiones veremos que va alternativamente a cada &lt;em&gt;backend&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@frontend:~# curl -i http://localhost/products/
HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Server: nginx/1.6.2
Date: Fri, &lt;span class="m"&gt;26&lt;/span&gt; Feb &lt;span class="m"&gt;2016&lt;/span&gt; &lt;span class="m"&gt;11&lt;/span&gt;:04:38 GMT
Content-Type: application/json
Content-Length: &lt;span class="m"&gt;3&lt;/span&gt;
Connection: keep-alive
Backend: backend1

&lt;span class="o"&gt;[]&lt;/span&gt;
root@frontend:~# curl -i http://localhost/products/
HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Server: nginx/1.6.2
Date: Fri, &lt;span class="m"&gt;26&lt;/span&gt; Feb &lt;span class="m"&gt;2016&lt;/span&gt; &lt;span class="m"&gt;11&lt;/span&gt;:04:40 GMT
Content-Type: application/json
Content-Length: &lt;span class="m"&gt;3&lt;/span&gt;
Connection: keep-alive
Backend: backend2

&lt;span class="o"&gt;[]&lt;/span&gt;
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para la parte privada, haremos la petición, de la misma manera; vamos a añadir el flag &lt;em&gt;-k&lt;/em&gt; para sobrepasar el certificado autofirmado. Como no hemos indicado el usuario y la contraseña, nos devuelve un error 401, que indica que no estamos autorizados a pasar mas allá.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@frontend:~# curl -i -k https://localhost/products
HTTP/1.1 &lt;span class="m"&gt;401&lt;/span&gt; Unauthorized
Server: nginx/1.6.2
Date: Fri, &lt;span class="m"&gt;26&lt;/span&gt; Feb &lt;span class="m"&gt;2016&lt;/span&gt; &lt;span class="m"&gt;11&lt;/span&gt;:05:35 GMT
Content-Type: text/html
Content-Length: &lt;span class="m"&gt;194&lt;/span&gt;
Connection: keep-alive
WWW-Authenticate: Basic &lt;span class="nv"&gt;realm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Admin Area&amp;quot;&lt;/span&gt;

&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;&amp;lt;title&amp;gt;401 Authorization Required&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;
&amp;lt;body &lt;span class="nv"&gt;bgcolor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;white&amp;quot;&lt;/span&gt;&amp;gt;
&amp;lt;center&amp;gt;&amp;lt;h1&amp;gt;401 Authorization Required&amp;lt;/h1&amp;gt;&amp;lt;/center&amp;gt;
&amp;lt;hr&amp;gt;&amp;lt;center&amp;gt;nginx/1.6.2&amp;lt;/center&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
root@frontend:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto parece que funciona, a falta de probar con un navegador adecuado.&lt;/p&gt;
&lt;h2&gt;Un pequeño detalle: abrimos los puertos&lt;/h2&gt;
&lt;p&gt;Puesto que este entorno está montado sobre virtualización &lt;strong&gt;LXC&lt;/strong&gt;, necesitamos que la dirección IP de la maquina anfitriona exponga los puertos de la máquina &lt;em&gt;frontend&lt;/em&gt;. Para ello hay que habilitar un mecanismo que se llama &lt;em&gt;port forwarding&lt;/em&gt;, coloquialmente conocido como "abrir el puerto".&lt;/p&gt;
&lt;p&gt;Mediante una directiva de &lt;strong&gt;firehol&lt;/strong&gt; indicamos que pasaremos todas las peticiones recibidas a los puertos 80 y 443 directamente a la máquina de &lt;em&gt;frontend&lt;/em&gt;. Hay que habilitar ese tráfico de &lt;strong&gt;FORWARD&lt;/strong&gt;, mediante otras reglas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# cat /etc/firehol/firehol.conf
...
&lt;span class="nv"&gt;frontend_server&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;10.0.0.2&amp;quot;&lt;/span&gt;
...
dnat to &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$frontend_server&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; proto tcp dport &lt;span class="m"&gt;80&lt;/span&gt;
dnat to &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$frontend_server&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; proto tcp dport &lt;span class="m"&gt;443&lt;/span&gt;
...
router world2lan inface eth0 outface lxc0
    route http accept dst &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$frontend_server&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
    route https accept dst &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$frontend_server&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
...
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y nuevamente reiniciamos el servicio para aplicar las nuevas reglas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# service firehol restart
...
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Accediendo a las aplicaciones en la IP pública&lt;/h2&gt;
&lt;p&gt;Vamos a acceder con un navegador a la parte de administración, para ver que funciona y para rellenar algunos datos, para que se vea una respuesta de la API con fundamento.&lt;/p&gt;
&lt;p&gt;El primer paso consiste en abrir el navegador con la URL adecuada, y nos tropezamos con la autenticación.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Auth basic" src="http://www.linuxsysadmin.ml/images/entorno-escalable-auth-basic.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Tras pasar la autenticación podemos acceder a los formularios para añadir productos.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Admin form" src="http://www.linuxsysadmin.ml/images/entorno-escalable-admin-form.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Tras añadir tres productos, vemos que ya se genera la lista, en formato web.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Admin list" src="http://www.linuxsysadmin.ml/images/entorno-escalable-admin-list.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Con los datos introducidos podemos consumir la API, para comprobar que los datos que hemos introducido en la base de datos (mediante la aplicación de administración) están disponibles.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@desktop:~$ wget -qO- http://192.168.1.232/products/
&lt;span class="o"&gt;[&lt;/span&gt;
    &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;price&amp;quot;&lt;/span&gt;: &lt;span class="m"&gt;1&lt;/span&gt;.5, 
        &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;123&amp;quot;&lt;/span&gt;, 
        &lt;span class="s2"&gt;&amp;quot;description&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;Apples&amp;quot;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;, 
    &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;price&amp;quot;&lt;/span&gt;: &lt;span class="m"&gt;1&lt;/span&gt;.0, 
        &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;456&amp;quot;&lt;/span&gt;, 
        &lt;span class="s2"&gt;&amp;quot;description&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;Oranges&amp;quot;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;, 
    &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;price&amp;quot;&lt;/span&gt;: &lt;span class="m"&gt;2&lt;/span&gt;.0, 
        &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;789&amp;quot;&lt;/span&gt;, 
        &lt;span class="s2"&gt;&amp;quot;description&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;Pears&amp;quot;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;]&lt;/span&gt;
gerard@desktop:~$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y consultando un producto concreto, también funciona como debe.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gerard@desktop:~$ wget -qO- http://192.168.1.232/products/456
&lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;price&amp;quot;&lt;/span&gt;: &lt;span class="m"&gt;1&lt;/span&gt;.0, 
    &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;456&amp;quot;&lt;/span&gt;, 
    &lt;span class="s2"&gt;&amp;quot;description&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;Oranges&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
gerard@desktop:~$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto comprobamos que todo queda en su sitio. Solo hará falta limpiar cualquier desecho que hayamos dejado en &lt;em&gt;/root/&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Y con este artículo cerramos la serie.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="proxy http"></category><category term="balanceador"></category><category term="ssl"></category><category term="nginx"></category><category term="virtual hosts"></category><category term="port forwarding"></category></entry><entry><title>Creando un entorno escalable (III)</title><link href="http://www.linuxsysadmin.ml/2016/03/creando-un-entorno-escalable-3.html" rel="alternate"></link><published>2016-03-14T08:00:00+01:00</published><updated>2016-03-14T08:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-03-14:/2016/03/creando-un-entorno-escalable-3.html</id><summary type="html">&lt;p&gt;En el artículo anterior de esta serie montamos el cluster de la base de datos que íbamos a necesitar para las aplicaciones que conformaban este entorno de ejemplo. Ahora que tenemos la base de datos, falta poner los servidores de aplicaciones que sirven nuestras aplicaciones y que usan el cluster …&lt;/p&gt;</summary><content type="html">&lt;p&gt;En el artículo anterior de esta serie montamos el cluster de la base de datos que íbamos a necesitar para las aplicaciones que conformaban este entorno de ejemplo. Ahora que tenemos la base de datos, falta poner los servidores de aplicaciones que sirven nuestras aplicaciones y que usan el cluster.&lt;/p&gt;
&lt;p&gt;Las aplicaciones que pretendemos servir son aplicaciones hechas en &lt;strong&gt;python&lt;/strong&gt;, siguiendo el protocolo &lt;strong&gt;WSGI&lt;/strong&gt;. Para ir rápidos, ambas utilizan el &lt;em&gt;framework&lt;/em&gt; &lt;strong&gt;bottle&lt;/strong&gt;. En realidad, nos sirve cualquier &lt;em&gt;framework&lt;/em&gt; que construya aplicaciones &lt;strong&gt;WSGI&lt;/strong&gt; estándares, de acuerdo al protocolo. Estas aplicaciones se conectan a la base de datos antes creadas para resolver las peticiones, mediante el &lt;em&gt;driver&lt;/em&gt; de &lt;strong&gt;mongodb&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Desde el punto de vista de entrada al servidor, ambas aplicaciones se van a servir mediante el protocolo &lt;strong&gt;HTTP&lt;/strong&gt; en puerto TCP 8080. Hay muchos servidores que sirven aplicaciones &lt;strong&gt;WSGI&lt;/strong&gt;, por ejemplo, &lt;strong&gt;Apache mod_wsgi&lt;/strong&gt;, &lt;strong&gt;gunicorn&lt;/strong&gt; o &lt;strong&gt;uWSGI&lt;/strong&gt;. De hecho hay docenas de ellos, casi todos capaces de servir aplicaciones &lt;strong&gt;WSGI&lt;/strong&gt; en un puerto cualquiera TCP.&lt;/p&gt;
&lt;p&gt;En este caso, usaremos un servidor de aplicaciones &lt;strong&gt;uWSGI&lt;/strong&gt; que, aunque es un poco mas complicado que &lt;strong&gt;gunicorn&lt;/strong&gt; (y menos que &lt;strong&gt;mod_wsgi&lt;/strong&gt;), me tiene enamorado. Destaco especialmente el modo de funcionamiento &lt;em&gt;emperador&lt;/em&gt; y la capacidad de usar un &lt;em&gt;virtualenv&lt;/em&gt; distinto para cada aplicación servida. De hecho, puede servir diferentes lenguajes y/o versiones, una por cada aplicación.&lt;/p&gt;
&lt;h2&gt;Instalar el servidor de aplicaciones&lt;/h2&gt;
&lt;p&gt;Este paso se repite en las máquinas &lt;em&gt;backend1&lt;/em&gt;, &lt;em&gt;backend2&lt;/em&gt; y  &lt;em&gt;backoffice&lt;/em&gt;; aunque cada una va a servir una aplicación distinta, el servidor de aplicaciones es el mismo. En puntos posteriores pondremos y activaremos las aplicaciones.&lt;/p&gt;
&lt;p&gt;El servidor &lt;strong&gt;uWSGI&lt;/strong&gt; está disponible en los repositorios oficiales de &lt;em&gt;Debian Jessie&lt;/em&gt;. Vamos a instalarlo con un &lt;em&gt;init script&lt;/em&gt; que levante un emperador y le vamos a añadir el &lt;em&gt;plugin&lt;/em&gt; para servir &lt;strong&gt;python&lt;/strong&gt; (en la versión 2.7, según podemos ver).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:~# apt-get install uwsgi-emperor uwsgi-plugin-python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  file libexpat1 libffi6 libjansson4 libmagic1 libmatheval1 libpgm-5.1-0 libpython2.7 libpython2.7-minimal libpython2.7-stdlib
  libsodium13 libsqlite3-0 libxml2 libyaml-0-2 libzmq3 mime-support sgml-base uwsgi-core xml-core
Paquetes sugeridos:
  sgml-base-doc nginx-full cherokee libapache2-mod-proxy-uwsgi libapache2-mod-uwsgi libapache2-mod-ruwsgi uwsgi-plugins-all
  uwsgi-extra python-uwsgidecorators debhelper
Se instalarán los siguientes paquetes NUEVOS:
  file libexpat1 libffi6 libjansson4 libmagic1 libmatheval1 libpgm-5.1-0 libpython2.7 libpython2.7-minimal libpython2.7-stdlib
  libsodium13 libsqlite3-0 libxml2 libyaml-0-2 libzmq3 mime-support sgml-base uwsgi-core uwsgi-emperor uwsgi-plugin-python
  xml-core
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;21&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;6&lt;/span&gt;.608 kB de archivos.
Se utilizarán &lt;span class="m"&gt;25&lt;/span&gt;,9 MB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto ya tenemos el servidor de aplicaciones en funcionamiento. Las instancias se declaran con un fichero de configuración en &lt;em&gt;/etc/uwsgi-emperor/vassals/&lt;/em&gt;, que haremos mas adelante.&lt;/p&gt;
&lt;h2&gt;Consideraciones de seguridad&lt;/h2&gt;
&lt;p&gt;Estas aplicaciones usarán el &lt;em&gt;driver&lt;/em&gt; &lt;strong&gt;pymongo&lt;/strong&gt; para conectar a las instancias de &lt;strong&gt;mongodb&lt;/strong&gt;. Para eso hay que habilitar el tráfico relativo (de los servidores de aplicaciones a los de mongodb, por el puerto TCP 27017).&lt;/p&gt;
&lt;p&gt;En nuestro caso, como estamos trabajando con &lt;strong&gt;LXC&lt;/strong&gt;, lo haremos desde el &lt;em&gt;host&lt;/em&gt;, mediante la modificación de las reglas de &lt;em&gt;firehol&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# cat /etc/firehol/firehol.conf
&lt;span class="nv"&gt;mongo_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;10.0.0.5 10.0.0.6 10.0.0.7&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;app_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;10.0.0.3 10.0.0.4 10.0.0.5&amp;quot;&lt;/span&gt;
...  
router internal inface lxc0 outface lxc0
...  
      route custom mongodb tcp/27017 default accept src &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$app_servers&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; dst &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$mongo_servers&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
...  
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;No os olvidéis de reiniciar el servicio &lt;em&gt;firehol&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Instalando las aplicaciones&lt;/h2&gt;
&lt;p&gt;Este punto se hace en los tres servidores que sirven aplicaciones (&lt;em&gt;backend1&lt;/em&gt;, &lt;em&gt;backend2&lt;/em&gt; y &lt;em&gt;backoffice&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Las aplicaciones de ejemplo que vamos a usar las podéis encontrar en &lt;a href="http://www.linuxsysadmin.ml/downloads/shop.tar.gz"&gt;este enlace&lt;/a&gt;. Debo admitir que no son bonitas, pero para esta demostración, nos valen.&lt;/p&gt;
&lt;p&gt;Descomprimimos el fichero comprimido con las dos aplicaciones.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:~# tar xzf shop.tar.gz
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Esta es la estructura que queda tras descomprimir:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:~# tree
.
├── shop
│   ├── requirements.txt
│   ├── shop_admin
│   │   ├── app.py
│   │   └── views
│   │       ├── index.tpl
│   │       ├── product_form.tpl
│   │       └── product_list.tpl
│   └── shop_api
│       └── app.py
└── shop.tar.gz

&lt;span class="m"&gt;4&lt;/span&gt; directories, &lt;span class="m"&gt;7&lt;/span&gt; files
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Esta estructura tiene las dos aplicaciones. Cada tipo de servidor usará solo una por simplicidad, así que borraremos la que no se utilice, de acuerdo al tipo de servidor.&lt;/p&gt;
&lt;p&gt;En resumen, vamos a poner la carpeta &lt;em&gt;shop&lt;/em&gt; en &lt;em&gt;/opt/&lt;/em&gt;, y vamos a poner dentro el &lt;em&gt;virtualenv&lt;/em&gt; con las librerías necesarias.&lt;/p&gt;
&lt;p&gt;Como buena &lt;em&gt;praxis&lt;/em&gt;, vamos a instalar las librerías en un &lt;em&gt;virtualenv&lt;/em&gt; dedicado por aplicación. Para ello necesitamos la herramienta, que puede salir del repositorio oficial o lo podemos descargar, para usarlo y desecharlo posteriormente. Podemos encontrar el paquete en &lt;a href="https://pypi.python.org/packages/source/v/virtualenv/virtualenv-14.0.6.tar.gz#md5=a035037925c82990a7659ecf8764bcdb"&gt;este enlace&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lo descomprimimos y lo dejamos ahí, para que los puntos específicos para cada servidor lo usen a su antojo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:~# tar xzf virtualenv-14.0.6.tar.gz
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El &lt;em&gt;script&lt;/em&gt; de creación del &lt;em&gt;virtualenv&lt;/em&gt; se ejecuta con &lt;strong&gt;python&lt;/strong&gt;; así que también lo necesitamos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:~# apt-get install python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  libpython-stdlib python-minimal python2.7 python2.7-minimal
Paquetes sugeridos:
  python-doc python-tk python2.7-doc binutils binfmt-support
Se instalarán los siguientes paquetes NUEVOS:
  libpython-stdlib python python-minimal python2.7 python2.7-minimal
0 actualizados, 5 nuevos se instalarán, 0 para eliminar y 0 no actualizados.
Se necesita descargar 1.854 kB de archivos.
Se utilizarán 5.131 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? [S/n] s
..
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Veamos ahora los puntos específicos por tipo de aplicación.&lt;/p&gt;
&lt;h3&gt;Aplicación de backend: la API pública&lt;/h3&gt;
&lt;p&gt;Este punto se ejecuta solamente en los &lt;em&gt;backends&lt;/em&gt; (&lt;em&gt;backend1&lt;/em&gt; y &lt;em&gt;backend2&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Eliminamos la aplicación de administración, que no se usa en los &lt;em&gt;backends&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:~# rm -R shop/shop_admin/
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Así nos queda la carpeta:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:~# tree shop
shop
├── requirements.txt
└── shop_api
    └── app.py

&lt;span class="m"&gt;1&lt;/span&gt; directory, &lt;span class="m"&gt;2&lt;/span&gt; files
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Copiamos la carpeta a &lt;em&gt;/opt/&lt;/em&gt; que va a ser su emplazamiento habitual.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:~# cp -R shop/ /opt/
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a trabajar ya desde la carpeta contenedora del proyecto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:~# &lt;span class="nb"&gt;cd&lt;/span&gt; /opt/shop/
root@backend1:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El siguiente paso es crear el conjunto de librerías necesarias, construyendo un &lt;em&gt;virtualenv&lt;/em&gt; con las librerías. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:/opt/shop# /root/virtualenv-14.0.6/virtualenv.py env
New python executable in /opt/shop/env/bin/python
Installing setuptools, pip, wheel...done.
root@backend1:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Activamos el entorno virtual para instalar las librerías declaradas en el fichero &lt;em&gt;requirements.txt&lt;/em&gt;. Luego salimos del entorno.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:/opt/shop# . env/bin/activate
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@backend1:/opt/shop# pip install -r requirements.txt
Collecting &lt;span class="nv"&gt;bottle&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.12.9 &lt;span class="o"&gt;(&lt;/span&gt;from -r requirements.txt &lt;span class="o"&gt;(&lt;/span&gt;line &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;
...
Installing collected packages: bottle, pymongo
Successfully installed bottle-0.12.9 pymongo-3.2
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@backend1:/opt/shop# deactivate
root@backend1:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para evitarnos problemas de permisos, uniformizamos el propietario de la carpeta:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:~# chown -R www-data:www-data /opt/shop/
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Con todo lo necesario para levantar la aplicación, la declaramos como &lt;em&gt;vasallo&lt;/em&gt; del &lt;em&gt;emperador&lt;/em&gt;; el mismo &lt;strong&gt;emperador&lt;/strong&gt; va a levantar un proceso para servir esa configuración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:/opt/shop# cat /etc/uwsgi-emperor/vassals/shop_api.ini
&lt;span class="o"&gt;[&lt;/span&gt;uwsgi&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;plugin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; python
http-socket &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:8080
&lt;span class="nv"&gt;master&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nv"&gt;workers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="nv"&gt;virtualenv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/shop/env
&lt;span class="nv"&gt;chdir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/shop/shop_api
&lt;span class="nv"&gt;module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; app:app
root@backend1:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y podemos comprobar que todo funciona como debe haciendo una petición a la &lt;strong&gt;API&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backend1:~# curl -i http://localhost:8080/products/
HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Content-Length: &lt;span class="m"&gt;3&lt;/span&gt;
Content-Type: application/json
Backend: backend1

&lt;span class="o"&gt;[]&lt;/span&gt;
root@backend1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Aplicación de backoffice: la interfaz de administración&lt;/h3&gt;
&lt;p&gt;Este punto aplica solamente a la máquina &lt;em&gt;backoffice&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;El proceso es análogo al de los &lt;em&gt;backends&lt;/em&gt;; quitamos la aplicación que no vamos a utilizar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backoffice:~# rm -R shop/shop_api/
root@backoffice:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Así nos queda la carpeta:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backoffice:~# tree shop
shop
├── requirements.txt
└── shop_admin
    ├── app.py
    └── views
        ├── index.tpl
        ├── product_form.tpl
        └── product_list.tpl

&lt;span class="m"&gt;2&lt;/span&gt; directories, &lt;span class="m"&gt;5&lt;/span&gt; files
root@backoffice:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La transferimos a la carpeta &lt;em&gt;/opt/&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backoffice:~# cp -R shop/ /opt/
root@backoffice:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Nos situamos en la carpeta contenedora:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backoffice:~# &lt;span class="nb"&gt;cd&lt;/span&gt; /opt/shop/
root@backoffice:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos el &lt;em&gt;virtualenv&lt;/em&gt; en la carpeta contenedora.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backoffice:/opt/shop# /root/virtualenv-14.0.6/virtualenv.py env
New python executable in /opt/shop/env/bin/python
Installing setuptools, pip, wheel...done.
root@backoffice:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y le instalamos las librerías necesarias, declaradas en el fichero &lt;em&gt;requirements.txt&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backoffice:/opt/shop# . env/bin/activate
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@backoffice:/opt/shop# pip install -r requirements.txt
Collecting &lt;span class="nv"&gt;bottle&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.12.9 &lt;span class="o"&gt;(&lt;/span&gt;from -r requirements.txt &lt;span class="o"&gt;(&lt;/span&gt;line &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;
...
Installing collected packages: bottle, pymongo
Successfully installed bottle-0.12.9 pymongo-3.2
&lt;span class="o"&gt;(&lt;/span&gt;env&lt;span class="o"&gt;)&lt;/span&gt; root@backoffice:/opt/shop# deactivate
root@backoffice:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Actualizamos el propietario de la aplicación &lt;strong&gt;WSGI&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backoffice:/opt/shop# chown -R www-data:www-data /opt/shop/
root@backoffice:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y creamos el fichero de configuración del &lt;em&gt;vasallo&lt;/em&gt;, para que lo levante el &lt;em&gt;emperador&lt;/em&gt;, quedando así:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backoffice:/opt/shop# cat /etc/uwsgi-emperor/vassals/shop_admin.ini
&lt;span class="o"&gt;[&lt;/span&gt;uwsgi&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;plugin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; python
http-socket &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:8080
&lt;span class="nv"&gt;master&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="nv"&gt;workers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="nv"&gt;virtualenv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/shop/env
&lt;span class="nv"&gt;chdir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; /opt/shop/shop_admin
&lt;span class="nv"&gt;module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; app:app
root@backoffice:/opt/shop#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y comprobamos que obtenemos la página web que se espera:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@backoffice:~# curl -i http://localhost:8080/
HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Content-Length: &lt;span class="m"&gt;33&lt;/span&gt;
Content-Type: text/html&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nv"&gt;charset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;UTF-8

&amp;lt;a &lt;span class="nv"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/products&amp;quot;&lt;/span&gt;&amp;gt;Products&amp;lt;/a&amp;gt;
root@backoffice:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto hemos acabado con las aplicaciones. Nuevamente, todo lo que queda en la carpeta &lt;em&gt;/root/&lt;/em&gt; es desechable.&lt;/p&gt;
&lt;p&gt;En el siguiente artículo vamos a montar el &lt;em&gt;proxy&lt;/em&gt;/balanceador que va a actuar como fachada de todo el sistema.&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="WSGI"></category><category term="uWSGI"></category><category term="python"></category><category term="virtualenv"></category><category term="firehol"></category></entry><entry><title>Creando un entorno escalable (II)</title><link href="http://www.linuxsysadmin.ml/2016/03/creando-un-entorno-escalable-2.html" rel="alternate"></link><published>2016-03-07T08:00:00+01:00</published><updated>2016-03-07T08:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-03-07:/2016/03/creando-un-entorno-escalable-2.html</id><summary type="html">&lt;p&gt;Seguimos con la serie de montar un entorno escalable. Tras explicar en el primer artículo lo que vamos a montar, seguimos con ello. En este artículo vamos a montar un &lt;em&gt;cluster&lt;/em&gt; de bases de datos; será &lt;strong&gt;mongodb&lt;/strong&gt; porque la aplicación lo requiere y usará la topología de un &lt;strong&gt;replica set …&lt;/strong&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Seguimos con la serie de montar un entorno escalable. Tras explicar en el primer artículo lo que vamos a montar, seguimos con ello. En este artículo vamos a montar un &lt;em&gt;cluster&lt;/em&gt; de bases de datos; será &lt;strong&gt;mongodb&lt;/strong&gt; porque la aplicación lo requiere y usará la topología de un &lt;strong&gt;replica set&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Este artículo se basa enormemente en &lt;a href="http://www.linuxsysadmin.ml/2015/12/construyendo-una-replica-set-en-mongodb.html"&gt;otro artículo&lt;/a&gt; que ya publicamos, al que vamos a añadir algunas mejoras reflejadas en otros.&lt;/p&gt;
&lt;p&gt;Como ya vimos en el artículo referido, solo necesitamos levantar un proceso &lt;em&gt;mongod&lt;/em&gt; en cada una de las máquinas, para posteriormente casarlos entre sí.&lt;/p&gt;
&lt;h2&gt;Levantando los procesos de mongodb&lt;/h2&gt;
&lt;p&gt;Este punto se repite en las máquinas que van a formar la &lt;strong&gt;replica set&lt;/strong&gt;, que son &lt;em&gt;mongo1&lt;/em&gt;, &lt;em&gt;mongo2&lt;/em&gt; y &lt;em&gt;backoffice&lt;/em&gt;. Vamos a seguir solamente una de ellas; el resto son análogas.&lt;/p&gt;
&lt;p&gt;Crearemos una estructura en &lt;em&gt;/opt/&lt;/em&gt; para alojar los binarios, las configuraciones, los datos y los logs.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# mkdir -p /opt/mongodb/&lt;span class="o"&gt;{&lt;/span&gt;bin,conf,data,logs&lt;span class="o"&gt;}&lt;/span&gt;
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En la carpeta de binarios vamos a poner el único que se necesita: el &lt;em&gt;mongod&lt;/em&gt;. Lo podemos sacar descomprimiendo el 
fichero comprimido &lt;em&gt;.tar.gz&lt;/em&gt; de la página de descargas de &lt;strong&gt;mongodb&lt;/strong&gt;. En nuestro caso concreto, lo he sacado de &lt;a href="https://fastdl.mongodb.org/linux/mongodb-linux-i686-3.2.3.tgz"&gt;https://fastdl.mongodb.org/linux/mongodb-linux-i686-3.2.3.tgz&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# cp mongodb-linux-i686-3.2.3/bin/mongod /opt/mongodb/bin/
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ponemos un fichero de configuración para la instancia que queremos correr. Esta configuración puede variar mucho, pero un ejemplo básico para salir del paso con una máquina de 32 bits (que no soportan &lt;em&gt;WiredTiger&lt;/em&gt;) podría ser:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# cat /opt/mongodb/conf/mongo.conf
systemLog:
    path: /opt/mongodb/logs/mongo.log
    logAppend: &lt;span class="nb"&gt;true&lt;/span&gt;
    destination: file

net:
    port: &lt;span class="m"&gt;27017&lt;/span&gt;
    bindIp: &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0

storage:
    dbPath: /opt/mongodb/data/
    engine: mmapv1
    mmapv1:
        smallFiles: &lt;span class="nb"&gt;true&lt;/span&gt;

replication:
    replSetName: rs
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Truco&lt;/strong&gt;: Es un buen momento para montar un sistema de ficheros alternativo para almacenar los datos, sea poner &lt;a href="http://www.linuxsysadmin.ml/2016/01/lvm-logical-volume-manager.html"&gt;LVM&lt;/a&gt; (para tener crecimiento dinámico o &lt;a href="http://www.linuxsysadmin.ml/2016/02/haciendo-snapshots-con-lvm.html"&gt;snapshots&lt;/a&gt;, sea un &lt;a href="http://www.linuxsysadmin.ml/2015/12/construyendo-un-raid-10-en-linux.html"&gt;RAID&lt;/a&gt; (por ejemplo para tener alto rendimiento y/o replicación de datos), o incluso ambos.&lt;/p&gt;
&lt;p&gt;Cumpliendo con una política de seguridad básica, vamos a crear un usuario de sistema para correr el proceso.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# useradd -s /usr/sbin/nologin -r -M mongo -d /opt/mongodb/
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Le damos la propiedad de toda la estructura de &lt;strong&gt;mongodb&lt;/strong&gt;, para ahorrarnos problemas de permisos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# chown -R mongo:mongo /opt/mongodb/
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y ya como resumen, ponemos una salida para ver como nos queda la estructura:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# tree /opt/mongodb/
/opt/mongodb/
├── bin
│   └── mongod
├── conf
│   └── mongo.conf
├── data
└── logs

&lt;span class="m"&gt;4&lt;/span&gt; directories, &lt;span class="m"&gt;2&lt;/span&gt; files
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El último paso consiste en crear una &lt;em&gt;unit&lt;/em&gt; en &lt;strong&gt;systemd&lt;/strong&gt; (o un &lt;em&gt;init script&lt;/em&gt;, dependiendo de la distribución usada; de hecho, cada máquina puede ir con una distribución distinta).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# cat /etc/systemd/system/mongo.service
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;MongoDB

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;User&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mongo
&lt;span class="nv"&gt;LimitFSIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitCPU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitNOFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;64000&lt;/span&gt;
&lt;span class="nv"&gt;LimitNPROC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;64000&lt;/span&gt;
&lt;span class="nv"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/rm -f /opt/mongodb/data/mongod.lock
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/opt/mongodb/bin/mongod -f /opt/mongodb/conf/mongo.conf

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lo activamos para que se levante solo en los siguientes arranques, y lo levantamos para la sesión actual.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# systemctl &lt;span class="nb"&gt;enable&lt;/span&gt; mongo
Created symlink from /etc/systemd/system/multi-user.target.wants/mongo.service to /etc/systemd/system/mongo.service.
root@mongo1:~# systemctl start mongo
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Repetid este paso en las otras máquinas de &lt;strong&gt;mongodb&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Consideraciones de seguridad&lt;/h2&gt;
&lt;p&gt;Para que una &lt;strong&gt;replica set&lt;/strong&gt; funcione como debe, todos los procesos deben comunicarse entre sí. Como los hemos puesto en el mismo puerto, podemos agruparlo todo en una sola regla.&lt;/p&gt;
&lt;p&gt;Como en nuestro caso estamos virtualizando con &lt;strong&gt;LXC&lt;/strong&gt;, vamos a controlar el tráfico con el &lt;strong&gt;firehol&lt;/strong&gt; de la máquina anfitriona.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;...
root@lxc:~# cat /etc/firehol/firehol.conf
&lt;span class="nv"&gt;mongo_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;10.0.0.5 10.0.0.6 10.0.0.7&amp;quot;&lt;/span&gt;
...  
router internal inface lxc0 outface lxc0
    route custom mongodb tcp/27017 default accept src &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$mongo_servers&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; dst &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$mongo_servers&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
...
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Acordaos de reiniciar &lt;strong&gt;firehol&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Atando la replica set&lt;/h2&gt;
&lt;p&gt;Este paso se ejecuta en una sola máquina, que va a reproducir los cambios a las demás, por efecto de la &lt;strong&gt;replica set&lt;/strong&gt;. Por ejemplo, lo hago en &lt;em&gt;mongo1&lt;/em&gt;, por hacer alguna.&lt;/p&gt;
&lt;p&gt;Entramos en el &lt;em&gt;mongo shell&lt;/em&gt;, desde donde lanzaremos el resto de comandos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# ./mongodb-linux-i686-3.2.3/bin/mongo
MongoDB shell version: &lt;span class="m"&gt;3&lt;/span&gt;.2.3
connecting to: &lt;span class="nb"&gt;test&lt;/span&gt;
Welcome to the MongoDB shell.
For interactive help, &lt;span class="nb"&gt;type&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;help&amp;quot;&lt;/span&gt;.
...
&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Siguiendo los pasos estándares, creamos una configuración vacía en la máquina elegida, y añadimos las otras dos. Tened en cuenta que la máquina &lt;em&gt;backoffice&lt;/em&gt; se declara como un árbitro, por decisión de diseño.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt; rs.initiate&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;info2&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;no configuration specified. Using a default configuration for the set&amp;quot;&lt;/span&gt;,
        &lt;span class="s2"&gt;&amp;quot;me&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
        &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
rs:SECONDARY&amp;gt; rs.add&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mongo2:27017&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
rs:PRIMARY&amp;gt; rs.addArb&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;backoffice:27017&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
rs:PRIMARY&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Podemos verificar que todo está bien mediante el comando &lt;em&gt;rs.status()&lt;/em&gt;, como sigue:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rs:PRIMARY&amp;gt; rs.status&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;set&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;rs&amp;quot;&lt;/span&gt;,
...  
        &lt;span class="s2"&gt;&amp;quot;members&amp;quot;&lt;/span&gt; : &lt;span class="o"&gt;[&lt;/span&gt;
                &lt;span class="o"&gt;{&lt;/span&gt;
...  
                        &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
                        &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;PRIMARY&amp;quot;&lt;/span&gt;,
...  
                &lt;span class="o"&gt;}&lt;/span&gt;,
                &lt;span class="o"&gt;{&lt;/span&gt;
...  
                        &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo2:27017&amp;quot;&lt;/span&gt;,
                        &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;SECONDARY&amp;quot;&lt;/span&gt;,
...  
                &lt;span class="o"&gt;}&lt;/span&gt;,
                &lt;span class="o"&gt;{&lt;/span&gt;
...  
                        &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;backoffice:27017&amp;quot;&lt;/span&gt;,
                        &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;ARBITER&amp;quot;&lt;/span&gt;,
...  
                &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="o"&gt;]&lt;/span&gt;,
        &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
rs:PRIMARY&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y salimos del &lt;em&gt;mongo shell&lt;/em&gt;, que ya no necesitamos; las aplicaciones de &lt;em&gt;backend&lt;/em&gt; y de &lt;em&gt;backoffice&lt;/em&gt; ya incluyen una librería para conectarse por sí mismos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rs:PRIMARY&amp;gt; &lt;span class="nb"&gt;exit&lt;/span&gt;
bye
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Todo lo que queda en &lt;em&gt;/root/&lt;/em&gt; es innecesario y se puede borrar. De todas formas podemos dejar el resto de binarios en &lt;em&gt;/opt/mongodb/&lt;/em&gt; en alguna de las máquinas por si acaso.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;El siguiente paso va a ser montar los servidores de aplicaciones en los backends y en el backoffice&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="mongodb"></category><category term="replica set"></category><category term="systemd"></category><category term="firehol"></category></entry><entry><title>Creando un entorno escalable (I)</title><link href="http://www.linuxsysadmin.ml/2016/02/creando-un-entorno-escalable.html" rel="alternate"></link><published>2016-02-29T08:00:00+01:00</published><updated>2016-02-29T08:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-02-29:/2016/02/creando-un-entorno-escalable.html</id><summary type="html">&lt;p&gt;Mucha gente tiene un servidor único para alojar páginas web dinámicas, por ejemplo con &lt;strong&gt;PHP&lt;/strong&gt; y con &lt;strong&gt;MySQL&lt;/strong&gt;. Sin embargo, a veces esto puede resultar insuficiente; nos puede interesar tener un entorno de bajas especificaciones y de bajo coste, pero preparado crecer al mismo ritmo que lo hacen los usuarios …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Mucha gente tiene un servidor único para alojar páginas web dinámicas, por ejemplo con &lt;strong&gt;PHP&lt;/strong&gt; y con &lt;strong&gt;MySQL&lt;/strong&gt;. Sin embargo, a veces esto puede resultar insuficiente; nos puede interesar tener un entorno de bajas especificaciones y de bajo coste, pero preparado crecer al mismo ritmo que lo hacen los usuarios.&lt;/p&gt;
&lt;p&gt;En este caso, el truco consiste en hacer trabajar a varias máquinas como si fueran una sola, escondidas en una o varias subredes privadas y poniendo un representante único de todo el sistema (que es el que va a recibir &lt;strong&gt;todas&lt;/strong&gt; las peticiones).&lt;/p&gt;
&lt;p&gt;Este representante suele ser lo que llamamos un &lt;strong&gt;balanceador de carga&lt;/strong&gt;, cuya función es repartir el trabajo entre varios servidores de &lt;strong&gt;backend&lt;/strong&gt;. Al tratarse solo de un "policía de tráfico" su rendimiento es elevado con unas especificaciones modestas, mientras que los servidores de &lt;strong&gt;backend&lt;/strong&gt; consiguen resolver las mismas peticiones por unidad de tiempo; la mejora reside en que pueden haber varios servidores de &lt;strong&gt;backend&lt;/strong&gt; resolviendo peticiones en paralelo.&lt;/p&gt;
&lt;p&gt;Normalmente, estos servidores de &lt;strong&gt;backend&lt;/strong&gt; suelen conectarse a otros servicios (idealmente en otros servidores) para cumplir con sus funciones, por ejemplo con un grupo de servidores de &lt;strong&gt;bases de datos&lt;/strong&gt; dispuestos como un &lt;em&gt;cluster&lt;/em&gt;, que suelen tener una topología propia.&lt;/p&gt;
&lt;p&gt;En este tutorial se va a montar un entorno pequeño de estas características, sirviendo una &lt;em&gt;API&lt;/em&gt; pública en servidores de &lt;strong&gt;backend&lt;/strong&gt;, una aplicación web de administración de los datos de la &lt;em&gt;API&lt;/em&gt; en un servidor de &lt;strong&gt;backoffice&lt;/strong&gt;, y un &lt;em&gt;cluster&lt;/em&gt; de &lt;strong&gt;bases de datos&lt;/strong&gt; representado por una &lt;em&gt;replica set&lt;/em&gt; de MongoDB; todo ello oculto en una red privada y un balanceador usando &lt;em&gt;virtualhosts&lt;/em&gt; para ir a una aplicación u otra según el protocolo usado.&lt;/p&gt;
&lt;p&gt;Esto es lo que propongo montar:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Entorno propuesto" src="http://www.linuxsysadmin.ml/images/entorno_propuesto.png"&gt;&lt;/p&gt;
&lt;p&gt;Para ello, vamos a crear las máquinas virtuales necesarias. En este caso, voy a usar mi servidor de &lt;strong&gt;virtualización con LXC&lt;/strong&gt;, tal como lo monté en &lt;a href="http://www.linuxsysadmin.ml/2015/11/virtualizando-contenedores-lxc-tras-bridge-interno.html"&gt;este artículo&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# lxc-ls -f
NAME        STATE    IPV4        IPV6  AUTOSTART
------------------------------------------------
backend1    RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.3    -     YES
backend2    RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.4    -     YES
backoffice  RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.5    -     YES
frontend    RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.2    -     YES
mongo1      RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.6    -     YES
mongo2      RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.7    -     YES
root@lxc:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para hacer mas fácil las referencias a las diferentes máquinas, vamos a utilizar sus nombres; como no me apetece montar un servidor DNS, vamos a ponerlas en el fichero &lt;em&gt;/etc/hosts&lt;/em&gt; en todas las máquinas virtuales.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# cat /etc/hosts
...
10.0.0.2        frontend
10.0.0.3        backend1
10.0.0.4        backend2
10.0.0.5        backoffice
10.0.0.6        mongo1
10.0.0.7        mongo2
...
root@mongo1:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a ir montando todas las máquinas una por una; es laborioso pero no es nada complicado. Las reglas del &lt;em&gt;firewall&lt;/em&gt; también las iremos explicando según el rol de cada máquina.&lt;/p&gt;
&lt;p&gt;El orden de montaje no es importante, pero como queremos ir comprobando en cada caso que va funcionando, se montarán de acuerdo al orden de requisitos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;El &lt;em&gt;cluster&lt;/em&gt; de &lt;strong&gt;bases de datos&lt;/strong&gt;, que no tiene dependencias.&lt;/li&gt;
&lt;li&gt;Los servidores de &lt;strong&gt;backend&lt;/strong&gt; y &lt;strong&gt;backoffice&lt;/strong&gt; que dependen del &lt;em&gt;cluster&lt;/em&gt; de &lt;strong&gt;bases de datos&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Finalmente, pondremos el servidor de &lt;strong&gt;frontend&lt;/strong&gt;, con los &lt;em&gt;virtualhosts&lt;/em&gt; y el balanceador, lanzando las peticiones contra los &lt;strong&gt;backends&lt;/strong&gt; y el &lt;strong&gt;backoffice&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Sabiendo lo que vamos a montar, solo queda decir: ¡Manos a la obra!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</content><category term="linux"></category><category term="entorno"></category><category term="escalable"></category></entry><entry><title>Restringiendo accesos mediante certificados de cliente</title><link href="http://www.linuxsysadmin.ml/2016/02/restringiendo-accesos-mediante-certificados-de-cliente.html" rel="alternate"></link><published>2016-02-22T08:00:00+01:00</published><updated>2016-02-22T08:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-02-22:/2016/02/restringiendo-accesos-mediante-certificados-de-cliente.html</id><summary type="html">&lt;p&gt;De vez en cuando, tenemos algún contenido web o una API que necesita un control de acceso superior. El método mas eficaz del que disponemos hoy en día es la autenticación con certificados SSL cliente, en donde es el cliente el que debe ofrecer un certificado que el servidor validará …&lt;/p&gt;</summary><content type="html">&lt;p&gt;De vez en cuando, tenemos algún contenido web o una API que necesita un control de acceso superior. El método mas eficaz del que disponemos hoy en día es la autenticación con certificados SSL cliente, en donde es el cliente el que debe ofrecer un certificado que el servidor validará.&lt;/p&gt;
&lt;p&gt;Como se trata de proteger contenido web, vamos a necesitar un servidor web, por ejemplo, &lt;strong&gt;nginx&lt;/strong&gt;. De paso, vamos a instalar el paquete &lt;strong&gt;openssl&lt;/strong&gt;, que nos permitirá generar los certificados usados.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# apt-get install nginx-light openssl
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  nginx-common
Paquetes sugeridos:
  fcgiwrap nginx-doc ssl-cert ca-certificates
Se instalarán los siguientes paquetes NUEVOS:
  nginx-common nginx-light openssl
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;3&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;1&lt;/span&gt;.126 kB de archivos.
Se utilizarán &lt;span class="m"&gt;2&lt;/span&gt;.148 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Generar el certificado y la clave de la CA&lt;/h2&gt;
&lt;p&gt;Empezaremos por generar la clave de la CA, que va a servir para firmar el certificado que pondremos en el servidor.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl genrsa -des3 -out ca.key &lt;span class="m"&gt;4096&lt;/span&gt;
Generating RSA private key, &lt;span class="m"&gt;4096&lt;/span&gt; bit long modulus
...................................................................++
.++
e is &lt;span class="m"&gt;65537&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;0x10001&lt;span class="o"&gt;)&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
Verifying - Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora generamos el certificado de la CA. Lo generamos directamente firmado en un solo paso.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl req -new -x509 -days &lt;span class="m"&gt;365&lt;/span&gt; -key ca.key -out ca.crt -subj &lt;span class="s2"&gt;&amp;quot;/C=ES/ST=Spain/L=Barcelona/O=LinuxSysadmin&amp;quot;&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Generar el certificado para el servidor web&lt;/h2&gt;
&lt;p&gt;Generamos la clave para el certificado del servidor web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl genrsa -des3 -out server.key &lt;span class="m"&gt;4096&lt;/span&gt;
Generating RSA private key, &lt;span class="m"&gt;4096&lt;/span&gt; bit long modulus
.............................................++
.....................................++
e is &lt;span class="m"&gt;65537&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;0x10001&lt;span class="o"&gt;)&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key:
Verifying - Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora creamos un certificado para el servidor web. Es importante que el campo &lt;strong&gt;CN&lt;/strong&gt; sea el mismo que el nombre del &lt;em&gt;virtualhost&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl req -new -key server.key -out server.csr -subj &lt;span class="s2"&gt;&amp;quot;/C=ES/ST=Spain/L=Barcelona/O=LinuxSysadmin/CN=private.linuxsysadmin.tk&amp;quot;&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y lo firmamos con la clave y el certificado de la CA.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl x509 -req -days &lt;span class="m"&gt;365&lt;/span&gt; -in server.csr -CA ca.crt -CAkey ca.key -set_serial &lt;span class="m"&gt;01&lt;/span&gt; -out server.crt
Signature ok
&lt;span class="nv"&gt;subject&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/C&lt;span class="o"&gt;=&lt;/span&gt;ES/ST&lt;span class="o"&gt;=&lt;/span&gt;Spain/L&lt;span class="o"&gt;=&lt;/span&gt;Barcelona/O&lt;span class="o"&gt;=&lt;/span&gt;LinuxSysadmin/CN&lt;span class="o"&gt;=&lt;/span&gt;private.linuxsysadmin.tk
Getting CA Private Key
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: Si la clave está protegida por una passphrase, se va a necesitar introducirla cada vez que se quiera levantar el servidor web. Nos lo podemos ahorrar con unos simples comandos, que dejará la clave como insegura.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mv server.key server.key.secure
root@server:~# openssl rsa -in server.key.secure -out server.key
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key.secure:
writing RSA key
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Generar el certificado cliente&lt;/h2&gt;
&lt;p&gt;Generamos la clave para el certificado del cliente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl genrsa -des3 -out client.key &lt;span class="m"&gt;1024&lt;/span&gt;
Generating RSA private key, &lt;span class="m"&gt;1024&lt;/span&gt; bit long modulus
...............................++++++
.....................++++++
e is &lt;span class="m"&gt;65537&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;0x10001&lt;span class="o"&gt;)&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; client.key:
Verifying - Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; client.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;El siguiente paso consiste en generar una petición de certificado, que posteriormente haremos firmar. El campo &lt;strong&gt;CN&lt;/strong&gt; puede ser recogido por el servidor web y trasladado mediante cabeceras a un hipotético &lt;em&gt;backend&lt;/em&gt;, en caso de hacer un &lt;em&gt;proxy_pass&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl req -new -key client.key -out client.csr -subj &lt;span class="s2"&gt;&amp;quot;/C=ES/ST=Spain/L=Barcelona/O=LinuxSysadmin/CN=Gerard Monells&amp;quot;&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; client.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Firmamos nuestra petición de certificado con la clave de la CA, obteniendo el certificado final.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl x509 -req -days &lt;span class="m"&gt;365&lt;/span&gt; -in client.csr -CA ca.crt -CAkey ca.key -set_serial &lt;span class="m"&gt;91&lt;/span&gt; -out client.crt
Signature ok
&lt;span class="nv"&gt;subject&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/C&lt;span class="o"&gt;=&lt;/span&gt;ES/ST&lt;span class="o"&gt;=&lt;/span&gt;Spain/L&lt;span class="o"&gt;=&lt;/span&gt;Barcelona/O&lt;span class="o"&gt;=&lt;/span&gt;LinuxSysadmin/CN&lt;span class="o"&gt;=&lt;/span&gt;Gerard Monells
Getting CA Private Key
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora queda empaquetar la clave y el certificado en un fichero &lt;em&gt;client.p12&lt;/em&gt; que pueda ser importado en un navegador web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl pkcs12 -export -in client.crt -inkey client.key -out client.p12 -name &lt;span class="s2"&gt;&amp;quot;LinuxSysadmin&amp;quot;&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; client.key:
Enter Export Password:
Verifying - Enter Export Password:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Montando el dominio web&lt;/h2&gt;
&lt;p&gt;Además de necesitar el certificado y la clave servidor, es necesario que el servidor web conozca el certificado de la CA para que pueda verificar el servidor cliente que nos ofrezca el navegador.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cp server.key /etc/ssl/private/
root@server:~# cp server.crt /etc/ssl/certs/
root@server:~# cp ca.crt /etc/ssl/certs/
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Así quedarían los certificados una vez en su sitio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# tree /etc/ssl/
/etc/ssl/
├── certs
│   ├── ca.crt
│   └── server.crt
├── openssl.cnf
└── private
    └── server.key

&lt;span class="m"&gt;2&lt;/span&gt; directories, &lt;span class="m"&gt;4&lt;/span&gt; files
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a poner un fichero de configuración en &lt;strong&gt;nginx&lt;/strong&gt;, que va a escuchar por el puerto 443 y con &lt;strong&gt;SSL&lt;/strong&gt; habilitado. Indicamos también donde están los ficheros que servirá el &lt;strong&gt;nginx&lt;/strong&gt;, la localización de los certificados y la necesidad de verificar al cliente mediante certificado contra el certificado de la CA.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cat /etc/nginx/sites-enabled/private.linuxsysadmin.tk
server &lt;span class="o"&gt;{&lt;/span&gt;
    listen                      &lt;span class="m"&gt;443&lt;/span&gt; ssl&lt;span class="p"&gt;;&lt;/span&gt;
    server_name                 private.linuxsysadmin.tk&lt;span class="p"&gt;;&lt;/span&gt;
    root                        /www&lt;span class="p"&gt;;&lt;/span&gt;

    ssl_certificate             /etc/ssl/certs/server.crt&lt;span class="p"&gt;;&lt;/span&gt;
    ssl_certificate_key         /etc/ssl/private/server.key&lt;span class="p"&gt;;&lt;/span&gt;
    ssl_client_certificate      /etc/ssl/certs/ca.crt&lt;span class="p"&gt;;&lt;/span&gt;
    ssl_verify_client           on&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Podemos verificar que la sintaxis de la configuración es correcta usando el binario de &lt;strong&gt;nginx&lt;/strong&gt; con el parámetro adecuado.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# nginx -t
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf &lt;span class="nb"&gt;test&lt;/span&gt; is successful
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y sabiendo que es correcto, reiniciamos el servidor web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# service nginx restart
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comprobación de funcionamiento&lt;/h2&gt;
&lt;p&gt;Como hemos indicado en la configuración en el &lt;em&gt;document root&lt;/em&gt;, vamos a servir el contenido que se encuentra en &lt;em&gt;/www&lt;/em&gt;. Empezaremos poniendo algún contenido en él.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mkdir /www
root@server:~# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Private area&amp;quot;&lt;/span&gt; &amp;gt; /www/index.html
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora apuntemos el navegador a la &lt;strong&gt;URL&lt;/strong&gt; del servidor web. Debemos aceptar el certificado autofirmado, puesto que no viene firmado por ninguna autoridad certificadora conocida, por ejemplo, &lt;strong&gt;VeriSign&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Aún así, como no hemos presentado el certificado cliente, el servidor web nos impide el acceso, con una respuesta &lt;strong&gt;HTTP 400&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="2 way SSL access denied" src="http://www.linuxsysadmin.ml/images/2-way-ssl-access-denied.png"&gt;&lt;/p&gt;
&lt;p&gt;Ahora debemos importar el certificado &lt;em&gt;client.p12&lt;/em&gt; en el navegador web. En el caso concreto de &lt;strong&gt;Google Chrome&lt;/strong&gt;, se hace desde el siguiente menú:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Menu &amp;rarr; Settings &amp;rarr; Show advanced settings &amp;rarr; HTTPS/SSL &amp;rarr; Manage certificates &amp;rarr; Your certificates &amp;rarr; Import &amp;rarr; client.p12&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Y ya podemos acceder a nuestro contenido protegido, previa selección del certificado a usar.&lt;/p&gt;
&lt;p&gt;&lt;img alt="2 way SSL certificate" src="http://www.linuxsysadmin.ml/images/2-way-ssl-certificate.png"&gt;&lt;/p&gt;
&lt;p&gt;Y con esto ya tenemos montada la autenticación cliente mediante certificados.&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="nginx"></category><category term="2 way ssl"></category><category term="ssl"></category><category term="https"></category><category term="certificado"></category></entry><entry><title>Restringiendo accesos web mediante autenticación básica</title><link href="http://www.linuxsysadmin.ml/2016/02/restringiendo-accesos-web-mediante-autenticacion-basica.html" rel="alternate"></link><published>2016-02-08T08:30:00+01:00</published><updated>2016-02-08T08:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-02-08:/2016/02/restringiendo-accesos-web-mediante-autenticacion-basica.html</id><summary type="html">&lt;p&gt;Algunas veces nos encontramos con la necesidad de restringir el acceso a algunos recursos web. Normalmente se suele implementar algún sistema de &lt;em&gt;login&lt;/em&gt;, &lt;em&gt;cookies&lt;/em&gt; o &lt;em&gt;sesiones&lt;/em&gt;; no obstante, esta opción no siempre nos es posible, y tenemos que proteger esos recursos usando los mecanismos que nos ofrezca el servidor web …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Algunas veces nos encontramos con la necesidad de restringir el acceso a algunos recursos web. Normalmente se suele implementar algún sistema de &lt;em&gt;login&lt;/em&gt;, &lt;em&gt;cookies&lt;/em&gt; o &lt;em&gt;sesiones&lt;/em&gt;; no obstante, esta opción no siempre nos es posible, y tenemos que proteger esos recursos usando los mecanismos que nos ofrezca el servidor web.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ATENCIÓN&lt;/strong&gt;: Este método es bastante simple, y se puede descodificar lo que manda el cliente; por eso se recomienda encarecidamente usar &lt;strong&gt;SSL&lt;/strong&gt;, mediante el uso de &lt;strong&gt;HTTPS&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Empezaremos instalando el servidor web y la herramienta de generación de certificados para usar con &lt;strong&gt;SSL&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# apt-get install nginx-light openssl
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  nginx-common
Paquetes sugeridos:
  fcgiwrap nginx-doc ssl-cert ca-certificates
Se instalarán los siguientes paquetes NUEVOS:
  nginx-common nginx-light openssl
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;3&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;1&lt;/span&gt;.126 kB de archivos.
Se utilizarán &lt;span class="m"&gt;2&lt;/span&gt;.148 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Generar el certificado y la clave de la CA&lt;/h2&gt;
&lt;p&gt;Empezaremos por generar la clave de la CA, que va a servir para firmar el certificado que pondremos en el servidor.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl genrsa -des3 -out ca.key &lt;span class="m"&gt;4096&lt;/span&gt;
Generating RSA private key, &lt;span class="m"&gt;4096&lt;/span&gt; bit long modulus
..................................++
.....................................................................++
e is &lt;span class="m"&gt;65537&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;0x10001&lt;span class="o"&gt;)&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
Verifying - Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora generamos el certificado de la CA. Lo generamos directamente firmado en un solo paso.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl req -new -x509 -days &lt;span class="m"&gt;365&lt;/span&gt; -key ca.key -out ca.crt -subj &lt;span class="s2"&gt;&amp;quot;/C=ES/ST=Spain/L=Barcelona/O=LinuxSysadmin&amp;quot;&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Generar el certificado para el servidor web&lt;/h2&gt;
&lt;p&gt;Generamos la clave para el certificado del servidor web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl genrsa -des3 -out server.key &lt;span class="m"&gt;4096&lt;/span&gt;
Generating RSA private key, &lt;span class="m"&gt;4096&lt;/span&gt; bit long modulus
.....................................................................++
......................................................................................................................................................................++
e is &lt;span class="m"&gt;65537&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;0x10001&lt;span class="o"&gt;)&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key:
Verifying - Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora creamos un certificado para el servidor web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl req -new -key server.key -out server.csr -subj &lt;span class="s2"&gt;&amp;quot;/C=ES/ST=Spain/L=Barcelona/O=LinuxSysadmin/CN=private.linuxsysadmin.tk&amp;quot;&lt;/span&gt;
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y lo firmamos con la clave y el certificado de la CA.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# openssl x509 -req -days &lt;span class="m"&gt;365&lt;/span&gt; -in server.csr -CA ca.crt -CAkey ca.key -set_serial &lt;span class="m"&gt;01&lt;/span&gt; -out server.crt
Signature ok
&lt;span class="nv"&gt;subject&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/C&lt;span class="o"&gt;=&lt;/span&gt;ES/ST&lt;span class="o"&gt;=&lt;/span&gt;Spain/L&lt;span class="o"&gt;=&lt;/span&gt;Barcelona/O&lt;span class="o"&gt;=&lt;/span&gt;LinuxSysadmin/CN&lt;span class="o"&gt;=&lt;/span&gt;private.linuxsysadmin.tk
Getting CA Private Key
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; ca.key:
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: Si la clave está protegida por una &lt;em&gt;passphrase&lt;/em&gt;, se va a necesitar introducirla cada vez que se quiera levantar el servidor web. Nos lo podemos ahorrar con unos simples comandos, que dejará la clave como insegura.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mv server.key server.key.secure
root@server:~# openssl rsa -in server.key.secure -out server.key
Enter pass phrase &lt;span class="k"&gt;for&lt;/span&gt; server.key.secure:
writing RSA key
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Montando el dominio web&lt;/h2&gt;
&lt;p&gt;Para habilitar &lt;strong&gt;SSL&lt;/strong&gt; en un dominio, necesitamos la clave y el certificado del servidor, así que vamos a ponerlos en una carpeta pensado para tal efecto.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cp server.key /etc/ssl/private/
root@server:~# cp server.crt /etc/ssl/certs/
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Así quedarían los certificados una vez en su sitio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# tree /etc/ssl/
/etc/ssl/
├── certs
│   └── server.crt
├── openssl.cnf
└── private
    └── server.key

&lt;span class="m"&gt;2&lt;/span&gt; directories, &lt;span class="m"&gt;3&lt;/span&gt; files
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a poner un fichero de configuración en &lt;strong&gt;nginx&lt;/strong&gt;, que va a escuchar por el puerto 443 y con &lt;strong&gt;SSL&lt;/strong&gt; habilitado. Indicamos también donde están los ficheros que servirá el &lt;strong&gt;nginx&lt;/strong&gt;, la localización de los certificados y activamos la autenticación básica.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# cat /etc/nginx/sites-enabled/private.linuxsysadmin.tk
server &lt;span class="o"&gt;{&lt;/span&gt;
        listen &lt;span class="m"&gt;443&lt;/span&gt; ssl&lt;span class="p"&gt;;&lt;/span&gt;
        server_name private.linuxsysadmin.tk&lt;span class="p"&gt;;&lt;/span&gt;
        root /www&lt;span class="p"&gt;;&lt;/span&gt;

        ssl_certificate /etc/ssl/certs/server.crt&lt;span class="p"&gt;;&lt;/span&gt;
        ssl_certificate_key /etc/ssl/private/server.key&lt;span class="p"&gt;;&lt;/span&gt;

        auth_basic &lt;span class="s2"&gt;&amp;quot;Admin Area&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        auth_basic_user_file /etc/nginx/auth/private&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora tenemos que crear un fichero tipo &lt;em&gt;.htpasswd&lt;/em&gt; como los de &lt;strong&gt;apache&lt;/strong&gt;. Crearemos primero la carpeta en donde lo vamos a dejar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mkdir /etc/nginx/auth
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En la carpeta creada pondremos un fichero llamado &lt;em&gt;private&lt;/em&gt; con un formato idéntico a los &lt;em&gt;.htpasswd&lt;/em&gt; de &lt;strong&gt;apache&lt;/strong&gt;. Aquí podríamos usar las herramientas de &lt;strong&gt;apache-utils&lt;/strong&gt;, pero de momento nos conformaremos con crearlo con &lt;strong&gt;openssl&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;admin:&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;openssl passwd -crypt s3cr3t&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; /etc/nginx/auth/private
root@server:~# cat /etc/nginx/auth/private
admin:y6xasR0LI8mbg
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente reiniciamos el servidor web para que aplique los cambios en la configuración.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# service nginx restart
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comprobación de funcionamiento&lt;/h2&gt;
&lt;p&gt;Es importante que nos acordemos de crear nuestro &lt;em&gt;document root&lt;/em&gt; con algún contenido.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mkdir /www
root@server:~# &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Private area&amp;quot;&lt;/span&gt; &amp;gt; /www/index.html
root@server:~#
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Si apuntamos un navegador al dominio configurado, y tras aceptar nuestro certificado autofirmado como excepción, deberíamos ver que se nos piden las credenciales en una ventana emergente.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Autenticación básica: credenciales" src="http://www.linuxsysadmin.ml/images/autenticacion-basica-credenciales.png"&gt;&lt;/p&gt;
&lt;p&gt;Y con eso tenemos nuestro contenido protegido de los curiosos.&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="nginx"></category><category term="autenticacion basica"></category><category term="htpasswd"></category><category term="ssl"></category><category term="https"></category><category term="certificado"></category></entry><entry><title>Un proxy DNS con dnsmasq</title><link href="http://www.linuxsysadmin.ml/2016/02/un-proxy-dns-con-dnsmasq.html" rel="alternate"></link><published>2016-02-01T08:30:00+01:00</published><updated>2016-02-01T08:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-02-01:/2016/02/un-proxy-dns-con-dnsmasq.html</id><summary type="html">&lt;p&gt;A veces nos puede interesar disponer de una servidor &lt;strong&gt;DNS&lt;/strong&gt; para nombrar las máquinas de nuestra red privada, sin la complejidad de &lt;strong&gt;BIND&lt;/strong&gt;. Otras, queremos acelerar el acceso a internet desde nuestra red; es interesante ver el tiempo que se pierde en la resolución &lt;strong&gt;DNS&lt;/strong&gt;. Para eso disponemos de &lt;strong&gt;dnsmasq …&lt;/strong&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;A veces nos puede interesar disponer de una servidor &lt;strong&gt;DNS&lt;/strong&gt; para nombrar las máquinas de nuestra red privada, sin la complejidad de &lt;strong&gt;BIND&lt;/strong&gt;. Otras, queremos acelerar el acceso a internet desde nuestra red; es interesante ver el tiempo que se pierde en la resolución &lt;strong&gt;DNS&lt;/strong&gt;. Para eso disponemos de &lt;strong&gt;dnsmasq&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;El servicio &lt;strong&gt;dnsmasq&lt;/strong&gt; proporciona servicios como caché &lt;strong&gt;DNS&lt;/strong&gt; y como servidor &lt;strong&gt;DHCP&lt;/strong&gt;. Se trata de un &lt;em&gt;proxy&lt;/em&gt; &lt;strong&gt;DNS&lt;/strong&gt; que va a dirigir las consultas &lt;strong&gt;DNS&lt;/strong&gt; contra el servidor configurado en el &lt;em&gt;proxy&lt;/em&gt;, guardando una copia en &lt;em&gt;caché&lt;/em&gt; para agilizar futuras consultas.&lt;/p&gt;
&lt;p&gt;Es muy fácil de configurar y es bastante ligero. Se considera ideal para redes pequeñas con menos de 50 ordenadores.&lt;/p&gt;
&lt;p&gt;En mi caso, resultó muy útil para solucionar el problema de &lt;strong&gt;DNS&lt;/strong&gt; que me planteaba una red &lt;strong&gt;Virtualbox&lt;/strong&gt; &lt;em&gt;solo anfitrión&lt;/em&gt;, en donde se escondían mis máquinas virtuales con dirección IP estática. Resulta que me muevo entre varias zonas de trabajo, y que no hay ningún servidor &lt;strong&gt;DNS&lt;/strong&gt; accesible desde todas; ir cambiando los &lt;strong&gt;DNS&lt;/strong&gt; de todas las máquinas era trabajoso.&lt;/p&gt;
&lt;p&gt;Con este problema, puse &lt;strong&gt;dnsmasq&lt;/strong&gt; en mi anfitrión (que usaba &lt;strong&gt;DHCP&lt;/strong&gt; y recibía el &lt;strong&gt;DNS&lt;/strong&gt; automáticamente), y configuré todas las máquinas para que usaran el anfitrión como servidor &lt;strong&gt;DNS&lt;/strong&gt;; nunca mas tuve que configurarlos.&lt;/p&gt;
&lt;h2&gt;Instalación&lt;/h2&gt;
&lt;p&gt;La instalación en una máquina derivada de &lt;em&gt;Debian&lt;/em&gt; es muy simple; está en los repositorios oficiales.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@proxy:~# apt-get install dnsmasq
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes extras:
  dns-root-data dnsmasq-base libnetfilter-conntrack3
Paquetes sugeridos:
  resolvconf
Se instalarán los siguientes paquetes NUEVOS:
  dns-root-data dnsmasq dnsmasq-base libnetfilter-conntrack3
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;4&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;488&lt;/span&gt; kB de archivos.
Se utilizarán &lt;span class="m"&gt;1&lt;/span&gt;.170 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@proxy:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En caso de querer modificar la configuración, se debe editar el fichero &lt;em&gt;/etc/dnsmasq.conf&lt;/em&gt;, y luego reiniciar el servicio &lt;em&gt;dnsmasq&lt;/em&gt;. En este mismo fichero se puede configurar el servicio &lt;strong&gt;DHCP&lt;/strong&gt; (directiva &lt;em&gt;dhcp-range&lt;/em&gt;), el servidor de nombres a dar al resto (la misma máquina de &lt;em&gt;dnsmasq&lt;/em&gt;, por defecto), el servidor &lt;strong&gt;NTP&lt;/strong&gt; o el &lt;em&gt;gateway&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;En mi caso, no vi necesario activar estos servicios, así que el fichero de configuración no se vio modificada. Así pues, con esto basta.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TRUCO&lt;/strong&gt;: En caso de querer resolver localmente, &lt;em&gt;dnsmasq&lt;/em&gt; sirve los nombres alojados en &lt;em&gt;/etc/hosts&lt;/em&gt;, a menos que se indique lo contrario en la configuración. Basta con modificar ese fichero.&lt;/p&gt;
&lt;h2&gt;Comprobación y uso&lt;/h2&gt;
&lt;p&gt;Para comprobar que funciona, vamos a poner otra máquina, configurada para usar el nuevo servidor &lt;strong&gt;DNS&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# cat /etc/resolv.conf 
nameserver &lt;span class="m"&gt;192&lt;/span&gt;.168.56.1
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En principio basta con comprobar que resuelve el nombre de una petición cualquiera, por ejemplo, con un &lt;strong&gt;ping&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Sin embargo, podemos apreciar la mejora de la &lt;em&gt;caché&lt;/em&gt; mediante una herramienta mas avanzada de resolución &lt;strong&gt;DNS&lt;/strong&gt;, por ejemplo, con &lt;strong&gt;dig&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# dig www.linuxsysadmin.tk &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="s2"&gt;&amp;quot;Query time&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;;;&lt;/span&gt; Query time: &lt;span class="m"&gt;118&lt;/span&gt; msec
root@client:~# dig www.linuxsysadmin.tk &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="s2"&gt;&amp;quot;Query time&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;;;&lt;/span&gt; Query time: &lt;span class="m"&gt;5&lt;/span&gt; msec
root@client:~# dig www.linuxsysadmin.tk &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="s2"&gt;&amp;quot;Query time&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;;;&lt;/span&gt; Query time: &lt;span class="m"&gt;4&lt;/span&gt; msec
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto hemos cumplido; tenemos un &lt;em&gt;proxy caché&lt;/em&gt; &lt;strong&gt;DNS&lt;/strong&gt;, que nos agiliza las peticiones, nos resuelve localmente y nos evita ir cambiando el &lt;strong&gt;DNS&lt;/strong&gt; cada vez que nos movemos de zona de trabajo.&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="dnsmasq"></category><category term="cache"></category><category term="dns"></category><category term="dhcp"></category></entry><entry><title>Un repositorio de Debian con reprepro</title><link href="http://www.linuxsysadmin.ml/2016/01/un-repositorio-de-debian-con-reprepro.html" rel="alternate"></link><published>2016-01-11T08:00:00+01:00</published><updated>2016-01-11T08:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2016-01-11:/2016/01/un-repositorio-de-debian-con-reprepro.html</id><summary type="html">&lt;p&gt;Una de las grandes facilidades que nos ofrece una distribución de Linux es su sistema de gestor de paquetes. Los paquetes oficiales nos simplifican la instalación y mantenimiento de paquetes; sin embargo, podemos sacar provecho del sistema de paquetes para uso personal, para automatizar instalaciones y actualizaciones que queramos hacer …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Una de las grandes facilidades que nos ofrece una distribución de Linux es su sistema de gestor de paquetes. Los paquetes oficiales nos simplifican la instalación y mantenimiento de paquetes; sin embargo, podemos sacar provecho del sistema de paquetes para uso personal, para automatizar instalaciones y actualizaciones que queramos hacer.&lt;/p&gt;
&lt;p&gt;En este artículo vamos a crear un repositorio en el que podemos poner paquetes, sean sacados del repositorio oficial (para hacer de caché), o sean paquetes creados por nosotros con aplicativos propios o empaquetados a partir de paquetes no libres.&lt;/p&gt;
&lt;p&gt;Para hacerlo, necesitamos una máquina en donde pondremos el repositorio, y a efectos de demostración, una máquina en donde instalaremos paquetes de dicho repositorio. En este caso, usaremos como &lt;em&gt;LXC&lt;/em&gt; tecnología para crear las máquina virtuales.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# lxc-ls -f
NAME        STATE    IPV4      IPV6  AUTOSTART  
----------------------------------------------
client      RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.3  -     YES        
repository  RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.2  -     YES        
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Montando el repositorio&lt;/h2&gt;
&lt;p&gt;Un repositorio &lt;em&gt;Debian&lt;/em&gt; no es mas que un servidor web sirviendo una estructura de ficheros con una forma concreta, que vamos a crear con &lt;strong&gt;reprepro&lt;/strong&gt; y vamos a servir con &lt;strong&gt;nginx&lt;/strong&gt;. Aís pues, los instalamos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@repository:~# apt-get install reprepro nginx-light
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
...
Se instalarán los siguientes paquetes NUEVOS:
  ca-certificates gnupg-agent gnupg2 libarchive13 libassuan0 libcurl3-gnutls libffi6 libgmp10 libgnutls-deb0-28 libgpgme11 libhogweed2 libidn11 libksba8 libldap-2.4-2
  liblzo2-2 libnettle4 libp11-kit0 libpth20 librtmp1 libsasl2-2 libsasl2-modules libsasl2-modules-db libssh2-1 libtasn1-6 libxml2 nginx-common nginx-light openssl
  pinentry-curses reprepro sgml-base xml-core
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;32&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;7&lt;/span&gt;.645 kB de archivos.
Se utilizarán &lt;span class="m"&gt;21&lt;/span&gt;,2 MB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@repository:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Un repositorio necesita una clave &lt;strong&gt;gpg&lt;/strong&gt; para firmar los paquetes que sirve; aunque de eso se encarga &lt;strong&gt;reprepro&lt;/strong&gt;, tenemos que generarla:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@repository:~# gpg --gen-key
gpg &lt;span class="o"&gt;(&lt;/span&gt;GnuPG&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;.4.18&lt;span class="p"&gt;;&lt;/span&gt; Copyright &lt;span class="o"&gt;(&lt;/span&gt;C&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="m"&gt;2014&lt;/span&gt; Free Software Foundation, Inc.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
...
gpg: /root/.gnupg/trustdb.gpg: se ha creado base de datos de confianza
gpg: clave C1B88DF7 marcada como de confianza absoluta
claves pública y secreta creadas y firmadas.
...
root@repository:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora podemos ver que las claves se han creado y podemos anotar su identificador para continuar con el procedimiento.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@repository:~# gpg --list-keys
/root/.gnupg/pubring.gpg
------------------------
pub   2048R/C1B88DF7 &lt;span class="m"&gt;2016&lt;/span&gt;-01-07
uid                  Gerard Monells &amp;lt;gerard.monells@gmail.com&amp;gt;
sub   2048R/5C5B84E3 &lt;span class="m"&gt;2016&lt;/span&gt;-01-07

root@repository:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a crear el repositorio en &lt;em&gt;/opt/repo/&lt;/em&gt;, con una carpeta &lt;em&gt;public&lt;/em&gt; que es lo que vamos a servir con &lt;strong&gt;nginx&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@repository:~# mkdir -p /opt/repo/&lt;span class="o"&gt;{&lt;/span&gt;conf,public&lt;span class="o"&gt;}&lt;/span&gt;
root@repository:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Por comodidad, vamos a trabajar en la carpeta base del repositorio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@repository:~# &lt;span class="nb"&gt;cd&lt;/span&gt; /opt/repo
root@repository:/opt/repo# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Un repositorio hecho con &lt;strong&gt;reprepro&lt;/strong&gt; se declara mediante un fichero de configuración, que vamos a crear en la carpeta &lt;em&gt;conf&lt;/em&gt;, declarando el nombre del repositorio, las arquitecturas y la clave con la que se firman los paquetes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@repository:/opt/repo# cat conf/distributions 
Codename: linuxsysadmin
Components: main
Architectures: i386
SignWith: C1B88DF7
root@repository:/opt/repo# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a poner la parte pública de nuestra clave &lt;strong&gt;gpg&lt;/strong&gt; en la raíz del servidor web, para que los clientes puedan agregarla a su almacén de claves, para usar sin problemas los paquetes de nuestro repositorio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@repository:/opt/repo# gpg -a --export C1B88DF7 &amp;gt; /opt/repo/public/key.gpg
root@repository:/opt/repo# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora vamos a poner una configuración a &lt;strong&gt;nginx&lt;/strong&gt; que nos permita servir la carpeta pública en el puerto web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@repository:/opt/repo# cat /etc/nginx/sites-enabled/repository
server &lt;span class="o"&gt;{&lt;/span&gt;
    server_name localhost&lt;span class="p"&gt;;&lt;/span&gt;
    root /opt/repo/public&lt;span class="p"&gt;;&lt;/span&gt;
    autoindex on&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
root@repository:/opt/repo# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Recargamos o reiniciamos el servicio &lt;strong&gt;nginx&lt;/strong&gt; para que la configuración surta efecto:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@repository:/opt/repo# service nginx restart
root@repository:/opt/repo# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Añadiendo paquetes al repositorio&lt;/h2&gt;
&lt;p&gt;Añadir un paquete a nuestro repositorio es tan fácil como invocar el comando &lt;em&gt;reprepro&lt;/em&gt;, con la opción &lt;em&gt;includedeb&lt;/em&gt; del paquete, en alguna carpeta de nuestra máquina. El resto son opciones que indican donde están las carpetas del repositorio.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: Si se pone un paquete empaquetado por nosotros, es importante que su fichero &lt;em&gt;control&lt;/em&gt; incluya las directivas &lt;em&gt;Section&lt;/em&gt; y &lt;em&gt;Priority&lt;/em&gt;, normalmente solo recomendadas, pero necesarias para &lt;strong&gt;reprepro&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Por ejemplo, podemos usar el paquete de un &lt;a href="http://www.linuxsysadmin.ml/2015/12/empaquetando-ficheros-punto-deb.html"&gt;artículo anterior&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@repository:/opt/repo# reprepro --distdir ./public/dists --outdir ./public includedeb linuxsysadmin /root/welcome_1.0-1_all.deb 
Exporting indices...
root@repository:/opt/repo# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: Puede que el comando falle si no se ha montado el sistema de ficheros &lt;em&gt;/dev/pts&lt;/em&gt;, especialmente en un entorno tipo &lt;strong&gt;chroot&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Usando el repositorio&lt;/h2&gt;
&lt;p&gt;Cambiamos de máquina; ahora vamos a la máquina que vaya a usar el repositorio y vamos a configurar el repositorio nuevo.&lt;/p&gt;
&lt;p&gt;Lo primero es declarar la &lt;strong&gt;source&lt;/strong&gt; de nuestro repositorio, declarando la dirección web del repositorio, el nombre del repositorio y el componente.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# cat /etc/apt/sources.list.d/linuxsysadmin.list 
deb http://10.0.0.2/ linuxsysadmin main
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora nos descargamos la clave pública del repositorio y la añadimos al almacén de claves de &lt;strong&gt;apt&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# wget -qO- http://10.0.0.2/key.gpg &lt;span class="p"&gt;|&lt;/span&gt; apt-key add -
OK
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto ya tenemos el repositorio habilitado. A partir de aquí su uso es el mismo que el de cualquier otro repositorio. Hacemos un &lt;em&gt;apt-get update&lt;/em&gt; para descargar la lista de paquetes del repositorio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# apt-get update
Des:1 http://10.0.0.2 linuxsysadmin InRelease &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.340 B&lt;span class="o"&gt;]&lt;/span&gt;
...
Des:2 http://10.0.0.2 linuxsysadmin/main i386 Packages &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;333&lt;/span&gt; B&lt;span class="o"&gt;]&lt;/span&gt;
...
Descargados &lt;span class="m"&gt;2&lt;/span&gt;.040 B en 6s &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;330&lt;/span&gt; B/s&lt;span class="o"&gt;)&lt;/span&gt;                                                                                                                                    
Leyendo lista de paquetes... Hecho
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A partir de aquí, y sabiendo nuestro sistema los paquetes de los que dispone el nuevo repositorio, podemos buscar los paquetes que hay en él.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# apt-cache search welcome &lt;span class="p"&gt;|&lt;/span&gt; grep ^welcome
welcome2l - Linux ANSI boot logo
welcome - A fancy shell script
root@client:~# apt-cache show welcome
Package: welcome
Version: &lt;span class="m"&gt;1&lt;/span&gt;.0-1
Architecture: all
Maintainer: Linux Sysadmin
Priority: optional
Section: main
Filename: pool/main/w/welcome/welcome_1.0-1_all.deb
Size: &lt;span class="m"&gt;786&lt;/span&gt;
SHA256: 2e701f7fbc090230fb7abc06597fbe5b4e9e70dcc553e749e69793a745b032f2
SHA1: 41351d1d2135bcee09e1fa3bade984ece9f23caf
MD5sum: 574fab58b3c871184047c40d0e732b35
Description: A fancy shell script
 To demonstrate how to package a .deb file
Description-md5: ed73975a1e7c5f0422fef1f624586821
Depends: bash, coreutils

root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Visto que el paquete está disponible, podemos instalarlo, usando &lt;em&gt;apt-get&lt;/em&gt; o cualquier otro frontal, gráfico o no.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# apt-get install welcome
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
Se instalarán los siguientes paquetes NUEVOS:
  welcome
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;1&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;786&lt;/span&gt; B de archivos.
Se utilizarán &lt;span class="m"&gt;0&lt;/span&gt; B de espacio de disco adicional después de esta operación.
Des:1 http://10.0.0.2/ linuxsysadmin/main welcome all &lt;span class="m"&gt;1&lt;/span&gt;.0-1 &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;786&lt;/span&gt; B&lt;span class="o"&gt;]&lt;/span&gt;
Descargados &lt;span class="m"&gt;786&lt;/span&gt; B en 0s &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;37&lt;/span&gt;,4 kB/s&lt;span class="o"&gt;)&lt;/span&gt;
debconf: se retrasa la configuración de los paquetes, ya que «apt-utils» no está instalado
Seleccionando el paquete welcome previamente no seleccionado.
&lt;span class="o"&gt;(&lt;/span&gt;Leyendo la base de datos ... &lt;span class="m"&gt;10434&lt;/span&gt; ficheros o directorios instalados actualmente.&lt;span class="o"&gt;)&lt;/span&gt;
Preparando para desempaquetar .../archives/welcome_1.0-1_all.deb ...
Desempaquetando welcome &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.0-1&lt;span class="o"&gt;)&lt;/span&gt; ...
Configurando welcome &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.0-1&lt;span class="o"&gt;)&lt;/span&gt; ...
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Tal como lo esperábamos, el comando &lt;em&gt;welcome&lt;/em&gt; está instalado y funciona como esperábamos:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# which welcome
/usr/bin/welcome
root@client:~# welcome
Hello world!
root@client:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto tenemos nuestro repositorio funcional.&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="repositorio"></category><category term="reprepro"></category><category term="nginx"></category><category term="gpg"></category><category term="apt"></category></entry><entry><title>Utilizando apt-cacher-ng para agilizar la instalación de paquetes</title><link href="http://www.linuxsysadmin.ml/2015/12/utilizando-apt-cacher-ng-para-agilizar-la-instalacion-de-paquetes.html" rel="alternate"></link><published>2015-12-21T10:00:00+01:00</published><updated>2015-12-21T10:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2015-12-21:/2015/12/utilizando-apt-cacher-ng-para-agilizar-la-instalacion-de-paquetes.html</id><summary type="html">&lt;p&gt;Hace tiempo veo que tras usar muchas maquinas virtuales &lt;em&gt;Debian&lt;/em&gt; para el uso diario y para las demostraciones de este blog, el ancho de banda usado para bajar los paquetes se dispara. La mayoría de veces se trata de los mismos paquetes, para instalar las mismas aplicaciones, servicios o actualizaciones …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Hace tiempo veo que tras usar muchas maquinas virtuales &lt;em&gt;Debian&lt;/em&gt; para el uso diario y para las demostraciones de este blog, el ancho de banda usado para bajar los paquetes se dispara. La mayoría de veces se trata de los mismos paquetes, para instalar las mismas aplicaciones, servicios o actualizaciones.&lt;/p&gt;
&lt;p&gt;En el artículo de hoy, voy a enseñar como usar un &lt;em&gt;proxy&lt;/em&gt; con una &lt;em&gt;caché&lt;/em&gt; para &lt;em&gt;apt-get&lt;/em&gt;, llamado &lt;strong&gt;apt-cacher-ng&lt;/strong&gt;, de forma que los paquetes son descargados por la primera máquina que los pida, guardados en un servidor local y aprovechados por el resto de máquinas.&lt;/p&gt;
&lt;h2&gt;Preparación de las máquinas&lt;/h2&gt;
&lt;p&gt;Partimos de la máquina habitual, llamada &lt;strong&gt;aptcacher&lt;/strong&gt;, siendo esta un contenedor LXC con una &lt;em&gt;Debian Jessie&lt;/em&gt; básica, aunque esto se podría haber puesto en una &lt;em&gt;Ubuntu&lt;/em&gt; o cualquier otra distribución que funcione con paquetes &lt;em&gt;.deb&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Otras máquinas que vamos a usar son unas máquinas cliente en donde vamos a instalar paquetes cualesquiera para demostrar el funcionamiento, llamadas &lt;strong&gt;client1&lt;/strong&gt; y &lt;strong&gt;client2&lt;/strong&gt;; estos clientes están en la misma red que la máquina &lt;strong&gt;aptcacher&lt;/strong&gt; y tienen conectividad con ella por el puerto &lt;em&gt;TCP&lt;/em&gt; 3142.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@lxc:~# lxc-ls -f
NAME       STATE    IPV4      IPV6  AUTOSTART  
---------------------------------------------
aptcacher  RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.2  -     YES        
client1    RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.3  -     YES        
client2    RUNNING  &lt;span class="m"&gt;10&lt;/span&gt;.0.0.4  -     YES        
root@lxc:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Empezamos instalando el servicio &lt;strong&gt;apt-cacher-ng&lt;/strong&gt; en la máquina servidor &lt;strong&gt;aptcacher&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@aptcacher:~# apt-get install apt-cacher-ng
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
...  
Se instalarán los siguientes paquetes NUEVOS:
  apt-cacher-ng ed
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;2&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;500&lt;/span&gt; kB de archivos.
Se utilizarán &lt;span class="m"&gt;1&lt;/span&gt;.168 kB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
root@aptcacher:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Las configuraciones que vienen por defecto son bastante adecuadas y no tuve que efectuar ningún cambio.&lt;/p&gt;
&lt;p&gt;Por otra parte, hay que configurar las máquinas que se quieran beneficiar de este servidor, añadiendo una línea de configuración en su &lt;strong&gt;apt-get&lt;/strong&gt;, por ejemplo, poniendo un fichero adicional en &lt;em&gt;/etc/apt/apt.conf.d/&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@aptcacher:~# cat /etc/apt/apt.conf.d/02proxy 
Acquire::http &lt;span class="o"&gt;{&lt;/span&gt; Proxy &lt;span class="s2"&gt;&amp;quot;http://10.0.0.2:3142&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
root@aptcacher:~# 

root@client1:~# cat /etc/apt/apt.conf.d/02proxy 
Acquire::http &lt;span class="o"&gt;{&lt;/span&gt; Proxy &lt;span class="s2"&gt;&amp;quot;http://10.0.0.2:3142&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
root@client1:~# 

root@client2:~# cat /etc/apt/apt.conf.d/02proxy 
Acquire::http &lt;span class="o"&gt;{&lt;/span&gt; Proxy &lt;span class="s2"&gt;&amp;quot;http://10.0.0.2:3142&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
root@client2:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esto queda montado todo el sistema.&lt;/p&gt;
&lt;h2&gt;Funcionamiento de la caché&lt;/h2&gt;
&lt;p&gt;El funcionamiento es muy simple: basta con instalar en un cliente un paquete, por ejemplo, &lt;em&gt;python&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client1:~# apt-get install python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
...  
Se instalarán los siguientes paquetes NUEVOS:
  file libexpat1 libffi6 libmagic1 libpython-stdlib libpython2.7-minimal
  libpython2.7-stdlib libsqlite3-0 mime-support python python-minimal
  python2.7 python2.7-minimal
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;13&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;5&lt;/span&gt;.010 kB de archivos.
Se utilizarán &lt;span class="m"&gt;21&lt;/span&gt;,3 MB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
Descargados &lt;span class="m"&gt;5&lt;/span&gt;.010 kB en 15s &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;327&lt;/span&gt; kB/s&lt;span class="o"&gt;)&lt;/span&gt;                                        
...
root@client1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como estos paquetes no están en la &lt;em&gt;caché&lt;/em&gt; del servidor, se han descargado de internet en 15 segundos, de acuerdo a la velocidad de mi conexión de internet y de la velocidad de respuesta de los repositorios elegidos.&lt;/p&gt;
&lt;p&gt;Si revisamos la página de estadísticas de &lt;strong&gt;apt-cacher-ng&lt;/strong&gt;, disponible en &lt;em&gt;http://aptcacher:3142/acng-report.html&lt;/em&gt; podemos ver que se han descargado 4,78mb en 13 paquetes; todos son &lt;strong&gt;miss&lt;/strong&gt; de la cache, es decir, se han ido a buscar al repositorio oficial.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Estadísticas web de apt-cacher" src="http://www.linuxsysadmin.ml/images/apt-cacher-ng-1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Ahora vamos a instalar &lt;em&gt;python&lt;/em&gt; en otro de los clientes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client2:~# apt-get install python
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
...
Se instalarán los siguientes paquetes NUEVOS:
  file libexpat1 libffi6 libmagic1 libpython-stdlib libpython2.7-minimal
  libpython2.7-stdlib libsqlite3-0 mime-support python python-minimal
  python2.7 python2.7-minimal
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;13&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
Se necesita descargar &lt;span class="m"&gt;5&lt;/span&gt;.010 kB de archivos.
Se utilizarán &lt;span class="m"&gt;21&lt;/span&gt;,3 MB de espacio de disco adicional después de esta operación.
¿Desea continuar? &lt;span class="o"&gt;[&lt;/span&gt;S/n&lt;span class="o"&gt;]&lt;/span&gt; s
...
Descargados &lt;span class="m"&gt;5&lt;/span&gt;.010 kB en 1s &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.902 kB/s&lt;span class="o"&gt;)&lt;/span&gt;
root@client2:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hemos elegido el paquete &lt;em&gt;python&lt;/em&gt; para asegurar que ambas máquinas instalan lo mismo; como se puede ver, se ha descargado la misma cantidad de datos, pero en vez de los 15 segundos anteriores, ahora se ha tardado 1 segundo. Eso es porque los paquetes solicitados estaban en el &lt;em&gt;proxy&lt;/em&gt;, es decir, en el servidor &lt;strong&gt;aptcacher&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Podemos ver en la misma página de administración el resultado: ahora hay 13 &lt;strong&gt;hits&lt;/strong&gt; adicionales, ya que los paquetes solicitados estaban en local.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Estadísticas web de apt-cacher" src="http://www.linuxsysadmin.ml/images/apt-cacher-ng-2.jpg"&gt;&lt;/p&gt;
&lt;p&gt;De esta forma, si tenemos un elevado número de máquinas del mismo tipo, solo consumiremos el ancho de banda necesario para traerlos de internet &lt;strong&gt;una sola vez&lt;/strong&gt;.&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="apt-cacher-ng"></category><category term="cache"></category></entry><entry><title>Construyendo un RAID 10 en linux</title><link href="http://www.linuxsysadmin.ml/2015/12/construyendo-un-raid-10-en-linux.html" rel="alternate"></link><published>2015-12-17T23:00:00+01:00</published><updated>2015-12-17T23:00:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2015-12-17:/2015/12/construyendo-un-raid-10-en-linux.html</id><summary type="html">&lt;p&gt;El otro día estaba habilitando un servidor de &lt;em&gt;mongodb&lt;/em&gt; para un entorno de producción. Como me interesaba mejorar el rendimiento de los accesos a disco y no disponía de discos SSD con una durabilidad aceptable, me propuse montar un &lt;em&gt;array de discos&lt;/em&gt; en configuración de &lt;strong&gt;RAID 10&lt;/strong&gt;, como se recomienda …&lt;/p&gt;</summary><content type="html">&lt;p&gt;El otro día estaba habilitando un servidor de &lt;em&gt;mongodb&lt;/em&gt; para un entorno de producción. Como me interesaba mejorar el rendimiento de los accesos a disco y no disponía de discos SSD con una durabilidad aceptable, me propuse montar un &lt;em&gt;array de discos&lt;/em&gt; en configuración de &lt;strong&gt;RAID 10&lt;/strong&gt;, como se recomienda.&lt;/p&gt;
&lt;p&gt;Para este tutorial vamos a tener una máquina virtual (es una &lt;em&gt;Debian&lt;/em&gt;, pero vale cualquier otra distribución) con 5 discos, 1 de sistema y otros 4 para usar en la configuración &lt;strong&gt;RAID 10&lt;/strong&gt;, cada uno con 8gb, a efecto de demostración.&lt;/p&gt;
&lt;p&gt;En este caso, el sistema operativo estaba en &lt;em&gt;/dev/sda&lt;/em&gt; y sus particiones, mientras que los discos para los datos de &lt;em&gt;mongodb&lt;/em&gt; fueron &lt;em&gt;/dev/sdb&lt;/em&gt;, &lt;em&gt;/dev/sdc&lt;/em&gt;, &lt;em&gt;/dev/sdd&lt;/em&gt;, &lt;em&gt;/dev/sde&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# ls /dev/sd* -1
/dev/sda
/dev/sda1
/dev/sdb
/dev/sdc
/dev/sdd
/dev/sde
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Creación del dispositivo RAID 10&lt;/h2&gt;
&lt;p&gt;Empezamos instalando el controlador de &lt;strong&gt;RAID&lt;/strong&gt; por software:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# apt-get install mdadm
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias       
Leyendo la información de estado... Hecho
..
Se instalarán los siguientes paquetes NUEVOS:
  bsd-mailx exim4-base exim4-config exim4-daemon-light liblockfile-bin
  liblockfile1 mdadm psmisc
&lt;span class="m"&gt;0&lt;/span&gt; actualizados, &lt;span class="m"&gt;8&lt;/span&gt; nuevos se instalarán, &lt;span class="m"&gt;0&lt;/span&gt; para eliminar y &lt;span class="m"&gt;0&lt;/span&gt; no actualizados.
...
update-initramfs: Generating /boot/initrd.img-3.16.0-4-586
W: mdadm: /etc/mdadm/mdadm.conf defines no arrays.
W: mdadm: no arrays defined in configuration file.
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Con las herramientas instaladas, procedemos a crear un &lt;em&gt;/dev/md0&lt;/em&gt; que será nuestro &lt;strong&gt;disco RAID&lt;/strong&gt;, indicando el nivel &lt;strong&gt;RAID 10&lt;/strong&gt; y los 4 discos reales que van a formarlo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mdadm -v --create /dev/md0 --level&lt;span class="o"&gt;=&lt;/span&gt;raid10 --raid-devices&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt; /dev/sdb /dev/sdc /dev/sdd /dev/sde
mdadm: layout defaults to n2
mdadm: layout defaults to n2
mdadm: chunk size defaults to 512K
mdadm: size &lt;span class="nb"&gt;set&lt;/span&gt; to 8380416K
mdadm: Defaulting to version &lt;span class="m"&gt;1&lt;/span&gt;.2 metadata
mdadm: array /dev/md0 started.
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para que ese array de discos sea reconocido en cada inicio del sistema, hay que añadir en &lt;em&gt;/etc/mdadm/mdadm.conf&lt;/em&gt; la información relacionada al array, de la misma forma que la tengamos en este momento.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mdadm --detail --scan --verbose &amp;gt;&amp;gt; /etc/mdadm/mdadm.conf
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y ya tenemos nuestro dispositivo &lt;strong&gt;RAID 10&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Preparación del dispositivo&lt;/h2&gt;
&lt;p&gt;Ahora disponemos de un &lt;strong&gt;RAID 10&lt;/strong&gt; de 4 discos de 8gb, que corresponden a una capacidad total de 16gb utilizables, como el dispositivo &lt;em&gt;/dev/md0&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Este dispositivo es transparente para nosotros y no es diferente de cualquier otro dispositivo de bloques, con lo que se puede particionar, formatear e incluso actuar como un &lt;em&gt;physical volume&lt;/em&gt; en caso de usar &lt;strong&gt;LVM&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Para esta demostración, se creará una única partición que ocupe todo el disco y que será montada en &lt;em&gt;/data&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Así pues, sin mas preámbulo la particionamos; en mi caso lo hice con &lt;em&gt;cfdisk&lt;/em&gt;. Este es el resultado:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# fdisk -l /dev/md0

Disco /dev/md0: &lt;span class="m"&gt;16&lt;/span&gt; GiB, &lt;span class="m"&gt;17163091968&lt;/span&gt; bytes, &lt;span class="m"&gt;33521664&lt;/span&gt; sectores
Unidades: sectores de &lt;span class="m"&gt;1&lt;/span&gt; * &lt;span class="nv"&gt;512&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;512&lt;/span&gt; bytes
Tamaño de sector &lt;span class="o"&gt;(&lt;/span&gt;lógico/físico&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;512&lt;/span&gt; bytes / &lt;span class="m"&gt;512&lt;/span&gt; bytes
Tamaño de E/S &lt;span class="o"&gt;(&lt;/span&gt;mínimo/óptimo&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;524288&lt;/span&gt; bytes / &lt;span class="m"&gt;1048576&lt;/span&gt; bytes
Tipo de etiqueta de disco: gpt
Identificador del disco: E3FE7B0A-0F5D-4151-84E8-49670C33B65E

Device     Start      End  Sectors Size Type
/dev/md0p1  &lt;span class="m"&gt;2048&lt;/span&gt; &lt;span class="m"&gt;33521630&lt;/span&gt; &lt;span class="m"&gt;33519583&lt;/span&gt;  16G Linux filesystem

root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;La primera (y única partición) se llama &lt;em&gt;/dev/md0p1&lt;/em&gt; y es el dispositivo que vamos a formatear, para posteriormente montarlo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mkfs.ext4 /dev/md0p1 
mke2fs &lt;span class="m"&gt;1&lt;/span&gt;.42.12 &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;29&lt;/span&gt;-Aug-2014&lt;span class="o"&gt;)&lt;/span&gt;
Se está creando El sistema de ficheros con &lt;span class="m"&gt;4189947&lt;/span&gt; 4k bloques y &lt;span class="m"&gt;1048576&lt;/span&gt; nodos-i

UUID del sistema de ficheros: 11e454ce-72c4-41f8-a7bc-4d4a78b873c0
Respaldo del superbloque guardado en los bloques: 
    &lt;span class="m"&gt;32768&lt;/span&gt;, &lt;span class="m"&gt;98304&lt;/span&gt;, &lt;span class="m"&gt;163840&lt;/span&gt;, &lt;span class="m"&gt;229376&lt;/span&gt;, &lt;span class="m"&gt;294912&lt;/span&gt;, &lt;span class="m"&gt;819200&lt;/span&gt;, &lt;span class="m"&gt;884736&lt;/span&gt;, &lt;span class="m"&gt;1605632&lt;/span&gt;, &lt;span class="m"&gt;2654208&lt;/span&gt;, 
    &lt;span class="m"&gt;4096000&lt;/span&gt;

Reservando las tablas de grupo: hecho                           
Escribiendo las tablas de nodos-i: hecho                           
Creando el fichero de transacciones &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;32768&lt;/span&gt; bloques&lt;span class="o"&gt;)&lt;/span&gt;: hecho
Escribiendo superbloques y la información contable del sistema de ficheros:   hecho  

root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos la carpeta que va a servir de &lt;em&gt;mountpoint&lt;/em&gt; para esta nueva partición:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mkdir /data
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Añadimos la partición en el fichero &lt;em&gt;/etc/fstab&lt;/em&gt;, para que se monte automáticamente tras cada reinicio:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# grep md0p1 /etc/fstab 
/dev/md0p1 /data ext4 defaults &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente la montamos. Como esta información ya está en el fichero &lt;em&gt;/etc/fstab&lt;/em&gt; no es necesario especificar los detalles.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mount /data
root@server:~# df -h
S.ficheros     Tamaño Usados  Disp Uso% Montado en
/dev/sda1        &lt;span class="m"&gt;2&lt;/span&gt;,0G   651M  &lt;span class="m"&gt;1&lt;/span&gt;,2G  &lt;span class="m"&gt;35&lt;/span&gt;% /
udev              10M      &lt;span class="m"&gt;0&lt;/span&gt;   10M   &lt;span class="m"&gt;0&lt;/span&gt;% /dev
tmpfs             50M   &lt;span class="m"&gt;4&lt;/span&gt;,4M   46M   &lt;span class="m"&gt;9&lt;/span&gt;% /run
tmpfs            124M      &lt;span class="m"&gt;0&lt;/span&gt;  124M   &lt;span class="m"&gt;0&lt;/span&gt;% /dev/shm
tmpfs            &lt;span class="m"&gt;5&lt;/span&gt;,0M      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;5&lt;/span&gt;,0M   &lt;span class="m"&gt;0&lt;/span&gt;% /run/lock
tmpfs            124M      &lt;span class="m"&gt;0&lt;/span&gt;  124M   &lt;span class="m"&gt;0&lt;/span&gt;% /sys/fs/cgroup
/dev/md0p1        16G    44M   15G   &lt;span class="m"&gt;1&lt;/span&gt;% /data
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Como detalle, al no tratarse de una partición raíz de sistema operativo, no hace falta reservar bloques de emergencia; se trata de un 5% de la capacidad que podemos liberar (5% de 16gb son 800mb que podemos usar).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# tune2fs -m &lt;span class="m"&gt;0&lt;/span&gt; /dev/md0p1 
tune2fs &lt;span class="m"&gt;1&lt;/span&gt;.42.12 &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;29&lt;/span&gt;-Aug-2014&lt;span class="o"&gt;)&lt;/span&gt;
Se pone el porcentaje de bloques reservados a &lt;span class="m"&gt;0&lt;/span&gt;% &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; bloques&lt;span class="o"&gt;)&lt;/span&gt;
root@server:~# df -h
S.ficheros     Tamaño Usados  Disp Uso% Montado en
/dev/sda1        &lt;span class="m"&gt;2&lt;/span&gt;,0G   651M  &lt;span class="m"&gt;1&lt;/span&gt;,2G  &lt;span class="m"&gt;35&lt;/span&gt;% /
udev              10M      &lt;span class="m"&gt;0&lt;/span&gt;   10M   &lt;span class="m"&gt;0&lt;/span&gt;% /dev
tmpfs             50M   &lt;span class="m"&gt;4&lt;/span&gt;,4M   46M   &lt;span class="m"&gt;9&lt;/span&gt;% /run
tmpfs            124M      &lt;span class="m"&gt;0&lt;/span&gt;  124M   &lt;span class="m"&gt;0&lt;/span&gt;% /dev/shm
tmpfs            &lt;span class="m"&gt;5&lt;/span&gt;,0M      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;5&lt;/span&gt;,0M   &lt;span class="m"&gt;0&lt;/span&gt;% /run/lock
tmpfs            124M      &lt;span class="m"&gt;0&lt;/span&gt;  124M   &lt;span class="m"&gt;0&lt;/span&gt;% /sys/fs/cgroup
/dev/md0p1        16G    44M   16G   &lt;span class="m"&gt;1&lt;/span&gt;% /data
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Verificación&lt;/h2&gt;
&lt;p&gt;Podemos ver la información de estado del array de discos con el mismo comando &lt;em&gt;mdadm&lt;/em&gt;, como sigue:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@server:~# mdadm --detail /dev/md0
/dev/md0:
        Version : &lt;span class="m"&gt;1&lt;/span&gt;.2
  Creation Time : Sat Dec &lt;span class="m"&gt;12&lt;/span&gt; &lt;span class="m"&gt;21&lt;/span&gt;:19:42 &lt;span class="m"&gt;2015&lt;/span&gt;
     Raid Level : raid10
     Array Size : &lt;span class="m"&gt;16760832&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;15&lt;/span&gt;.98 GiB &lt;span class="m"&gt;17&lt;/span&gt;.16 GB&lt;span class="o"&gt;)&lt;/span&gt;
  Used Dev Size : &lt;span class="m"&gt;8380416&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;.99 GiB &lt;span class="m"&gt;8&lt;/span&gt;.58 GB&lt;span class="o"&gt;)&lt;/span&gt;
   Raid Devices : &lt;span class="m"&gt;4&lt;/span&gt;
  Total Devices : &lt;span class="m"&gt;4&lt;/span&gt;
    Persistence : Superblock is persistent

    Update Time : Sat Dec &lt;span class="m"&gt;12&lt;/span&gt; &lt;span class="m"&gt;21&lt;/span&gt;:30:11 &lt;span class="m"&gt;2015&lt;/span&gt;
          State : clean 
 Active Devices : &lt;span class="m"&gt;4&lt;/span&gt;
Working Devices : &lt;span class="m"&gt;4&lt;/span&gt;
 Failed Devices : &lt;span class="m"&gt;0&lt;/span&gt;
  Spare Devices : &lt;span class="m"&gt;0&lt;/span&gt;

         Layout : &lt;span class="nv"&gt;near&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;
     Chunk Size : 512K

           Name : server:0  &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;local&lt;/span&gt; to host server&lt;span class="o"&gt;)&lt;/span&gt;
           UUID : 217558a7:bc1cb1d4:9530ecda:ea477a6b
         Events : &lt;span class="m"&gt;19&lt;/span&gt;

    Number   Major   Minor   RaidDevice State
       &lt;span class="m"&gt;0&lt;/span&gt;       &lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;16&lt;/span&gt;        &lt;span class="m"&gt;0&lt;/span&gt;      active sync set-A   /dev/sdb
       &lt;span class="m"&gt;1&lt;/span&gt;       &lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;32&lt;/span&gt;        &lt;span class="m"&gt;1&lt;/span&gt;      active sync set-B   /dev/sdc
       &lt;span class="m"&gt;2&lt;/span&gt;       &lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;48&lt;/span&gt;        &lt;span class="m"&gt;2&lt;/span&gt;      active sync set-A   /dev/sdd
       &lt;span class="m"&gt;3&lt;/span&gt;       &lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;64&lt;/span&gt;        &lt;span class="m"&gt;3&lt;/span&gt;      active sync set-B   /dev/sde
root@server:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;RESUMEN&lt;/strong&gt;: Ahora tengo un disco doble de rápido, doble de capacidad y con doble copia de datos. Afortunadamente, los discos duros son baratos...&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="raid"></category></entry><entry><title>Construyendo una replica set en mongodb</title><link href="http://www.linuxsysadmin.ml/2015/12/construyendo-una-replica-set-en-mongodb.html" rel="alternate"></link><published>2015-12-08T12:30:00+01:00</published><updated>2015-12-08T12:30:00+01:00</updated><author><name>Gerard</name></author><id>tag:www.linuxsysadmin.ml,2015-12-08:/2015/12/construyendo-una-replica-set-en-mongodb.html</id><summary type="html">&lt;p&gt;Muchas veces nos interesa obtener alta disponibilidad en los servicios que gestionamos. No hay nada mas desagradable que una llamada a las tantas de la noche porque se ha caído un nodo de una base de datos y no damos servicio. Para eso &lt;em&gt;mongodb&lt;/em&gt; nos ofrece el mecanismo de replicación …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Muchas veces nos interesa obtener alta disponibilidad en los servicios que gestionamos. No hay nada mas desagradable que una llamada a las tantas de la noche porque se ha caído un nodo de una base de datos y no damos servicio. Para eso &lt;em&gt;mongodb&lt;/em&gt; nos ofrece el mecanismo de replicación.&lt;/p&gt;
&lt;p&gt;En este artículo vamos a montar una &lt;em&gt;replica set&lt;/em&gt;, de forma que si se cayera un nodo de la base de datos, otro asumiría su rol, de forma que se seguiría dando servicio.&lt;/p&gt;
&lt;p&gt;Nuestra &lt;em&gt;replica set&lt;/em&gt; va a tener 3 nodos, que vamos a alojar en 3 máquinas distintas, de forma que la caída de una máquina afecte solamente a 1 proceso de &lt;em&gt;mongodb&lt;/em&gt;. La caonfiguración de 3 nodos nos da una tolerancia a fallos de 1 máquina; mientras queden 2, el clúster va a seguir operativo.&lt;/p&gt;
&lt;h2&gt;Descripción del entorno&lt;/h2&gt;
&lt;p&gt;Disponemos de 3 máquinas que vamos a llamar &lt;strong&gt;mongo1&lt;/strong&gt;, &lt;strong&gt;mongo2&lt;/strong&gt; y &lt;strong&gt;mongo3&lt;/strong&gt;. Cada una funciona con un sistema operativo &lt;em&gt;Debian jessie&lt;/em&gt; con &lt;em&gt;systemd&lt;/em&gt; y cuenta 1 gb de disco y con 256 mb de memoria; para esta demostración no se necesita mas.&lt;/p&gt;
&lt;p&gt;Como pequeño detalle, las máquinas se van referir entre ellas por nombre, pero como no me interesa poner una solución completa de &lt;em&gt;DNS&lt;/em&gt;, he puesto en el fichero &lt;em&gt;/etc/hosts&lt;/em&gt; de todas las máquinas las equivalencias.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# grep mongo /etc/hosts
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.2    mongo1
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.3    mongo2
&lt;span class="m"&gt;10&lt;/span&gt;.0.0.4    mongo3
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Consideraciones de seguridad&lt;/h2&gt;
&lt;p&gt;Estas máquinas se comunican entre sí por el puerto TCP en el que corran sus procesos; para seguir con el puerto "titular" vamos a ponerlos en el puerto 27017. Es importante que las 3 máquinas puedan acceder al puerto de las otras 2. Adicionalmente, la máquina que vaya a usar este clúster también debe pode acceder al puerto 27017 de las 3 máquinas.&lt;/p&gt;
&lt;h2&gt;Preparación de las máquinas individuales&lt;/h2&gt;
&lt;p&gt;Queremos una versión de &lt;em&gt;mongodb&lt;/em&gt; un poco reciente, así que no vamos a usar los paquetes oficiales de la distribución, y la empresa de &lt;em&gt;mongodb&lt;/em&gt; no ofrece paquete para &lt;em&gt;Debian jessie&lt;/em&gt;. Por ello vamos a montar un esqueleto de ficheros como se describe en &lt;a href="http://www.linuxsysadmin.ml/2015/11/escribiendo-units-en-systemd.html"&gt;un artículo anterior&lt;/a&gt;. Vamos a describir el proceso en la máquina &lt;strong&gt;mongo1&lt;/strong&gt;, para replicarlo a posteriori en las otras 2.&lt;/p&gt;
&lt;p&gt;Creamos la estructura de carpetas que van a contener todo lo relativo a &lt;strong&gt;mongodb&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# mkdir -p /opt/mongodb/&lt;span class="o"&gt;{&lt;/span&gt;bin,conf,data/replica,logs&lt;span class="o"&gt;}&lt;/span&gt;
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Copiamos el binario &lt;strong&gt;mongod&lt;/strong&gt; que encontraremos en el fichero &lt;em&gt;.tar.gz&lt;/em&gt; de la página de descargas de la página web.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# cp mongod /opt/mongodb/bin/
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Creamos un fichero de configuración con el que vamos a levantar el proceso en esta máquina.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# cat /opt/mongodb/conf/replica.conf
systemLog:
    path: /opt/mongodb/logs/replica.log
    logAppend: &lt;span class="nb"&gt;true&lt;/span&gt;
    destination: file

net:
    port: &lt;span class="m"&gt;27017&lt;/span&gt;
    bindIp: &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0

storage:
    dbPath: /opt/mongodb/data/replica
    smallFiles: &lt;span class="nb"&gt;true&lt;/span&gt;

replication:
    replSetName: replica
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Por razones de seguridad vamos a lanzar el servicio con un usuario propio de sistema.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# useradd -s /usr/sbin/nologin -r -M mongo -d /opt/mongodb/
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y para ahorrarnos problemas de permisos, lo hacemos propietario de todo lo referente al servicio:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# chown -R mongo:mongo /opt/mongodb/
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a crearle una &lt;strong&gt;unit&lt;/strong&gt; para que el sistema se encargue de levantar automáticamente el servicio en caso de reinicio de la máquina:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# cat /etc/systemd/system/mongo.service
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;MongoDB

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;User&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mongo
&lt;span class="nv"&gt;LimitFSIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitCPU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;infinity
&lt;span class="nv"&gt;LimitNOFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;64000&lt;/span&gt;
&lt;span class="nv"&gt;LimitNPROC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;64000&lt;/span&gt;
&lt;span class="nv"&gt;ExecStartPre&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/rm -f /opt/mongodb/data/replica/mongod.lock
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/opt/mongodb/bin/mongod -f /opt/mongodb/conf/replica.conf

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finalmente activamos la &lt;strong&gt;unit&lt;/strong&gt; e iniciamos el servicio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@mongo1:~# systemctl &lt;span class="nb"&gt;enable&lt;/span&gt; mongo
Created symlink from /etc/systemd/system/multi-user.target.wants/mongo.service to /etc/systemd/system/mongo.service.
root@mongo1:~# systemctl start mongo
root@mongo1:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ahora toca repetir el proceso en las otras 2 máquinas, exactamente igual.&lt;/p&gt;
&lt;h2&gt;Configuración del clúster&lt;/h2&gt;
&lt;p&gt;Accedemos a una de las máquinas del futuro clúster desde cualquier máquina que pueda hacerlo y que disponga del binario &lt;strong&gt;mongo&lt;/strong&gt; (el mongo shell), que también viene en el archivo &lt;em&gt;.tar.gz&lt;/em&gt; descargado de la página oficial; este shell no es necesario para la aplicación que use el clúster ya que el &lt;strong&gt;driver&lt;/strong&gt; de cada lenguaje suple sus funciones, pero es muy útil tenerlo a mano para tareas de administración y consultas varias.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root@client:~# ./mongo --host &lt;span class="m"&gt;10&lt;/span&gt;.0.0.2
MongoDB shell version: &lt;span class="m"&gt;3&lt;/span&gt;.0.7
connecting to: &lt;span class="m"&gt;10&lt;/span&gt;.0.0.2:27017/test
Welcome to the MongoDB shell.
For interactive help, &lt;span class="nb"&gt;type&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;help&amp;quot;&lt;/span&gt;.
&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hay dos formas de crear la configuración del clúster: pasando el documento de configuración en el método &lt;em&gt;initiate&lt;/em&gt; o añadir los nodos a posteriori con el método &lt;em&gt;add&lt;/em&gt;. Voy a usar este método por ser mas fácil.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt; rs.initiate&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;info2&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;no configuration explicitly specified -- making one&amp;quot;&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;me&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; rs.add&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mongo2:27017&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; rs.add&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mongo3:27017&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vamos a lanzar el método &lt;em&gt;status&lt;/em&gt; hasta que todos los nodos sean primarios o secundarios, momento en el que la &lt;em&gt;replica&lt;/em&gt; va a quedar correctamente montada.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;replica:PRIMARY&amp;gt; rs.status&lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;set&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;replica&amp;quot;&lt;/span&gt;,
...
    &lt;span class="s2"&gt;&amp;quot;members&amp;quot;&lt;/span&gt; : &lt;span class="o"&gt;[&lt;/span&gt;
        &lt;span class="o"&gt;{&lt;/span&gt;
...
            &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;PRIMARY&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;self&amp;quot;&lt;/span&gt; : &lt;span class="nb"&gt;true&lt;/span&gt;
...
        &lt;span class="o"&gt;}&lt;/span&gt;,
        &lt;span class="o"&gt;{&lt;/span&gt;
...
            &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo2:27017&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;SECONDARY&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;syncingTo&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
...
        &lt;span class="o"&gt;}&lt;/span&gt;,
        &lt;span class="o"&gt;{&lt;/span&gt;
...
            &lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo3:27017&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;stateStr&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;SECONDARY&amp;quot;&lt;/span&gt;,
            &lt;span class="s2"&gt;&amp;quot;syncingTo&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;mongo1:27017&amp;quot;&lt;/span&gt;,
...
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;]&lt;/span&gt;,
    &lt;span class="s2"&gt;&amp;quot;ok&amp;quot;&lt;/span&gt; : &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
replica:PRIMARY&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y con esta salida del método &lt;em&gt;status&lt;/em&gt; ya lo tenemos todo funcionando correctamente.&lt;/p&gt;</content><category term="linux"></category><category term="debian"></category><category term="jessie"></category><category term="mongodb"></category><category term="replica set"></category><category term="systemd"></category></entry></feed>